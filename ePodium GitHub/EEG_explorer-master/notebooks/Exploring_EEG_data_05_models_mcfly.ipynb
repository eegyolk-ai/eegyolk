{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out first CNN on EEG data with labels\n",
    "\n",
    "## Pre-processing\n",
    "+ Import data.\n",
    "+ Apply filters (bandpass).\n",
    "+ Detect potential bad channels and replace them by interpolation.\n",
    "+ Detect potential bad epochs and remove them.\n",
    "\n",
    "## Train CNN network\n",
    "+ Define network architecture\n",
    "+ Split data\n",
    "+ Train model\n",
    "\n",
    "### Use mcfly for some first model testing: https://github.com/NLeSC/mcfly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages & links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "#%matplotlib inline\n",
    "\n",
    "from mayavi import mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"C:\\\\OneDrive - Netherlands eScience Center\\\\Project_ePodium\\\\\"\n",
    "PATH_CODE = ROOT + \"EEG_explorer\\\\\"\n",
    "PATH_DATA = ROOT + \"Data\\\\\"\n",
    "PATH_OUTPUT = ROOT + \"Data\\\\processed\\\\\"\n",
    "PATH_METADATA = ROOT + \"Data\\\\metadata\\\\\"\n",
    "file_labels = \"metadata.xlsx\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, PATH_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-processed dataset\n",
    "+ See notebook for preprocessing: Exploring_EEG_data_04_prepare_data_for_ML.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = PATH_OUTPUT + \"EEG_data_30channels_1s_corrected.npy\"\n",
    "signal_collection = np.load(filename)\n",
    "\n",
    "filename = PATH_OUTPUT + \"EEG_data_30channels_1s_corrected_labels.npy\"\n",
    "label_collection = np.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data\n",
    "The entire dataset is split into:\n",
    "+ training data (here: about 70%) which is used to train a model.\n",
    "+ validation data, used to monitor the model progress and avoid overfitting.\n",
    "+ testing data, meant for final check on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(signal_collection, label_collection, test_size=0.15, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 28237\n",
      "Validation set size: 4983\n",
      "Test set size: 5863\n"
     ]
    }
   ],
   "source": [
    "print('Train set size:', X_train.shape[0])\n",
    "print('Validation set size:', X_val.shape[0])\n",
    "print('Test set size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to 1-hot encoding for labels\n",
    "+ We have six categories or classes. Those are best represented by a so called 1-hot encoding. This means nothing else than simply a binary 0-or-1 for every class.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_transform = LabelBinarizer()\n",
    "\n",
    "y_train_binary = label_transform.fit_transform(y_train.astype(int))\n",
    "y_val_binary = label_transform.fit_transform(y_val.astype(int))\n",
    "y_test_binary = label_transform.fit_transform(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_binary[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   6,  13,  26,  66, 132])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show found labels:\n",
    "label_transform.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution accross the 6 label categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.313206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.488437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.038885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.061515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.038141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.059815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     frequency\n",
       "3     0.313206\n",
       "6     0.488437\n",
       "13    0.038885\n",
       "26    0.061515\n",
       "66    0.038141\n",
       "132   0.059815"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(label_transform.classes_)\n",
    "frequencies = y_train_binary.mean(axis=0)\n",
    "frequencies_df = pd.DataFrame(frequencies, index=labels, columns=['frequency'])\n",
    "frequencies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "We have more data on group 2 than on group 1. And far more data for stimuli 3 than for stimuli 13 and 66 (not surprising). \n",
    "\n",
    "--> post on balancing datasets: https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758\n",
    "\n",
    "### Needs some thinking on how to balance the data set !\n",
    "e.g. by frequency dependend selection rule, or by defining a suitied special loss function...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import mcfly\n",
    "\n",
    "num_classes = y_train_binary.shape[1]\n",
    "models = mcfly.modelgen.generate_models(X_train.shape,\n",
    "                                  number_of_classes=num_classes,\n",
    "                                  number_of_models = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 0\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0001353096649122913, 'regularization_rate': 0.08347912108149602, 'filters': array([ 60,  70, 100,  45,  39,  41,  27,  25]), 'fc_hidden_nodes': 1894}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 30, 60)            90240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 60)            240       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 60)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 30, 70)            12670     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 70)            280       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 70)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 30, 100)           21100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 100)           400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 30, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 30, 45)            13545     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 45)            180       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 45)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 30, 39)            5304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 39)            156       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 39)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 30, 41)            4838      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 41)            164       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 30, 41)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 30, 27)            3348      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 27)            108       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 27)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 30, 25)            2050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 25)            100       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 25)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 750)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1894)              1422394   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1894)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 11370     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,590,515\n",
      "Trainable params: 1,588,687\n",
      "Non-trainable params: 1,828\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 1\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.06640809560572995, 'regularization_rate': 0.00014947901657453097, 'filters': [25, 41, 78, 78, 65, 17, 62, 46], 'lstm_dims': [23]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_11 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 501, 25)       100       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 501, 25)       100       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 30, 501, 25)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 501, 41)       3116      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 501, 41)       164       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 30, 501, 41)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 501, 78)       9672      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 501, 78)       312       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 30, 501, 78)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 501, 78)       18330     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 501, 78)       312       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 501, 78)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 501, 65)       15275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 501, 65)       260       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 30, 501, 65)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 501, 17)       3332      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 501, 17)       68        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 30, 501, 17)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 501, 62)       3224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 30, 501, 62)       248       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 30, 501, 62)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 501, 46)       8602      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 501, 46)       184       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 30, 501, 46)       0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 30, 23046)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 23)            2122440   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 23)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 6)             144       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 2,187,887\n",
      "Trainable params: 2,186,061\n",
      "Non-trainable params: 1,826\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 2\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0009021310490093333, 'regularization_rate': 0.008064861601900458, 'filters': [52, 50, 27, 81], 'lstm_dims': [76]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_20 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 501, 52)       208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 30, 501, 52)       208       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 30, 501, 52)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 501, 50)       7850      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 30, 501, 50)       200       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 30, 501, 50)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 501, 27)       4077      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 30, 501, 27)       108       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 30, 501, 27)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 501, 81)       6642      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 30, 501, 81)       324       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 30, 501, 81)       0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 30, 40581)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 76)            12360032  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 76)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 6)             462       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 12,382,115\n",
      "Trainable params: 12,380,693\n",
      "Non-trainable params: 1,422\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 3\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0011361429425767724, 'regularization_rate': 0.000937399713706023, 'filters': [68, 50, 30, 52, 84, 92], 'lstm_dims': [18, 62, 42]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_25 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 501, 68)       272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 30, 501, 68)       272       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 30, 501, 68)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 501, 50)       10250     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 501, 50)       200       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 30, 501, 50)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 501, 30)       4530      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 501, 30)       120       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 30, 501, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 501, 52)       4732      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 30, 501, 52)       208       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 30, 501, 52)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 501, 84)       13188     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 30, 501, 84)       336       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 30, 501, 84)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 30, 501, 92)       23276     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 30, 501, 92)       368       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 30, 501, 92)       0         \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 30, 46092)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30, 18)            3319992   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 62)            20088     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 42)            17640     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 42)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 6)             258       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 3,417,734\n",
      "Trainable params: 3,415,980\n",
      "Non-trainable params: 1,754\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 4\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.00036451786911403326, 'regularization_rate': 0.014949860185056889, 'filters': array([15, 57]), 'fc_hidden_nodes': 694}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_32 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 30, 15)            22560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 30, 15)            60        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 30, 15)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 30, 57)            2622      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 30, 57)            228       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 30, 57)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1710)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 694)               1187434   \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 694)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 4170      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 1,219,102\n",
      "Trainable params: 1,217,944\n",
      "Non-trainable params: 1,158\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 5\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.061905645467897834, 'regularization_rate': 0.00014730457266302929, 'filters': [78, 42, 36, 69, 46, 29, 68, 66, 47, 95], 'lstm_dims': [73, 80]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_36 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 501, 78)       312       \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 30, 501, 78)       312       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 30, 501, 78)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 30, 501, 42)       9870      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 30, 501, 42)       168       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 30, 501, 42)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 501, 36)       4572      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 30, 501, 36)       144       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 30, 501, 36)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 30, 501, 69)       7521      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 30, 501, 69)       276       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 30, 501, 69)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 30, 501, 46)       9568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 30, 501, 46)       184       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 30, 501, 46)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 30, 501, 29)       4031      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 30, 501, 29)       116       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 30, 501, 29)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 501, 68)       5984      \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 30, 501, 68)       272       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 30, 501, 68)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 501, 66)       13530     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 30, 501, 66)       264       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 30, 501, 66)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 30, 501, 47)       9353      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 30, 501, 47)       188       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 30, 501, 47)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 30, 501, 95)       13490     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 30, 501, 95)       380       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 30, 501, 95)       0         \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 30, 47595)         0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 73)            13919348  \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30, 80)            49280     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 80)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 6)             486       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 14,051,653\n",
      "Trainable params: 14,049,499\n",
      "Non-trainable params: 2,154\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 6\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.009962109969681159, 'regularization_rate': 0.01697670453031972, 'filters': [99, 68, 30, 66, 27, 32, 36], 'lstm_dims': [69, 19, 40]}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_47 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 30, 501, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 30, 501, 99)       396       \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 30, 501, 99)       396       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 30, 501, 99)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 30, 501, 68)       20264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 30, 501, 68)       272       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 30, 501, 68)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 30, 501, 30)       6150      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 30, 501, 30)       120       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 30, 501, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 30, 501, 66)       6006      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 30, 501, 66)       264       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 30, 501, 66)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 30, 501, 27)       5373      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 30, 501, 27)       108       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 30, 501, 27)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 30, 501, 32)       2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 30, 501, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 30, 501, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 30, 501, 36)       3492      \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 30, 501, 36)       144       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 30, 501, 36)       0         \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 30, 18036)         0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 30, 69)            4997256   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 30, 19)            6764      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 30, 40)            9600      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 40)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 6)             246       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 30, 6)             0         \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 5,061,607\n",
      "Trainable params: 5,059,889\n",
      "Non-trainable params: 1,718\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 7\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.013922563533153916, 'regularization_rate': 0.038549462963669526, 'filters': array([66, 79, 37, 20, 80, 86, 56, 69]), 'fc_hidden_nodes': 1159}\n",
      " \n",
      "Model description:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_55 (Batc (None, 30, 501)           2004      \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 30, 66)            99264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 30, 66)            264       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 30, 66)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 30, 79)            15721     \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 30, 79)            316       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 30, 79)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 30, 37)            8806      \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 30, 37)            148       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 30, 37)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 30, 20)            2240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 30, 20)            80        \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 30, 20)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 30, 80)            4880      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 30, 80)            320       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 30, 80)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 30, 86)            20726     \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 30, 86)            344       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 30, 86)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 30, 56)            14504     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 30, 56)            224       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 30, 56)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 30, 69)            11661     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 30, 69)            276       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 30, 69)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2070)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1159)              2400289   \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1159)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 6960      \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 2,589,051\n",
      "Trainable params: 2,587,051\n",
      "Non-trainable params: 2,000\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n"
     ]
    }
   ],
   "source": [
    "models_to_print = range(len(models))\n",
    "for i, item in enumerate(models):\n",
    "    if i in models_to_print:\n",
    "        model, params, model_types = item\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Model \" + str(i))\n",
    "        print(\" \")\n",
    "        print(\"Hyperparameters:\")\n",
    "        print(params)\n",
    "        print(\" \")\n",
    "        print(\"Model description:\")\n",
    "        model.summary()\n",
    "        print(\" \")\n",
    "        print(\"Model type:\")\n",
    "        print(model_types)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 CNN\n",
      "WARNING:tensorflow:From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2000 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 155.9839 - acc: 0.3270 - val_loss: 121.4596 - val_acc: 0.4164\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 96.8957 - acc: 0.3565 - val_loss: 76.0037 - val_acc: 0.3117\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 61.4584 - acc: 0.4140 - val_loss: 49.5331 - val_acc: 0.2806\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 41.1918 - acc: 0.4330 - val_loss: 34.4188 - val_acc: 0.3761\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 29.5706 - acc: 0.4465 - val_loss: 25.6414 - val_acc: 0.3662\n",
      "Training model 1 DeepConvLSTM\n",
      "WARNING:tensorflow:From C:\\Users\\FlorianHuber\\Anaconda3\\envs\\mne\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 2000 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 1818s 909ms/step - loss: 2.0418 - acc: 0.4365 - val_loss: 1.8908 - val_acc: 0.4808\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 1724s 862ms/step - loss: 1.6588 - acc: 0.4480 - val_loss: 1.4471 - val_acc: 0.4808\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 1730s 865ms/step - loss: 1.4255 - acc: 0.4590 - val_loss: 1.4028 - val_acc: 0.3141\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 1728s 864ms/step - loss: 1.3919 - acc: 0.4560 - val_loss: 1.3807 - val_acc: 0.3141\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 1709s 855ms/step - loss: 1.3769 - acc: 0.4420 - val_loss: 1.3453 - val_acc: 0.4808\n",
      "Training model 2 DeepConvLSTM\n",
      "Train on 2000 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 880s 440ms/step - loss: 2.8415 - acc: 0.4215 - val_loss: 2.2233 - val_acc: 0.4808\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 879s 439ms/step - loss: 2.0704 - acc: 0.4380 - val_loss: 1.7704 - val_acc: 0.4808\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 880s 440ms/step - loss: 1.7473 - acc: 0.4350 - val_loss: 1.5915 - val_acc: 0.4808\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 897s 448ms/step - loss: 1.5994 - acc: 0.4370 - val_loss: 1.5021 - val_acc: 0.4808\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 870s 435ms/step - loss: 1.5202 - acc: 0.4575 - val_loss: 1.4534 - val_acc: 0.4808\n",
      "Training model 3 DeepConvLSTM\n",
      "Train on 2000 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 1509s 755ms/step - loss: 1.6175 - acc: 0.4495 - val_loss: 1.4664 - val_acc: 0.4808\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 1502s 751ms/step - loss: 1.4430 - acc: 0.4650 - val_loss: 1.3863 - val_acc: 0.4808\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 1499s 750ms/step - loss: 1.3804 - acc: 0.4750 - val_loss: 1.3597 - val_acc: 0.4808\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 1522s 761ms/step - loss: 1.3776 - acc: 0.4715 - val_loss: 1.3489 - val_acc: 0.4808\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 1490s 745ms/step - loss: 1.3538 - acc: 0.4870 - val_loss: 1.3474 - val_acc: 0.4808\n",
      "Training model 4 CNN\n",
      "Train on 2000 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 10.2028 - acc: 0.2975 - val_loss: 7.6914 - val_acc: 0.2924\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 5.2417 - acc: 0.3770 - val_loss: 4.7601 - val_acc: 0.2187\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 3.2857 - acc: 0.4095 - val_loss: 3.8006 - val_acc: 0.1162\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 2.5348 - acc: 0.4555 - val_loss: 3.0064 - val_acc: 0.0779\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 8s 4ms/step - loss: 2.2165 - acc: 0.4705 - val_loss: 4.1289 - val_acc: 0.3046\n",
      "Training model 5 DeepConvLSTM\n",
      "Train on 2000 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 2298s 1s/step - loss: 2.0970 - acc: 0.4135 - val_loss: 1.6050 - val_acc: 0.3141\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 2278s 1s/step - loss: 1.5566 - acc: 0.4205 - val_loss: 1.4750 - val_acc: 0.4808\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 2274s 1s/step - loss: 1.5503 - acc: 0.4195 - val_loss: 1.4500 - val_acc: 0.4808\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 2305s 1s/step - loss: 1.5216 - acc: 0.4190 - val_loss: 1.3898 - val_acc: 0.4808\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 2253s 1s/step - loss: 1.5524 - acc: 0.4205 - val_loss: 1.4109 - val_acc: 0.4808\n",
      "Training model 6 DeepConvLSTM\n",
      "Train on 2000 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 1401s 700ms/step - loss: 2.2456 - acc: 0.4560 - val_loss: 1.3791 - val_acc: 0.4808\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 1395s 697ms/step - loss: 1.3544 - acc: 0.4770 - val_loss: 1.3428 - val_acc: 0.4808\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 1378s 689ms/step - loss: 1.3469 - acc: 0.4815 - val_loss: 1.3395 - val_acc: 0.4808\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 1313s 656ms/step - loss: 1.3369 - acc: 0.4665 - val_loss: 1.3326 - val_acc: 0.4808\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 1157s 578ms/step - loss: 1.3330 - acc: 0.4825 - val_loss: 1.3386 - val_acc: 0.4808\n",
      "Training model 7 CNN\n",
      "Train on 2000 samples, validate on 4983 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 12.1271 - acc: 0.4045 - val_loss: 2.1409 - val_acc: 0.4808\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.8372 - acc: 0.4825 - val_loss: 1.6062 - val_acc: 0.4808\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.7048 - acc: 0.4830 - val_loss: 6.6644 - val_acc: 0.0594\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.7043 - acc: 0.4830 - val_loss: 2.0262 - val_acc: 0.3141\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9760 - acc: 0.4815 - val_loss: 1.7287 - val_acc: 0.4808\n",
      "Details of the training process were stored in  C:\\OneDrive - Netherlands eScience Center\\Project_ePodium\\Data\\processed\\modelcomparison.json\n"
     ]
    }
   ],
   "source": [
    "outputfile = os.path.join(PATH_OUTPUT, 'modelcomparison.json')\n",
    "histories, val_accuracies, val_losses = mcfly.find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                           X_val, y_val_binary,\n",
    "                                                                           models, nr_epochs=5,\n",
    "                                                                           subset_size=2000,\n",
    "                                                                           verbose=True,\n",
    "                                                                           outputfile=outputfile)\n",
    "print('Details of the training process were stored in ',outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.0001353096649122913, 'regu...</td>\n",
       "      <td>0.4465</td>\n",
       "      <td>29.570633</td>\n",
       "      <td>0.366245</td>\n",
       "      <td>25.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.06640809560572995, 'regula...</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>1.376897</td>\n",
       "      <td>0.480835</td>\n",
       "      <td>1.345288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.0009021310490093333, 'regu...</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>1.520157</td>\n",
       "      <td>0.480835</td>\n",
       "      <td>1.453386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.0011361429425767724, 'regu...</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>1.353813</td>\n",
       "      <td>0.480835</td>\n",
       "      <td>1.347448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.00036451786911403326, 'reg...</td>\n",
       "      <td>0.4705</td>\n",
       "      <td>2.216500</td>\n",
       "      <td>0.304636</td>\n",
       "      <td>4.128861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.061905645467897834, 'regul...</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>1.552352</td>\n",
       "      <td>0.480835</td>\n",
       "      <td>1.410927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 0.009962109969681159, 'regul...</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>1.332951</td>\n",
       "      <td>0.480835</td>\n",
       "      <td>1.338628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 0.013922563533153916, 'regul...</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>1.975973</td>\n",
       "      <td>0.480835</td>\n",
       "      <td>1.728680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  train_acc  train_loss  \\\n",
       "0  {'learning_rate': 0.0001353096649122913, 'regu...     0.4465   29.570633   \n",
       "1  {'learning_rate': 0.06640809560572995, 'regula...     0.4420    1.376897   \n",
       "2  {'learning_rate': 0.0009021310490093333, 'regu...     0.4575    1.520157   \n",
       "3  {'learning_rate': 0.0011361429425767724, 'regu...     0.4870    1.353813   \n",
       "4  {'learning_rate': 0.00036451786911403326, 'reg...     0.4705    2.216500   \n",
       "5  {'learning_rate': 0.061905645467897834, 'regul...     0.4205    1.552352   \n",
       "6  {'learning_rate': 0.009962109969681159, 'regul...     0.4825    1.332951   \n",
       "7  {'learning_rate': 0.013922563533153916, 'regul...     0.4815    1.975973   \n",
       "\n",
       "    val_acc   val_loss  \n",
       "0  0.366245  25.641414  \n",
       "1  0.480835   1.345288  \n",
       "2  0.480835   1.453386  \n",
       "3  0.480835   1.347448  \n",
       "4  0.304636   4.128861  \n",
       "5  0.480835   1.410927  \n",
       "6  0.480835   1.338628  \n",
       "7  0.480835   1.728680  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcomparisons = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                       'train_acc': [history.history['acc'][-1] for history in histories],\n",
    "                       'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                       'val_acc': [history.history['val_acc'][-1] for history in histories],\n",
    "                       'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                       })\n",
    "modelcomparisons.to_csv(os.path.join(PATH_OUTPUT, 'modelcomparisons.csv'))\n",
    "\n",
    "modelcomparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem occuring here:\n",
    "+ Input values are TOO low --> add normalization\n",
    "+ Most labels are in \"6\" (group 2, stimuli 3). This are about 48.8%. So here the networks mostly just learned that it's OK to just always output \"6\" as a prediction..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
