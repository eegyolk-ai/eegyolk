* Installing
  This has only been tested on Linux so far.

  #+begin_src sh
    python -m venv .venv
    . .venv/bin/activate
    ./setup.py install
  #+end_src

* Configuring
  In order to preprocess and to train the models the code needs to be
  able to locate the raw data and the metadata, and for the training
  it also needs the preprocessed data to be available.

  There are several ways to specify the location of the following
  directories:

  + root :: Special directory.  The rest of the directory layout can
    be derived from its location.
  + data :: The location of raw CNT data files.  This is the directory
    containing =11mnd mmn= and similar files.
  + metadata :: The location of metadata files.  This is the directory
    that contains =ages= directory, which, in turn, contains files
    like =ages_11mnths.txt=.
  + preprocessed :: The directory that will be used by preprocessing
    code to output CSVs and h5 files.  This directory will be used
    by the model training code to read the training data.
  + models :: The directory to output trained models to.

  You can store this information persistently in several locations.

  1. In the same directory where you run the script (or the notebook).
     Eg. =./config.json=.
  2. In home directory, eg. =~/.epodium/config.json=.
  3. In global directory, eg =/etc/epodium/config.json=.

  This file can have this or similar contents:

  #+begin_src json
    {
        "root": "/mnt/data",
        "metadata": "/mnt/data/meta",
        "preprocessed": "/mnt/data/processed"
    }
  #+end_src

  The file is read as follows: if the files specifies =root=
  directory, then the missing entires are assumed to be relative to
  the root.  You don't need to specify the root entry, if you specify
  all other entires.

* Command-Line Interface
  You can preprocess and tain the models using command-line interface.

  Below are some examples of how to do that:

  This will pre-process the first ten CNT files in the
  =/mnt/data/original-cnts= directory.

  #+begin_src sh
    python -m epodium acquire \
           --input /mnt/data/original-cnts \
           --metadata /mnt/data/metadata \
           --output /mnt/data/preprocessed \
           --limit 10
  #+end_src

  This will train a model using dummy algorithm.  In case of dummy
  algorithm both =best_fit= and =fit= do the same thing.

  #+begin_src sh
    python -m epodium ml \
           --input /mnt/data/preprocessed \
           --output /mnt/data/trained_models \
           --size 100 \
           dummy best_fit
  #+end_src

  Similarly, for neural networks training and assessment:

  #+begin_src sh
    python -m epodium nn \
           --input /mnt/data/preprocessed \
           --output /mnt/data/trained_models \
           --epochs 100 \
           train_model 1
  #+end_src

  It's possible to load configuration (used for directory layout) from
  alternative file:

  #+begin_src sh
    python -m epodium --config /another/config.json ml \
           --input /mnt/data/preprocessed \
           --output /mnt/data/trained_models \
           --size 100 \
           dummy best_fit
  #+end_src

  All long options have short aliases.
