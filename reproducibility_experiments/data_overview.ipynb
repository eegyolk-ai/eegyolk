{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a2d8c6",
   "metadata": {},
   "source": [
    "# Explore 'old' dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d1412c",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21cbd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mne\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "# %matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4557858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5ec6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from config_for_repro_prepro  import PATH_RAW_DATA, PATH_METADATA, PATH_DATA_PROCESSED_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a65c5",
   "metadata": {},
   "source": [
    "### Now let's get all our old cnt files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d87630",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_names = {11: '11mnd mmn',\n",
    "             17: '17mnd mmn',\n",
    "             23: '23mnd mmn',\n",
    "             29: '29mnd mmn',\n",
    "             35: '35mnd mmn',\n",
    "             41: '41mnd mmn',\n",
    "             47: '47mnd mmn'}\n",
    "    \n",
    "df_list = []\n",
    "\n",
    "for age_group, directory in dir_names.items(): # Go into every age group folder        \n",
    "    dir_path = os.path.join('C:/Projects/EEG_explorer/Data', directory)\n",
    "    file_names = os.listdir(dir_path)\n",
    "    \n",
    "    cnt_paths = [os.path.join(dir_path, file_name) for file_name in fnmatch.filter(file_names, \"*.cnt\")]\n",
    "    # list comprehension - creates a list of all cnt file names with thisdirectory\n",
    "    cnt_files = [os.path.basename(x)[:-4] for x in cnt_paths]\n",
    "    # list comprehension\n",
    "    codes = [int(re.search(r'\\d+', x).group()) for x in cnt_files]\n",
    "    # takes number out of string (\\d+ takes out digits)\n",
    "    df = pd.DataFrame(list(zip(codes, cnt_paths, cnt_files)), columns=['code', 'cnt_path','cnt_file']) \n",
    "    \n",
    "    df['age_group'] = age_group\n",
    "    df_list.append(df)\n",
    "\n",
    "cnt_files = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a4234c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2149 .cnt files\n"
     ]
    }
   ],
   "source": [
    "print( \"We have\", len(cnt_files), \".cnt files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b157b",
   "metadata": {},
   "source": [
    "### Now let's get all our old edf files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e79b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_names = {11: '11mnd mmn',\n",
    "             17: '17mnd mmn',\n",
    "             23: '23mnd mmn',\n",
    "             29: '29mnd mmn',\n",
    "             35: '35mnd mmn',\n",
    "             41: '41mnd mmn',\n",
    "             47: '47mnd mmn'}\n",
    "    \n",
    "edf_df_list = []\n",
    "\n",
    "for age_group, directory in dir_names.items(): # Go into every age group folder        \n",
    "    dir_path = os.path.join('C:/Projects/EEG_explorer/Data', directory)\n",
    "    file_names = os.listdir(dir_path)\n",
    "    \n",
    "    edf_paths = [os.path.join(dir_path, file_name) for file_name in fnmatch.filter(file_names, \"*.edf\")]\n",
    "    # list comprehension - creates a list of all cnt file names with thisdirectory\n",
    "    edf_files = [os.path.basename(x)[:-4] for x in edf_paths]\n",
    "    # list comprehension\n",
    "    #codes = [int(re.search(r'\\d+', x).group()) for x in cnt_files]\n",
    "    # takes number out of string (\\d+ takes out digits)\n",
    "    df_edf = pd.DataFrame(list(zip(edf_paths, edf_files)), columns=['edf_path','edf_file']) \n",
    "    \n",
    "    \n",
    "    edf_df_list.append(df_edf)\n",
    "\n",
    "edf_files = pd.concat(edf_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0395927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 157 .edf files\n"
     ]
    }
   ],
   "source": [
    "print( \"We have\", len(edf_files), \".edf files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c80432",
   "metadata": {},
   "source": [
    "### We can now clean out the \"cleaned\", but not be sure about certain other changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f3ecdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No .cnt files have cleaned in the name\n"
     ]
    }
   ],
   "source": [
    "# make set of all files,,\n",
    "# make sure of probably cleaned files\n",
    "\n",
    "# set of all files\n",
    "files_list = []\n",
    "cleaned_files_list = []\n",
    "for i in cnt_files['cnt_path']:\n",
    "    files_list.append(i)\n",
    "    if 'cleaned' in i:\n",
    "        print(i)\n",
    "if len(cleaned_files_list) == 0:\n",
    "    print(\"No .cnt files have cleaned in the name\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d64ed841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 files appear to have been cleaned or have it in the name, out of 157\n"
     ]
    }
   ],
   "source": [
    "edf_files_list = []\n",
    "edf_cleaned_files_list = []\n",
    "for i in edf_files['edf_path']:\n",
    "    edf_files_list.append(i)\n",
    "    if 'cleaned' in i:\n",
    "        edf_cleaned_files_list.append(i)\n",
    "if len(edf_cleaned_files_list) == 0:\n",
    "    print(\"No .edf files have cleaned in the name\")\n",
    "else:\n",
    "    print(len(edf_cleaned_files_list), \"files appear to have been cleaned or have it in the name, out of\", len(edf_files_list) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa6e0b",
   "metadata": {},
   "source": [
    "### So we can see the edf files are cleaned, but were they just preprocessed, or what process generated them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39e778",
   "metadata": {},
   "source": [
    "## Let's also examine the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55aef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
