{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8907b38d",
   "metadata": {},
   "source": [
    "## ML reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535f28c-2063-4f95-84ab-44c2455bad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215f61b-3964-44a4-bf20-4fbbf84e18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy seaborn matplotlib pandas joblib ipdb scikit-learn==0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70ff67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, fnmatch, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "PATH_MODELS = './models'\n",
    "PATH_DATA_PROCESSED_ML =  './data_prepro_ml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18f4ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed_data_008_11_jc_mmn_36_slp_mmn25_slp_mmn47_wk_2.csv',\n",
       " 'processed_data_006_29_mc_mmn36_1_wk.csv',\n",
       " 'processed_data_006_23_mc_mmn25_slp.csv',\n",
       " 'extracted_features_004_29_mc_mmn25_2_wk.h5',\n",
       " 'extracted_features_004_23_mc_mmn36_wk.h5',\n",
       " 'processed_data_007_17_jc_mmn2.csv',\n",
       " 'processed_data_001_23_jc_mmn36_wk_mmn25_wk.csv',\n",
       " 'processed_data_005_35_jc_mmn36_wk.csv',\n",
       " 'extracted_features_005_29_jc_mmn25.h5',\n",
       " 'extracted_features_1_nakijken_mmn3-6.h5',\n",
       " 'processed_data_007_23_jc_mmn36_wk.csv',\n",
       " 'processed_data_008_11_jc_mmn_3.csv',\n",
       " 'processed_data_001_29_jc_mmn.csv',\n",
       " 'extracted_features_008_11_jc_mmn_3.h5',\n",
       " 'processed_data_002_23_jc_mmn36_wk_mmn25.csv',\n",
       " 'processed_data_009_29_jc_mmn36_wk.csv',\n",
       " 'extracted_features_005_29_jc_mmn36_wk.h5',\n",
       " 'processed_data_009_23_jc_mmn25_wk.csv',\n",
       " 'extracted_features_007_23_jc_mmn25_wk.h5',\n",
       " 'processed_data_009_17_jc_mmn36_wk_mmn25_wk.csv',\n",
       " 'processed_data_009_23_jc_mmn36_wk.csv',\n",
       " 'extracted_features_002_29_jc_mmn25_wk.h5',\n",
       " 'processed_data_1_nakijken_mmn3-6.npy',\n",
       " 'extracted_features_009_23_jc_mmn25_wk.h5',\n",
       " 'extracted_features_009_17_jc_mmn36_wk_mmn25_wk.h5',\n",
       " 'extracted_features_006_29_mc_mmn36_1_wk.h5',\n",
       " 'extracted_features_009_23_jc_mmn47_wk.h5',\n",
       " 'processed_data_006_29_mc_mmn36_2_wk.csv',\n",
       " 'extracted_features_009_35_jc_mmn36_wk.h5',\n",
       " 'extracted_features_002_29_jc_mmn36_wk.h5',\n",
       " 'processed_data_005_29_jc_mmn36_wk.csv',\n",
       " 'extracted_features_001_23_jc_mmn36_wk_mmn25_wk.h5',\n",
       " 'extracted_features_005_11_jc_mmn2.h5',\n",
       " 'extracted_features_005_17_jc_mmn36_slp_mmn25_slp_mmn47_mixed.h5',\n",
       " 'processed_data_009_23_jc_mmn47_wk.csv',\n",
       " 'processed_data_008_35_jc_mmn36_wk.csv',\n",
       " 'processed_data_009_29_jc_mmn36_slp.csv',\n",
       " 'processed_data_1_nakijken_mmn3-6.csv',\n",
       " 'extracted_features_007_11_jc_mmn36_wk_mmn25_wk.h5',\n",
       " 'extracted_features_008_17_jc_mmn.h5',\n",
       " 'processed_data_004_29_mc_mmn36_wk.csv',\n",
       " 'processed_data_007_11_jc_mmn2_36_wk.csv',\n",
       " 'extracted_features_002_35_jc_mmn36_wk.h5',\n",
       " 'extracted_features_004_29_mc_mmn36_wk.h5',\n",
       " 'extracted_features_008_11_jc_mmn.h5',\n",
       " 'processed_data_005_29_jc_mmn25.csv',\n",
       " 'extracted_features_007_17_jc_mmn2.h5',\n",
       " 'processed_data_008_17_jc_mmn2.csv',\n",
       " 'processed_data_004_29_mc_mmn25_2_wk.csv',\n",
       " 'extracted_features_005_29_jc_mmn36_2.h5',\n",
       " 'processed_data_004_29_mc_mmn47_wk.csv',\n",
       " 'extracted_features_009_23_jc_mmn36_wk.h5',\n",
       " 'extracted_features_006_23_mc_mmn36_slp.h5',\n",
       " 'extracted_features_008_35_jc_mmn36_wk.h5',\n",
       " 'processed_data_006_29_mc_mmn36_3_wk.csv',\n",
       " 'extracted_features_006_29_mc_mmn36_3_wk.h5',\n",
       " 'extracted_features_001_29_jc_mmn.h5',\n",
       " 'extracted_features_009_29_jc_mmn25_slp.h5',\n",
       " 'extracted_features_009_29_jc_mmn36_slp.h5',\n",
       " 'processed_data_008_11_jc_mmn.csv',\n",
       " 'processed_data_009_35_jc_mmn36_wk.csv',\n",
       " 'processed_data_004_23_mc_mmn36_wk.csv',\n",
       " 'extracted_features_009_29_jc_mmn36_wk.h5',\n",
       " 'processed_data_009_29_jc_mmn25_slp.csv',\n",
       " 'extracted_features_006_29_mc_mmn36_2_wk.h5',\n",
       " 'processed_data_006_23_mc_mmn36_slp.csv',\n",
       " 'processed_data_005_11_jc_mmn2.csv',\n",
       " 'extracted_features_008_11_jc_mmn_36_slp_mmn25_slp_mmn47_wk_2.h5',\n",
       " '.ipynb_checkpoints',\n",
       " 'extracted_features_006_23_mc_mmn25_slp.h5',\n",
       " 'extracted_features_001_35_jc_mmn36_wk.h5',\n",
       " 'processed_data_003_35_jc_mmn36_wk.csv',\n",
       " 'processed_data_002_29_jc_mmn25_wk.csv',\n",
       " 'processed_data_002_29_jc_mmn36_wk.csv',\n",
       " 'extracted_features_005_35_jc_mmn36_wk.h5',\n",
       " 'extracted_features_007_23_jc_mmn36_wk.h5',\n",
       " 'processed_data_005_17_jc_mmn36_slp_mmn25_slp_mmn47_mixed.csv',\n",
       " 'extracted_features_003_35_jc_mmn36_wk.h5',\n",
       " 'processed_data_007_11_jc_mmn36_wk_mmn25_wk.csv',\n",
       " 'extracted_features_004_29_mc_mmn47_wk.h5',\n",
       " 'extracted_features_008_17_jc_mmn2.h5',\n",
       " 'processed_data_007_23_jc_mmn25_wk.csv',\n",
       " 'processed_data_001_35_jc_mmn36_wk.csv',\n",
       " 'extracted_features_007_11_jc_mmn2_36_wk.h5',\n",
       " 'processed_data_008_17_jc_mmn.csv',\n",
       " 'processed_data_005_29_jc_mmn36_2.csv',\n",
       " 'processed_data_002_35_jc_mmn36_wk.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_names = os.listdir(PATH_DATA_PROCESSED_ML)\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0198a37-d474-42b7-8fb4-609aa13e46e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /home/cmoore/.local/lib/python3.8/site-packages (3.7.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tables) (21.3)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /home/cmoore/.local/lib/python3.8/site-packages (from tables) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/cmoore/.local/lib/python3.8/site-packages (from tables) (1.22.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->tables) (2.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd9507c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 582 ms, sys: 120 ms, total: 702 ms\n",
      "Wall time: 708 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Get all the files in the output folder\n",
    "file_names = os.listdir(PATH_DATA_PROCESSED_ML)\n",
    "\n",
    "# Step 2: Get the full paths of the files (without extensions)\n",
    "files = [os.path.splitext(os.path.join(PATH_DATA_PROCESSED_ML, file_name))[0] for file_name in fnmatch.filter(file_names, \"*.h5\")]\n",
    "\n",
    "# Step 3: Load the features\n",
    "frames = []\n",
    "\n",
    "for idx, feature_file in enumerate(files):\n",
    "    df_features = pd.read_hdf(feature_file + \".h5\")\n",
    "    df_metadata = pd.read_csv(feature_file.replace(\"extracted_features_\", \"processed_data_\") + \".csv\")\n",
    "    \n",
    "    # Step 4: Assign labels\n",
    "    df_features['label'] = df_metadata['age_months'][0]\n",
    "    \n",
    "    # Step 5: Assign subject code\n",
    "    df_features['code'] = df_metadata['code'][0]\n",
    "    frames.append(df_features)\n",
    "\n",
    "df = pd.concat(frames) \n",
    "\n",
    "# Step 6: List all the unique subject IDs\n",
    "subject_ids = sorted(list(set(df[\"code\"].tolist())))\n",
    "\n",
    "IDs_train, IDs_temp = train_test_split(subject_ids, test_size=0.3, random_state=42)\n",
    "IDs_test, IDs_val = train_test_split(IDs_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 7: Split the DataFrames into train, validation and test\n",
    "df_train = df[df['code'].isin(IDs_train)]\n",
    "df_val = df[df['code'].isin(IDs_val)]\n",
    "df_test = df[df['code'].isin(IDs_test)]\n",
    "\n",
    "feature_names = df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923cd24d-8463-40b7-8a46-79871f819ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/val/test proportions: 0.5981548335338949/0.2833935018050541/0.11845166466105095\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train/val/test proportions: {len(df_train)/len(df)}/{len(df_val)/len(df)}/{len(df_test)/len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed82a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:981: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:992: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n",
      "/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:1012: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n",
      "/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:981: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:992: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 338 ms, sys: 94.6 ms, total: 432 ms\n",
      "Wall time: 440 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py:1012: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train = df_train.drop(['label', 'code'], axis=1).reset_index(drop=True)\n",
    "y_train = df_train['label'].reset_index(drop=True)\n",
    "codes_train = df_train['code'].reset_index(drop=True)\n",
    "\n",
    "X_val = df_val.drop(['label', 'code'], axis=1).reset_index(drop=True)\n",
    "y_val = df_val['label'].reset_index(drop=True)\n",
    "codes_val = df_val['code'].reset_index(drop=True)\n",
    "\n",
    "X_test = df_test.drop(['label', 'code'], axis=1).reset_index(drop=True)\n",
    "y_test = df_test['label'].reset_index(drop=True)\n",
    "codes_test = df_test['code'].reset_index(drop=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_val = scaler.fit_transform(X_val)\n",
    "# X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# MARK: reducing from 64 bit float to 32 bit float, to reduce memory usage\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train)).astype('float32')\n",
    "X_val = pd.DataFrame(scaler.fit_transform(X_val)).astype('float32')\n",
    "X_test = pd.DataFrame(scaler.fit_transform(X_test)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5552ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = pd.concat([X_train, X_val])\n",
    "y_train_val = pd.concat([y_train, y_val])\n",
    "codes_train_val = pd.concat([codes_train, codes_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fb35e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(file_names, files, df, frames, df_features, df_metadata, df_train, df_test, df_val, IDs_train, IDs_val, IDs_test, IDs_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f09bf55-e4f9-4d3f-8218-91d997231aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053683328\n",
      "0.000119424\n",
      "0.000119424\n",
      "0.025434128\n",
      "5.6648e-05\n",
      "5.6648e-05\n",
      "0.079293016\n",
      "0.000351632\n",
      "0.000351632\n",
      "0.010630928\n",
      "2.3752e-05\n",
      "2.3752e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.memory_usage(deep=True).sum()/1000000000}\")\n",
    "print(f\"{y_train.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{codes_train.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{X_val.memory_usage(deep=True).sum()/1000000000}\")\n",
    "print(f\"{y_val.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{codes_val.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{X_train_val.memory_usage(deep=True).sum()/1000000000}\")\n",
    "print(f\"{y_train_val.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{codes_train_val.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{X_test.memory_usage(deep=True).sum()/1000000000}\")\n",
    "print(f\"{y_test.memory_usage(deep=True)/1000000000}\")\n",
    "print(f\"{codes_test.memory_usage(deep=True)/1000000000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a56e723-c53d-403d-a4bd-98a63e23ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(X_train, y_train, codes_train, X_val, y_val, codes_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1d20f1-fff1-44c0-806d-6ad09a5d9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle data before using\n",
    "X_train_val, y_train_val, codes_train_val = shuffle(X_train_val, y_train_val, codes_train_val, random_state=42)\n",
    "\n",
    "chunked_X_train = np.array_split(X_train_val, 100)    \n",
    "chunked_y_train = np.array_split(y_train_val, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b57f784-124b-4579-96a7-b4e62d4d42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_X_train_ten = []\n",
    "chunks_y_train_ten = []\n",
    "\n",
    "for i in range(10):\n",
    "    chunks_X_train_ten.append(chunked_X_train[i])\n",
    "    chunks_y_train_ten.append(chunked_y_train[i])\n",
    "\n",
    "chunks_X_train_ten = pd.concat(chunks_X_train_ten)\n",
    "chunks_y_train_ten = pd.concat(chunks_y_train_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f1df6b-4cea-44a0-8dbd-c8a87c842af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 ms, sys: 0 ns, total: 1.28 ms\n",
      "Wall time: 1.41 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/Dummy_mean.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr.fit(X_train_val, y_train_val)\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'Dummy_mean.joblib')\n",
    "dump(dummy_regr, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b71198-a0ff-4bf1-80b3-c4b1c48158bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 ms, sys: 0 ns, total: 1.14 ms\n",
      "Wall time: 1.58 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/Dummy_median.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "dummy_regr = DummyRegressor(strategy=\"median\")\n",
    "dummy_regr.fit(X_train_val, y_train_val)\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'Dummy_median.joblib')\n",
    "dump(dummy_regr, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142a1546-cee2-4df0-881f-81360b9a42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # NOTE: Gridsearch was extended multiple times initial search, therefore the results \n",
    "# # for max_features = 40, 60, 70, 80, 90, 100, 150, 250, None can be found in \n",
    "# # \"RF_gridsearchX.joblib\" files (X = 2, 3, 4, 5)\n",
    "\n",
    "# parameters = { \n",
    "#               'max_features': ['sqrt', 'log2', 15, 30, 40, 50, 60, 70, 80, 90, 100, 150, 250, None],\n",
    "#               'min_samples_leaf': [1, 2, 3, 4, 5, 10, 20, 30, 40, 50]\n",
    "#              }\n",
    "\n",
    "# RF_gridsearch = GridSearchCV(RandomForestRegressor(n_estimators=100, verbose=10, n_jobs=-1), \n",
    "#                              parameters, verbose=10, n_jobs=1)\n",
    "\n",
    "# RF_gridsearch.fit(X_train_val, y_train_val)\n",
    "\n",
    "# output_file = os.path.join(PATH_MODELS, 'RF_gridsearch5.joblib')\n",
    "# dump(RF_gridsearch, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b3e765-57cb-4034-91f2-ee4d3b4cc486",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RF_gridsearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mRF_gridsearch\u001b[49m\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RF_gridsearch' is not defined"
     ]
    }
   ],
   "source": [
    "RF_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be67e9f-0faa-49d6-bce4-cd3eac60e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5; 1/100] START linearsvr__C=0.834745097290563, linearsvr__epsilon=5.127483195687349\n",
      "> \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m(985)\u001b[0;36m_incremental_mean_and_var\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    983 \u001b[0;31m        \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    984 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 985 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'updated_sample_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_sample_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    986 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_sum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnew_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    987 \u001b[0;31m        \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  updated_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  last_sum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  new_sum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([-2.49963452e+01, -5.32368044e+01, -4.92288263e+01, -2.89690244e+01,\n",
      "       -2.74162415e+01,  2.71791356e+00,  2.32717359e+00, -1.24501774e+01,\n",
      "        1.00388737e+01, -9.06281762e-01, -1.80334769e+01, -3.71868992e+01,\n",
      "        4.98913674e+00, -2.01608918e+01,  4.66988877e+00, -1.18000351e+00,\n",
      "        2.89375655e+01, -1.94344752e+01, -1.83755573e+01,  9.30788978e+00,\n",
      "       -1.14264068e+01, -2.56914148e+00,  3.39160814e+01, -2.11150309e+01,\n",
      "       -7.90832872e+00, -2.10097491e+01, -1.43537845e+01, -1.60093024e+01,\n",
      "        2.85359069e+00, -1.15407450e+01, -2.56307509e+01, -5.40915571e+01,\n",
      "       -1.02440257e+01, -3.48002802e+01, -1.09902719e+01, -1.13999400e+01,\n",
      "        3.96717928e-01, -3.06907199e+01, -6.46633324e+00,  1.73153906e+01,\n",
      "       -3.33771300e+01, -4.53527135e+01, -1.65420890e+01, -2.33068723e+01,\n",
      "       -1.09262638e+01, -6.57842208e+00, -2.27532928e+01, -6.50266299e+01,\n",
      "       -3.26503006e+01, -1.77384503e+01, -3.74764027e+01, -4.18584097e+01,\n",
      "        1.59270125e+01, -1.56900334e+01, -1.70640957e+01, -1.05905723e+01,\n",
      "       -2.04485525e+01,  2.89200115e+00,  8.62074485e+00,  2.36964564e+01,\n",
      "       -5.33625918e+01, -9.15406724e+00, -1.43537881e+01,  3.55823590e+01,\n",
      "       -9.95280801e+00,  6.82420489e+00, -2.13854960e+01, -5.34217496e+01,\n",
      "       -2.97039134e+00,  3.61705880e+01, -2.65751133e+01, -1.92676578e+01,\n",
      "        4.52620328e-01,  5.23184505e+01,  2.58082094e+01,  3.80124178e+01,\n",
      "        5.02390813e+00, -4.18296980e+01, -9.16362176e+00,  4.42140854e+01,\n",
      "        2.53836750e+01, -1.26113494e+01, -5.51345030e+00, -9.46546491e+00,\n",
      "       -4.75517419e+01, -1.36060725e+01, -1.98197167e+00, -4.04287577e+01,\n",
      "       -4.88658591e+01,  2.94811887e+00, -7.94639833e+01, -7.44737463e+01,\n",
      "       -7.41147472e+01, -6.98767545e+01, -1.32232918e+02, -1.00903826e+02,\n",
      "       -4.80543163e+01, -3.10586568e+01, -3.30438309e+01, -4.77031932e+00,\n",
      "        1.50463517e+01, -9.22637847e+01, -2.57950417e+01, -2.71165808e+01,\n",
      "        4.25351578e+01,  3.56236648e+01,  3.62353639e+01,  4.22926166e+01,\n",
      "        2.64264634e+01,  1.49794244e+01,  1.67208544e+01,  3.49936271e+01,\n",
      "        4.09670042e+01,  5.64397181e+01,  4.91354337e+01,  1.53102619e+01,\n",
      "       -2.08222365e+01,  2.22538895e+01,  1.82422943e+01,  7.96633836e+00,\n",
      "       -4.65942288e+01, -5.16994801e+01, -5.99680670e+01, -5.37881911e+01,\n",
      "       -6.51846838e+01, -3.47915861e+01, -2.65852692e+01, -3.17128644e+01,\n",
      "       -8.51326792e+00, -1.57670352e+01, -2.60339168e+01, -4.60996637e+01,\n",
      "       -8.95043825e+00, -4.26817783e+01, -1.01286230e+01, -1.20100200e+01,\n",
      "        7.18467201e+00, -3.48676321e+01, -2.30036103e+01,  2.42778493e+00,\n",
      "       -1.46273427e+01,  7.24795045e+00,  1.96388600e+01, -2.52064782e+01,\n",
      "       -2.10320860e+01, -1.76812268e+00, -6.15738617e+00, -9.67142214e+00,\n",
      "        1.83875568e+00, -2.20704917e+01, -2.76170210e+00, -3.50686606e+01,\n",
      "       -3.09005847e+01, -2.63146918e+01, -7.65554017e+00,  1.02271220e+01,\n",
      "        1.52297626e+01, -2.64344224e+01,  1.19142275e+01, -6.29615061e+00,\n",
      "       -2.05746265e+01, -6.57207304e+00,  8.78740788e+00,  2.79714534e+00,\n",
      "        2.57943597e+01, -1.08393137e+01,  5.28397038e+01, -5.04395008e+01,\n",
      "       -1.40552474e+00,  2.73020220e+01, -1.55592003e+00, -6.97987235e+00,\n",
      "        4.82281681e+01, -2.50692066e+01,  5.38118703e+00,  2.51051748e-01,\n",
      "        5.29951018e+00,  3.07259122e+01, -9.49752469e-01,  1.29383047e+01,\n",
      "        3.38208453e+01,  3.79517002e+01,  6.74252193e+01,  4.06300917e+01,\n",
      "        4.50062854e+01,  1.23266424e+01, -1.94461929e+01,  1.11227405e+01,\n",
      "       -5.86798554e+00, -1.00305475e+01,  1.16892083e+01,  3.69156815e+01,\n",
      "       -1.75951582e+01,  2.55753314e+01,  2.17246836e+01, -5.71140659e+00,\n",
      "       -2.09967383e+01,  2.17335978e+01, -3.40856165e+01,  4.33334837e+00,\n",
      "       -2.12788146e+01, -3.05275462e+01, -1.11884680e+01, -2.66027987e+01,\n",
      "        2.81164469e+01, -1.86222422e+01, -2.32205378e+01,  4.59456248e+01,\n",
      "        1.36153470e+01,  2.85875185e+01, -8.19457418e-01,  2.06673501e+01,\n",
      "        3.32305343e+01,  2.27208666e+01,  4.25781105e+01,  2.24483863e+01,\n",
      "       -4.63744920e+01,  1.78656541e+00,  3.68698193e+01, -1.49544042e+01,\n",
      "        1.52477251e+01,  2.51041715e+01, -7.85969184e+00,  1.49548865e+01,\n",
      "        2.05615299e+01,  2.85443796e+00, -1.22556550e+01,  1.26764094e+01,\n",
      "       -4.17108951e+01,  4.76869331e+01,  1.35798050e+00, -3.19760449e+01,\n",
      "       -1.05337126e+01, -3.72640787e+01,  3.08598180e+01, -6.28079414e+00,\n",
      "       -1.71371357e+01,  2.49984444e+01,  8.23149495e+00,  1.06536256e+01,\n",
      "        5.23786363e+01,  4.71434560e+01,  4.43632679e+01,  2.58001485e+01,\n",
      "        3.18287309e+01,  4.19105312e+01,  1.25080650e+01,  3.98926399e+01,\n",
      "        6.22793958e+00,  4.47998404e+01,  2.33273176e+01,  9.41257241e+00,\n",
      "       -1.38676031e+01,  8.71115275e+00,  3.52140322e+01,  9.61257418e-01,\n",
      "       -9.07007972e+00,  3.83028566e+01, -1.05997397e+00,  1.78574530e+01,\n",
      "        3.68207032e+00, -3.44750459e+01, -7.79942485e+00,  2.32660029e+01,\n",
      "        4.36130132e+01, -1.97989771e+01, -1.97590781e+01,  2.58912416e+01,\n",
      "        1.43000930e+01, -1.98093694e+00,  2.45859807e-01,  1.23147861e+01,\n",
      "        1.62170821e+01, -6.80895928e-01,  5.75532745e+00, -2.49008663e+01,\n",
      "       -2.06024479e+01, -2.81156625e+01, -3.80183762e+00,  1.28062543e+01,\n",
      "       -5.67946048e+00, -4.75741880e-01,  1.34014107e+01, -1.72862479e+00,\n",
      "        6.81161549e+00, -8.59495863e+00,  1.23140405e+00,  2.75115703e+00,\n",
      "       -1.21744081e+00,  6.84826930e+00, -3.19102794e+00,  6.20259925e+00,\n",
      "        8.15238600e+00, -1.86209222e+00,  6.70840353e+00, -1.29361900e+01,\n",
      "       -2.26682545e+01, -1.54091252e+01, -6.64419155e-01,  5.77806259e+00,\n",
      "       -2.71005249e+01, -1.19697516e+01, -4.22499226e-01,  3.31400741e+00,\n",
      "        1.00252955e+01, -1.89799879e+01, -2.18952094e+01, -2.36141118e+01,\n",
      "       -8.53654195e+00,  4.25343100e+00, -2.49356075e+01, -3.74408719e+01,\n",
      "       -2.20191989e+01,  1.27198453e+01, -4.83320217e-01,  9.54044108e-02,\n",
      "       -3.97546774e+00, -7.99154473e+00, -1.02880342e+01, -1.93640348e+00,\n",
      "       -2.88574871e+01, -1.55631749e+01, -2.68091347e+01, -2.58669311e+01,\n",
      "       -2.11119417e+01, -2.08058060e+01,  1.15830283e+01,  1.04617036e+01,\n",
      "       -2.64645855e+00,  5.86704270e+00, -1.47178309e+01,  9.86176502e+00,\n",
      "       -7.91451321e+00,  3.12193799e-02,  7.50229236e+00, -1.44939030e+01,\n",
      "        1.37942071e+01,  7.83896716e+00, -1.71870904e+00,  9.26220920e+00,\n",
      "       -1.64401574e+01, -1.09893046e+01,  8.54465361e+00, -7.88586599e-01,\n",
      "        7.03161713e+00, -1.71625041e+01,  2.12014794e+00, -5.30883928e+00,\n",
      "       -2.44185666e+00,  7.58730735e+00,  2.70024025e+01,  9.77774659e+00,\n",
      "       -6.24300231e-02,  7.34163518e+00,  1.63724361e+01, -1.10259611e+01,\n",
      "        2.53781253e+01,  5.24160024e+00, -1.47405114e+01, -1.21636696e+01,\n",
      "       -2.37974768e+01, -2.48592104e+01, -2.89227458e+01, -8.34367722e+00,\n",
      "        6.67572476e+00, -1.21421772e+01,  4.95506398e+00,  1.72323280e+01,\n",
      "       -2.05966825e+00,  6.94896998e+00, -1.58603925e+01,  2.37376437e+01,\n",
      "        2.26855814e+01,  1.18414876e+00,  9.90248180e+00, -3.00714040e+01,\n",
      "       -4.64379668e+00, -7.13878047e+00, -1.31847179e+00,  5.64594182e+00,\n",
      "       -2.88523673e+00,  2.21272238e+01,  1.58949010e+01,  5.08971138e+01,\n",
      "        4.98197848e+01, -2.18773108e+01,  3.05850289e+01,  2.18477622e+01,\n",
      "       -3.06566753e+00, -7.25460812e+00,  3.91711654e+01,  7.64589281e+01,\n",
      "        3.90745335e+01,  1.03095198e+01,  3.83529705e+00, -3.23415308e+01,\n",
      "       -1.37633359e+01, -3.92717493e+01, -1.07558825e+01,  1.42867116e+00,\n",
      "       -4.48301516e+01, -1.75622544e+01, -6.65483090e+00,  1.80475885e+01,\n",
      "        1.32016020e+01, -1.89953249e+01,  6.15556000e+00,  1.54653989e+00,\n",
      "        2.85654355e+01,  3.68829495e+01, -3.39663373e+01, -1.14113208e+01,\n",
      "       -2.66975685e+01,  1.39855356e+01,  2.51036821e+01, -6.22331374e+00,\n",
      "        2.15809657e+01,  1.37326713e+01,  1.29777645e+01,  1.95581842e+01,\n",
      "        3.61656697e+01,  1.80760906e+01,  3.08304267e+01,  9.34413766e+00,\n",
      "       -2.78679406e+00, -1.66353056e+01,  3.85124892e+01, -2.45633233e+00,\n",
      "       -1.66012090e+00, -1.65243144e+01,  6.39609684e+00,  3.89472656e+01,\n",
      "       -5.71960472e+00, -1.80732091e+01,  1.64116396e+01, -1.41117634e+01,\n",
      "        1.17783636e+01,  2.21322464e+01, -3.09973211e+01,  2.43936298e+01,\n",
      "        1.93659950e+01,  1.06906447e+01,  4.41291814e+00,  8.62938219e-01,\n",
      "        3.70307025e+01,  1.86839283e+01,  2.46855382e+01, -2.17450676e+01,\n",
      "        1.49730222e+01,  2.20676322e+01,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  last_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,\n",
      "       1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760, 1760,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "          0,    0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_nan_mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[False, False, False, ...,  True,  True,  True],\n",
      "       [False, False, False, ...,  True,  True,  True],\n",
      "       [False, False, False, ...,  True,  True,  True],\n",
      "       ...,\n",
      "       [False, False, False, ...,  True,  True,  True],\n",
      "       [False, False, False, ...,  True,  True,  True],\n",
      "       [False, False, False, ...,  True,  True,  True]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X_nan_mask[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n_samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-0.4297868 , -0.3064694 , -0.3860518 , ...,         nan,\n",
      "                nan,         nan],\n",
      "       [ 1.4344859 ,  1.644264  ,  1.7644737 , ...,         nan,\n",
      "                nan,         nan],\n",
      "       [-0.25884303, -1.0847396 , -1.0948586 , ...,         nan,\n",
      "                nan,         nan],\n",
      "       ...,\n",
      "       [ 0.01262396,  1.1252204 ,  0.5714156 , ...,         nan,\n",
      "                nan,         nan],\n",
      "       [ 0.1942347 , -0.03161406,  0.12647119, ...,         nan,\n",
      "                nan,         nan],\n",
      "       [-0.37361547, -0.6177594 , -0.52353966, ...,         nan,\n",
      "                nan,         nan]], dtype=float32)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  bt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m    [... skipping 21 hidden frame(s)]\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/tmp/ipykernel_32337/1925296218.py\u001b[0m(1)\u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nimport importlib\\n\\n# importlib.reload(np)\\nnp.seterr(all='raise')\\n\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.svm import LinearSVR\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.metrics import make_scorer, mean_absolute_error\\nfrom scipy.stats import uniform\\n\\n# Started with large parameter space, decreased the range of parameters and increased training data\\n# RS with 1/10th of data shows that C = 0.75 performs best and epsilon = 2.5\\nparameters = {'linearsvr__C': uniform(0.01, 1),\\n              'linearsvr__epsilon': uniform(0, 6),\\n}\\n\\nscorer = make_scorer(mean_absolute_error, greater_is_better=False)\\n\\npipe  = make_pipeline(StandardScaler(),\\n                      LinearSVR(verbose=2, max_iter=50000))\\n\\nLSVR_randomsearch = RandomizedSearchCV(pipe, parameters, n_iter=100, cv=5, n_jobs=-1, scoring=scorer, verbose=10)\\n# LSVR_randomsearch.fit(X_train_val, y_train_val)\\nLSVR_randomsearch.fit(chunks_X_train_ten, chunks_y_train_ten)\\n\\noutput_file = os.path.join(PATH_MODELS, 'LSVR_randomsearch.joblib')\\ndump(LSVR_randomsearch, output_file)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m(2358)\u001b[0;36mrun_cell_magic\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m   2356 \u001b[0m            \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   2357 \u001b[0m                \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 2358 \u001b[0;31m                \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   2359 \u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   2360 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/magics/execution.py\u001b[0m(1316)\u001b[0;36mtime\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m   1314 \u001b[0m            \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1315 \u001b[0m            \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1316 \u001b[0;31m                \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1317 \u001b[0m                \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1318 \u001b[0m                \u001b[0;31m# multi-line %%time case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m<timed exec>\u001b[0m(26)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m(875)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    873 \u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    874 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 875 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    876 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    877 \u001b[0m            \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m(1749)\u001b[0;36m_run_search\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m   1747 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1748 \u001b[0m        \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1749 \u001b[0;31m        evaluate_candidates(\n",
      "\u001b[0m\u001b[1;32m   1750 \u001b[0m            ParameterSampler(\n",
      "\u001b[1;32m   1751 \u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m(822)\u001b[0;36mevaluate_candidates\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    820 \u001b[0m                    )\n",
      "\u001b[1;32m    821 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 822 \u001b[0;31m                out = parallel(\n",
      "\u001b[0m\u001b[1;32m    823 \u001b[0m                    delayed(_fit_and_score)(\n",
      "\u001b[1;32m    824 \u001b[0m                        \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m(1043)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m   1041 \u001b[0m            \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1042 \u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1043 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1044 \u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1045 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m(861)\u001b[0;36mdispatch_one_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    859 \u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    860 \u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 861 \u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    862 \u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    863 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m(779)\u001b[0;36m_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    777 \u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    778 \u001b[0m            \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 779 \u001b[0;31m            \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    780 \u001b[0m            \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    781 \u001b[0m            \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m(208)\u001b[0;36mapply_async\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    206 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    207 \u001b[0m        \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 208 \u001b[0;31m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    209 \u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    210 \u001b[0m            \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m(572)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    570 \u001b[0m        \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    571 \u001b[0m        \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 572 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    573 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    574 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m(262)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    260 \u001b[0m        \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    261 \u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 262 \u001b[0;31m            return [func(*args, **kwargs)\n",
      "\u001b[0m\u001b[1;32m    263 \u001b[0m                    for func, args, kwargs in self.items]\n",
      "\u001b[1;32m    264 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m(262)\u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    260 \u001b[0m        \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    261 \u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 262 \u001b[0;31m            return [func(*args, **kwargs)\n",
      "\u001b[0m\u001b[1;32m    263 \u001b[0m                    for func, args, kwargs in self.items]\n",
      "\u001b[1;32m    264 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m(117)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    115 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    116 \u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 117 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    118 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    119 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m(686)\u001b[0;36m_fit_and_score\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    684 \u001b[0m            \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    685 \u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 686 \u001b[0;31m            \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    687 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    688 \u001b[0m    \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m(378)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    376 \u001b[0m        \"\"\"\n",
      "\u001b[1;32m    377 \u001b[0m        \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 378 \u001b[0;31m        \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    379 \u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    380 \u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m(336)\u001b[0;36m_fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    334 \u001b[0m                \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    335 \u001b[0m            \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 336 \u001b[0;31m            X, fitted_transformer = fit_transform_one_cached(\n",
      "\u001b[0m\u001b[1;32m    337 \u001b[0m                \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    338 \u001b[0m                \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/joblib/memory.py\u001b[0m(349)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    347 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    348 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 349 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    350 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    351 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m(870)\u001b[0;36m_fit_transform_one\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    868 \u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    869 \u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 870 \u001b[0;31m            \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    871 \u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    872 \u001b[0m            \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m(870)\u001b[0;36mfit_transform\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    868 \u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    869 \u001b[0m            \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 870 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    871 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    872 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m(809)\u001b[0;36mfit\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    807 \u001b[0m        \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    808 \u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 809 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    810 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    811 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "  \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m(929)\u001b[0;36mpartial_fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    927 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    928 \u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 929 \u001b[0;31m                self.mean_, self.var_, self.n_samples_seen_ = _incremental_mean_and_var(\n",
      "\u001b[0m\u001b[1;32m    930 \u001b[0m                    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    931 \u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "> \u001b[0;32m/home/cmoore/.local/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m(985)\u001b[0;36m_incremental_mean_and_var\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    983 \u001b[0;31m        \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    984 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 985 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'updated_sample_count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdated_sample_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    986 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_sum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnew_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    987 \u001b[0;31m        \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import importlib\n",
    "\n",
    "# importlib.reload(np)\n",
    "np.seterr(all='raise')\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Started with large parameter space, decreased the range of parameters and increased training data\n",
    "# RS with 1/10th of data shows that C = 0.75 performs best and epsilon = 2.5\n",
    "parameters = {'linearsvr__C': uniform(0.01, 1),\n",
    "              'linearsvr__epsilon': uniform(0, 6),\n",
    "}\n",
    "\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "pipe  = make_pipeline(StandardScaler(),\n",
    "                      LinearSVR(verbose=2, max_iter=50000))\n",
    "\n",
    "LSVR_randomsearch = RandomizedSearchCV(pipe, parameters, n_iter=100, cv=5, n_jobs=-1, scoring=scorer, verbose=10)\n",
    "# LSVR_randomsearch.fit(X_train_val, y_train_val)\n",
    "LSVR_randomsearch.fit(chunks_X_train_ten, chunks_y_train_ten)\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'LSVR_randomsearch.joblib')\n",
    "dump(LSVR_randomsearch, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c500403-6e47-4574-b3f9-fba6dbaf3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVR_randomsearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab7d69-863b-4f86-8dbe-3e97423c7e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVR_randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1fac8-5907-4c18-984e-7765e6a1a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_DF = pd.DataFrame(LSVR_randomsearch.cv_results_).sort_values('rank_test_score').head(50)\n",
    "\n",
    "pd.DataFrame(LSVR_randomsearch.cv_results_).sort_values('rank_test_score').head(30)\n",
    "\n",
    "# Best C: 1.04, epsilon: 1.467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0964000-fe0c-4a7c-b666-1b6e059660f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "ax = sns.scatterplot(x=\"param_linearsvr__C\", y=\"param_linearsvr__epsilon\", hue=\"mean_test_score\", palette='RdBu', data=cv_DF)\n",
    "\n",
    "norm = plt.Normalize(cv_DF['mean_test_score'].min(), cv_DF['mean_test_score'].max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"RdBu\", norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "ax.get_legend().remove()\n",
    "ax.figure.colorbar(sm)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a028f-8baf-40f0-ae1d-76593f879f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "\n",
    "parameters = {'linearsvr__C': [0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8],\n",
    "              'linearsvr__epsilon': [1.5, 2, 2.5, 3],\n",
    "}\n",
    "\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "pipe  = make_pipeline(StandardScaler(),\n",
    "                      LinearSVR(verbose=2, max_iter=50000))\n",
    "\n",
    "LSVR_gridsearch = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1,  scoring=scorer, verbose=10)\n",
    "# LSVR_gridsearch.fit(X_train_val, y_train_val)\n",
    "LSVR_gridsearch.fit(chunks_X_train_ten, chunks_y_train_ten)\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'LSVR_gridsearch.joblib')\n",
    "dump(LSVR_gridsearch, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99efdf3d-2532-4e66-87d7-3703adcb8084",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8caac-ceac-4ab6-85fa-7caef3efaa80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
