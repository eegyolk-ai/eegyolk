{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional machine learning models for age prediction on EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses traditional ML methods to predict the age of infants using EEG data. The EEG data is preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 05:14:56.715977: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-14 05:14:56.716007: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from epodium.config import Config\n",
    "from epodium.loaders import RegressionsLoader\n",
    "from epodium.ml import Regressions\n",
    "from epodium.nn import NnOptimizer\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Get all the files in the output folder\n",
    "2. Get the full paths of the files without the .h5 or .csv extensions\n",
    "3. Load the features from the .h5 files\n",
    "4. Assign the proper labels to the files based on the metadata\n",
    "5. Assign the subject's code to the files based on the metadata\n",
    "6. Split the data into a training, validation and test set (NOTE: make sure data points from same subjects don't end up in same set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we seem to have a problem- we have features that are multi-dimensional, and from what I see in the code they were not reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hjorth_complexity_O2</th>\n",
       "      <th>hjorth_complexity_O1</th>\n",
       "      <th>hjorth_complexity_OZ</th>\n",
       "      <th>hjorth_complexity_PZ</th>\n",
       "      <th>hjorth_complexity_P4</th>\n",
       "      <th>hjorth_complexity_CP4</th>\n",
       "      <th>hjorth_complexity_P8</th>\n",
       "      <th>hjorth_complexity_C4</th>\n",
       "      <th>hjorth_complexity_TP8</th>\n",
       "      <th>hjorth_complexity_T8</th>\n",
       "      <th>...</th>\n",
       "      <th>kurtosis_FZ</th>\n",
       "      <th>kurtosis_F4</th>\n",
       "      <th>kurtosis_F8</th>\n",
       "      <th>kurtosis_T7</th>\n",
       "      <th>kurtosis_FT7</th>\n",
       "      <th>kurtosis_FC3</th>\n",
       "      <th>kurtosis_F3</th>\n",
       "      <th>kurtosis_FP2</th>\n",
       "      <th>kurtosis_F7</th>\n",
       "      <th>kurtosis_FP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.844394</td>\n",
       "      <td>5.285615</td>\n",
       "      <td>4.714020</td>\n",
       "      <td>4.544710</td>\n",
       "      <td>1.658952</td>\n",
       "      <td>4.459770</td>\n",
       "      <td>3.651870</td>\n",
       "      <td>2.953397</td>\n",
       "      <td>3.291691</td>\n",
       "      <td>2.914745</td>\n",
       "      <td>...</td>\n",
       "      <td>2.055386</td>\n",
       "      <td>2.303099</td>\n",
       "      <td>2.542408</td>\n",
       "      <td>3.068982</td>\n",
       "      <td>3.418724</td>\n",
       "      <td>2.657893</td>\n",
       "      <td>2.372468</td>\n",
       "      <td>3.185538</td>\n",
       "      <td>2.092215</td>\n",
       "      <td>3.008556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.417027</td>\n",
       "      <td>2.626444</td>\n",
       "      <td>4.403926</td>\n",
       "      <td>3.043164</td>\n",
       "      <td>2.034024</td>\n",
       "      <td>2.411991</td>\n",
       "      <td>3.348194</td>\n",
       "      <td>3.159142</td>\n",
       "      <td>2.899417</td>\n",
       "      <td>4.565265</td>\n",
       "      <td>...</td>\n",
       "      <td>2.670512</td>\n",
       "      <td>3.148539</td>\n",
       "      <td>2.688797</td>\n",
       "      <td>2.922697</td>\n",
       "      <td>3.541677</td>\n",
       "      <td>3.702186</td>\n",
       "      <td>3.218444</td>\n",
       "      <td>4.924635</td>\n",
       "      <td>3.751193</td>\n",
       "      <td>3.726647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.507933</td>\n",
       "      <td>5.908041</td>\n",
       "      <td>6.899218</td>\n",
       "      <td>6.282867</td>\n",
       "      <td>2.969392</td>\n",
       "      <td>6.678296</td>\n",
       "      <td>5.882777</td>\n",
       "      <td>6.328652</td>\n",
       "      <td>3.454919</td>\n",
       "      <td>6.847669</td>\n",
       "      <td>...</td>\n",
       "      <td>2.580961</td>\n",
       "      <td>2.691047</td>\n",
       "      <td>2.993296</td>\n",
       "      <td>3.024504</td>\n",
       "      <td>3.359949</td>\n",
       "      <td>2.963878</td>\n",
       "      <td>3.422704</td>\n",
       "      <td>2.830353</td>\n",
       "      <td>3.541482</td>\n",
       "      <td>2.820758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.378624</td>\n",
       "      <td>3.176170</td>\n",
       "      <td>2.945529</td>\n",
       "      <td>4.003992</td>\n",
       "      <td>1.537418</td>\n",
       "      <td>3.072991</td>\n",
       "      <td>3.133565</td>\n",
       "      <td>4.155132</td>\n",
       "      <td>2.842107</td>\n",
       "      <td>2.998760</td>\n",
       "      <td>...</td>\n",
       "      <td>2.427195</td>\n",
       "      <td>3.072564</td>\n",
       "      <td>2.810491</td>\n",
       "      <td>3.044418</td>\n",
       "      <td>2.455291</td>\n",
       "      <td>2.491790</td>\n",
       "      <td>3.226719</td>\n",
       "      <td>2.430481</td>\n",
       "      <td>2.523738</td>\n",
       "      <td>2.288575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.595716</td>\n",
       "      <td>2.823651</td>\n",
       "      <td>3.383794</td>\n",
       "      <td>2.899973</td>\n",
       "      <td>1.924664</td>\n",
       "      <td>3.105019</td>\n",
       "      <td>4.375562</td>\n",
       "      <td>3.215412</td>\n",
       "      <td>2.416628</td>\n",
       "      <td>3.819207</td>\n",
       "      <td>...</td>\n",
       "      <td>2.689158</td>\n",
       "      <td>2.981971</td>\n",
       "      <td>2.585572</td>\n",
       "      <td>2.913774</td>\n",
       "      <td>2.413742</td>\n",
       "      <td>2.018164</td>\n",
       "      <td>2.809000</td>\n",
       "      <td>2.670755</td>\n",
       "      <td>2.437741</td>\n",
       "      <td>2.699543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>3.788516</td>\n",
       "      <td>5.015761</td>\n",
       "      <td>3.622249</td>\n",
       "      <td>5.324916</td>\n",
       "      <td>1.578261</td>\n",
       "      <td>5.441124</td>\n",
       "      <td>5.961255</td>\n",
       "      <td>3.377872</td>\n",
       "      <td>2.403643</td>\n",
       "      <td>8.646042</td>\n",
       "      <td>...</td>\n",
       "      <td>2.555178</td>\n",
       "      <td>2.582785</td>\n",
       "      <td>2.496452</td>\n",
       "      <td>2.627511</td>\n",
       "      <td>3.361375</td>\n",
       "      <td>2.446408</td>\n",
       "      <td>2.929544</td>\n",
       "      <td>3.162804</td>\n",
       "      <td>2.626943</td>\n",
       "      <td>2.396528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>5.694019</td>\n",
       "      <td>4.978446</td>\n",
       "      <td>5.758974</td>\n",
       "      <td>4.023781</td>\n",
       "      <td>1.946865</td>\n",
       "      <td>5.119463</td>\n",
       "      <td>5.793373</td>\n",
       "      <td>3.489983</td>\n",
       "      <td>3.885625</td>\n",
       "      <td>3.133482</td>\n",
       "      <td>...</td>\n",
       "      <td>2.716574</td>\n",
       "      <td>2.734104</td>\n",
       "      <td>2.202228</td>\n",
       "      <td>2.096609</td>\n",
       "      <td>2.094368</td>\n",
       "      <td>2.364857</td>\n",
       "      <td>1.836433</td>\n",
       "      <td>1.703992</td>\n",
       "      <td>1.977626</td>\n",
       "      <td>1.606735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>4.520942</td>\n",
       "      <td>2.506913</td>\n",
       "      <td>4.147480</td>\n",
       "      <td>4.322664</td>\n",
       "      <td>1.730429</td>\n",
       "      <td>3.097054</td>\n",
       "      <td>3.243782</td>\n",
       "      <td>4.310385</td>\n",
       "      <td>2.388814</td>\n",
       "      <td>5.321362</td>\n",
       "      <td>...</td>\n",
       "      <td>5.439471</td>\n",
       "      <td>2.684431</td>\n",
       "      <td>2.691150</td>\n",
       "      <td>5.740503</td>\n",
       "      <td>3.752384</td>\n",
       "      <td>2.974340</td>\n",
       "      <td>3.547407</td>\n",
       "      <td>4.102953</td>\n",
       "      <td>3.549382</td>\n",
       "      <td>2.297193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>4.483920</td>\n",
       "      <td>2.912305</td>\n",
       "      <td>5.364835</td>\n",
       "      <td>10.737846</td>\n",
       "      <td>2.950583</td>\n",
       "      <td>3.600636</td>\n",
       "      <td>2.438044</td>\n",
       "      <td>4.722172</td>\n",
       "      <td>1.872033</td>\n",
       "      <td>4.795071</td>\n",
       "      <td>...</td>\n",
       "      <td>3.781560</td>\n",
       "      <td>2.498872</td>\n",
       "      <td>3.458072</td>\n",
       "      <td>2.476443</td>\n",
       "      <td>2.374693</td>\n",
       "      <td>2.490436</td>\n",
       "      <td>3.049023</td>\n",
       "      <td>2.752978</td>\n",
       "      <td>2.950096</td>\n",
       "      <td>2.023796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2.476560</td>\n",
       "      <td>2.898021</td>\n",
       "      <td>2.668578</td>\n",
       "      <td>2.782797</td>\n",
       "      <td>1.543748</td>\n",
       "      <td>3.922543</td>\n",
       "      <td>3.575462</td>\n",
       "      <td>3.137146</td>\n",
       "      <td>2.472605</td>\n",
       "      <td>3.928527</td>\n",
       "      <td>...</td>\n",
       "      <td>3.153326</td>\n",
       "      <td>2.479262</td>\n",
       "      <td>2.373739</td>\n",
       "      <td>2.598962</td>\n",
       "      <td>2.870775</td>\n",
       "      <td>2.328405</td>\n",
       "      <td>2.499386</td>\n",
       "      <td>2.658134</td>\n",
       "      <td>2.477948</td>\n",
       "      <td>2.484826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hjorth_complexity_O2  hjorth_complexity_O1  hjorth_complexity_OZ  \\\n",
       "0                3.844394              5.285615              4.714020   \n",
       "1                3.417027              2.626444              4.403926   \n",
       "2                5.507933              5.908041              6.899218   \n",
       "3                4.378624              3.176170              2.945529   \n",
       "4                2.595716              2.823651              3.383794   \n",
       "..                    ...                   ...                   ...   \n",
       "369              3.788516              5.015761              3.622249   \n",
       "370              5.694019              4.978446              5.758974   \n",
       "371              4.520942              2.506913              4.147480   \n",
       "372              4.483920              2.912305              5.364835   \n",
       "373              2.476560              2.898021              2.668578   \n",
       "\n",
       "     hjorth_complexity_PZ  hjorth_complexity_P4  hjorth_complexity_CP4  \\\n",
       "0                4.544710              1.658952               4.459770   \n",
       "1                3.043164              2.034024               2.411991   \n",
       "2                6.282867              2.969392               6.678296   \n",
       "3                4.003992              1.537418               3.072991   \n",
       "4                2.899973              1.924664               3.105019   \n",
       "..                    ...                   ...                    ...   \n",
       "369              5.324916              1.578261               5.441124   \n",
       "370              4.023781              1.946865               5.119463   \n",
       "371              4.322664              1.730429               3.097054   \n",
       "372             10.737846              2.950583               3.600636   \n",
       "373              2.782797              1.543748               3.922543   \n",
       "\n",
       "     hjorth_complexity_P8  hjorth_complexity_C4  hjorth_complexity_TP8  \\\n",
       "0                3.651870              2.953397               3.291691   \n",
       "1                3.348194              3.159142               2.899417   \n",
       "2                5.882777              6.328652               3.454919   \n",
       "3                3.133565              4.155132               2.842107   \n",
       "4                4.375562              3.215412               2.416628   \n",
       "..                    ...                   ...                    ...   \n",
       "369              5.961255              3.377872               2.403643   \n",
       "370              5.793373              3.489983               3.885625   \n",
       "371              3.243782              4.310385               2.388814   \n",
       "372              2.438044              4.722172               1.872033   \n",
       "373              3.575462              3.137146               2.472605   \n",
       "\n",
       "     hjorth_complexity_T8  ...  kurtosis_FZ  kurtosis_F4  kurtosis_F8  \\\n",
       "0                2.914745  ...     2.055386     2.303099     2.542408   \n",
       "1                4.565265  ...     2.670512     3.148539     2.688797   \n",
       "2                6.847669  ...     2.580961     2.691047     2.993296   \n",
       "3                2.998760  ...     2.427195     3.072564     2.810491   \n",
       "4                3.819207  ...     2.689158     2.981971     2.585572   \n",
       "..                    ...  ...          ...          ...          ...   \n",
       "369              8.646042  ...     2.555178     2.582785     2.496452   \n",
       "370              3.133482  ...     2.716574     2.734104     2.202228   \n",
       "371              5.321362  ...     5.439471     2.684431     2.691150   \n",
       "372              4.795071  ...     3.781560     2.498872     3.458072   \n",
       "373              3.928527  ...     3.153326     2.479262     2.373739   \n",
       "\n",
       "     kurtosis_T7  kurtosis_FT7  kurtosis_FC3  kurtosis_F3  kurtosis_FP2  \\\n",
       "0       3.068982      3.418724      2.657893     2.372468      3.185538   \n",
       "1       2.922697      3.541677      3.702186     3.218444      4.924635   \n",
       "2       3.024504      3.359949      2.963878     3.422704      2.830353   \n",
       "3       3.044418      2.455291      2.491790     3.226719      2.430481   \n",
       "4       2.913774      2.413742      2.018164     2.809000      2.670755   \n",
       "..           ...           ...           ...          ...           ...   \n",
       "369     2.627511      3.361375      2.446408     2.929544      3.162804   \n",
       "370     2.096609      2.094368      2.364857     1.836433      1.703992   \n",
       "371     5.740503      3.752384      2.974340     3.547407      4.102953   \n",
       "372     2.476443      2.374693      2.490436     3.049023      2.752978   \n",
       "373     2.598962      2.870775      2.328405     2.499386      2.658134   \n",
       "\n",
       "     kurtosis_F7  kurtosis_FP1  \n",
       "0       2.092215      3.008556  \n",
       "1       3.751193      3.726647  \n",
       "2       3.541482      2.820758  \n",
       "3       2.523738      2.288575  \n",
       "4       2.437741      2.699543  \n",
       "..           ...           ...  \n",
       "369     2.626943      2.396528  \n",
       "370     1.977626      1.606735  \n",
       "371     3.549382      2.297193  \n",
       "372     2.950096      2.023796  \n",
       "373     2.477948      2.484826  \n",
       "\n",
       "[374 rows x 450 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef_ex =pd.read_hdf('../../volume-ceph/preprocessed-ml/extracted_features_001_29_jc_mmn.h5')\n",
    "ef_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374, 450)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hjorth_complexity_O2</th>\n",
       "      <th>hjorth_complexity_O1</th>\n",
       "      <th>hjorth_complexity_OZ</th>\n",
       "      <th>hjorth_complexity_PZ</th>\n",
       "      <th>hjorth_complexity_P4</th>\n",
       "      <th>hjorth_complexity_CP4</th>\n",
       "      <th>hjorth_complexity_P8</th>\n",
       "      <th>hjorth_complexity_C4</th>\n",
       "      <th>hjorth_complexity_TP8</th>\n",
       "      <th>hjorth_complexity_T8</th>\n",
       "      <th>...</th>\n",
       "      <th>kurtosis_FZ</th>\n",
       "      <th>kurtosis_F4</th>\n",
       "      <th>kurtosis_F8</th>\n",
       "      <th>kurtosis_T7</th>\n",
       "      <th>kurtosis_FT7</th>\n",
       "      <th>kurtosis_FC3</th>\n",
       "      <th>kurtosis_F3</th>\n",
       "      <th>kurtosis_FP2</th>\n",
       "      <th>kurtosis_F7</th>\n",
       "      <th>kurtosis_FP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.120505</td>\n",
       "      <td>3.730505</td>\n",
       "      <td>3.205375</td>\n",
       "      <td>3.529707</td>\n",
       "      <td>3.445155</td>\n",
       "      <td>3.532043</td>\n",
       "      <td>4.100093</td>\n",
       "      <td>3.047061</td>\n",
       "      <td>3.213816</td>\n",
       "      <td>3.851944</td>\n",
       "      <td>...</td>\n",
       "      <td>2.399696</td>\n",
       "      <td>6.176483</td>\n",
       "      <td>3.124231</td>\n",
       "      <td>2.249034</td>\n",
       "      <td>2.059224</td>\n",
       "      <td>3.278414</td>\n",
       "      <td>2.542662</td>\n",
       "      <td>3.239702</td>\n",
       "      <td>3.177960</td>\n",
       "      <td>3.115319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.566804</td>\n",
       "      <td>4.194747</td>\n",
       "      <td>5.452748</td>\n",
       "      <td>4.920088</td>\n",
       "      <td>2.759034</td>\n",
       "      <td>3.282675</td>\n",
       "      <td>7.387417</td>\n",
       "      <td>2.953358</td>\n",
       "      <td>3.860556</td>\n",
       "      <td>4.568681</td>\n",
       "      <td>...</td>\n",
       "      <td>2.620529</td>\n",
       "      <td>2.444163</td>\n",
       "      <td>3.247432</td>\n",
       "      <td>2.426343</td>\n",
       "      <td>2.239892</td>\n",
       "      <td>2.861497</td>\n",
       "      <td>2.322857</td>\n",
       "      <td>2.623000</td>\n",
       "      <td>3.227037</td>\n",
       "      <td>3.819862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.006311</td>\n",
       "      <td>7.328448</td>\n",
       "      <td>4.785770</td>\n",
       "      <td>4.068938</td>\n",
       "      <td>2.300908</td>\n",
       "      <td>6.936230</td>\n",
       "      <td>5.945792</td>\n",
       "      <td>2.879884</td>\n",
       "      <td>2.776556</td>\n",
       "      <td>8.107701</td>\n",
       "      <td>...</td>\n",
       "      <td>3.169681</td>\n",
       "      <td>2.256984</td>\n",
       "      <td>2.858533</td>\n",
       "      <td>2.133400</td>\n",
       "      <td>2.137958</td>\n",
       "      <td>2.634927</td>\n",
       "      <td>2.332557</td>\n",
       "      <td>2.798153</td>\n",
       "      <td>2.382952</td>\n",
       "      <td>2.626738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.939739</td>\n",
       "      <td>2.679574</td>\n",
       "      <td>3.140329</td>\n",
       "      <td>3.602519</td>\n",
       "      <td>2.480139</td>\n",
       "      <td>3.737771</td>\n",
       "      <td>3.495600</td>\n",
       "      <td>4.560246</td>\n",
       "      <td>4.933089</td>\n",
       "      <td>9.273948</td>\n",
       "      <td>...</td>\n",
       "      <td>2.971585</td>\n",
       "      <td>3.991573</td>\n",
       "      <td>2.609726</td>\n",
       "      <td>2.063039</td>\n",
       "      <td>2.559048</td>\n",
       "      <td>2.452298</td>\n",
       "      <td>2.310617</td>\n",
       "      <td>2.410712</td>\n",
       "      <td>1.924318</td>\n",
       "      <td>2.442920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.401915</td>\n",
       "      <td>2.684335</td>\n",
       "      <td>4.923735</td>\n",
       "      <td>5.330649</td>\n",
       "      <td>4.008512</td>\n",
       "      <td>4.505154</td>\n",
       "      <td>3.344369</td>\n",
       "      <td>4.876172</td>\n",
       "      <td>4.154387</td>\n",
       "      <td>5.325330</td>\n",
       "      <td>...</td>\n",
       "      <td>3.636426</td>\n",
       "      <td>2.612162</td>\n",
       "      <td>2.347731</td>\n",
       "      <td>3.301192</td>\n",
       "      <td>2.597156</td>\n",
       "      <td>2.944806</td>\n",
       "      <td>2.062676</td>\n",
       "      <td>3.018968</td>\n",
       "      <td>2.293102</td>\n",
       "      <td>2.368643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>2.890692</td>\n",
       "      <td>3.448004</td>\n",
       "      <td>3.570491</td>\n",
       "      <td>3.772927</td>\n",
       "      <td>2.480316</td>\n",
       "      <td>3.177406</td>\n",
       "      <td>2.318948</td>\n",
       "      <td>2.746175</td>\n",
       "      <td>2.339679</td>\n",
       "      <td>4.105380</td>\n",
       "      <td>...</td>\n",
       "      <td>2.359276</td>\n",
       "      <td>6.614177</td>\n",
       "      <td>3.014793</td>\n",
       "      <td>3.135483</td>\n",
       "      <td>2.086609</td>\n",
       "      <td>2.772631</td>\n",
       "      <td>2.740312</td>\n",
       "      <td>5.043128</td>\n",
       "      <td>5.457685</td>\n",
       "      <td>9.711739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>2.921146</td>\n",
       "      <td>3.324517</td>\n",
       "      <td>3.498953</td>\n",
       "      <td>2.927086</td>\n",
       "      <td>2.792203</td>\n",
       "      <td>3.008127</td>\n",
       "      <td>4.481938</td>\n",
       "      <td>2.724597</td>\n",
       "      <td>5.270908</td>\n",
       "      <td>3.604442</td>\n",
       "      <td>...</td>\n",
       "      <td>3.870975</td>\n",
       "      <td>2.558482</td>\n",
       "      <td>2.913526</td>\n",
       "      <td>2.537148</td>\n",
       "      <td>2.128364</td>\n",
       "      <td>2.370526</td>\n",
       "      <td>2.014445</td>\n",
       "      <td>2.726510</td>\n",
       "      <td>2.313950</td>\n",
       "      <td>7.310882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>3.851551</td>\n",
       "      <td>3.329561</td>\n",
       "      <td>4.851749</td>\n",
       "      <td>5.490593</td>\n",
       "      <td>2.328013</td>\n",
       "      <td>3.324403</td>\n",
       "      <td>5.392880</td>\n",
       "      <td>3.696231</td>\n",
       "      <td>3.889106</td>\n",
       "      <td>3.913235</td>\n",
       "      <td>...</td>\n",
       "      <td>3.428506</td>\n",
       "      <td>3.612941</td>\n",
       "      <td>2.799006</td>\n",
       "      <td>2.608251</td>\n",
       "      <td>2.601824</td>\n",
       "      <td>2.435638</td>\n",
       "      <td>2.432502</td>\n",
       "      <td>2.339043</td>\n",
       "      <td>2.849219</td>\n",
       "      <td>2.841555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>4.444722</td>\n",
       "      <td>5.786780</td>\n",
       "      <td>5.630836</td>\n",
       "      <td>4.795795</td>\n",
       "      <td>2.304020</td>\n",
       "      <td>7.416496</td>\n",
       "      <td>5.115721</td>\n",
       "      <td>4.855955</td>\n",
       "      <td>2.663749</td>\n",
       "      <td>3.914910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.277445</td>\n",
       "      <td>2.843975</td>\n",
       "      <td>2.191248</td>\n",
       "      <td>2.360067</td>\n",
       "      <td>2.467876</td>\n",
       "      <td>2.512492</td>\n",
       "      <td>2.288658</td>\n",
       "      <td>2.936312</td>\n",
       "      <td>2.484780</td>\n",
       "      <td>2.551581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>3.080230</td>\n",
       "      <td>2.429913</td>\n",
       "      <td>2.088846</td>\n",
       "      <td>1.806167</td>\n",
       "      <td>1.543953</td>\n",
       "      <td>4.643841</td>\n",
       "      <td>2.757513</td>\n",
       "      <td>2.162098</td>\n",
       "      <td>4.287201</td>\n",
       "      <td>2.988736</td>\n",
       "      <td>...</td>\n",
       "      <td>2.902446</td>\n",
       "      <td>4.149579</td>\n",
       "      <td>3.310786</td>\n",
       "      <td>3.160118</td>\n",
       "      <td>3.116579</td>\n",
       "      <td>2.717108</td>\n",
       "      <td>2.550682</td>\n",
       "      <td>2.978461</td>\n",
       "      <td>2.873703</td>\n",
       "      <td>3.078165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1478 rows × 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hjorth_complexity_O2  hjorth_complexity_O1  hjorth_complexity_OZ  \\\n",
       "0                 7.120505              3.730505              3.205375   \n",
       "1                 5.566804              4.194747              5.452748   \n",
       "2                 3.006311              7.328448              4.785770   \n",
       "3                 2.939739              2.679574              3.140329   \n",
       "4                 3.401915              2.684335              4.923735   \n",
       "...                    ...                   ...                   ...   \n",
       "1473              2.890692              3.448004              3.570491   \n",
       "1474              2.921146              3.324517              3.498953   \n",
       "1475              3.851551              3.329561              4.851749   \n",
       "1476              4.444722              5.786780              5.630836   \n",
       "1477              3.080230              2.429913              2.088846   \n",
       "\n",
       "      hjorth_complexity_PZ  hjorth_complexity_P4  hjorth_complexity_CP4  \\\n",
       "0                 3.529707              3.445155               3.532043   \n",
       "1                 4.920088              2.759034               3.282675   \n",
       "2                 4.068938              2.300908               6.936230   \n",
       "3                 3.602519              2.480139               3.737771   \n",
       "4                 5.330649              4.008512               4.505154   \n",
       "...                    ...                   ...                    ...   \n",
       "1473              3.772927              2.480316               3.177406   \n",
       "1474              2.927086              2.792203               3.008127   \n",
       "1475              5.490593              2.328013               3.324403   \n",
       "1476              4.795795              2.304020               7.416496   \n",
       "1477              1.806167              1.543953               4.643841   \n",
       "\n",
       "      hjorth_complexity_P8  hjorth_complexity_C4  hjorth_complexity_TP8  \\\n",
       "0                 4.100093              3.047061               3.213816   \n",
       "1                 7.387417              2.953358               3.860556   \n",
       "2                 5.945792              2.879884               2.776556   \n",
       "3                 3.495600              4.560246               4.933089   \n",
       "4                 3.344369              4.876172               4.154387   \n",
       "...                    ...                   ...                    ...   \n",
       "1473              2.318948              2.746175               2.339679   \n",
       "1474              4.481938              2.724597               5.270908   \n",
       "1475              5.392880              3.696231               3.889106   \n",
       "1476              5.115721              4.855955               2.663749   \n",
       "1477              2.757513              2.162098               4.287201   \n",
       "\n",
       "      hjorth_complexity_T8  ...  kurtosis_FZ  kurtosis_F4  kurtosis_F8  \\\n",
       "0                 3.851944  ...     2.399696     6.176483     3.124231   \n",
       "1                 4.568681  ...     2.620529     2.444163     3.247432   \n",
       "2                 8.107701  ...     3.169681     2.256984     2.858533   \n",
       "3                 9.273948  ...     2.971585     3.991573     2.609726   \n",
       "4                 5.325330  ...     3.636426     2.612162     2.347731   \n",
       "...                    ...  ...          ...          ...          ...   \n",
       "1473              4.105380  ...     2.359276     6.614177     3.014793   \n",
       "1474              3.604442  ...     3.870975     2.558482     2.913526   \n",
       "1475              3.913235  ...     3.428506     3.612941     2.799006   \n",
       "1476              3.914910  ...     2.277445     2.843975     2.191248   \n",
       "1477              2.988736  ...     2.902446     4.149579     3.310786   \n",
       "\n",
       "      kurtosis_T7  kurtosis_FT7  kurtosis_FC3  kurtosis_F3  kurtosis_FP2  \\\n",
       "0        2.249034      2.059224      3.278414     2.542662      3.239702   \n",
       "1        2.426343      2.239892      2.861497     2.322857      2.623000   \n",
       "2        2.133400      2.137958      2.634927     2.332557      2.798153   \n",
       "3        2.063039      2.559048      2.452298     2.310617      2.410712   \n",
       "4        3.301192      2.597156      2.944806     2.062676      3.018968   \n",
       "...           ...           ...           ...          ...           ...   \n",
       "1473     3.135483      2.086609      2.772631     2.740312      5.043128   \n",
       "1474     2.537148      2.128364      2.370526     2.014445      2.726510   \n",
       "1475     2.608251      2.601824      2.435638     2.432502      2.339043   \n",
       "1476     2.360067      2.467876      2.512492     2.288658      2.936312   \n",
       "1477     3.160118      3.116579      2.717108     2.550682      2.978461   \n",
       "\n",
       "      kurtosis_F7  kurtosis_FP1  \n",
       "0        3.177960      3.115319  \n",
       "1        3.227037      3.819862  \n",
       "2        2.382952      2.626738  \n",
       "3        1.924318      2.442920  \n",
       "4        2.293102      2.368643  \n",
       "...           ...           ...  \n",
       "1473     5.457685      9.711739  \n",
       "1474     2.313950      7.310882  \n",
       "1475     2.849219      2.841555  \n",
       "1476     2.484780      2.551581  \n",
       "1477     2.873703      3.078165  \n",
       "\n",
       "[1478 rows x 450 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef_ex2 =pd.read_hdf('../../volume-ceph/preprocessed-ml/extracted_features_742-421-41m-mr-mmn39.h5')\n",
    "ef_ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478, 450)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef_ex2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hjorth_complexity_O2', 'hjorth_complexity_O1', 'hjorth_complexity_OZ',\n",
       "       'hjorth_complexity_PZ', 'hjorth_complexity_P4', 'hjorth_complexity_CP4',\n",
       "       'hjorth_complexity_P8', 'hjorth_complexity_C4', 'hjorth_complexity_TP8',\n",
       "       'hjorth_complexity_T8',\n",
       "       ...\n",
       "       'kurtosis_FZ', 'kurtosis_F4', 'kurtosis_F8', 'kurtosis_T7',\n",
       "       'kurtosis_FT7', 'kurtosis_FC3', 'kurtosis_F3', 'kurtosis_FP2',\n",
       "       'kurtosis_F7', 'kurtosis_FP1'],\n",
       "      dtype='object', length=450)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef_ex2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_ex2.loc['Mean'] = ef_ex[ef_ex2.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hjorth_complexity_O2</th>\n",
       "      <th>hjorth_complexity_O1</th>\n",
       "      <th>hjorth_complexity_OZ</th>\n",
       "      <th>hjorth_complexity_PZ</th>\n",
       "      <th>hjorth_complexity_P4</th>\n",
       "      <th>hjorth_complexity_CP4</th>\n",
       "      <th>hjorth_complexity_P8</th>\n",
       "      <th>hjorth_complexity_C4</th>\n",
       "      <th>hjorth_complexity_TP8</th>\n",
       "      <th>hjorth_complexity_T8</th>\n",
       "      <th>...</th>\n",
       "      <th>kurtosis_FZ</th>\n",
       "      <th>kurtosis_F4</th>\n",
       "      <th>kurtosis_F8</th>\n",
       "      <th>kurtosis_T7</th>\n",
       "      <th>kurtosis_FT7</th>\n",
       "      <th>kurtosis_FC3</th>\n",
       "      <th>kurtosis_F3</th>\n",
       "      <th>kurtosis_FP2</th>\n",
       "      <th>kurtosis_F7</th>\n",
       "      <th>kurtosis_FP1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.120505</td>\n",
       "      <td>3.730505</td>\n",
       "      <td>3.205375</td>\n",
       "      <td>3.529707</td>\n",
       "      <td>3.445155</td>\n",
       "      <td>3.532043</td>\n",
       "      <td>4.100093</td>\n",
       "      <td>3.047061</td>\n",
       "      <td>3.213816</td>\n",
       "      <td>3.851944</td>\n",
       "      <td>...</td>\n",
       "      <td>2.399696</td>\n",
       "      <td>6.176483</td>\n",
       "      <td>3.124231</td>\n",
       "      <td>2.249034</td>\n",
       "      <td>2.059224</td>\n",
       "      <td>3.278414</td>\n",
       "      <td>2.542662</td>\n",
       "      <td>3.239702</td>\n",
       "      <td>3.177960</td>\n",
       "      <td>3.115319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.566804</td>\n",
       "      <td>4.194747</td>\n",
       "      <td>5.452748</td>\n",
       "      <td>4.920088</td>\n",
       "      <td>2.759034</td>\n",
       "      <td>3.282675</td>\n",
       "      <td>7.387417</td>\n",
       "      <td>2.953358</td>\n",
       "      <td>3.860556</td>\n",
       "      <td>4.568681</td>\n",
       "      <td>...</td>\n",
       "      <td>2.620529</td>\n",
       "      <td>2.444163</td>\n",
       "      <td>3.247432</td>\n",
       "      <td>2.426343</td>\n",
       "      <td>2.239892</td>\n",
       "      <td>2.861497</td>\n",
       "      <td>2.322857</td>\n",
       "      <td>2.623000</td>\n",
       "      <td>3.227037</td>\n",
       "      <td>3.819862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.006311</td>\n",
       "      <td>7.328448</td>\n",
       "      <td>4.785770</td>\n",
       "      <td>4.068938</td>\n",
       "      <td>2.300908</td>\n",
       "      <td>6.936230</td>\n",
       "      <td>5.945792</td>\n",
       "      <td>2.879884</td>\n",
       "      <td>2.776556</td>\n",
       "      <td>8.107701</td>\n",
       "      <td>...</td>\n",
       "      <td>3.169681</td>\n",
       "      <td>2.256984</td>\n",
       "      <td>2.858533</td>\n",
       "      <td>2.133400</td>\n",
       "      <td>2.137958</td>\n",
       "      <td>2.634927</td>\n",
       "      <td>2.332557</td>\n",
       "      <td>2.798153</td>\n",
       "      <td>2.382952</td>\n",
       "      <td>2.626738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.939739</td>\n",
       "      <td>2.679574</td>\n",
       "      <td>3.140329</td>\n",
       "      <td>3.602519</td>\n",
       "      <td>2.480139</td>\n",
       "      <td>3.737771</td>\n",
       "      <td>3.495600</td>\n",
       "      <td>4.560246</td>\n",
       "      <td>4.933089</td>\n",
       "      <td>9.273948</td>\n",
       "      <td>...</td>\n",
       "      <td>2.971585</td>\n",
       "      <td>3.991573</td>\n",
       "      <td>2.609726</td>\n",
       "      <td>2.063039</td>\n",
       "      <td>2.559048</td>\n",
       "      <td>2.452298</td>\n",
       "      <td>2.310617</td>\n",
       "      <td>2.410712</td>\n",
       "      <td>1.924318</td>\n",
       "      <td>2.442920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.401915</td>\n",
       "      <td>2.684335</td>\n",
       "      <td>4.923735</td>\n",
       "      <td>5.330649</td>\n",
       "      <td>4.008512</td>\n",
       "      <td>4.505154</td>\n",
       "      <td>3.344369</td>\n",
       "      <td>4.876172</td>\n",
       "      <td>4.154387</td>\n",
       "      <td>5.325330</td>\n",
       "      <td>...</td>\n",
       "      <td>3.636426</td>\n",
       "      <td>2.612162</td>\n",
       "      <td>2.347731</td>\n",
       "      <td>3.301192</td>\n",
       "      <td>2.597156</td>\n",
       "      <td>2.944806</td>\n",
       "      <td>2.062676</td>\n",
       "      <td>3.018968</td>\n",
       "      <td>2.293102</td>\n",
       "      <td>2.368643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>3.851551</td>\n",
       "      <td>3.329561</td>\n",
       "      <td>4.851749</td>\n",
       "      <td>5.490593</td>\n",
       "      <td>2.328013</td>\n",
       "      <td>3.324403</td>\n",
       "      <td>5.392880</td>\n",
       "      <td>3.696231</td>\n",
       "      <td>3.889106</td>\n",
       "      <td>3.913235</td>\n",
       "      <td>...</td>\n",
       "      <td>3.428506</td>\n",
       "      <td>3.612941</td>\n",
       "      <td>2.799006</td>\n",
       "      <td>2.608251</td>\n",
       "      <td>2.601824</td>\n",
       "      <td>2.435638</td>\n",
       "      <td>2.432502</td>\n",
       "      <td>2.339043</td>\n",
       "      <td>2.849219</td>\n",
       "      <td>2.841555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>4.444722</td>\n",
       "      <td>5.786780</td>\n",
       "      <td>5.630836</td>\n",
       "      <td>4.795795</td>\n",
       "      <td>2.304020</td>\n",
       "      <td>7.416496</td>\n",
       "      <td>5.115721</td>\n",
       "      <td>4.855955</td>\n",
       "      <td>2.663749</td>\n",
       "      <td>3.914910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.277445</td>\n",
       "      <td>2.843975</td>\n",
       "      <td>2.191248</td>\n",
       "      <td>2.360067</td>\n",
       "      <td>2.467876</td>\n",
       "      <td>2.512492</td>\n",
       "      <td>2.288658</td>\n",
       "      <td>2.936312</td>\n",
       "      <td>2.484780</td>\n",
       "      <td>2.551581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>3.080230</td>\n",
       "      <td>2.429913</td>\n",
       "      <td>2.088846</td>\n",
       "      <td>1.806167</td>\n",
       "      <td>1.543953</td>\n",
       "      <td>4.643841</td>\n",
       "      <td>2.757513</td>\n",
       "      <td>2.162098</td>\n",
       "      <td>4.287201</td>\n",
       "      <td>2.988736</td>\n",
       "      <td>...</td>\n",
       "      <td>2.902446</td>\n",
       "      <td>4.149579</td>\n",
       "      <td>3.310786</td>\n",
       "      <td>3.160118</td>\n",
       "      <td>3.116579</td>\n",
       "      <td>2.717108</td>\n",
       "      <td>2.550682</td>\n",
       "      <td>2.978461</td>\n",
       "      <td>2.873703</td>\n",
       "      <td>3.078165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>1552.133942</td>\n",
       "      <td>1544.735496</td>\n",
       "      <td>1331.190401</td>\n",
       "      <td>1751.694362</td>\n",
       "      <td>822.893334</td>\n",
       "      <td>1445.111655</td>\n",
       "      <td>1473.329026</td>\n",
       "      <td>1405.212654</td>\n",
       "      <td>1004.485512</td>\n",
       "      <td>1757.797518</td>\n",
       "      <td>...</td>\n",
       "      <td>1483.461514</td>\n",
       "      <td>1138.566501</td>\n",
       "      <td>1077.565461</td>\n",
       "      <td>1073.113956</td>\n",
       "      <td>1145.476094</td>\n",
       "      <td>1031.328934</td>\n",
       "      <td>1030.295444</td>\n",
       "      <td>1080.668118</td>\n",
       "      <td>1119.322856</td>\n",
       "      <td>1057.238064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>4.150091</td>\n",
       "      <td>4.130309</td>\n",
       "      <td>3.559333</td>\n",
       "      <td>4.683675</td>\n",
       "      <td>2.200250</td>\n",
       "      <td>3.863935</td>\n",
       "      <td>3.939382</td>\n",
       "      <td>3.757253</td>\n",
       "      <td>2.685790</td>\n",
       "      <td>4.699993</td>\n",
       "      <td>...</td>\n",
       "      <td>3.966475</td>\n",
       "      <td>3.044295</td>\n",
       "      <td>2.881191</td>\n",
       "      <td>2.869289</td>\n",
       "      <td>3.062770</td>\n",
       "      <td>2.757564</td>\n",
       "      <td>2.754801</td>\n",
       "      <td>2.889487</td>\n",
       "      <td>2.992842</td>\n",
       "      <td>2.826840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows × 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hjorth_complexity_O2  hjorth_complexity_O1  hjorth_complexity_OZ  \\\n",
       "0                  7.120505              3.730505              3.205375   \n",
       "1                  5.566804              4.194747              5.452748   \n",
       "2                  3.006311              7.328448              4.785770   \n",
       "3                  2.939739              2.679574              3.140329   \n",
       "4                  3.401915              2.684335              4.923735   \n",
       "...                     ...                   ...                   ...   \n",
       "1475               3.851551              3.329561              4.851749   \n",
       "1476               4.444722              5.786780              5.630836   \n",
       "1477               3.080230              2.429913              2.088846   \n",
       "Total           1552.133942           1544.735496           1331.190401   \n",
       "Mean               4.150091              4.130309              3.559333   \n",
       "\n",
       "       hjorth_complexity_PZ  hjorth_complexity_P4  hjorth_complexity_CP4  \\\n",
       "0                  3.529707              3.445155               3.532043   \n",
       "1                  4.920088              2.759034               3.282675   \n",
       "2                  4.068938              2.300908               6.936230   \n",
       "3                  3.602519              2.480139               3.737771   \n",
       "4                  5.330649              4.008512               4.505154   \n",
       "...                     ...                   ...                    ...   \n",
       "1475               5.490593              2.328013               3.324403   \n",
       "1476               4.795795              2.304020               7.416496   \n",
       "1477               1.806167              1.543953               4.643841   \n",
       "Total           1751.694362            822.893334            1445.111655   \n",
       "Mean               4.683675              2.200250               3.863935   \n",
       "\n",
       "       hjorth_complexity_P8  hjorth_complexity_C4  hjorth_complexity_TP8  \\\n",
       "0                  4.100093              3.047061               3.213816   \n",
       "1                  7.387417              2.953358               3.860556   \n",
       "2                  5.945792              2.879884               2.776556   \n",
       "3                  3.495600              4.560246               4.933089   \n",
       "4                  3.344369              4.876172               4.154387   \n",
       "...                     ...                   ...                    ...   \n",
       "1475               5.392880              3.696231               3.889106   \n",
       "1476               5.115721              4.855955               2.663749   \n",
       "1477               2.757513              2.162098               4.287201   \n",
       "Total           1473.329026           1405.212654            1004.485512   \n",
       "Mean               3.939382              3.757253               2.685790   \n",
       "\n",
       "       hjorth_complexity_T8  ...  kurtosis_FZ  kurtosis_F4  kurtosis_F8  \\\n",
       "0                  3.851944  ...     2.399696     6.176483     3.124231   \n",
       "1                  4.568681  ...     2.620529     2.444163     3.247432   \n",
       "2                  8.107701  ...     3.169681     2.256984     2.858533   \n",
       "3                  9.273948  ...     2.971585     3.991573     2.609726   \n",
       "4                  5.325330  ...     3.636426     2.612162     2.347731   \n",
       "...                     ...  ...          ...          ...          ...   \n",
       "1475               3.913235  ...     3.428506     3.612941     2.799006   \n",
       "1476               3.914910  ...     2.277445     2.843975     2.191248   \n",
       "1477               2.988736  ...     2.902446     4.149579     3.310786   \n",
       "Total           1757.797518  ...  1483.461514  1138.566501  1077.565461   \n",
       "Mean               4.699993  ...     3.966475     3.044295     2.881191   \n",
       "\n",
       "       kurtosis_T7  kurtosis_FT7  kurtosis_FC3  kurtosis_F3  kurtosis_FP2  \\\n",
       "0         2.249034      2.059224      3.278414     2.542662      3.239702   \n",
       "1         2.426343      2.239892      2.861497     2.322857      2.623000   \n",
       "2         2.133400      2.137958      2.634927     2.332557      2.798153   \n",
       "3         2.063039      2.559048      2.452298     2.310617      2.410712   \n",
       "4         3.301192      2.597156      2.944806     2.062676      3.018968   \n",
       "...            ...           ...           ...          ...           ...   \n",
       "1475      2.608251      2.601824      2.435638     2.432502      2.339043   \n",
       "1476      2.360067      2.467876      2.512492     2.288658      2.936312   \n",
       "1477      3.160118      3.116579      2.717108     2.550682      2.978461   \n",
       "Total  1073.113956   1145.476094   1031.328934  1030.295444   1080.668118   \n",
       "Mean      2.869289      3.062770      2.757564     2.754801      2.889487   \n",
       "\n",
       "       kurtosis_F7  kurtosis_FP1  \n",
       "0         3.177960      3.115319  \n",
       "1         3.227037      3.819862  \n",
       "2         2.382952      2.626738  \n",
       "3         1.924318      2.442920  \n",
       "4         2.293102      2.368643  \n",
       "...            ...           ...  \n",
       "1475      2.849219      2.841555  \n",
       "1476      2.484780      2.551581  \n",
       "1477      2.873703      3.078165  \n",
       "Total  1119.322856   1057.238064  \n",
       "Mean      2.992842      2.826840  \n",
       "\n",
       "[1480 rows x 450 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef_ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(df, prop, x, y):\n",
    "    sns.set()\n",
    "    ax = sns.scatterplot(x=x, y=y, hue=prop, palette='RdBu', data=df)\n",
    "\n",
    "    norm = plt.Normalize(df[prop].min(), df[prop].max())\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"RdBu\", norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    # Remove the legend and add a colorbar\n",
    "    ax.get_legend().remove()\n",
    "    ax.figure.colorbar(sm)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.46 s, sys: 1.12 s, total: 5.58 s\n",
      "Wall time: 6.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rloader = RegressionsLoader(config.get_directory('preprocessed'), config.get_directory('models'), samples=100)\n",
    "rloader.load()\n",
    "rloader.split()\n",
    "regressions = Regressions(rloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we make predictions with dummy regressors as a simple baseline to see whether other models learn \"something\". From the sklearn docs: \n",
    "\n",
    "> `DummyRegressor` is a regressor that makes predictions using simple rules. This regressor is useful as a simple baseline to compare with other (real) regressors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.86 ms, total: 1.86 ms\n",
      "Wall time: 27.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "regressions.algorithms['dummy'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, rmse, ma, y_test, y_pred =  regressions.algorithms['dummy'].predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.47890061657830585 13.658630142623013 11.007143892410616\n"
     ]
    }
   ],
   "source": [
    "print(score, rmse, ma )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17., 17., 17., ..., 17., 17., 17.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43697"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43697"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_test = np.array(y_test)\n",
    "len(array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    43697.000000\n",
       "mean        24.772493\n",
       "std         11.231626\n",
       "min         10.833333\n",
       "25%         11.100000\n",
       "50%         23.033333\n",
       "75%         35.066667\n",
       "max         41.266667\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred)\n",
    "plt.title('pred of dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So dummy regressor just called everyone 17 months old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 1: Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['rf'].grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, rmsee, ma, y_test, y_pred =  regressions.algorithms['rf'].predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score, rmse, ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['rf'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, rmsee, mae, y_test, y_pred =  regressions.algorithms['rf'].predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score, rmsee, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test)\n",
    "plt.title('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred)\n",
    "plt.title('random forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Linear Support Vector Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of training examples in the training set. According to the sklearn docs: \"The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to datasets with more than a couple of 10000 samples.\" \n",
    "\n",
    "They recommend using a linear SVR for large data sets. Therefore, let's try this first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lsv_result = regressions.algorithms['lsv'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(lsv_result.cv_results_).sort_values('rank_test_score').head(50)\n",
    "cv_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(cv_df, 'mean_test_score', \"param_linearsvr__C\", \"param_linearsvr__epsilon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lsv_gs_result = regressions.algorithms['lsv'].grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsv_gs_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df_gs = pd.DataFrame(lsv_gs_result.cv_results_).sort_values('rank_test_score').head(50)\n",
    "cv_df_gs.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_result(cv_df_gs, 'mean_test_score', \"param_linearsvr__C\", \"param_linearsvr__epsilon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on all data with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['lsv'].best_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, rmsee, mae, y_test, y_pred_lsv =  regressions.algorithms['lsv'].predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score, rmsee, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_lsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_res = pd.DataFrame(data = [y_test, y_pred_lsv])\n",
    "#graph_res = graph_res.reset_index(inplace=True)\n",
    "graph_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(graph_res[:40]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test)\n",
    "plt.plot(y_pred_lsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred_lsv)\n",
    "plt.title('lsv predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: (Non-linear) Support Vector Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try fitting a SVR on a (small) chunk of the training data. The parameter search below is quite small, but a broader search has been done before. However, a more fine-grained search is still necessary. The downside of SVR with a non-linear kernel is that it's very slow to fit and predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nl_srv_result = regressions.algorithms['svr'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_srv_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rs_svr = pd.DataFrame(nl_srv_result.cv_results_).sort_values('rank_test_score')\n",
    "df_rs_svr = df_rs_svr.loc[df_rs_svr['param_svr__gamma'] < 0.0025].head(20)\n",
    "df_rs_svr.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(df_rs_svr, 'mean_test_score', 'param_svr__C', 'param_svr__epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"param_svr__gamma\", y=\"mean_test_score\", data=df_rs_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, rmsee, mae, y_test, y_pred =  regressions.algorithms['svr'].predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score, rmsee, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svr_gs_result = regressions.algorithms['svr'].grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_gs_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs_svr = pd.DataFrame(svr_gs_result.cv_results_).sort_values('rank_test_score')\n",
    "df_gs_svr.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(df_gs_svr, 'mean_test_score', 'param_svr__C', 'param_svr__epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svr_result = regressions.algorithms['svr'].best_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: SGD Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inschatting tijd, mijn computer:\n",
    "    \n",
    "- X min voor een SGD (1 configuratie)\n",
    "- RandomizedSearch: 250 iteraties, 5 folds per iteratie = 1250\n",
    "- 1250 SGD * X = X uur (Schatting met mijn 1 core)\n",
    "\n",
    "Memory usage:\n",
    "- X GB per core?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a SVR is computationally expensive. Therefore, we try prediction with an SGD Regressor. According to the sklearn documentation, it's best to start with a RandomizedSearchCV to find reasonable hyperparameters. Therefore, we start with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_result = regressions.algorithms['sgd'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rs_sgd = pd.DataFrame(sgd_result.cv_results_).sort_values('rank_test_score')\n",
    "df_rs_sgd = df_rs_sgd.loc[\n",
    "    df_rs_sgd['param_sgdregressor__loss'] == 'huber'\n",
    "].sort_values('rank_test_score').head(5000)\n",
    "df_rs_sgd.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"param_sgdregressor__alpha\", y=\"mean_test_score\", data=df_rs_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_gs_result = regressions.algorithms['sgd'].grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_gs_predict = regressions.algorithms['sgd'].predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_gs_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs_sgd = pd.DataFrame(sgd_gs_result.cv_results_).sort_values('rank_test_score')\n",
    "df_gs_sgd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(df_gs_sgd, 'mean_test_score', 'param_sgdregressor__alpha', 'param_sgdregressor__epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['sgd'].best_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Relevance Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to the SVR is the Relevance Vector Machine, also used by Vandenbosch (2018). This isn't included in sklearn, but there are two packages called 'scikit-rvm' and 'sklearn-rvm' using the sklearn API that has implemented this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inschatting tijd, mijn computer:\n",
    "    \n",
    "- 4 min voor een RVR (1 configuratie)\n",
    "- RandomizedSearch: 250 iteraties, 5 folds per iteratie = 1250\n",
    "- 1250 RVR * 4 min = 84 uur (Schatting met mijn 2 cores)\n",
    "\n",
    "Memory usage:\n",
    "- 4 GB per core?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emrvr_result = regressions.algorithms['emrvr'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emrvr_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on best SVR parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['emrvr'].best_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inschatting tijd, mijn computer: \n",
    "\n",
    "- 4 min voor 1 RVR (1 configuratie). \n",
    "- GridSearch: 50 configuraties, 5 folds per configuratie = 250\n",
    "- 250 RVR * 4 min = 17 uur (Schatting met mijn 2 cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    TODO(wvxvw): The code below seems bogus.\n",
    "    The pipeline uses unexpected kernel.\n",
    "    I don't know why it does this. Need more info\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_rvm import EMRVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "parameters = {'svr__epsilon': [4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8],\n",
    "              'svr__gamma': ['scale', 'auto', 0.0015]\n",
    "}\n",
    "\n",
    "pipe  = make_pipeline(StandardScaler(),\n",
    "                      SVR(verbose=True, kernel='rbf'))\n",
    "\n",
    "RVR_gridsearch = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "RVR_gridsearch.fit(chunked_X_train[0], chunked_y_train[0])\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'RVR_gridsearch.joblib')\n",
    "dump(RVR_gridsearch, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RVR_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "try:\n",
    "    RVR_gridsearch\n",
    "except:\n",
    "    RVR_gridsearch = load(os.path.join(PATH_MODELS, 'RVR_gridsearch.joblib'))    \n",
    "\n",
    "# Update verbosity\n",
    "RVR_gridsearch.verbose = 0\n",
    "\n",
    "# R2\n",
    "score = RVR_gridsearch.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = RVR_gridsearch.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"Performance of Relevance Vector Regressor: R-squared = {score}, RMSE = {rmse} and MAE = {mae}.\")\n",
    "\n",
    "del rvr_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressions.algorithms['emrvr'].predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressions.algorithms['sgd'].predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = NnOptimizer(rloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot NN training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    \"\"\" Plots the MSE, RMSE, and MAE loss for the training and validation data over time \"\"\"\n",
    "    \n",
    "    %matplotlib inline\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(12, 12), dpi=200)\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='training data')  \n",
    "    min_loss = min(history.history['val_loss'])\n",
    "    val_plot1 = ax1.plot(history.history['val_loss'], label='validation data')\n",
    "    ax1.axhline(y = min_loss, color = val_plot1[0].get_color(), linestyle='--') \n",
    "    x0,x1 = ax1.get_xlim()\n",
    "    ax1.text(x1, min_loss, \"{:.2f}\".format(min_loss), ha='left', va='center')\n",
    "    ax1.set_title('MSE loss')\n",
    "    ax1.set_ylabel('MSE')\n",
    "    ax1.set_xlabel('epochs')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['root_mean_squared_error'], label='training data')\n",
    "    min_loss = min(history.history['val_root_mean_squared_error'])\n",
    "    val_plot2 = ax2.plot(history.history['val_root_mean_squared_error'], label='validation data')\n",
    "    ax2.axhline(y = min_loss, color=val_plot2[0].get_color(), linestyle='--') \n",
    "    x0,x1 = ax2.get_xlim()\n",
    "    ax2.text(x1, min_loss, '{:.2f}'.format(min_loss), ha='left', va='center')\n",
    "    ax2.set_title('RMSE loss')\n",
    "    ax2.set_ylabel('RMSE')\n",
    "    ax2.set_xlabel('epochs')\n",
    "    ax2.legend()\n",
    "    \n",
    "    ax3.plot(history.history['mean_absolute_error'], label='training data')    \n",
    "    min_loss = min(history.history['val_mean_absolute_error'])\n",
    "    val_plot3 = ax3.plot(history.history['val_mean_absolute_error'], label='validation data')\n",
    "    ax3.axhline(y=min_loss, color=val_plot3[0].get_color(), linestyle='--') \n",
    "    x0,x1 = ax3.get_xlim()\n",
    "    ax3.text(x1, min_loss, \"{:.2f}\".format(min_loss), ha='left', va='center')\n",
    "    ax3.set_title('MAE loss')\n",
    "    ax3.set_ylabel('MAE')\n",
    "    ax3.set_xlabel('epochs')\n",
    "    ax3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has to be repeated multiple times because the output from optimizer prevents proper display of the plot\n",
    "history = optimizer.fit_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer.fit_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer.fit_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer.fit_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer.fit_model(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(optimizer.optimization_params):\n",
    "    prediction, rmse, mae = optimizer.predict(i)\n",
    "    print('\\n'.join((\n",
    "        f'Performance of simple FC neural network regressor #{i} ({p}):',\n",
    "        f'  RMSE: {rmse}',\n",
    "        f'  MAE: {mae}.',\n",
    "    )))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
