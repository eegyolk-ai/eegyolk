{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applies Deep Learning to ePodium dataset for prediction of Dyslexia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Precision, BinaryAccuracy, Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from functions import epodium\n",
    "from models.dnn import fully_connected_model\n",
    "from models.transformer import TransformerModel\n",
    "\n",
    "import local_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose which processed data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70070d4da344f57b0830e3a3fa0e1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='processing:', options=('autoreject', 'ransac'), value='autoreject')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processing_method_widget = ipywidgets.RadioButtons(options=['autoreject', 'ransac'], description='processing:')\n",
    "display(processing_method_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(processing_method_widget.value == \"autoreject\"):\n",
    "    path_processed = local_paths.ePod_processed_autoreject\n",
    "if(processing_method_widget.value == \"ransac\"):\n",
    "    path_processed = local_paths.ePod_processed_ransac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Preparing data as input to the deep learning models.\n",
    "\n",
    "#### Check number of clean epochs* in each file after processing and split into train and test dataset\n",
    "\n",
    "*In the context of electroencephalography (EEG), *epochs* are EEG segments in which an event occurs. During processing, the epochs are chosen to be 1 second in which the event occurs at 0.2s. In the context of deep learning, *epochs* are iterations over the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed: 214, bad: 40\n",
      "174 files have enough epochs for analysis.\n",
      "The dataset is split up into 129 train and 45 test experiments\n"
     ]
    }
   ],
   "source": [
    "train, test = epodium.train_test_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Iterator Sequence as input to feed the model\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 32, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequence = epodium.EvokedDataIterator(train)\n",
    "test_sequence = epodium.EvokedDataIterator(test)\n",
    "\n",
    "x, y = train_sequence.__getitem__(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose Deep Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_widget = ipywidgets.RadioButtons(options=['fully_connected', 'transformer'], description='processing:')\n",
    "display(model_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train model\n",
    "\n",
    "The data is an *evoked* or *ERP* from a participant in the ePodium experiment. 60 EEG signals were averaged from -0.2 to +0.8 seconds after onset of an event. This is done for each of the 12 event types seperately.\n",
    "\n",
    "__dimensions__: \n",
    "+ x (batches, timesteps, channels)\n",
    "+ y (batches, labels)\n",
    "\n",
    "__labels__: \n",
    "+ (Sex, At risk of dyslexia, first standard, standard, deviant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel()\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                         loss=BinaryCrossentropy(),\n",
    "                         metrics=[Precision(), BinaryAccuracy(), Recall()])\n",
    "\n",
    "output_filename = 'transformer_model'\n",
    "output_file = os.path.join(local_paths.models, output_filename)\n",
    "checkpointer = ModelCheckpoint(filepath = output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=1200, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=200, min_lr=0.0001, verbose=1)\n",
    "\n",
    "history = model.fit(x=train_sequence,\n",
    "                    validation_data=test_sequence,\n",
    "                    epochs=100,\n",
    "                    callbacks=[checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_paths.models"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
