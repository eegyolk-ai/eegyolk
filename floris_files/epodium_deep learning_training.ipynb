{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applies Deep Learning to ePodium dataset for prediction of Dyslexia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 18:13:45.347971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-07 18:13:45.348010: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-07 18:13:46.641625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-07 18:13:46.641666: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-07 18:13:46.641681: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (floriscpu): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Precision, BinaryAccuracy, Recall\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "from functions import epodium, epodium_deep_learning, display_helper\n",
    "from models.dnn import fully_connected_model\n",
    "from models import transformer\n",
    "\n",
    "import local_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose which processed data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99347b6156848d6a86d75ef7df1ed36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='processing:', options=('autoreject', 'ransac'), value='autoreject')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processing_method_widget = ipywidgets.RadioButtons(options=['autoreject', 'ransac'], \n",
    "                                                   value='autoreject', \n",
    "                                                   description='processing:')\n",
    "display(processing_method_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Preparing data iterator (Sequence) as input to the deep learning models.\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
    "\n",
    "#### Split processed epochs* into train and test sequence.\n",
    "\n",
    "*In the context of electroencephalography (EEG), *epochs* are EEG segments in which an event occurs. During processing, the epochs are chosen to be 1 second in which the event occurs at 0.2s. In the context of deep learning, *epochs* are iterations over the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed: 228, bad: 42\n",
      "186 files have enough epochs for analysis.\n",
      "The dataset is split up into 138 train and 48 test experiments\n"
     ]
    }
   ],
   "source": [
    "if(processing_method_widget.value == \"autoreject\"):\n",
    "    path_processed = local_paths.ePod_processed_autoreject\n",
    "if(processing_method_widget.value == \"ransac\"):\n",
    "    path_processed = local_paths.ePod_processed_ransac\n",
    "\n",
    "train, test = epodium_deep_learning.split_train_test_datasets(path_processed)\n",
    "train_sequence = epodium_deep_learning.EvokedDataIterator(train, path_processed)\n",
    "test_sequence = epodium_deep_learning.EvokedDataIterator(test, path_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "The data is an *evoked* or *ERP* from a participant in the ePodium experiment. 60 EEG signals were averaged from -0.2 to +0.8 seconds after onset of an event. This is done for each of the 12 event types seperately.\n",
    "\n",
    "__dimensions__: \n",
    "+ x (batches, timesteps, channels)\n",
    "+ y (batches, labels)\n",
    "\n",
    "__labels__: \n",
    "+ (Sex, At risk of dyslexia, first standard, standard, deviant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose Deep Learning model\n",
    "\n",
    "TODO check all trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a390f3d565094aaea576a47d08e3887b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Models:', options=('fully_connected', 'transformer', 'new_transformer'), value='fullâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_widget = ipywidgets.RadioButtons(options=['fully_connected', 'transformer', 'new_transformer'],\n",
    "                                       value='fully_connected', \n",
    "                                       description='Models:')\n",
    "display(model_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model: fully_connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 18:13:47.352289: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Paths to save model info\n",
    "base_path = os.path.join(local_paths.models, model_widget.value)\n",
    "path_history = base_path + \"_history.npy\"\n",
    "path_model = base_path + \"_model\"\n",
    "path_testset = base_path + \"_testset.txt\"\n",
    "path_weights = base_path + \"_weights.h5\"\n",
    "\n",
    "\n",
    "# Train Model\n",
    "print(f\"Create model: {model_widget.value}\")\n",
    "\n",
    "# Save validation-set for future testing\n",
    "with open(path_testset, 'w') as f:\n",
    "    for participant in test:\n",
    "        f.write(participant + '\\n')\n",
    "\n",
    "# Instantiate model\n",
    "if(model_widget.value == \"fully_connected\"):\n",
    "    model = fully_connected_model()\n",
    "elif(model_widget.value == \"transformer\"):\n",
    "    model = transformer.TransformerModel()\n",
    "elif(model_widget.value == \"new_transformer\"):\n",
    "    model = transformer.TransformerModel()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss=BinaryCrossentropy(), metrics=[Precision(), BinaryAccuracy(), Recall()])\n",
    "checkpointer = ModelCheckpoint(filepath = path_weights, monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=4, factor=0.5, verbose=1)\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(x=train_sequence,\n",
    "                    validation_data=test_sequence,\n",
    "                    epochs=5,\n",
    "                    callbacks=[checkpointer, reduce_lr])\n",
    "\n",
    "np.save(path_history, history.history)\n",
    "model.save(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_helper.show_plot(x = range(len(history['loss'])), y = history['loss'] ,xlabel = \"epochs\", ylabel = \"validation loss\", title = \"Loss during training\")\n",
    "display_helper.show_plot(x = range(len(history['loss'])), y = history['val_loss'] ,xlabel = \"epochs\", ylabel = \"validation loss\", title = \"Validation loss during training\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
