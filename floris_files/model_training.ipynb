{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "In this notebook the *Dutch Dyslexia Programme (DDP)* and *ePodium* datasets are used to train a deep neural network model.\n",
    "\n",
    "The model is trained to predict the age and risk of dyslexia from brain signals. This input data consists of the average of multiple epochs of the EEG data, called an *Event Related Potential* (ERP).\n",
    "\n",
    "+ In section 1. [Prepare Dataset](#1mt) the ePodium and DDP dataset are prepared for input in the deep learning model. The metadata containing the participant info is loaded and the dataset is split into a train, test and validation set. The data is loaded with the *Sequencer* class from TensorFlow, which iterates over the participants in the sets when the data is needed by the model.\n",
    "+ In section 2. [Deep Learning](#2mt) a deep neural network is trained to predict the age and risk of dyslexia from the ERPs from toddlers. The model types that are used are the *encoder*, *resnet* models. The models, training history, and subset contents are saved in *local_paths.models*.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "    It is recommended to run this notebook with CUDA enabled with a dedicated graphics card to speed-up the model training.\n",
    "    \n",
    "    In the context of electroencephalography, 'epochs' are EEG intervals in which an event occurs. In this notebook 'epochs' are used in the context of deep learning, in which epochs are iterations over the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 21:48:59.399163: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-05 21:48:59.496674: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-05 21:48:59.524936: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-05 21:48:59.965218: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-05 21:48:59.965277: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-05 21:48:59.965283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Local\n",
    "import local_paths\n",
    "from functions import processing, display_helper, data_io\n",
    "from functions.epodium import Epodium\n",
    "from functions.ddp import DDP\n",
    "from functions.sequences import EpodiumSequence, DDPSequence\n",
    "\n",
    "# Models\n",
    "from models.dl_4_tsc import encoder_model, fully_convolutional_model, resnet_model\n",
    "from models.eeg_dl import transformer_model\n",
    "\n",
    "# Tensorflow dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from keras.metrics import Precision, BinaryAccuracy, Recall\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1mt'></a>\n",
    "## 1. Prepare Data\n",
    "\n",
    "#### Choose dataset\n",
    "\n",
    "This notebook works with both the ePodium and the DDP dataset. Choose which dataset to use by changing the variable: *dataset_name*. \n",
    "\n",
    "The *dataset* variable contains information and functions about the specific dataset. The directories to the data and the labels of the selected dataset are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available labels are:\n",
      " ['filename', 'participant', 'age_group', 'age_days']\n"
     ]
    }
   ],
   "source": [
    "# Choose between datasets: \"epodium\" \"ddp\"\n",
    "dataset_name = \"ddp\"\n",
    "\n",
    "if dataset_name == \"epodium\":\n",
    "    dataset = Epodium()    \n",
    "    epochs_directory = local_paths.ePod_epochs\n",
    "    event_directory = local_paths.ePod_epochs_events    \n",
    "    epod_labels = dataset.create_labels(local_paths.ePod_metadata)\n",
    "    print(f\"The available labels are:\\n {list(epod_labels.columns)}\")\n",
    "\n",
    "elif dataset_name == \"ddp\":\n",
    "    dataset = DDP()\n",
    "    epochs_directory = local_paths.DDP_epochs\n",
    "    event_directory = local_paths.DDP_epochs_events    \n",
    "    directory_age_metadata = os.path.join(local_paths.DDP_metadata, \"ages\")\n",
    "    ddp_labels = dataset.create_labels(local_paths.DDP_dataset, directory_age_metadata)\n",
    "    print(f\"The available labels are:\\n {list(ddp_labels.columns)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split valid experiments into train, validation, test set.\n",
    "\n",
    "1. Get only the valid experiments from each participants. The minimum amount of *standard* and *deviant* trials that need to be in each experiment can be selected.\n",
    "\n",
    "2. The data is split up into a train, validation, and test set. Each participant can have multiple experiments. The data is split up according to participants, so that no two experiments from the same participant are in multiple sets. The ratio *r* of the subsets is set to 70% test, 15% validation and 15% test set size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed: 1057 bad: 238\n",
      "819 experiments have enough epochs for analysis.\n",
      "109 experiments have incorrect channels. 710 experiments remain\n",
      "\n",
      "The dataset is split up into 487 train, 106 test, and 117 validation experiments\n"
     ]
    }
   ],
   "source": [
    "experiment_list = processing.valid_experiments(dataset, event_directory, min_standards=180, min_deviants=80)\n",
    "\n",
    "# In the DDP dataset some experiments are ignored due to incorrect channels \n",
    "if dataset_name == \"ddp\":\n",
    "    experiment_list = list(set(experiment_list)-set(dataset.wrong_channels_experiments))\n",
    "    print(f\"{len(dataset.wrong_channels_experiments)} experiments have incorrect channels. \"\n",
    "          f\"{len(experiment_list)} experiments remain\")\n",
    "\n",
    "# [train / test / validation] ratio\n",
    "r = np.array([0.7, 0.15, 0.15])\n",
    "experiments_train_val, experiments_test = dataset.split_dataset(experiment_list, (r[0]+r[2])/r.sum())\n",
    "experiments_train, experiments_val = dataset.split_dataset(experiments_train_val, r[0]/(r[0]+r[2]))\n",
    "\n",
    "print(f\"\\nThe dataset is split up into {len(experiments_train)} train, \"\n",
    "      f\"{len(experiments_test)} test, and {len(experiments_val)} validation experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing a 'Sequence' as input to the deep learning models.\n",
    "\n",
    "In this deep learning notebook, the model iterates over a sequence of data. Each data instance in this sequence is only loaded when it is used, and unloaded when the model is done using the data instance. In Tensorflow, such a sequence is implemented with the *Sequence* class:\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
    "\n",
    "This notebook uses an extended version of this *Sequence* class for both the ePodium and the DDP dataset: *EpodiumSequence*, *DDPSequence*. When instantiating, some of the variables can be varied without breaking the code. These variables are discussed below.\n",
    "\n",
    "+ *n_trials_averaged*: The number of trials that are averaged together to get the ERP that is the input to the model. A lower number means more data-points, while a higher number of averaged trials reduces the noise.\n",
    "+ *gaussian_noise*: Noise can be artificially added to the data to reduce overfitting on the training set. The value of this parameter indicates the variation of the noise that is added to each individual time-step of each channel. \n",
    "+ *batch_size*: The number of experiments that are put into a single batch. In deep learning, a model is updated after processing a batch. A lower batch size means more updates, while a larger batch size has the advantage of less variations in the updates.\n",
    "\n",
    "\n",
    "The *train_sequence* is used for training the model, and the *val_sequence* is used to measure the actual performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"epodium\":\n",
    "    train_sequence = EpodiumSequence(experiments_train, epod_labels, epochs_directory, \n",
    "                                     batch_size=4, gaussian_noise=1e-6)\n",
    "    val_sequence = EpodiumSequence(experiments_val, epod_labels, epochs_directory, \n",
    "                                   batch_size=4)\n",
    "    \n",
    "if dataset_name == \"ddp\":\n",
    "    train_sequence = DDPSequence(experiments_train, ddp_labels, epochs_directory, \n",
    "                                 batch_size=8, n_trials_averaged=60, gaussian_noise=1e-6)\n",
    "    val_sequence = DDPSequence(experiments_val, ddp_labels, epochs_directory, \n",
    "                               batch_size=8, n_trials_averaged=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "<a id='2mt'></a>\n",
    "## 2. Deep Learning\n",
    "\n",
    "Now that the data is set-up, the training model created. The model dimensions are set to the dimensions of the input data and predicted output label(s): \n",
    "\n",
    "+ Input x has dimensions: *(batches, timesteps, channels)*\n",
    "+ Output y has dimensions: *(batches, labels)*\n",
    "\n",
    "An ERP consists of 2-dimensional input data. One of the dimensions represents the time where *n_timesteps* contains the number of timesteps. The other dimension represents the channels, i.e. the sensor locations on the scalp. The variable *n_channels* signifies the number of channels in the ERP.\n",
    "\n",
    "The model is trained to predict the output y from an input x. When *y_dimension* is set to 1, the model outputs a single floating point number from the ERP data input. This number can represent a regressive label like *age* and the *risk of dyslexia*.\n",
    "\n",
    "#### Choose model\n",
    "\n",
    "Multiple model types can be trained. To pick a model, change the *model_name* variable to contain the desired model. The model options are: **encoder** / **transformer** / **resnet**. Of course, it is also possible to import and use other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 21:49:06.161430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-05 21:49:06.190526: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-05 21:49:06.190541: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-05 21:49:06.191235: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ddp_encoder_age_60avg\"\n",
    "# os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# Model dimensions\n",
    "n_channels = 26\n",
    "n_timesteps = 501\n",
    "x_dimension = (n_channels, n_timesteps)\n",
    "y_dimension = 1\n",
    "\n",
    "if \"encoder\" in model_name:\n",
    "    model = encoder_model(x_dimension, y_dimension)\n",
    "elif \"resnet\" in model_name:\n",
    "    model = resnet_model(x_dimension, y_dimension)\n",
    "else:\n",
    "    print(\"No model found. Add a model to the model name.\")\n",
    "#elif \"transformer\" in model_name:\n",
    "#     model = transformer_model(x_dimension, y_dimension)\n",
    "# elif \"fcn\" in model_name:\n",
    "#     model = fully_convolutional_model(x_dimension, y_dimension)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model\n",
    "\n",
    "The models, training history, and subset contents are saved in the folder *model_name* inside *local_paths.models*. \n",
    "\n",
    "Multiple hyperparameters can be adjusted:\n",
    "+ *epochs*: number of iterations over the dataset\n",
    "+ *learning_rate*: step size in optimizing the model parameters at each update\n",
    "\n",
    "*Adam* is used as an optimizer, since this optimizer performs well in a wide variety of cases. The loss of the optimizer is set to *MeanSquaredError*. This is a commonly used loss function in regression analysis where a 2x increase in error corresponds to a 4x increase in the loss.\n",
    "\n",
    "The model weights are saved when the validation loss is improved with the *ModelCheckpoint* callback. If however the validation loss is not improved, the learning rate is reduced with the *ReduceLROnPlateau* callback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model: ddp_encoder_age_60avg\n",
      "Epoch 1/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 646870.6875\n",
      "Epoch 1: val_loss improved from inf to 504929.28125, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 307s 5s/step - loss: 646870.6875 - val_loss: 504929.2812 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 447026.2188\n",
      "Epoch 2: val_loss improved from 504929.28125 to 316837.31250, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 301s 5s/step - loss: 447026.2188 - val_loss: 316837.3125 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 280933.8750\n",
      "Epoch 3: val_loss improved from 316837.31250 to 193155.09375, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 294s 5s/step - loss: 280933.8750 - val_loss: 193155.0938 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 177108.1250\n",
      "Epoch 4: val_loss improved from 193155.09375 to 123901.03906, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 309s 5s/step - loss: 177108.1250 - val_loss: 123901.0391 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 122615.7578\n",
      "Epoch 5: val_loss improved from 123901.03906 to 95473.16406, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 307s 5s/step - loss: 122615.7578 - val_loss: 95473.1641 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 99685.5547\n",
      "Epoch 6: val_loss improved from 95473.16406 to 87745.35938, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 306s 5s/step - loss: 99685.5547 - val_loss: 87745.3594 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 92521.3047\n",
      "Epoch 7: val_loss improved from 87745.35938 to 86430.89062, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 302s 5s/step - loss: 92521.3047 - val_loss: 86430.8906 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 86467.7578\n",
      "Epoch 8: val_loss improved from 86430.89062 to 80073.35156, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 302s 5s/step - loss: 86467.7578 - val_loss: 80073.3516 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 79387.9609\n",
      "Epoch 9: val_loss did not improve from 80073.35156\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "61/61 [==============================] - 301s 5s/step - loss: 79387.9609 - val_loss: 85276.8984 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 78059.3984\n",
      "Epoch 10: val_loss improved from 80073.35156 to 75416.64062, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 303s 5s/step - loss: 78059.3984 - val_loss: 75416.6406 - lr: 9.0000e-04\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 72856.0000\n",
      "Epoch 11: val_loss improved from 75416.64062 to 69078.51562, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 301s 5s/step - loss: 72856.0000 - val_loss: 69078.5156 - lr: 9.0000e-04\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 70143.1484\n",
      "Epoch 12: val_loss did not improve from 69078.51562\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "61/61 [==============================] - 301s 5s/step - loss: 70143.1484 - val_loss: 70203.8516 - lr: 9.0000e-04\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 65448.9219\n",
      "Epoch 13: val_loss did not improve from 69078.51562\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "61/61 [==============================] - 303s 5s/step - loss: 65448.9219 - val_loss: 69541.0469 - lr: 8.1000e-04\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 62359.8125\n",
      "Epoch 14: val_loss improved from 69078.51562 to 64309.27734, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 309s 5s/step - loss: 62359.8125 - val_loss: 64309.2773 - lr: 7.2900e-04\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 61407.4414\n",
      "Epoch 15: val_loss improved from 64309.27734 to 61490.39062, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 300s 5s/step - loss: 61407.4414 - val_loss: 61490.3906 - lr: 7.2900e-04\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 57962.5664\n",
      "Epoch 16: val_loss improved from 61490.39062 to 59649.41406, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 292s 5s/step - loss: 57962.5664 - val_loss: 59649.4141 - lr: 7.2900e-04\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 57290.5703\n",
      "Epoch 17: val_loss did not improve from 59649.41406\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "61/61 [==============================] - 292s 5s/step - loss: 57290.5703 - val_loss: 61085.0039 - lr: 7.2900e-04\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 56229.7344\n",
      "Epoch 18: val_loss improved from 59649.41406 to 59224.02344, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 293s 5s/step - loss: 56229.7344 - val_loss: 59224.0234 - lr: 6.5610e-04\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 54773.3086\n",
      "Epoch 19: val_loss improved from 59224.02344 to 57801.57422, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 304s 5s/step - loss: 54773.3086 - val_loss: 57801.5742 - lr: 6.5610e-04\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 55503.3008\n",
      "Epoch 20: val_loss improved from 57801.57422 to 57576.88281, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 302s 5s/step - loss: 55503.3008 - val_loss: 57576.8828 - lr: 6.5610e-04\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 54577.7188\n",
      "Epoch 21: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "61/61 [==============================] - 306s 5s/step - loss: 54577.7188 - val_loss: 58293.5664 - lr: 6.5610e-04\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 52841.6484\n",
      "Epoch 22: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "61/61 [==============================] - 297s 5s/step - loss: 52841.6484 - val_loss: 62758.9336 - lr: 5.9049e-04\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 54370.0781\n",
      "Epoch 23: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "61/61 [==============================] - 299s 5s/step - loss: 54370.0781 - val_loss: 69278.7109 - lr: 5.3144e-04\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 55319.8398\n",
      "Epoch 24: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "61/61 [==============================] - 302s 5s/step - loss: 55319.8398 - val_loss: 64540.4023 - lr: 4.7830e-04\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 52084.9961\n",
      "Epoch 25: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "61/61 [==============================] - 299s 5s/step - loss: 52084.9961 - val_loss: 57921.2539 - lr: 4.3047e-04\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 52797.4844\n",
      "Epoch 26: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "61/61 [==============================] - 302s 5s/step - loss: 52797.4844 - val_loss: 61136.4492 - lr: 3.8742e-04\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 51761.9805\n",
      "Epoch 27: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "61/61 [==============================] - 298s 5s/step - loss: 51761.9805 - val_loss: 59546.0781 - lr: 3.4868e-04\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49013.3984\n",
      "Epoch 28: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "61/61 [==============================] - 307s 5s/step - loss: 49013.3984 - val_loss: 59845.0508 - lr: 3.1381e-04\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 50521.2461\n",
      "Epoch 29: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "61/61 [==============================] - 305s 5s/step - loss: 50521.2461 - val_loss: 62144.0508 - lr: 2.8243e-04\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48203.8867\n",
      "Epoch 30: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "61/61 [==============================] - 296s 5s/step - loss: 48203.8867 - val_loss: 61932.9727 - lr: 2.5419e-04\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 51322.3047\n",
      "Epoch 31: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "61/61 [==============================] - 304s 5s/step - loss: 51322.3047 - val_loss: 59944.7461 - lr: 2.2877e-04\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48681.5156\n",
      "Epoch 32: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "61/61 [==============================] - 289s 5s/step - loss: 48681.5156 - val_loss: 60951.8750 - lr: 2.0589e-04\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 51457.1484\n",
      "Epoch 33: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "61/61 [==============================] - 307s 5s/step - loss: 51457.1484 - val_loss: 60242.6406 - lr: 1.8530e-04\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48668.1875\n",
      "Epoch 34: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "61/61 [==============================] - 309s 5s/step - loss: 48668.1875 - val_loss: 61495.9609 - lr: 1.6677e-04\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48351.5000\n",
      "Epoch 35: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "61/61 [==============================] - 310s 5s/step - loss: 48351.5000 - val_loss: 58944.6094 - lr: 1.5009e-04\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 50478.5508\n",
      "Epoch 36: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "61/61 [==============================] - 302s 5s/step - loss: 50478.5508 - val_loss: 61518.3867 - lr: 1.3509e-04\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48823.5625\n",
      "Epoch 37: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "61/61 [==============================] - 286s 5s/step - loss: 48823.5625 - val_loss: 60208.1914 - lr: 1.2158e-04\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49117.9258\n",
      "Epoch 38: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "61/61 [==============================] - 307s 5s/step - loss: 49117.9258 - val_loss: 57607.9531 - lr: 1.0942e-04\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 50514.2461\n",
      "Epoch 39: val_loss did not improve from 57576.88281\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "61/61 [==============================] - 302s 5s/step - loss: 50514.2461 - val_loss: 62074.0039 - lr: 9.8477e-05\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 46765.6055\n",
      "Epoch 40: val_loss improved from 57576.88281 to 55901.69922, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 302s 5s/step - loss: 46765.6055 - val_loss: 55901.6992 - lr: 8.8629e-05\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47852.4688\n",
      "Epoch 41: val_loss did not improve from 55901.69922\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "61/61 [==============================] - 293s 5s/step - loss: 47852.4688 - val_loss: 60906.2070 - lr: 8.8629e-05\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49378.0742\n",
      "Epoch 42: val_loss did not improve from 55901.69922\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "61/61 [==============================] - 306s 5s/step - loss: 49378.0742 - val_loss: 60746.8750 - lr: 7.9766e-05\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48570.1328\n",
      "Epoch 43: val_loss improved from 55901.69922 to 55602.77344, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 312s 5s/step - loss: 48570.1328 - val_loss: 55602.7734 - lr: 7.1790e-05\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49532.5391\n",
      "Epoch 44: val_loss did not improve from 55602.77344\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "61/61 [==============================] - 310s 5s/step - loss: 49532.5391 - val_loss: 57699.6602 - lr: 7.1790e-05\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48476.0117\n",
      "Epoch 45: val_loss did not improve from 55602.77344\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 5.8149741380475466e-05.\n",
      "61/61 [==============================] - 287s 5s/step - loss: 48476.0117 - val_loss: 61978.8125 - lr: 6.4611e-05\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49033.1797\n",
      "Epoch 46: val_loss did not improve from 55602.77344\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 5.233476658759173e-05.\n",
      "61/61 [==============================] - 300s 5s/step - loss: 49033.1797 - val_loss: 60522.0469 - lr: 5.8150e-05\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48287.0898\n",
      "Epoch 47: val_loss improved from 55602.77344 to 54901.02344, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 298s 5s/step - loss: 48287.0898 - val_loss: 54901.0234 - lr: 5.2335e-05\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 45979.0508\n",
      "Epoch 48: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 4.7101289601414466e-05.\n",
      "61/61 [==============================] - 294s 5s/step - loss: 45979.0508 - val_loss: 58895.2227 - lr: 5.2335e-05\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49185.2891\n",
      "Epoch 49: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 4.239116096869111e-05.\n",
      "61/61 [==============================] - 291s 5s/step - loss: 49185.2891 - val_loss: 60029.1992 - lr: 4.7101e-05\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 46628.0977\n",
      "Epoch 50: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.815204618149437e-05.\n",
      "61/61 [==============================] - 293s 5s/step - loss: 46628.0977 - val_loss: 59260.4883 - lr: 4.2391e-05\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 46894.2656\n",
      "Epoch 51: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 3.4336842873017304e-05.\n",
      "61/61 [==============================] - 291s 5s/step - loss: 46894.2656 - val_loss: 60776.9375 - lr: 3.8152e-05\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47104.6914\n",
      "Epoch 52: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 3.0903160222806036e-05.\n",
      "61/61 [==============================] - 300s 5s/step - loss: 47104.6914 - val_loss: 63938.9805 - lr: 3.4337e-05\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48272.9805\n",
      "Epoch 53: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 2.7812844200525434e-05.\n",
      "61/61 [==============================] - 306s 5s/step - loss: 48272.9805 - val_loss: 59851.0195 - lr: 3.0903e-05\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48834.2695\n",
      "Epoch 54: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 2.5031560107890984e-05.\n",
      "61/61 [==============================] - 300s 5s/step - loss: 48834.2695 - val_loss: 57880.9141 - lr: 2.7813e-05\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49006.9805\n",
      "Epoch 55: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 2.2528404588229024e-05.\n",
      "61/61 [==============================] - 294s 5s/step - loss: 49006.9805 - val_loss: 63080.5586 - lr: 2.5032e-05\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48913.9180\n",
      "Epoch 56: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 2.0275563474569936e-05.\n",
      "61/61 [==============================] - 281s 5s/step - loss: 48913.9180 - val_loss: 56757.8828 - lr: 2.2528e-05\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 50113.8945\n",
      "Epoch 57: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.8248007290821987e-05.\n",
      "61/61 [==============================] - 293s 5s/step - loss: 50113.8945 - val_loss: 57231.9531 - lr: 2.0276e-05\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49333.4609\n",
      "Epoch 58: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 1.6423206398030745e-05.\n",
      "61/61 [==============================] - 286s 5s/step - loss: 49333.4609 - val_loss: 61267.9844 - lr: 1.8248e-05\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48089.3516\n",
      "Epoch 59: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.4780885430809576e-05.\n",
      "61/61 [==============================] - 293s 5s/step - loss: 48089.3516 - val_loss: 59427.5391 - lr: 1.6423e-05\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47528.2109\n",
      "Epoch 60: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.3302796560310526e-05.\n",
      "61/61 [==============================] - 296s 5s/step - loss: 47528.2109 - val_loss: 57633.3008 - lr: 1.4781e-05\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48010.6211\n",
      "Epoch 61: val_loss did not improve from 54901.02344\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 1.1972517313552089e-05.\n",
      "61/61 [==============================] - 296s 5s/step - loss: 48010.6211 - val_loss: 62139.0000 - lr: 1.3303e-05\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48277.1914\n",
      "Epoch 62: val_loss improved from 54901.02344 to 53973.07812, saving model to /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/weights.h5\n",
      "61/61 [==============================] - 286s 5s/step - loss: 48277.1914 - val_loss: 53973.0781 - lr: 1.1973e-05\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47883.9844\n",
      "Epoch 63: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1.077526558219688e-05.\n",
      "61/61 [==============================] - 298s 5s/step - loss: 47883.9844 - val_loss: 59898.2617 - lr: 1.1973e-05\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47617.0352\n",
      "Epoch 64: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.697739187686238e-06.\n",
      "61/61 [==============================] - 304s 5s/step - loss: 47617.0352 - val_loss: 60656.8008 - lr: 1.0775e-05\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47857.4414\n",
      "Epoch 65: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 8.727965268917615e-06.\n",
      "61/61 [==============================] - 315s 5s/step - loss: 47857.4414 - val_loss: 60873.8789 - lr: 9.6977e-06\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48718.4883\n",
      "Epoch 66: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 7.855168496462283e-06.\n",
      "61/61 [==============================] - 301s 5s/step - loss: 48718.4883 - val_loss: 63792.5742 - lr: 8.7280e-06\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47467.5625\n",
      "Epoch 67: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 7.069651564961533e-06.\n",
      "61/61 [==============================] - 307s 5s/step - loss: 47467.5625 - val_loss: 56417.9219 - lr: 7.8552e-06\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47380.8828\n",
      "Epoch 68: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.362686326610856e-06.\n",
      "61/61 [==============================] - 303s 5s/step - loss: 47380.8828 - val_loss: 60123.7930 - lr: 7.0697e-06\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47159.0234\n",
      "Epoch 69: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 5.726417612095247e-06.\n",
      "61/61 [==============================] - 300s 5s/step - loss: 47159.0234 - val_loss: 56960.4570 - lr: 6.3627e-06\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 46345.6289\n",
      "Epoch 70: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 5.15377605552203e-06.\n",
      "61/61 [==============================] - 304s 5s/step - loss: 46345.6289 - val_loss: 58678.2539 - lr: 5.7264e-06\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49109.8945\n",
      "Epoch 71: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 4.638398286260781e-06.\n",
      "61/61 [==============================] - 297s 5s/step - loss: 49109.8945 - val_loss: 63883.8984 - lr: 5.1538e-06\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47312.5820\n",
      "Epoch 72: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 4.174558580416488e-06.\n",
      "61/61 [==============================] - 302s 5s/step - loss: 47312.5820 - val_loss: 59489.3359 - lr: 4.6384e-06\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48585.1133\n",
      "Epoch 73: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.7571025586657926e-06.\n",
      "61/61 [==============================] - 304s 5s/step - loss: 48585.1133 - val_loss: 62066.2695 - lr: 4.1746e-06\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47477.8711\n",
      "Epoch 74: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 3.381392343726475e-06.\n",
      "61/61 [==============================] - 302s 5s/step - loss: 47477.8711 - val_loss: 59135.6289 - lr: 3.7571e-06\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47851.4688\n",
      "Epoch 75: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 3.043253150281089e-06.\n",
      "61/61 [==============================] - 300s 5s/step - loss: 47851.4688 - val_loss: 59274.4141 - lr: 3.3814e-06\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 45853.4258\n",
      "Epoch 76: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 2.7389278557166107e-06.\n",
      "61/61 [==============================] - 301s 5s/step - loss: 45853.4258 - val_loss: 60677.7695 - lr: 3.0433e-06\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49370.3672\n",
      "Epoch 77: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 2.465035049681319e-06.\n",
      "61/61 [==============================] - 304s 5s/step - loss: 49370.3672 - val_loss: 57577.2891 - lr: 2.7389e-06\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48894.3281\n",
      "Epoch 78: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 2.2185315856404485e-06.\n",
      "61/61 [==============================] - 297s 5s/step - loss: 48894.3281 - val_loss: 57189.3242 - lr: 2.4650e-06\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49044.9219\n",
      "Epoch 79: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.996678406612773e-06.\n",
      "61/61 [==============================] - 294s 5s/step - loss: 49044.9219 - val_loss: 59773.2734 - lr: 2.2185e-06\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47905.1367\n",
      "Epoch 80: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 1.7970104636333418e-06.\n",
      "61/61 [==============================] - 297s 5s/step - loss: 47905.1367 - val_loss: 61318.7617 - lr: 1.9967e-06\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47915.3242\n",
      "Epoch 81: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.6173093968063768e-06.\n",
      "61/61 [==============================] - 294s 5s/step - loss: 47915.3242 - val_loss: 61829.7695 - lr: 1.7970e-06\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47346.1406\n",
      "Epoch 82: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.4555784673575544e-06.\n",
      "61/61 [==============================] - 292s 5s/step - loss: 47346.1406 - val_loss: 61239.9492 - lr: 1.6173e-06\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48842.5312\n",
      "Epoch 83: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.3100206615490606e-06.\n",
      "61/61 [==============================] - 283s 5s/step - loss: 48842.5312 - val_loss: 62488.6055 - lr: 1.4556e-06\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 46625.6055\n",
      "Epoch 84: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 84: ReduceLROnPlateau reducing learning rate to 1.179018636321416e-06.\n",
      "61/61 [==============================] - 288s 5s/step - loss: 46625.6055 - val_loss: 61099.0781 - lr: 1.3100e-06\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47640.3320\n",
      "Epoch 85: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.0611168136165362e-06.\n",
      "61/61 [==============================] - 300s 5s/step - loss: 47640.3320 - val_loss: 58656.4375 - lr: 1.1790e-06\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47810.9180\n",
      "Epoch 86: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 9.550051117912518e-07.\n",
      "61/61 [==============================] - 294s 5s/step - loss: 47810.9180 - val_loss: 56001.3594 - lr: 1.0611e-06\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48632.2617\n",
      "Epoch 87: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 8.595046210757574e-07.\n",
      "61/61 [==============================] - 296s 5s/step - loss: 48632.2617 - val_loss: 57743.7969 - lr: 9.5501e-07\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 46488.2812\n",
      "Epoch 88: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 7.735541487363662e-07.\n",
      "61/61 [==============================] - 295s 5s/step - loss: 46488.2812 - val_loss: 59101.8555 - lr: 8.5950e-07\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48894.1172\n",
      "Epoch 89: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 6.961987082831911e-07.\n",
      "61/61 [==============================] - 288s 5s/step - loss: 48894.1172 - val_loss: 60094.7578 - lr: 7.7355e-07\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 50286.6211\n",
      "Epoch 90: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 6.265788272230566e-07.\n",
      "61/61 [==============================] - 292s 5s/step - loss: 50286.6211 - val_loss: 59474.9453 - lr: 6.9620e-07\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 50121.7969\n",
      "Epoch 91: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 5.639209291530278e-07.\n",
      "61/61 [==============================] - 295s 5s/step - loss: 50121.7969 - val_loss: 60468.7500 - lr: 6.2658e-07\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48896.3125\n",
      "Epoch 92: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 5.075288413536328e-07.\n",
      "61/61 [==============================] - 301s 5s/step - loss: 48896.3125 - val_loss: 60221.3945 - lr: 5.6392e-07\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49764.7969\n",
      "Epoch 93: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 4.5677596745008485e-07.\n",
      "61/61 [==============================] - 303s 5s/step - loss: 49764.7969 - val_loss: 58889.3711 - lr: 5.0753e-07\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 49573.1367\n",
      "Epoch 94: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 4.110983809368918e-07.\n",
      "61/61 [==============================] - 300s 5s/step - loss: 49573.1367 - val_loss: 63732.4297 - lr: 4.5678e-07\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47074.9453\n",
      "Epoch 95: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 3.6998853261138723e-07.\n",
      "61/61 [==============================] - 302s 5s/step - loss: 47074.9453 - val_loss: 59344.4648 - lr: 4.1110e-07\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48856.9141\n",
      "Epoch 96: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 3.3298967423434077e-07.\n",
      "61/61 [==============================] - 296s 5s/step - loss: 48856.9141 - val_loss: 58972.9922 - lr: 3.6999e-07\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 46972.0977\n",
      "Epoch 97: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 2.9969071704272213e-07.\n",
      "61/61 [==============================] - 295s 5s/step - loss: 46972.0977 - val_loss: 61278.9258 - lr: 3.3299e-07\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47228.6641\n",
      "Epoch 98: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 2.6972165301231144e-07.\n",
      "61/61 [==============================] - 288s 5s/step - loss: 47228.6641 - val_loss: 61781.9531 - lr: 2.9969e-07\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 47129.0469\n",
      "Epoch 99: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 2.427494877110803e-07.\n",
      "61/61 [==============================] - 295s 5s/step - loss: 47129.0469 - val_loss: 60353.5430 - lr: 2.6972e-07\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - ETA: 0s - loss: 48430.4883\n",
      "Epoch 100: val_loss did not improve from 53973.07812\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 2.1847453126611072e-07.\n",
      "61/61 [==============================] - 291s 5s/step - loss: 48430.4883 - val_loss: 62375.6211 - lr: 2.4275e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/fpauwels/eegyolk/floris_files/models/trained_models/ddp_encoder_age_60avg/model/assets\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Paths for saving model data\n",
    "base_dir = os.path.join(local_paths.models, model_name)\n",
    "model_dir = os.path.join(base_dir, \"model\")\n",
    "subsets_dir = os.path.join(base_dir, \"subsets\")\n",
    "path_history = os.path.join(base_dir, \"history.npy\")\n",
    "path_weights = os.path.join(base_dir, \"weights.h5\")\n",
    "\n",
    "if os.path.exists(model_dir):\n",
    "    print(f\"Model: '{model_name}' already exist. Delete the existing model first or rename this model.\")    \n",
    "else:\n",
    "    print(f\"Create model: {model_name}\")\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.mkdir(base_dir)\n",
    "    if not os.path.exists(subsets_dir):\n",
    "        os.mkdir(subsets_dir)\n",
    "\n",
    "    # Save train / test / validation sets for future testing\n",
    "    data_io.save_experiment_names(experiments_train, os.path.join(subsets_dir, \"train_set.txt\"))\n",
    "    data_io.save_experiment_names(experiments_test, os.path.join(subsets_dir, \"test_set.txt\"))\n",
    "    data_io.save_experiment_names(experiments_val, os.path.join(subsets_dir, \"validation_set.txt\"))\n",
    "\n",
    "    # Model configurations\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "    checkpointer = ModelCheckpoint(filepath=path_weights, monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=1, factor=0.9, verbose=1)\n",
    "    \n",
    "    # Fit model\n",
    "    history = model.fit(x=train_sequence, validation_data=val_sequence, epochs=epochs, callbacks=[checkpointer, reduce_lr])\n",
    "    \n",
    "    # Save model and training history\n",
    "    model.save(model_dir)\n",
    "    np.save(path_history, history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_helper.show_plot(x=range(len(history.history['loss'])), \n",
    "                         y=[history.history['loss'], history.history['val_loss']], \n",
    "                         legend=[\"loss\",\"validation loss\"], \n",
    "                         xlabel=\"epochs\", ylabel=\"validation loss (MSE)\", \n",
    "                         title=f\"Loss during training ({model_name})\",\n",
    "                         xlim=[0,100], ylim=[0,150000])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
