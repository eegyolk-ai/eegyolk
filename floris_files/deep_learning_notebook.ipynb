{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning\n",
    "\n",
    "+ A model processes data and lables \n",
    "+ The model optimizes through a training loop\n",
    "+ New dummy data is generated for each training loop\n",
    "+ Able to use multiple models (standard is FNN)\n",
    "+ Introduce Transformer model\n",
    "\n",
    "TODO:\n",
    "+ Show the confidence of a prediction (with softmax probability between 0 and 1) \n",
    "+ Compare multiple models on dummy data (ML, FNN, CNN, RNN, Transformer(Encoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as sk\n",
    "import numpy as np   \n",
    "import matplotlib.pyplot as plt\n",
    "import os              \n",
    "import sys\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from IPython.display import clear_output\n",
    "\n",
    "main_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "eegyolk_path = os.path.join(main_path, 'eegyolk')\n",
    "sys.path.insert(0, eegyolk_path)\n",
    "from eegyolk import dummy_data_functions as dummy\n",
    "from eegyolk import display_helper as disp\n",
    "\n",
    "from models import transfomer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise Model\n",
    "\n",
    "Feedforward neural network (FNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(1024,)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer model:\n",
    "\n",
    "Run *training loop* again after this cell, to use this transformer model instead of the feedforward NN.\n",
    "\n",
    "The model is originally from:\n",
    "+ Author: Bruce Shuyue Jia\n",
    "+ Source: https://github.com/SuperBruceJia/EEG-DL/blob/master/Models/main-Transformer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transfomer.TransformerModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=\"binary_crossentropy\")\n",
    "              # metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall()]\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for creating batch of data with mixed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "planck_distribution = dummy.generate_frequency_distribution(\"planck\")\n",
    "const_distribution = dummy.generate_frequency_distribution(\"constant\")\n",
    "\n",
    "def create_batch(batch_size):\n",
    "  X = []\n",
    "  Y = np.zeros(batch_size)\n",
    "\n",
    "  for i in range(batch_size):\n",
    "      if random.random() < 0.5:\n",
    "          X.append(dummy.generate_epoch(const_distribution))\n",
    "      else:\n",
    "          X.append(dummy.generate_epoch(planck_distribution))\n",
    "          Y[i] = 1\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0640 - precision: 1.0000 - binary_accuracy: 0.9922 - recall: 0.9853\n",
      "Epoch 2/4\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0747 - precision: 0.9710 - binary_accuracy: 0.9766 - recall: 0.9853\n",
      "Epoch 3/4\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1054 - precision: 0.9848 - binary_accuracy: 0.9688 - recall: 0.9559\n",
      "Epoch 4/4\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0651 - precision: 0.9855 - binary_accuracy: 0.9922 - recall: 1.0000\n",
      "4/4 - 0s - loss: 0.0064 - precision: 1.0000 - binary_accuracy: 1.0000 - recall: 1.0000 - 46ms/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "for j in range(4):\n",
    "  X_train, Y_train = create_batch(batch_size)\n",
    "  model.fit(np.array(X_train), Y_train, epochs=4, batch_size=10)\n",
    "\n",
    "  X_test, Y_test = create_batch(batch_size)\n",
    "  loss = model.evaluate(np.array(X_test),  Y_test, verbose=2)\n",
    "\n",
    "  clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mType:\u001b[0m        list\n",
      "\u001b[1;31mString form:\u001b[0m [0.006358501501381397, 1.0, 1.0, 1.0]\n",
      "\u001b[1;31mLength:\u001b[0m      4\n",
      "\u001b[1;31mDocstring:\u001b[0m  \n",
      "Built-in mutable sequence.\n",
      "\n",
      "If no argument is given, the constructor creates a new empty list.\n",
      "The argument must be an iterable if specified.\n"
     ]
    }
   ],
   "source": [
    "loss?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('VENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
