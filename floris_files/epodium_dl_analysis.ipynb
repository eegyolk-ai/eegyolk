{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive tool for analyzing trained models on the ePodium dataset\n",
    "\n",
    "1. [Input Data](#1)\n",
    "2. [Deep Learning Model](#02)\n",
    "3. [Make predictions on test-set](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages\n",
    "Note: This notebook may output tensorflow errors if cuda is not properly installed. The notebook still functions with these errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 21:29:04.448203: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-28 21:29:04.448250: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "import tensorflow as tf\n",
    "\n",
    "from functions import epodium, epodium_deep_learning, display_helper\n",
    "from models.dnn import fully_connected_model\n",
    "from models.hfawaz import cnn, encoder\n",
    "\n",
    "import local_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "## 1. Input Data \n",
    "\n",
    "####  Choose which processed data to use\n",
    "Choose from the different processed _experiment_event.npy_ files. If the _local_path.split_ folder is empty, process the raw ePodium files in the _epodium_processing_ notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275aba6647c246488fdf6875d2334e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='processing:', options=('autoreject_128hz', 'autoreject_512hz', 'ransac_512hz'), valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processing_methods = sorted(f for f in os.listdir(local_paths.epod_split) if not f.startswith(\".\"))\n",
    "processing_method_widget = ipywidgets.RadioButtons(options=processing_methods, \n",
    "                                                   description='processing:',\n",
    "                                                   value='autoreject_128hz')\n",
    "display(processing_method_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed: 228, bad: 42\n",
      "186 experiments have enough epochs for analysis.\n"
     ]
    }
   ],
   "source": [
    "cleaning_method = processing_method_widget.value.split('_')[0]\n",
    "experiment_list = epodium_deep_learning.clean_experiments(cleaning_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the data sequence of a single participant\n",
    "\n",
    "TODO: SHOW Downsample differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ec9a50c84f4a3bb43f21ed1a2d54ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Experiment:', options=('101a', '101b', '102a', '102b', '103b', '104a', '1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b35069ea3ab42678c16b39ed2b0f772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_standard_deviant_instance(experiment, codition, avg, noise):    \n",
    "    # Create data instance\n",
    "    participant_sequence = epodium_deep_learning.EvokedDataIterator([experiment], \n",
    "                                                                    processing_method_widget.value,\n",
    "                                                                    n_experiments_batch=1,\n",
    "                                                                    n_trials_averaged=avg,\n",
    "                                                                    gaussian_noise=noise*1e-6)\n",
    "    x, y = participant_sequence.__getitem__(0)\n",
    "    print(f\"The data instance has shape: {x.shape}\")\n",
    "\n",
    "    # Plot an evoked (ERP) of the specified condition\n",
    "    index = epodium.conditions.index(codition)\n",
    "    display_helper.plot_array_as_evoked(x[index][:32], epodium.channel_names, \n",
    "                                        frequency=128, n_trials=avg, ylim=[-20, 20])\n",
    "    display_helper.plot_array_as_evoked(x[index][32:], epodium.channel_names, \n",
    "                                        frequency=128, n_trials=avg, ylim=[-20, 20])\n",
    "\n",
    "# Create widgets\n",
    "experiment_widget = ipywidgets.Dropdown(options=sorted(experiment_list), description='Experiment:')\n",
    "condition_widget = ipywidgets.RadioButtons(options=epodium.conditions, description='Condition:')\n",
    "n_trials_averaged_widget = ipywidgets.IntSlider(value=60, min=1, max=80,description='Averaged trials:')\n",
    "gaussian_noise_widget = ipywidgets.FloatSlider(value=1, min=0, max=5,description='Noise (micro-volt):')\n",
    "\n",
    "# Widget settings\n",
    "options = {'experiment':experiment_widget, 'codition':condition_widget, 'avg':n_trials_averaged_widget, 'noise':gaussian_noise_widget}\n",
    "ui = ipywidgets.VBox([experiment_widget, condition_widget, n_trials_averaged_widget, gaussian_noise_widget])\n",
    "out = ipywidgets.interactive_output(plot_standard_deviant_instance, options)\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id=\"02\"></a>\n",
    "## 2. Deep Learning Model\n",
    "\n",
    "#### Choose a trained model\n",
    "Choose from the trained models in the _local_paths.models_ folder. If the folder is empty, train a model in the _epodium_model_training_ notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc911ab611247d2b826b6dc4ab25c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Models:', options=('encoder_age_128', 'encoder_age_128_2', 'encoder_age_128_20', 'en…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532b8a4bf76446ffacbe796ab5b73ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Required plot setting\n",
    "%matplotlib inline \n",
    "trained_models = sorted(f for f in os.listdir(local_paths.epod_models) if not f.startswith(\".\"))\n",
    "\n",
    "model_widget = ipywidgets.RadioButtons(options=trained_models, description='Models:')\n",
    "display(model_widget)\n",
    "\n",
    "history = []\n",
    "                                       \n",
    "def load_model(mod):\n",
    "    base_path = os.path.join(local_paths.epod_models, mod)\n",
    "\n",
    "    path_history = os.path.join(base_path, \"history.npy\")\n",
    "    path_model = os.path.join(base_path, \"model\")\n",
    "    path_testset = os.path.join(base_path, \"testset.txt\")\n",
    "    path_weights = os.path.join(base_path, \"weights.h5\")\n",
    "    \n",
    "    global model\n",
    "    global testset\n",
    "    global history\n",
    "\n",
    "    # Load Model\n",
    "    if(os.path.exists(path_model)):\n",
    "        print(f\"Loading Model: '{model_widget.value}'.\")\n",
    "\n",
    "        # Loads the entire model from a folder:\n",
    "        model = tf.keras.models.load_model(path_model)\n",
    "        model.load_weights(path_weights)\n",
    "        # Reads the test-set of the trained model and puts the experiment names into a list:\n",
    "        testset = open(path_testset, \"r\").read().split()\n",
    "        # Loads the training history dictionary:\n",
    "        history = np.load(path_history, allow_pickle=True).item()\n",
    "        \n",
    "        # Show Loss of Training History\n",
    "        display_helper.show_plot(x=range(len(history['loss'][:])), y=history['loss'][:],\n",
    "                                 xlabel=\"epochs\", ylabel=\"validation loss\", title=\"Loss during training\")\n",
    "        display_helper.show_plot(x=range(len(history['loss']))[:], y=history['val_loss'][:],\n",
    "                                 xlabel=\"epochs\", ylabel=\"validation loss\", title=\"Validation loss during training\")\n",
    "        print(f\"The lowest validation loss is {round(min(history['val_loss']), 3)}\")\n",
    "\n",
    "    else: \n",
    "        print(\"Model not found\")\n",
    "\n",
    "out = ipywidgets.interactive_output(load_model, {'mod': model_widget})\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "<a id='3'></a>\n",
    "## 3. Make predictions on test-set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_passthroughs = 20 # 1 passtrough gives 4 predictions, 1 for each condition\n",
    "results = []\n",
    "\n",
    "trainset = list(set(experiment_list) - set(testset))\n",
    "\n",
    "# For each experiment in the test-set\n",
    "for experiment in trainset: # TODO: Check difference trainset/testset \n",
    "    test_sequence = epodium_deep_learning.EvokedDataIterator([experiment],\n",
    "                                                             processing_method_widget.value,                                                                    \n",
    "                                                             n_experiments_batch=n_passthroughs,                                                                    \n",
    "                                                             n_trials_averaged=60)\n",
    "\n",
    "    x, y = test_sequence.__getitem__(0)\n",
    "    # print(f\"The data instance has shape: {x.shape}\")\n",
    "\n",
    "    real_pred = [y[0], np.squeeze(model.predict(x, verbose=0)).mean()]\n",
    "    results.append(real_pred)\n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_helper.show_plot(np.array(results)[:,0], \n",
    "                         np.array(results)[:,1], \n",
    "                         f\"Age prediction on train set (encoder_age_128_20, passes: {n_passthroughs})\", \n",
    "                         \"Actual age (normalized)\",\n",
    "                         \"Predicted age (normalized)\",\n",
    "                         scatter=True,\n",
    "                         show=False)\n",
    "plt.plot([-1, 1], [-1, 1]) # Line where predicted=actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD!\n",
    "\n",
    "\n",
    "#     label_sex = 'male' if y[index][0] else 'female'\n",
    "#     label_dyslexia = 'risk' if y[index][1] else 'no risk'\n",
    "#     label_event = 'deviant' if y[index][2] else 'standard'\n",
    "\n",
    "#     print (f\"{int(y[index][0])}: {label_sex}, \\\n",
    "#          {int(y[index][1])}: {label_risk}, \\\n",
    "#          {int(y[index][2])}: {label_event}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
