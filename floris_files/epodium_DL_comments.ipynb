{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applies Deep Learning methods to ePodium dataset for prediction of Dyslexia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functions import epodium\n",
    "\n",
    "import PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same comments on the names as in other notebook, but fine for now...I would add at least one markdown cell comment explaining what epochs are in this context. Remember for AI people who may read this (future job interviews?) epochs has a diffferent meaning, and you should stay very clear on your terms for everyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check number of epochs in each experiment\n",
    "Experiments with enough epochs are added to *clean_list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzed: 188, bad: 37\n",
      "151 files have enough epochs for analysis.\n"
     ]
    }
   ],
   "source": [
    "standard_minimum = 180  # total of 360\n",
    "deviant_minimum = 80  # total size of 120\n",
    "firststandard_minimum = 80  # total size of 120\n",
    "\n",
    "count_analyzed = 0\n",
    "count_bad = 0\n",
    "\n",
    "clean_list = []\n",
    "\n",
    "firststandard_index = [1, 4, 7, 10]\n",
    "standard_index = [2, 5, 8, 11]\n",
    "deviant_index = [3, 6, 9, 12]\n",
    "\n",
    "# REVIEW: using glob.glob() would've been more appropropriate here:\n",
    "# for event_file in glob(os.path.join(PATH.ePod_processed_autorject_events, '?' * 8 + '.txt'))\n",
    "# which would allow you to not have the following `if' inside the loop, also would prevent you\n",
    "# from needing `count_analyzed' variable, as the number of files thus retrieved would be the\n",
    "# final value of this variable.\n",
    "for event_file in os.listdir(PATH.ePod_processed_autoreject_events):\n",
    "    if event_file.endswith('.txt') and len(event_file) == 8:\n",
    "        # print(f\"Analyzing {event_file}\")\n",
    "        count_analyzed += 1\n",
    "        event = np.loadtxt(os.path.join(\n",
    "            PATH.ePod_processed_autoreject_events, event_file), dtype=int)\n",
    "\n",
    "        # Count how many events are left in standard, deviant, and FS\n",
    "        # REVIEW: What is the significance of number 4?\n",
    "        # REVIEW: This would've easier to understand if it was a separate\n",
    "        # function.\n",
    "        # REVIEW: Removed unnecessary parenthesis.\n",
    "        # REVIEW: It's better to make things that do similar things look similar.\n",
    "        # This code isrepeatedly calling `np.count_nonzero()' on a similar argument.\n",
    "        # Essentially, the question this condition is asking is something like:\n",
    "        # \"are the numbers of events within desired range\".  This may be made to\n",
    "        # stand out more if expressed as:\n",
    "        # if any(exceeds_limit(kind, limit) for kind, limit in event_ranges[i]):\n",
    "        #     ...\n",
    "        # -----\n",
    "        # where `event_ranges = ((standard_index, standard_minimum), ...)'\n",
    "        # REVIEW: If you decide to rewrite this loop as a separate function, you\n",
    "        # could also avoid having `count_bad' variable, the desired value would be the\n",
    "        # difference between the total number of processed files and the number of\n",
    "        # files yielded by the generator.\n",
    "        for i in range(4):\n",
    "            if np.count_nonzero(event[:, 2] == standard_index[i]) < standard_minimum\n",
    "                or np.count_nonzero(event[:, 2] == deviant_index[i]) < deviant_minimum\n",
    "                    or np.count_nonzero(event[:, 2] == firststandard_index[i]) < firststandard_minimum:\n",
    "                count_bad += 1\n",
    "                break\n",
    "            # REVIEW: Nore This condition is nearly equivalent to adding `else' statement to the loop:\n",
    "            # for i in range(...):\n",
    "            #     if condition:\n",
    "            #        break\n",
    "            # else:\n",
    "            #     this code is executed if `break' was never reached\n",
    "            if i == 3:  # No bads found at end of for loop\n",
    "                clean_list.append(event_file)\n",
    "\n",
    "clean_list = sorted(clean_list)\n",
    "print(f\"Analyzed: {count_analyzed}, bad: {count_bad}\")\n",
    "print(f\"{len(clean_list)} files have enough epochs for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I improved the formatting (minor issue). If there is time, make this a function on the back end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split into train and test dataset\n",
    "Both the train and test sets have the same proportion of participants that did either a, b, or both experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test/train on participant\n",
    "# REVIEW: I believe, that what you wanted here is `os.path.splitext(file)[0]'\n",
    "experiments = [file.replace('.txt', '') for file in clean_list]\n",
    "\n",
    "# Split experiments into participants that did a, b, and both\n",
    "# REVIEW: Could you also just check if 'a' is in the file name?\n",
    "experiments_a = [file.replace('a', '') for file in experiments]\n",
    "experiments_a = [item for item in experiments_a if len(item) == 3]\n",
    "experiments_b = [file.replace('b', '') for file in experiments]\n",
    "experiments_b = [item for item in experiments_b if len(item) == 3]\n",
    "# REVIEW: Is order important here? Otherwise these are best accomplished\n",
    "# by using methods defined on `set()'\n",
    "# Something like:\n",
    "# as = set(exp for exp in experiments if 'a' in exp)\n",
    "# bs = set(exp for exp in experiments if 'b' in exp)\n",
    "# as_and_bs = as.union(bs)\n",
    "experiments_a_and_b = [file for file in experiments_a if file in experiments_b]\n",
    "experiments_a_only = [file for file in experiments_a if file not in experiments_b]\n",
    "experiments_b_only = [file for file in experiments_b if file not in experiments_a]\n",
    "\n",
    "participants = sorted(experiments_a_and_b + experiments_a_only + experiments_b_only)\n",
    "\n",
    "# Split participants into train and test dataset\n",
    "train_ab, test_ab = train_test_split(experiments_a_and_b, test_size=0.25)  \n",
    "train_a, test_a = train_test_split(experiments_a_only, test_size=0.25) \n",
    "train_b, test_b = train_test_split(experiments_b_only, test_size=0.25) \n",
    "\n",
    "# REVIEW: See my comment above. If you simply check for 'a' or 'b'\n",
    "# being present, you don't need to add them back.\n",
    "train = [x + 'a' for x in train_ab] + [x + 'b' for x in train_ab] + \\\n",
    "        [x + 'a' for x in train_a] + [x + 'b' for x in train_b]\n",
    "test = [x + 'a' for x in test_ab] + [x + 'b' for x in test_ab] + \\\n",
    "       [x + 'a' for x in test_a] + [x + 'b' for x in test_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Iterator Sequence as input to feed the model\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class EvokedIterator(Sequence):\n",
    "\n",
    "    # REVIEW: Fixed formatting: extra white space around named arguments,\n",
    "    # also a lot of extra white space in empty lines and at the end of lines.\n",
    "    # Also, spaces after commas and unnecessary parenthesis.\n",
    "    def __init__(self, experiments, n_experiments=8, n_trials_averaged=60):\n",
    "        self.experiments = experiments                \n",
    "        self.n_experiments = n_experiments\n",
    "        self.n_trials_averaged = n_trials_averaged\n",
    "                \n",
    "        metadata_path = os.path.join(PATH.ePod_metadata, \"children.txt\")\n",
    "        self.metadata = pd.read_table(metadata_path)\n",
    "        \n",
    "        event_types = 12 # (FS/S/D in 4 conditions)\n",
    "        self.n_files = len(self.experiments) * event_types\n",
    "        self.batch_size = self.n_experiments * event_types\n",
    "    \n",
    "    def __len__(self):\n",
    "        # The number of batches in the Sequence.\n",
    "        return int(np.ceil(len(self.experiments) / self.n_experiments))  \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in range(self.n_experiments):\n",
    "            participant_index = (index * self.n_experiments + i) % len(self.experiments)\n",
    "            participant_id = self.experiments[participant_index][:3]\n",
    "            participant_metadata = self.metadata.loc[self.metadata['ParticipantID'] == float(participant_id)]\n",
    "\n",
    "            for key in epodium.event_dictionary:\n",
    "\n",
    "                # Get file\n",
    "                # REVIEW: If you are already using f-strings, be consistent, use them here too.\n",
    "                npy_name = self.experiments[participant_index] + \"_\" + key + \".npy\"\n",
    "                npy_path = os.path.join(PATH.ePod_processed_autoreject_epochs_split_downsampled, npy_name)\n",
    "                npy = np.load(npy_path)\n",
    "                \n",
    "                # Create ERP from averaging 'n_trials_averaged' trials.\n",
    "                trial_indexes = np.random.choice(npy.shape[0], self.n_trials_averaged, replace=False)\n",
    "                evoked = np.mean(npy[trial_indexes, :, :], axis=0)\n",
    "                x_batch.append(evoked)\n",
    "\n",
    "                # Create labels\n",
    "                y = np.zeros(5)\n",
    "                if participant_metadata[\"Sex\"].item() == \"F\":\n",
    "                    y[0] = 1\n",
    "                if participant_metadata[\"Group_AccToParents\"].item() == \"At risk\":\n",
    "                    y[1] = 1\n",
    "                \n",
    "                if key.endswith(\"_FS\"):\n",
    "                    y[2] = 1\n",
    "                if key.endswith(\"_S\"):\n",
    "                    y[3] = 1\n",
    "                if key.endswith(\"_D\"):\n",
    "                    y[4] = 1\n",
    "                y_batch.append(y)        \n",
    "\n",
    "        return np.array(x_batch), np.array(y_batch)\n",
    "\n",
    "train_sequence = EvokedIterator(train)\n",
    "test_sequence = EvokedIterator(test)\n",
    "# x,y = train_sequence.__getitem__(0)\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train model\n",
    "\n",
    "The data is an *evoked* or *ERP* from a participant in the ePodium experiment. 60 EEG signals were averaged from -0.2 to +0.8 seconds after onset of an event. This is done for each of the 12 event types seperately.\n",
    "\n",
    "dimensions: \n",
    "+ x (batches, timesteps, channels)\n",
    "+ y (batches, labels)\n",
    "\n",
    "labels: \n",
    "+ (Sex, At risk of dyslexia, first standard, standard, deviant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x7f56d48631f0> already loaded\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6423 - precision_6: 0.5281 - binary_accuracy: 0.6235 - recall_6: 0.3501\n",
      "Epoch 1: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 173s 13s/step - loss: 0.6423 - precision_6: 0.5281 - binary_accuracy: 0.6235 - recall_6: 0.3501 - val_loss: 0.6524 - val_precision_6: 0.4934 - val_binary_accuracy: 0.5817 - val_recall_6: 0.3022 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6443 - precision_6: 0.5294 - binary_accuracy: 0.6234 - recall_6: 0.3322\n",
      "Epoch 2: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 111s 8s/step - loss: 0.6443 - precision_6: 0.5294 - binary_accuracy: 0.6234 - recall_6: 0.3322 - val_loss: 0.6579 - val_precision_6: 0.4915 - val_binary_accuracy: 0.5808 - val_recall_6: 0.2912 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6406 - precision_6: 0.5383 - binary_accuracy: 0.6272 - recall_6: 0.3288\n",
      "Epoch 3: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 110s 8s/step - loss: 0.6406 - precision_6: 0.5383 - binary_accuracy: 0.6272 - recall_6: 0.3288 - val_loss: 0.6530 - val_precision_6: 0.4897 - val_binary_accuracy: 0.5800 - val_recall_6: 0.2871 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6336 - precision_6: 0.5419 - binary_accuracy: 0.6299 - recall_6: 0.3470\n",
      "Epoch 4: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 109s 8s/step - loss: 0.6336 - precision_6: 0.5419 - binary_accuracy: 0.6299 - recall_6: 0.3470 - val_loss: 0.6515 - val_precision_6: 0.4992 - val_binary_accuracy: 0.5846 - val_recall_6: 0.3153 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6350 - precision_6: 0.5457 - binary_accuracy: 0.6333 - recall_6: 0.3729\n",
      "Epoch 5: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 109s 8s/step - loss: 0.6350 - precision_6: 0.5457 - binary_accuracy: 0.6333 - recall_6: 0.3729 - val_loss: 0.6510 - val_precision_6: 0.4939 - val_binary_accuracy: 0.5817 - val_recall_6: 0.3263 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6358 - precision_6: 0.5397 - binary_accuracy: 0.6301 - recall_6: 0.3676\n",
      "Epoch 6: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 109s 8s/step - loss: 0.6358 - precision_6: 0.5397 - binary_accuracy: 0.6301 - recall_6: 0.3676 - val_loss: 0.6558 - val_precision_6: 0.4831 - val_binary_accuracy: 0.5763 - val_recall_6: 0.3022 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6342 - precision_6: 0.5493 - binary_accuracy: 0.6345 - recall_6: 0.3649\n",
      "Epoch 7: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 111s 8s/step - loss: 0.6342 - precision_6: 0.5493 - binary_accuracy: 0.6345 - recall_6: 0.3649 - val_loss: 0.6570 - val_precision_6: 0.4937 - val_binary_accuracy: 0.5817 - val_recall_6: 0.3122 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6345 - precision_6: 0.5436 - binary_accuracy: 0.6321 - recall_6: 0.3702\n",
      "Epoch 8: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 114s 8s/step - loss: 0.6345 - precision_6: 0.5436 - binary_accuracy: 0.6321 - recall_6: 0.3702 - val_loss: 0.6518 - val_precision_6: 0.4909 - val_binary_accuracy: 0.5800 - val_recall_6: 0.3243 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6379 - precision_6: 0.5428 - binary_accuracy: 0.6317 - recall_6: 0.3691\n",
      "Epoch 9: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 113s 8s/step - loss: 0.6379 - precision_6: 0.5428 - binary_accuracy: 0.6317 - recall_6: 0.3691 - val_loss: 0.6581 - val_precision_6: 0.4916 - val_binary_accuracy: 0.5804 - val_recall_6: 0.3243 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6333 - precision_6: 0.5444 - binary_accuracy: 0.6329 - recall_6: 0.3756\n",
      "Epoch 10: val_loss did not improve from 0.65021\n",
      "14/14 [==============================] - 111s 8s/step - loss: 0.6333 - precision_6: 0.5444 - binary_accuracy: 0.6329 - recall_6: 0.3756 - val_loss: 0.6534 - val_precision_6: 0.5008 - val_binary_accuracy: 0.5854 - val_recall_6: 0.3323 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6368 - precision_6: 0.5370 - binary_accuracy: 0.6289 - recall_6: 0.3702\n",
      "Epoch 11: val_loss improved from 0.65021 to 0.64824, saving model to /volume-ceph/models/model.hdf5\n",
      "14/14 [==============================] - 116s 8s/step - loss: 0.6368 - precision_6: 0.5370 - binary_accuracy: 0.6289 - recall_6: 0.3702 - val_loss: 0.6482 - val_precision_6: 0.4848 - val_binary_accuracy: 0.5771 - val_recall_6: 0.3032 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6345 - precision_6: 0.5428 - binary_accuracy: 0.6324 - recall_6: 0.3813\n",
      "Epoch 12: val_loss did not improve from 0.64824\n",
      "14/14 [==============================] - 111s 8s/step - loss: 0.6345 - precision_6: 0.5428 - binary_accuracy: 0.6324 - recall_6: 0.3813 - val_loss: 0.6515 - val_precision_6: 0.4918 - val_binary_accuracy: 0.5804 - val_recall_6: 0.3313 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6360 - precision_6: 0.5442 - binary_accuracy: 0.6327 - recall_6: 0.3752\n",
      "Epoch 13: val_loss did not improve from 0.64824\n",
      "14/14 [==============================] - 106s 8s/step - loss: 0.6360 - precision_6: 0.5442 - binary_accuracy: 0.6327 - recall_6: 0.3752 - val_loss: 0.6562 - val_precision_6: 0.4856 - val_binary_accuracy: 0.5775 - val_recall_6: 0.3052 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6372 - precision_6: 0.5378 - binary_accuracy: 0.6284 - recall_6: 0.3543\n",
      "Epoch 14: val_loss improved from 0.64824 to 0.64788, saving model to /volume-ceph/models/model.hdf5\n",
      "14/14 [==============================] - 111s 8s/step - loss: 0.6372 - precision_6: 0.5378 - binary_accuracy: 0.6284 - recall_6: 0.3543 - val_loss: 0.6479 - val_precision_6: 0.5032 - val_binary_accuracy: 0.5867 - val_recall_6: 0.3143 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6386 - precision_6: 0.5374 - binary_accuracy: 0.6284 - recall_6: 0.3581\n",
      "Epoch 15: val_loss did not improve from 0.64788\n",
      "14/14 [==============================] - 111s 8s/step - loss: 0.6386 - precision_6: 0.5374 - binary_accuracy: 0.6284 - recall_6: 0.3581 - val_loss: 0.6500 - val_precision_6: 0.5063 - val_binary_accuracy: 0.5883 - val_recall_6: 0.3203 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6312 - precision_6: 0.5459 - binary_accuracy: 0.6339 - recall_6: 0.3801\n",
      "Epoch 16: val_loss did not improve from 0.64788\n",
      "14/14 [==============================] - 103s 8s/step - loss: 0.6312 - precision_6: 0.5459 - binary_accuracy: 0.6339 - recall_6: 0.3801 - val_loss: 0.6573 - val_precision_6: 0.4833 - val_binary_accuracy: 0.5754 - val_recall_6: 0.3343 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6365 - precision_6: 0.5438 - binary_accuracy: 0.6323 - recall_6: 0.3706\n",
      "Epoch 17: val_loss did not improve from 0.64788\n",
      "14/14 [==============================] - 113s 8s/step - loss: 0.6365 - precision_6: 0.5438 - binary_accuracy: 0.6323 - recall_6: 0.3706 - val_loss: 0.6488 - val_precision_6: 0.5017 - val_binary_accuracy: 0.5858 - val_recall_6: 0.2942 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6351 - precision_6: 0.5528 - binary_accuracy: 0.6359 - recall_6: 0.3607\n",
      "Epoch 18: val_loss did not improve from 0.64788\n",
      "14/14 [==============================] - 102s 7s/step - loss: 0.6351 - precision_6: 0.5528 - binary_accuracy: 0.6359 - recall_6: 0.3607 - val_loss: 0.6498 - val_precision_6: 0.5008 - val_binary_accuracy: 0.5854 - val_recall_6: 0.3273 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6335 - precision_6: 0.5423 - binary_accuracy: 0.6321 - recall_6: 0.3801\n",
      "Epoch 19: val_loss improved from 0.64788 to 0.64246, saving model to /volume-ceph/models/model.hdf5\n",
      "14/14 [==============================] - 110s 8s/step - loss: 0.6335 - precision_6: 0.5423 - binary_accuracy: 0.6321 - recall_6: 0.3801 - val_loss: 0.6425 - val_precision_6: 0.5063 - val_binary_accuracy: 0.5883 - val_recall_6: 0.3253 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6314 - precision_6: 0.5443 - binary_accuracy: 0.6329 - recall_6: 0.3767\n",
      "Epoch 20: val_loss did not improve from 0.64246\n",
      "14/14 [==============================] - 111s 8s/step - loss: 0.6314 - precision_6: 0.5443 - binary_accuracy: 0.6329 - recall_6: 0.3767 - val_loss: 0.6487 - val_precision_6: 0.4977 - val_binary_accuracy: 0.5838 - val_recall_6: 0.3263 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6325 - precision_6: 0.5514 - binary_accuracy: 0.6371 - recall_6: 0.3855\n",
      "Epoch 21: val_loss did not improve from 0.64246\n",
      "14/14 [==============================] - 115s 8s/step - loss: 0.6325 - precision_6: 0.5514 - binary_accuracy: 0.6371 - recall_6: 0.3855 - val_loss: 0.6570 - val_precision_6: 0.4777 - val_binary_accuracy: 0.5725 - val_recall_6: 0.3223 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.6299 - precision_6: 0.5429 - binary_accuracy: 0.6327 - recall_6: 0.3855\n",
      "Epoch 22: val_loss did not improve from 0.64246\n",
      "14/14 [==============================] - 108s 8s/step - loss: 0.6299 - precision_6: 0.5429 - binary_accuracy: 0.6327 - recall_6: 0.3855 - val_loss: 0.6491 - val_precision_6: 0.4992 - val_binary_accuracy: 0.5846 - val_recall_6: 0.3303 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "13/14 [==========================>...] - ETA: 5s - loss: 0.6307 - precision_6: 0.5566 - binary_accuracy: 0.6311 - recall_6: 0.3822 "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from models.DNN import fully_connected_model\n",
    "from models.Transformer import TransformerModel\n",
    "\n",
    "# fit network\n",
    "# REVIEW:  Move all libraries to the top, please. Also, ideally notebooks need to execute in one go.  \n",
    "# Please don't rely on\n",
    "# variables being defined in the cells *following* the cell, or later inside the \n",
    "# same cell (as here) that uses\n",
    "# the variable.  In this case, writing a function that applies to `model'\n",
    "# would've been an appropriate alternative.\n",
    "try:\n",
    "    print(f\"{model} already loaded\")\n",
    "except:\n",
    "    print(\"initialise model\")\n",
    "    model = fully_connected_model()\n",
    "    # REVIEW: Be consistent in the way you import definitions.\n",
    "    # A good rule of thumb is to import classes from modules.  In this\n",
    "    # instance, this means:\n",
    "    # from tf.kears.optimizers import Adam\n",
    "    # and later used as simply `Adam' instead of `tf.keras.optimizers.Adam'\n",
    "    #also formatting\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    output_filename = 'fully_connecteed_model'\n",
    "    output_file = os.path.join(PATH.models, output_filename)\n",
    "    # REVIEW:formatting\n",
    "    checkpointer = ModelCheckpoint(filepath=output_file + \".hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=1200, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=200, min_lr=0.0001, verbose=1)\n",
    "\n",
    "history = model.fit(x=train_sequence,\n",
    "                    validation_data=test_sequence,\n",
    "                    epochs=100,\n",
    "                    callbacks=[checkpointer, earlystopper, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as mentioned before, save off a graph of things like loss, and then you can just clear the outputs before saving...will look better.\n",
    "Needs a final conclusion in a markdown cell about what was proved here. We want to know how the accuracy went up ; or not"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
