{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning on Dutch Dyslexia Program dataset\n",
    "\n",
    "Inspired by: https://github.com/epodium/EEG_age_prediction\n",
    "\n",
    "(- Load subject ages from excel file)\n",
    "- Load raw EEG data from .cnt files\n",
    "- Apply filters (bandpass)\n",
    "- Detect potential bad channels and replace them by interpolation\n",
    "- Detect potential bad epochs and remove them\n",
    "- Save processed data (and metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os              \n",
    "import sys\n",
    "import glob\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import mne\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# PATH_MAIN = os.path.join(main_path, 'researchdrive', 'ePodium (Projectfolder)')\n",
    "PATH_MAIN = os.path.join('D:', 'EEG Data', 'DDP Surfdrive')\n",
    "PATH_METADATA = os.path.join(PATH_MAIN, 'metadata')\n",
    "PATH_PROCESSED = os.path.join(PATH_MAIN, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eegyolk initialization_functions\n",
    "\n",
    "def load_dataset(folder_dataset, file_extension = '.bdf', preload=True, max_files_preloaded = 5):\n",
    "    '''\n",
    "    This function is for datasets under 5 files. Otherwise use generator_load_dataset\n",
    "    Reads and returns the files that store the EEG data,\n",
    "    along with a list of the filenames and paths of these bdf files. \n",
    "    Takes as input the top folder location of the dataset.\n",
    "    '''\n",
    "    pattern = os.path.join(folder_dataset, '**/*' + file_extension)\n",
    "    eeg_filepaths = glob.glob(pattern, recursive=True)\n",
    "    eeg_dataset = []\n",
    "    eeg_filenames = []\n",
    "    eeg_filenames_failed_to_load = []\n",
    "\n",
    "    files_loaded = 0\n",
    "    files_failed_to_load = 0\n",
    "    for path in eeg_filepaths:\n",
    "        filename = os.path.split(path)[1].replace(file_extension, '')\n",
    "\n",
    "        if(file_extension == '.bdf'):\n",
    "            raw = mne.io.read_raw_bdf(path,preload=preload)\n",
    "\n",
    "        if(file_extension == '.cnt'): # .cnt files do not always load.\n",
    "            try:\n",
    "                raw = mne.io.read_raw_cnt(path,preload=preload)\n",
    "            except:\n",
    "                eeg_filenames_failed_to_load.append(filename)\n",
    "                files_failed_to_load += 1\n",
    "                print(f\"File {filename} could not be loaded.\") \n",
    "                continue\n",
    "\n",
    "        eeg_dataset.append(raw)\n",
    "        eeg_filenames.append(filename)\n",
    "        files_loaded += 1\n",
    "        print(files_loaded, \"EEG files loaded\")\n",
    "        if preload and files_loaded >= max_files_preloaded : break\n",
    "\n",
    "        clear_output(wait=True)\n",
    "    print(len(eeg_dataset), \"EEG files loaded\")\n",
    "    if(files_failed_to_load>0): print(files_failed_to_load, \"EEG files failed to load\")\n",
    "\n",
    "    return eeg_dataset, eeg_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 EEG files loaded\n"
     ]
    }
   ],
   "source": [
    "# folder_ddp_dataset = os.path.join(data_path, \"DDP Dataset\") # folder in Surf research drive\n",
    "main_folder_ddp_dataset = os.path.join(\"D:\", \"EEG Data\", \"DDP Surfdrive\") # local folder\n",
    "\n",
    "ddp_age_folders = ['5mnd mmn', '11mnd mmn', '17mnd mmn', '23mnd mmn',\n",
    "                    '29mnd mmn', '35mnd mmn', '41mnd mmn', '47mnd mmn']\n",
    "\n",
    "for i, ddp_age_group in enumerate(ddp_age_folders):\n",
    "    age_group_folder_location = os.path.join(main_folder_ddp_dataset, ddp_age_folders[i])\n",
    "    epod_raw, epod_filenames = load_dataset(age_group_folder_location, file_extension = '.cnt', preload=False)\n",
    "    epod_raw_preload, epod_filenames_preload = load_dataset(age_group_folder_location, file_extension = '.cnt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "\n",
    "- From https://github.com/epodium/EEG_age_prediction/blob/main/Notebooks/Deep%20learning%20EEG_dataset%20preprocessing_DL.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cnt_file(file,\n",
    "                  label_group,\n",
    "                  event_idx = [2, 3, 4, 5, 12, 13, 14, 15],\n",
    "                  channel_set = \"30\",\n",
    "                  tmin = -0.2,\n",
    "                  tmax = 0.8,\n",
    "                  lpass = 0.5, \n",
    "                  hpass = 40, \n",
    "                  threshold = 5, \n",
    "                  max_bad_fraction = 0.2,\n",
    "                  max_bad_channels = 2):\n",
    "    \"\"\" Function to read cnt file. Run bandpass filter. \n",
    "    Then detect and correct/remove bad channels and bad epochs.\n",
    "    Store resulting epochs as arrays.\n",
    "    \n",
    "    Args:\n",
    "    --------\n",
    "    file: str\n",
    "        Name of file to import.\n",
    "    label_group: int\n",
    "        Unique ID of specific group (must be >0).\n",
    "    channel_set: str\n",
    "        Select among pre-defined channel sets. Here: \"30\" or \"62\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if channel_set == \"30\":\n",
    "        channel_set = ['O2', 'O1', 'OZ', 'PZ', 'P4', 'CP4', 'P8', 'C4', 'TP8', 'T8', 'P7', \n",
    "                       'P3', 'CP3', 'CPZ', 'CZ', 'FC4', 'FT8', 'TP7', 'C3', 'FCZ', 'FZ', \n",
    "                       'F4', 'F8', 'T7', 'FT7', 'FC3', 'F3', 'FP2', 'F7', 'FP1']\n",
    "    elif channel_set == \"62\":\n",
    "        channel_set = ['O2', 'O1', 'OZ', 'PZ', 'P4', 'CP4', 'P8', 'C4', 'TP8', 'T8', 'P7', \n",
    "                       'P3', 'CP3', 'CPZ', 'CZ', 'FC4', 'FT8', 'TP7', 'C3', 'FCZ', 'FZ', \n",
    "                       'F4', 'F8', 'T7', 'FT7', 'FC3', 'F3', 'FP2', 'F7', 'FP1', 'AFZ', 'PO3', \n",
    "                       'P1', 'POZ', 'P2', 'PO4', 'CP2', 'P6', 'M1', 'CP6', 'C6', 'PO8', 'PO7', \n",
    "                       'P5', 'CP5', 'CP1', 'C1', 'C2', 'FC2', 'FC6', 'C5', 'FC1', 'F2', 'F6', \n",
    "                       'FC5', 'F1', 'AF4', 'AF8', 'F5', 'AF7', 'AF3', 'FPZ']\n",
    "    else:\n",
    "        print(\"Predefined channel set given by 'channel_set' not known...\")\n",
    "        \n",
    "    \n",
    "    # Initialize array\n",
    "    signal_collection = np.zeros((0,len(channel_set),501))\n",
    "    label_collection = [] #np.zeros((0))\n",
    "    channel_names_collection = []\n",
    "    \n",
    "    # Import file\n",
    "    try:\n",
    "        data_raw = mne.io.read_raw_cnt(file, eog='auto', preload=True, verbose=False)\n",
    "    except ValueError:\n",
    "        print(\"ValueError\")\n",
    "        print(\"Could not load file:\", file)\n",
    "        return None, None, None\n",
    "    \n",
    "    # Band-pass filter (between 0.5 and 40 Hz. was 0.5 to 30Hz in Stober 2016)\n",
    "    data_raw.filter(0.5, 40, fir_design='firwin')\n",
    "\n",
    "    # Get events from annotations in the data\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(data_raw)\n",
    "    \n",
    "    # Set baseline:\n",
    "    baseline = (None, 0)  # means from the first instant to t = 0\n",
    "\n",
    "    # Select channels to exclude (if any)\n",
    "    channels_exclude = [x for x in data_raw.ch_names if x not in channel_set]\n",
    "    channels_exclude = [x for x in channels_exclude if x not in ['HEOG', 'VEOG']]\n",
    "    \n",
    "    for event_id in event_idx:\n",
    "        if str(event_id) in event_dict:\n",
    "            # Pick EEG channels\n",
    "            picks = mne.pick_types(data_raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                               #exclude=data_exclude)#'bads'])\n",
    "                                   include=channel_set, exclude=channels_exclude)#'bads'])\n",
    "\n",
    "            epochs = mne.Epochs(data_raw, events=events_from_annot, event_id=event_dict,\n",
    "                                tmin=tmin, tmax=tmax, proj=True, picks=picks,\n",
    "                                baseline=baseline, preload=True, event_repeated='merge', verbose=False)\n",
    "\n",
    "            # Detect potential bad channels and epochs\n",
    "            bad_channels, bad_epochs = helper_functions.select_bad_epochs(epochs,\n",
    "                                                                          event_id,\n",
    "                                                                          threshold = threshold,\n",
    "                                                                          max_bad_fraction = max_bad_fraction)\n",
    "\n",
    "            # Interpolate bad channels\n",
    "            # ------------------------------------------------------------------\n",
    "            if len(bad_channels) > 0:\n",
    "                if len(bad_channels) > max_bad_channels:\n",
    "                    print(20*'--')\n",
    "                    print(\"Found too many bad channels (\" + str(len(bad_channels)) + \")\")\n",
    "                    return None, None, None\n",
    "                else:\n",
    "                    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "                    montage.ch_names = [ch_name.upper() for ch_name in montage.ch_names]\n",
    "                    data_raw.set_montage(montage)\n",
    "                    \n",
    "                    # MARK: Think about using all channels before removing (62 -> 30), to enable for better interpolation\n",
    "                    \n",
    "                    # Mark bad channels:\n",
    "                    data_raw.info['bads'] = bad_channels\n",
    "                    # Pick EEG channels:\n",
    "                    picks = mne.pick_types(data_raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                                       #exclude=data_exclude)#'bads'])\n",
    "                                       include=channel_set, exclude=channels_exclude)#'bads'])\n",
    "                    epochs = mne.Epochs(data_raw, events=events_from_annot, event_id=event_dict,\n",
    "                                        tmin=tmin, tmax=tmax, proj=True, picks=picks,\n",
    "                                        baseline=baseline, preload=True, verbose=False)\n",
    "                    \n",
    "                    # Interpolate bad channels using functionality of 'mne'\n",
    "                    epochs.interpolate_bads()\n",
    "                    \n",
    "\n",
    "            # Get signals as array and add to total collection\n",
    "            channel_names_collection.append(epochs.ch_names)\n",
    "            signals_cleaned = epochs[str(event_id)].drop(bad_epochs).get_data()\n",
    "            signal_collection = np.concatenate((signal_collection, signals_cleaned), axis=0)\n",
    "            label_collection += [event_id + label_group] * signals_cleaned.shape[0]\n",
    "\n",
    "    return signal_collection, label_collection, channel_names_collection"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('VENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
