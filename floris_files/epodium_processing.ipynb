{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing raw EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from autoreject import AutoReject # https://autoreject.github.io/stable/index.html\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "import local_paths\n",
    "\n",
    "from functions import epodium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering ePodium dataset and rejecting bad trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running autoreject on ch_type=eeg\n",
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec968bfa282644a781a8a1cb6f56dd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1e60bd35c741a58711d8d33c718b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c8d77e68964716a5c031320b828739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8490ff5f79440da802041b0035e703d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29a2ecfdac74032a56e8f671f960aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcde719bee2458b8681fb9fb644ee22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# These experiments are incomplete\n",
    "ignore_files = [\"113a\", \"107b (deel 1+2)\", \"132a\", \"121b(2)\", \"113b\", \"107b (deel 3+4)\", \"147a\",\n",
    "                \"121a\", \"134a\", \"143b\", \"121b(1)\", \"145b\", \"152a\", \"184a\", \"165a\", \"151a\", \"163a\"]\n",
    "\n",
    "def process_file(method, file):\n",
    "    # methods are: 'autoreject'\n",
    "    filename, extension = os.path.splitext(file)\n",
    "    path = os.path.join(local_paths.ePod_dataset, file)\n",
    "    \n",
    "    if extension == '.bdf':\n",
    "        if(method == \"autoreject\"):\n",
    "            path_processed = os.path.join(local_paths.ePod_processed_autoreject, 'epochs', filename + \".npy\")\n",
    "            path_events = os.path.join(local_paths.ePod_processed_autoreject, 'events', filename + \".txt\")        \n",
    "\n",
    "            if os.path.exists(path_processed) and os.path.exists(path_events):\n",
    "                # print(f\"File {file} already processed \\n\", end = '')\n",
    "                return\n",
    "\n",
    "            if filename in ignore_files:\n",
    "                return\n",
    "\n",
    "            # print(f\"Processing file: {file}  \\n\" , end = '')        \n",
    "            raw = mne.io.read_raw_bdf(path, preload = True, verbose = False)\n",
    "            events = mne.find_events(raw, verbose = False)\n",
    "            events_12 = epodium.group_events_12(events)\n",
    "\n",
    "            # Set electrodes\n",
    "            raw.pick_channels(epodium.channel_names)\n",
    "            montage = mne.channels.make_standard_montage('standard_1020') \n",
    "            raw.info.set_montage(montage, on_missing = 'ignore')\n",
    "\n",
    "            # High-pass filter for detrending\n",
    "            raw.filter(0.1, None, verbose = False)\n",
    "            # Create epochs from raw\n",
    "            try:\n",
    "                epochs = mne.Epochs(raw, events_12, epodium.event_dictionary, -0.2, 0.8, preload = True, verbose = False)\n",
    "            except:\n",
    "                print(f\"Not all events in file {file} \\n\", end = '')\n",
    "                return\n",
    "            # Low pass filter for high-frequency artifacts\n",
    "            epochs.filter(None, 40, verbose = False)\n",
    "\n",
    "            # Reject bad trials and repair bad sensors in EEG\n",
    "            ar = AutoReject()\n",
    "            epochs_clean = ar.fit_transform(epochs)  \n",
    "\n",
    "            # Save data and events\n",
    "            np.save(path_processed, epochs_clean.get_data())        \n",
    "            np.savetxt(path_events, epochs_clean.events, fmt='%i')\n",
    "\n",
    "# Multiprocessing\n",
    "pool = Pool(processes = 4)\n",
    "# TODO glob :glob.glob(os.path.join(local_paths.ePod_dataset, '*.bdf')\n",
    "pool.map(functools.partial(process_file, \"autoreject\"), os.listdir(local_paths.ePod_dataset))\n",
    "\n",
    "print(\"All files processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into seperate files for each events and downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1020') \n",
    "\n",
    "# Check if each file already exist\n",
    "unsaved_files = []\n",
    "for npy_file in os.listdir(os.path.join(local_paths.ePod_processed_autoreject, 'epochs')):\n",
    "    for event in epodium.event_dictionary:\n",
    "        npy_name = npy_file[:-4] + \"_\" + event + \".npy\"\n",
    "        path_processed = os.path.join(local_paths.ePod_processed_autoreject_epochs_split_downsampled, \\\n",
    "                                      npy_file[:-4] + \"_\" + event + \".npy\")\n",
    "        if not os.path.exists(path_processed):\n",
    "            unsaved_files.append(npy_file)\n",
    "\n",
    "if(unsaved_files): \n",
    "    print(f\"Splitting files: {unsaved_files}\")\n",
    "else: \n",
    "    print(\"All files complete\")\n",
    "\n",
    "for npy_file in unsaved_files:\n",
    "    npy = np.load(os.path.join(local_paths.ePod_processed_autoreject, 'epochs', file))\n",
    "    events_12 = np.loadtxt(os.path.join(local_paths.ePod_processed_autoreject, 'events', file[:-4] + \".txt\"), dtype=int)\n",
    "    info = mne.create_info(epodium.channel_names, 2048, ch_types='eeg')\n",
    "\n",
    "    epochs = mne.EpochsArray(npy, info, events=events_12, tmin=-0.2, \n",
    "                             event_id=epodium.event_dictionary, verbose=False)\n",
    "    epochs.info.set_montage(montage, on_missing = 'ignore')\n",
    "\n",
    "    for event in epodium.event_dictionary:\n",
    "        path_processed = os.path.join(local_paths.ePod_processed_autoreject_epochs_split_downsampled, \\\n",
    "                                      npy_file[:-4] + \"_\" + event + \".npy\")\n",
    "        if os.path.exists(path_processed):\n",
    "            continue\n",
    "        np.save(path_processed, epochs[event].resample(512).get_data())  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step of ideal pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Pipeline\n",
    "\n",
    "+ Prepare EEG \n",
    "1. Drop unused channels\n",
    "2. Subtract reference (mastoids)\n",
    "3. Detrend \n",
    "4. Filter\n",
    "5. Remove bad channels\n",
    "\n",
    "+ Segment EEG into standard and deviant epochs (ERPs)\n",
    "1. subtract baseline\n",
    "2. Reject artefacts\n",
    "3. Average to get evoked (for each marker/subject/channel separately)\n",
    "\n",
    "+ Calculate Mismatch response \n",
    "1. deviant - standard for a single subject, for example GiepST_D - GiepST_S\n",
    "2. check differences between channels and subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse mismatch response \n",
    "\n",
    "Deviant minus standard ERP\n",
    "+ Check between subjects to see if the subjects have similar responses\n",
    "+ Check between channels to observe which parts of the brain are more influenced by the events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract features (Optional)\n",
    "+ peak latency\n",
    "+ peak amplitude\n",
    "+ mean amplitude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data into DL models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
