{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing raw EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from autoreject import AutoReject # https://autoreject.github.io/stable/index.html\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import local_paths\n",
    "from functions import epodium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering ePodium dataset and rejecting bad trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 101a.bdf already processed \n",
      "File 108a.bdf already processed \n",
      "File 116a.bdf already processed \n",
      "File 123a.bdf already processed \n",
      "File 116b.bdf already processed \n",
      "File 101b.bdf already processed \n",
      "File 109a.bdf already processed \n",
      "File 123b.bdf already processed \n",
      "File 117a.bdf already processed \n",
      "File 124a.bdf already processed \n",
      "File 102a.bdf already processed \n",
      "File 109b.bdf already processed \n",
      "File 117b.bdf already processed \n",
      "File 125a.bdf already processed \n",
      "File 102b.bdf already processed \n",
      "File 110a.bdf already processed \n",
      "File 118a.bdf already processed \n",
      "File 125b.bdf already processed \n",
      "File 110b.bdf already processed \n",
      "File 103a.bdf already processed \n",
      "File 118b.bdf already processed \n",
      "File 126a.bdf already processed \n",
      "File 111a.bdf already processed \n",
      "File 103b.bdf already processed \n",
      "File 119a.bdf already processed \n",
      "File 111b.bdf already processed \n",
      "File 126b.bdf already processed \n",
      "File 104a.bdf already processed \n",
      "File 119b.bdf already processed \n",
      "File 112a.bdf already processed \n",
      "File 104b.bdf already processed \n",
      "File 127a.bdf already processed \n",
      "File 120a.bdf already processed \n",
      "File 112b.bdf already processed \n",
      "File 127b.bdf already processed \n",
      "File 113a.bdf ignored \n",
      "File 105a.bdf already processed \n",
      "File 113b.bdf ignored \n",
      "File 120b.bdf already processed \n",
      "File 128a.bdf already processed \n",
      "File 105b.bdf already processed \n",
      "File 121a.bdf ignored \n",
      "File 128b.bdf already processed \n",
      "File 114a.bdf already processed \n",
      "File 106a.bdf already processed \n",
      "File 121b(1).bdf ignored \n",
      "File 129a.bdf already processed \n",
      "File 114b.bdf already processed \n",
      "File 121b(2).bdf ignored \n",
      "File 106b.bdf already processed \n",
      "File 129b.bdf already processed \n",
      "File 122a.bdf already processed \n",
      "File 115a.bdf already processed \n",
      "File 130a.bdf already processed \n",
      "File 107a.bdf already processed \n",
      "File 122b.bdf already processed \n",
      "File 115b.bdf already processed \n",
      "File 107b (deel 1+2).bdf ignored \n",
      "File 130b.bdf already processed \n",
      "File 131a.bdf already processed \n",
      "File 107b (deel 3+4).bdf ignored \n",
      "File 138b.bdf already processed \n",
      "File 131b.bdf already processed \n",
      "File 154b.bdf already processed \n",
      "File 146b.bdf already processed \n",
      "File 139a.bdf already processed \n",
      "File 155a.bdf already processed \n",
      "File 147a.bdf ignored \n",
      "File 132a.bdf ignored \n",
      "File 155b.bdf already processed \n",
      "File 139b.bdf already processed \n",
      "File 132b.bdf already processed \n",
      "File 148a.bdf already processed \n",
      "File 156a.bdf already processed \n",
      "File 140a.bdf already processed \n",
      "File 133a.bdf already processed \n",
      "File 148b.bdf already processed \n",
      "File 156b.bdf already processed \n",
      "File 140b.bdf already processed \n",
      "File 149a.bdf already processed \n",
      "File 133b.bdf already processed \n",
      "File 157a.bdf already processed \n",
      "File 141a.bdf already processed \n",
      "File 149b.bdf already processed \n",
      "File 134a.bdf ignored \n",
      "File 157b.bdf already processed \n",
      "File 142a.bdf already processed \n",
      "File 150a.bdf already processed \n",
      "File 134b.bdf already processed \n",
      "File 158a.bdf already processed \n",
      "File 150b.bdf already processed \n",
      "File 142b.bdf already processed \n",
      "File 158b.bdf already processed \n",
      "File 135a.bdf already processed \n",
      "File 143a.bdf already processed \n",
      "File 159a.bdf already processed \n",
      "File 151a.bdf ignored \n",
      "File 135b.bdf already processed \n",
      "File 143b.bdf ignored \n",
      "File 159b.bdf already processed \n",
      "File 151b.bdf already processed \n",
      "File 144a.bdf already processed \n",
      "File 152a.bdf ignored \n",
      "File 136a.bdf already processed \n",
      "File 160a (2).bdf already processed \n",
      "File 152b.bdf already processed \n",
      "File 136b.bdf already processed \n",
      "File 144b.bdf already processed \n",
      "File 160a.bdf already processed \n",
      "File 153a.bdf already processed \n",
      "File 160b.bdf already processed \n",
      "File 153b.bdf already processed \n",
      "File 145a.bdf already processed \n",
      "File 137a.bdf already processed \n",
      "File 161a.bdf already processed \n",
      "File 145b.bdf ignored \n",
      "File 154a.bdf already processed \n",
      "File 137b.bdf already processed \n",
      "File 161b.bdf already processed \n",
      "File 146a.bdf already processed \n",
      "File 138a.bdf already processed \n",
      "File 162a.bdf already processed \n",
      "File 169b.bdf already processed \n",
      "File 177a.bdf already processed \n",
      "File 162b.bdf already processed \n",
      "File 184b.bdf already processed \n",
      "File 177b.bdf already processed \n",
      "File 185a.bdf already processed \n",
      "File 163a.bdf ignored \n",
      "File 178a.bdf already processed \n",
      "File 185b.bdf already processed \n",
      "File 163b.bdf already processed \n",
      "File 170a.bdf already processed \n",
      "File 164a.bdf already processed \n",
      "File 186a.bdf already processed \n",
      "File 178b.bdf already processed \n",
      "File 170b.bdf already processed \n",
      "File 164b.bdf already processed \n",
      "File 186b.bdf already processed \n",
      "File 179a.bdf already processed \n",
      "File 165a.bdf ignored \n",
      "File 171a.bdf already processed \n",
      "File 179b.bdf already processed \n",
      "File 165b.bdf already processed \n",
      "File 187a.bdf already processed \n",
      "File 171b.bdf already processed \n",
      "File 180a.bdf already processed \n",
      "File 188a.bdf already processed \n",
      "File 172a.bdf already processed \n",
      "File 166a.bdf already processed \n",
      "File 180b.bdf already processed \n",
      "File 166b.bdf already processed \n",
      "File 188b.bdf already processed \n",
      "File 181a.bdf already processed \n",
      "File 172b.bdf already processed \n",
      "File 181b.bdf already processed \n",
      "File 189a.bdf already processed \n",
      "File 167a.bdf already processed \n",
      "File 173a.bdf already processed \n",
      "File 182a.bdf already processed \n",
      "File 189b.bdf already processed \n",
      "File 168a.bdf already processed \n",
      "File 173b.bdf already processed \n",
      "File 182b.bdf already processed \n",
      "File 190a.bdf already processed \n",
      "File 168b.bdf already processed \n",
      "File 183a.bdf already processed \n",
      "File 174a.bdf already processed \n",
      "File 169a.bdf already processed \n",
      "File 190b.bdf already processed \n",
      "File 183b.bdf already processed \n",
      "File 174b.bdf already processed \n",
      "File 192b.bdf already processed \n",
      "File 184a.bdf ignored \n",
      "File 191a.bdf already processed \n",
      "File 175a.bdf already processed \n",
      "File 193a.bdf already processed \n",
      "File 200b.bdf already processed \n",
      "File 191b.bdf already processed \n",
      "File 175b.bdf already processed \n",
      "Processing file: 201a.bdf  \n",
      "File 192a.bdf already processed \n",
      "File 176a.bdf already processed \n",
      "File 193b.bdf already processed \n",
      "File 176b.bdf already processed \n",
      "File 194a.bdf already processed \n",
      "File 194b.bdf already processed \n",
      "File 195a.bdf already processed \n",
      "File 208b.bdf already processed \n",
      "File 216a.bdf already processed \n",
      "File 196a.bdf already processed \n",
      "File 209a.bdf already processed \n",
      "File 196b.bdf already processed \n",
      "File 209b.bdf already processed \n",
      "File 197a.bdf already processed \n",
      "File 197b.bdf already processed \n",
      "Processing file: 210a.bdf  \n",
      "File 198a.bdf already processed \n",
      "File 198b.bdf already processed \n",
      "File 199a.bdf already processed \n",
      "File 216b.bdf already processed \n",
      "File 199b.bdf already processed \n",
      "File 217a.bdf already processed \n",
      "File 200a.bdf already processed \n",
      "File 217b.bdf already processed \n",
      "File 218a.bdf already processed \n",
      "File 218b.bdf already processed \n",
      "File 219a.bdf already processed \n",
      "File 219b.bdf already processed \n",
      "File 220a.bdf already processed \n",
      "Processing file: 220b.bdf  \n",
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ee060a0ce349398884f486fc3e9a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487975e6187a44e68669f735eb265f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6639d3ff372543c6b821faae70b2c008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77d721da0734d80a180ddd09261b2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/32 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# These experiments are incomplete\n",
    "ignore_files = [\"113a\", \"107b (deel 1+2)\", \"132a\", \"121b(2)\", \"113b\", \"107b (deel 3+4)\", \"147a\",\n",
    "                \"121a\", \"134a\", \"143b\", \"121b(1)\", \"145b\", \"152a\", \"184a\", \"165a\", \"151a\", \"163a\",\n",
    "                \"207a\", \"215b\"]\n",
    "\n",
    "def process_file(path_file, method = \"autoreject\"):\n",
    "    # methods are: 'autoreject' ... TODO\n",
    "    file = os.path.basename(path_file)\n",
    "    filename, extension = os.path.splitext(file)\n",
    "    path = os.path.join(local_paths.ePod_dataset, file)\n",
    "    \n",
    "    path_processed = os.path.join(local_paths.ePod_processed_autoreject, 'epochs', filename + \".npy\")\n",
    "    path_events = os.path.join(local_paths.ePod_processed_autoreject, 'events', filename + \".txt\")        \n",
    "\n",
    "    if os.path.exists(path_processed) and os.path.exists(path_events):\n",
    "        print(f\"File {file} already processed \\n\", end = '')\n",
    "        return\n",
    "\n",
    "    if filename in ignore_files:\n",
    "        print(f\"File {file} ignored \\n\", end = '')\n",
    "        return\n",
    "\n",
    "    print(f\"Processing file: {file}  \\n\" , end = '')        \n",
    "    raw = mne.io.read_raw_bdf(path_file, preload = True, verbose = False)\n",
    "    events = mne.find_events(raw, verbose = False)\n",
    "    events_12 = epodium.group_events_12(events)\n",
    "\n",
    "    # Set electrodes\n",
    "    raw.pick_channels(epodium.channel_names)\n",
    "    montage = mne.channels.make_standard_montage('standard_1020') \n",
    "    raw.info.set_montage(montage, on_missing = 'ignore')\n",
    "\n",
    "    # High-pass filter for detrending\n",
    "    raw.filter(0.1, None, verbose = False)\n",
    "    # Create epochs from raw\n",
    "    try:\n",
    "        epochs = mne.Epochs(raw, events_12, epodium.event_dictionary, -0.2, 0.8, preload = True, verbose = False)\n",
    "    except:\n",
    "        print(f\"Not all events in file {file} \\n\", end = '')\n",
    "        return\n",
    "    # Low pass filter for high-frequency artifacts\n",
    "    epochs.filter(None, 40, verbose = False)\n",
    "\n",
    "    # Reject bad trials and repair bad sensors in EEG\n",
    "    ar = AutoReject()\n",
    "    epochs_clean = ar.fit_transform(epochs)  \n",
    "\n",
    "    # Save data and events\n",
    "    np.save(path_processed, epochs_clean.get_data())        \n",
    "    np.savetxt(path_events, epochs_clean.events, fmt='%i')\n",
    "\n",
    "# Multiprocessing\n",
    "pool = Pool(processes = 4)\n",
    "pool.map(functools.partial(process_file, method = \"autoreject\"), sorted(glob.glob(os.path.join(local_paths.ePod_dataset, '*.bdf'))))\n",
    "\n",
    "print(\"All files processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into seperate files for each events and downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1020') \n",
    "\n",
    "# Check if each file already exist\n",
    "unsaved_files = []\n",
    "for npy_file in os.listdir(os.path.join(local_paths.ePod_processed_autoreject, 'epochs')):\n",
    "    for event in epodium.event_dictionary:\n",
    "        npy_name = npy_file[:-4] + \"_\" + event + \".npy\"\n",
    "        path_processed = os.path.join(local_paths.ePod_processed_autoreject_epochs_split_downsampled, \\\n",
    "                                      npy_file[:-4] + \"_\" + event + \".npy\")\n",
    "        if not os.path.exists(path_processed):\n",
    "            unsaved_files.append(npy_file)\n",
    "\n",
    "if(unsaved_files): \n",
    "    print(f\"Splitting files: {unsaved_files}\")\n",
    "else: \n",
    "    print(\"All files complete\")\n",
    "\n",
    "for npy_file in unsaved_files:\n",
    "    npy = np.load(os.path.join(local_paths.ePod_processed_autoreject, 'epochs', file))\n",
    "    events_12 = np.loadtxt(os.path.join(local_paths.ePod_processed_autoreject, 'events', file[:-4] + \".txt\"), dtype=int)\n",
    "    info = mne.create_info(epodium.channel_names, 2048, ch_types='eeg')\n",
    "\n",
    "    epochs = mne.EpochsArray(npy, info, events=events_12, tmin=-0.2, \n",
    "                             event_id=epodium.event_dictionary, verbose=False)\n",
    "    epochs.info.set_montage(montage, on_missing = 'ignore')\n",
    "\n",
    "    for event in epodium.event_dictionary:\n",
    "        path_processed = os.path.join(local_paths.ePod_processed_autoreject_epochs_split_downsampled, \\\n",
    "                                      npy_file[:-4] + \"_\" + event + \".npy\")\n",
    "        if os.path.exists(path_processed):\n",
    "            continue\n",
    "        np.save(path_processed, epochs[event].resample(512).get_data())  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step of ideal pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Pipeline\n",
    "\n",
    "+ Prepare EEG \n",
    "1. Drop unused channels\n",
    "2. Subtract reference (mastoids)\n",
    "3. Detrend \n",
    "4. Filter\n",
    "5. Remove bad channels\n",
    "\n",
    "+ Segment EEG into standard and deviant epochs (ERPs)\n",
    "1. subtract baseline\n",
    "2. Reject artefacts\n",
    "3. Average to get evoked (for each marker/subject/channel separately)\n",
    "\n",
    "+ Calculate Mismatch response \n",
    "1. deviant - standard for a single subject, for example GiepST_D - GiepST_S\n",
    "2. check differences between channels and subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse mismatch response \n",
    "\n",
    "Deviant minus standard ERP\n",
    "+ Check between subjects to see if the subjects have similar responses\n",
    "+ Check between channels to observe which parts of the brain are more influenced by the events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract features (Optional)\n",
    "+ peak latency\n",
    "+ peak amplitude\n",
    "+ mean amplitude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data into DL models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
