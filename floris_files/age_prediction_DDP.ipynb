{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning on Dutch Dyslexia Program dataset\n",
    "\n",
    "+ Load in the DDP dataset in corresponding age groups\n",
    "+ A model processes data and learns to predict the subject's age\n",
    "+ Use transformer model\n",
    "+ Plot loss and accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import os              \n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "main_path = os.path.dirname(os.getcwd())\n",
    "eegyolk_path = os.path.join(main_path, 'eegyolk')\n",
    "data_path = os.path.join(main_path, 'researchdrive', 'ePodium (Projectfolder)')\n",
    "\n",
    "sys.path.insert(0, eegyolk_path)\n",
    "from eegyolk import initialization_functions as ifun\n",
    "from eegyolk import dummy_data_functions as dummy\n",
    "from eegyolk import display_helper as disp\n",
    "\n",
    "from models.Transformer import TransformerModel\n",
    "from models.DNN import NN, DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 EEG files loaded\n"
     ]
    }
   ],
   "source": [
    "# folder_ddp_dataset = os.path.join(data_path, \"DDP Dataset\") # folder in Surf research drive\n",
    "main_folder_ddp_dataset = os.path.join(\"D:\", \"EEG Data\", \"DDP Surfdrive\") # local folder\n",
    "\n",
    "ddp_age_folders = ['5mnd mmn', '11mnd mmn', '17mnd mmn', '23mnd mmn',\n",
    "                    '29mnd mmn', '35mnd mmn', '41mnd mmn', '47mnd mmn']\n",
    "\n",
    "for i, ddp_age_group in enumerate(ddp_age_folders):\n",
    "    if(ddp_age_folders != '5mnd mmn'): break # Uncomment for loading just a single age group\n",
    "    age_group_folder_location = os.path.join(main_folder_ddp_dataset, ddp_age_folders[0])\n",
    "    epod_raw, epod_filenames = ifun.load_dataset(age_group_folder_location, file_extension = '.cnt', preload=False)\n",
    "    epod_raw_preload, epod_filenames_preload = ifun.load_dataset(age_group_folder_location, file_extension = '.cnt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epod_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise and Compile Models\n",
    "\n",
    "+ Fully connected feedforward Neural Network (NN) \n",
    "+ Transformer model (https://github.com/SuperBruceJia/EEG-DL/blob/master/Models/main-Transformer.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleModel = NN()\n",
    "transformerModel = TransformerModel()\n",
    "\n",
    "simpleModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy())\n",
    "transformerModel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformerModel      # simpleModel , transformerModel\n",
    "\n",
    "# X, Y = dummy.create_labeled_dataset(1000, [\"planck\", \"constant\"])\n",
    "\n",
    "# history = model.fit(np.array(X), Y, validation_split=0.33, \n",
    "#                 epochs=20, batch_size=50, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Loss \n",
    "(Test loss is lower since it has no dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# disp.show_plot(title = \"model loss\", xlabel = \"epoch\", ylabel = \"loss\", legend = ['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "+ make todo list"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('VENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
