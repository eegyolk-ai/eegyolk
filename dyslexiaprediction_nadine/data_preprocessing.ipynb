{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook: \n",
    "- Necessary imports\n",
    "- Data loader for events, eeg and metadata\n",
    "- Filtering raw EEG data\n",
    "- Transform raw EEG into epochs\n",
    "- saving filtered data to `metadata.csv`\n",
    "\n",
    "Preprocessing steps: \n",
    "+ Prepare EEG (1. Subtract reference (mastoids), 2. Detrend, 3. Filter, 4. Remove bad channels)\n",
    "+ Segment EEG into standard and deviant epochs (ERPs) (1. subtract baseline, 2. Reject artefacts, 3. Average (for each marker/subject/channel separately))\n",
    "+ Calculate Mismatch response (deviant - standard for a single subject) (check differences between channels and subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be processed using the mne library and the custom made eegyolk library. The eegyolk library contains methods to load the metadata, eeg data and the event markers. Make sure to pip install the library first using `pip install eegyolk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne      # toolbox for analyzing and visualizing EEG data\n",
    "import os       # using operating system dependent functionality (folders)\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import eegyolk\n",
    "from eegyolk import helper_functions, initialization_functions, epod_helper\n",
    "from eegyolk.config import Config\n",
    "from eegyolk.rawf import RawData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata and eeg files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config file needs to be created with the data pathways custom to your workspace. How to configure the `config.json` can be found in the eegyolk `readme.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "data_path = config.get_directory('root_2022')\n",
    "path_eeg = config.get_directory('data')\n",
    "path_metadata = config.get_directory('metadata')\n",
    "path_eventmarkers = config.get_directory('events')\n",
    "path_epochs = config.get_directory('preprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three pathways necessary for importing the data: the path to raw eeg files, the metadata and the events. The files can be loaded using the initialization_functions method. All event markers needs to be saved in a seperate folder. If not saved already, the event markers will be saved using the initialization_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata\n",
    "files_metadata = [\"children.txt\", \"cdi.txt\", \"parents.txt\", \"CODES_overview.txt\"]  \n",
    "children, cdi, parents, codes = eegyolk.initialization_functions.i_load_metadata(path_metadata, files_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/eegyolk/initialization_functions.py:61: RuntimeWarning: Number of records from the header does not match the file size (perhaps the recording was not stopped before exiting). Inferring from the file size.\n",
      "  raw = mne.io.read_raw_bdf(path, preload=preload, verbose=verbose)\n",
      "/usr/local/lib/python3.8/dist-packages/eegyolk/initialization_functions.py:61: RuntimeWarning: Number of records from the header does not match the file size (perhaps the recording was not stopped before exiting). Inferring from the file size.\n",
      "  raw = mne.io.read_raw_bdf(path, preload=preload, verbose=verbose)\n",
      "/usr/local/lib/python3.8/dist-packages/eegyolk/initialization_functions.py:61: RuntimeWarning: Number of records from the header does not match the file size (perhaps the recording was not stopped before exiting). Inferring from the file size.\n",
      "  raw = mne.io.read_raw_bdf(path, preload=preload, verbose=verbose)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 EEG files loaded\n"
     ]
    }
   ],
   "source": [
    "# load eeg\n",
    "eeg, eeg_filename =  initialization_functions.load_dataset(path_eeg, preload=False) # preload must be set to True once on the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 Event Marker files loaded\n"
     ]
    }
   ],
   "source": [
    "# load events \n",
    "events_files = os.listdir(path_eventmarkers)\n",
    "if len(events_files) == 0 or path_eventmarkers == False: # check if event markers are saved in a seperate folder\n",
    "    initialization_functions.save_event_markers(path_eventmarkers, eeg, eeg_filename) # save event markers\n",
    "\n",
    "event_markers = initialization_functions.load_events(path_eventmarkers, eeg_filename) # load event markers\n",
    "event_markers_simplified = epod_helper.group_events_12(event_markers) # simplify events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering raw EEG "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 steps for the filtering:\n",
    "1. Set the filter parameters. Which are:\n",
    "    - High pass \n",
    "    - Low pass\n",
    "    - Frequencies\n",
    "    - Event dictionary\n",
    "    - Time window for each epoch\n",
    "2. A generator to filter the raw eeg data\n",
    "3. Transforming the filtered eeg into epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set filter parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can define the frequencies for the bandpass filter. The lowpass can not be below 0 and the highpass can not be higher then 100. Most common bandpass filter is filtering between 0.1 and 40. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bcf3c27f9141dcb6ed7d4b590cbc20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(BoundedFloatText(value=0.1, description='lowpass:', step=0.1), BoundedFloatText(value=40.0, des…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowpass = widgets.BoundedFloatText(\n",
    "    value=0.1,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=0.1,\n",
    "    description='lowpass:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "highpass = widgets.BoundedFloatText(\n",
    "    value=40,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=0.1,\n",
    "    description='highpass:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "widgets.VBox([lowpass,highpass])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change type to integer\n",
    "lowpass = float(lowpass.value)\n",
    "highpass = float(highpass.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of freqs can vary and be adjusted by changing `n`. The used frequency for this analysis is `[60, 120, 180, 240]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6428470d07d4084b9ad73bbbb60d0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(BoundedIntText(value=60, description='freq[0]', max=300), BoundedIntText(value=120, description…"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4\n",
    "freq = list(widgets.BoundedIntText(\n",
    "    description='freq[{}]'.format(i),\n",
    "    min=0,\n",
    "    max=300,\n",
    "    step=1,\n",
    "    value=(i+1)*60)\n",
    "    for i in range(n))\n",
    "\n",
    "widgets.VBox(children=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs= [f.value for f in freq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs are created with joining the eeg data with a specific event.  mne.Epochs automaticaly create a baseline correction and artefact rejection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GiepM_FS': 1,\n",
       " 'GiepM_S': 2,\n",
       " 'GiepM_D': 3,\n",
       " 'GiepS_FS': 4,\n",
       " 'GiepS_S': 5,\n",
       " 'GiepS_D': 6,\n",
       " 'GopM_FS': 7,\n",
       " 'GopM_S': 8,\n",
       " 'GopM_D': 9,\n",
       " 'GopS_FS': 10,\n",
       " 'GopS_S': 11,\n",
       " 'GopS_D': 12}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_dictionary = eegyolk.epod_helper.event_dictionary\n",
    "event_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create the epochs, the time before `tmin` and after an event `tmax` needs to be defined. The default values are set to -0.2 and 0.8. `tmin` and `tmax` are the start and stop time relative to each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b37c3cee1984c1b8ce94d2423d2d533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(BoundedFloatText(value=-0.2, description='tmin:', max=1.0, min=-1.0, step=0.1), BoundedFloatTex…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmin = widgets.BoundedFloatText(\n",
    "    value=-0.2,\n",
    "    min=-1,\n",
    "    max=1,\n",
    "    step=0.1,\n",
    "    description='tmin:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "tmax = widgets.BoundedFloatText(\n",
    "    value=0.8,\n",
    "    min=-1,\n",
    "    max=1,\n",
    "    step=0.1,\n",
    "    description='tmax:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "widgets.VBox([tmin,tmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = float(tmin.value)\n",
    "tmax = float(tmax.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part to prepocess the data is creating a filter to filter the raw eeg data. This filter contains a bandpass filter, with as input the parameters `lowpass` and `highpass`. It also contains a notch filter to filter out power line noise and needs as input `freqs` for frequencies to apply the notch filter on. The next input is `mastoid_channels`, to subtract the reference from the raw eeg data. Finally, channels from the eeg can be dropped by adjusting the `drop_ch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mastoid_channels = ['EXG1', 'EXG2']\n",
    "drop_ch = ['EXG1', 'EXG2','EXG3', 'EXG4', 'EXG5', 'EXG6', 'EXG7', 'EXG8', 'Status']\n",
    "\n",
    "def filter_raweeg_gen(eeg, lowpass, highpass, freqs, mastoid_channels, drop_ch): # filters the raw eeg\n",
    "    for i in range(len(eeg)): #loops over all files\n",
    "        processed_file = os.path.join(path_epochs, eeg_filename[i]+\"_epo.fif\") # creates new filename\n",
    "        if not os.path.exists(processed_file): # if file isn't processed yet, it uses the filter function from the eegyolk library to preprocess\n",
    "            yield helper_functions.filter_eeg_raw(eeg[i].load_data(), lowpass, highpass, freqs, mastoid_channels, drop_ch)\n",
    "        else: \n",
    "            yield # print(f\"File {processed_file} already processed \\n\", end = '')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second part loops over all filtered files and checks for each file if it is already processed before, to save memory. Filtering the data needs a lot of computation power. If the code breaks due to a memory error, simply restart the kernel until all files are processed. For a selected event, an interval is created with a time before and after event. This represents an epoch. The function automatically performs a baseline correction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_eegs = filter_raweeg_gen(eeg, lowpass, highpass, freqs, mastoid_channels, drop_ch)\n",
    "\n",
    "if not os.path.exists(path_epochs):\n",
    "        os.mkdir(path_epochs)\n",
    "        \n",
    "for idx, single_eeg in enumerate(filtered_eegs):\n",
    "    processed_file = os.path.join(path_epochs, eeg_filename[idx]+\"_epo.fif\")\n",
    "    if not os.path.exists(processed_file):\n",
    "        epoch = hf.create_epoch(single_eeg, event_markers_simplified[idx], tmin, tmax)\n",
    "        epoch_file = os.path.join(path_epochs, eeg_filename[idx]+\"_epo.fif\")\n",
    "        epoch.save(epoch_file, overwrite=True)\n",
    "        print(\"\\n\", idx+1, \" saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame with metadata and eeg/epoch paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final part of the code creates a dataframe to store all preprocessed epoch files with the corresponding metadata. It consists out of simple pandas operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dependent variable Group_AccToParents\n",
    "children = children.drop(['Group_AccToParents'],axis=1)\n",
    "parents['Group_AccToParents'] = np.where(((parents['dyslexia_mother_accToMother']=='Ja') | (parents['dyslexia_father_accToFather']=='Ja')) , 1,0)\n",
    "\n",
    "# create key to merge \n",
    "parents.rename(columns = {'child':'ParticipantID'}, inplace=True)\n",
    "cdi.rename(columns = {'participant':'ParticipantID'}, inplace=True)\n",
    "metadata = pd.merge(cdi, children, on=\"ParticipantID\")\n",
    "metadata = pd.merge(metadata, parents, on=\"ParticipantID\")\n",
    "\n",
    "# create filepath columns\n",
    "metadata['eeg_file']= metadata['ParticipantID'].astype(str) + metadata['test']\n",
    "\n",
    "epoch_filename = []\n",
    "for path in os.listdir(path_epochs): # iterate directory\n",
    "    if os.path.isfile(os.path.join(path_epochs, path)): # check if current path is a file\n",
    "        epoch_filename.append(path)\n",
    "\n",
    "df_eegfilenames = pd.DataFrame(eeg_filename, columns=['eeg_file'])\n",
    "df_epochfilenames = pd.DataFrame(epoch_filename, columns=['epoch_file'])\n",
    "df_epochfilenames['eeg_file'] = df_epochfilenames.epoch_file.str[:4]\n",
    "\n",
    "metadata['path_eeg'] = path_eeg\n",
    "metadata['path_epoch'] = path_epochs \n",
    "metadata['path_eventmarkers'] = path_eventmarkers\n",
    "\n",
    "# merge to final dataframe\n",
    "df = pd.merge(df_eegfilenames, metadata, on='eeg_file')\n",
    "df = pd.merge(df, df_epochfilenames, on='eeg_file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe contains a lot of columns which we do not use in this research. Only important columns are kept. Some files are also dropped for this research. This is based on the outcome of the `data_analysis.ipynb` notebook, where we found that those files are missing events or contains bad channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns and files\n",
    "df = df[['eeg_file', 'ParticipantID', 'test', 'sex', 'age_months',\n",
    "       'dyslexic_parent', 'Group_AccToParents', 'path_eeg', 'path_epoch',\n",
    "       'path_eventmarkers', 'epoch_file']]\n",
    "\n",
    "drop_files = [\"102a\",\"113a\", \"107b (deel 1+2)\", \"132a\", \"121b(2)\", \"113b\", \"107b (deel 3+4)\", \"147a\",\n",
    "                \"121a\", \"134a\", \"143b\", \"121b(1)\",\"136a\", \"145b\", \"150a\",\"152a\", \"184a\", \"165a\", \"151a\", \"163a\", \"179a\",\"179b\", \"182b\", \"186a\", \"193b\", \"207a\"]\n",
    "\n",
    "df = df[~df['eeg_file'].isin(drop_files)]\n",
    "df = df.drop(df[df['test'] == \"b\"].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `metadata.csv` will be used in the follow up notebook `data_analysis.ipynb` and `model_preperation.ipynb`, where the data will be analysed and further transformed to function as input for the different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_file</th>\n",
       "      <th>ParticipantID</th>\n",
       "      <th>test</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_months</th>\n",
       "      <th>dyslexic_parent</th>\n",
       "      <th>Group_AccToParents</th>\n",
       "      <th>path_eeg</th>\n",
       "      <th>path_epoch</th>\n",
       "      <th>path_eventmarkers</th>\n",
       "      <th>epoch_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105a</td>\n",
       "      <td>105</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>17</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>105a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107a</td>\n",
       "      <td>107</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>107a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106a</td>\n",
       "      <td>106</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>19</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>106a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109a</td>\n",
       "      <td>109</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>21</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>109a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110a</td>\n",
       "      <td>110</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>17</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>110a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>222a</td>\n",
       "      <td>222</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>18</td>\n",
       "      <td>Nee</td>\n",
       "      <td>0</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>222a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>223a</td>\n",
       "      <td>223</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>18</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>223a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>228a</td>\n",
       "      <td>228</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>19</td>\n",
       "      <td>Nee</td>\n",
       "      <td>0</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>228a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>225a</td>\n",
       "      <td>225</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>225a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>226a</td>\n",
       "      <td>226</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>19</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/epochs_fif</td>\n",
       "      <td>/volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>226a_epo.fif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    eeg_file  ParticipantID test sex  age_months dyslexic_parent  \\\n",
       "0       105a            105    a   f          17               f   \n",
       "1       107a            107    a   f          16               m   \n",
       "2       106a            106    a   m          19               f   \n",
       "3       109a            109    a   m          21               m   \n",
       "4       110a            110    a   m          17               m   \n",
       "..       ...            ...  ...  ..         ...             ...   \n",
       "104     222a            222    a   m          18             Nee   \n",
       "105     223a            223    a   f          18               m   \n",
       "106     228a            228    a   m          19             Nee   \n",
       "107     225a            225    a   f          16               m   \n",
       "108     226a            226    a   m          19               f   \n",
       "\n",
       "     Group_AccToParents                                    path_eeg  \\\n",
       "0                     1  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "1                     1  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "2                     0  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "3                     0  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "4                     1  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "..                  ...                                         ...   \n",
       "104                   0  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "105                   1  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "106                   0  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "107                   0  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "108                   1  /volume-ceph/ePodium_projectfolder/dataset   \n",
       "\n",
       "                                        path_epoch  \\\n",
       "0    /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "1    /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "2    /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "3    /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "4    /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "..                                             ...   \n",
       "104  /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "105  /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "106  /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "107  /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "108  /volume-ceph/ePodium_projectfolder/epochs_fif   \n",
       "\n",
       "                             path_eventmarkers    epoch_file  \n",
       "0    /volume-ceph/ePodium_projectfolder/events  105a_epo.fif  \n",
       "1    /volume-ceph/ePodium_projectfolder/events  107a_epo.fif  \n",
       "2    /volume-ceph/ePodium_projectfolder/events  106a_epo.fif  \n",
       "3    /volume-ceph/ePodium_projectfolder/events  109a_epo.fif  \n",
       "4    /volume-ceph/ePodium_projectfolder/events  110a_epo.fif  \n",
       "..                                         ...           ...  \n",
       "104  /volume-ceph/ePodium_projectfolder/events  222a_epo.fif  \n",
       "105  /volume-ceph/ePodium_projectfolder/events  223a_epo.fif  \n",
       "106  /volume-ceph/ePodium_projectfolder/events  228a_epo.fif  \n",
       "107  /volume-ceph/ePodium_projectfolder/events  225a_epo.fif  \n",
       "108  /volume-ceph/ePodium_projectfolder/events  226a_epo.fif  \n",
       "\n",
       "[109 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "06729ff297c23dc5f38d677b38924ba81e0166cc67df261027dcc0563b16e0b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
