{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning models on connectivity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook: \n",
    "- Necessary imports\n",
    "- SVM model \n",
    "- Logistic Regression model\n",
    "- Decision Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import copy     # Can Copy and Deepcopy files so original file is untouched.\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../eegyolk') # path to helper functions\n",
    "import helper_functions as hf # library useful for eeg and erp data cleaning\n",
    "#import initialization_functions #library to import data\n",
    "import epod_helper\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_connectivity.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>Group_AccToParents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.152030</td>\n",
       "      <td>0.069506</td>\n",
       "      <td>0.028244</td>\n",
       "      <td>0.216019</td>\n",
       "      <td>0.236540</td>\n",
       "      <td>0.110768</td>\n",
       "      <td>0.146072</td>\n",
       "      <td>0.234775</td>\n",
       "      <td>0.123786</td>\n",
       "      <td>0.224846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092895</td>\n",
       "      <td>0.109223</td>\n",
       "      <td>0.091130</td>\n",
       "      <td>0.110989</td>\n",
       "      <td>0.126434</td>\n",
       "      <td>0.059135</td>\n",
       "      <td>0.116726</td>\n",
       "      <td>0.058032</td>\n",
       "      <td>0.164387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.049602</td>\n",
       "      <td>0.027627</td>\n",
       "      <td>0.060067</td>\n",
       "      <td>0.021557</td>\n",
       "      <td>0.016116</td>\n",
       "      <td>0.090414</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>0.053370</td>\n",
       "      <td>0.050649</td>\n",
       "      <td>0.114483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114692</td>\n",
       "      <td>0.096693</td>\n",
       "      <td>0.043533</td>\n",
       "      <td>0.169527</td>\n",
       "      <td>0.042905</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.031812</td>\n",
       "      <td>0.038928</td>\n",
       "      <td>0.098577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.380034</td>\n",
       "      <td>0.336761</td>\n",
       "      <td>0.322622</td>\n",
       "      <td>0.404456</td>\n",
       "      <td>0.434876</td>\n",
       "      <td>0.360326</td>\n",
       "      <td>0.452442</td>\n",
       "      <td>0.464439</td>\n",
       "      <td>0.064267</td>\n",
       "      <td>0.492716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339332</td>\n",
       "      <td>0.338046</td>\n",
       "      <td>0.392888</td>\n",
       "      <td>0.127249</td>\n",
       "      <td>0.395458</td>\n",
       "      <td>0.368038</td>\n",
       "      <td>0.422022</td>\n",
       "      <td>0.341902</td>\n",
       "      <td>0.328620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044057</td>\n",
       "      <td>0.063730</td>\n",
       "      <td>0.048361</td>\n",
       "      <td>0.123975</td>\n",
       "      <td>0.148566</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>0.107992</td>\n",
       "      <td>0.155943</td>\n",
       "      <td>0.071107</td>\n",
       "      <td>0.087090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045082</td>\n",
       "      <td>0.057582</td>\n",
       "      <td>0.068238</td>\n",
       "      <td>0.159016</td>\n",
       "      <td>0.117418</td>\n",
       "      <td>0.093033</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>0.086475</td>\n",
       "      <td>0.150410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137384</td>\n",
       "      <td>0.124695</td>\n",
       "      <td>0.082479</td>\n",
       "      <td>0.244021</td>\n",
       "      <td>0.198389</td>\n",
       "      <td>0.036115</td>\n",
       "      <td>0.171791</td>\n",
       "      <td>0.170327</td>\n",
       "      <td>0.102733</td>\n",
       "      <td>0.158370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.029771</td>\n",
       "      <td>0.063202</td>\n",
       "      <td>0.110786</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.121279</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>0.085652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.066393</td>\n",
       "      <td>0.027664</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.107992</td>\n",
       "      <td>0.030533</td>\n",
       "      <td>0.080123</td>\n",
       "      <td>0.150205</td>\n",
       "      <td>0.065164</td>\n",
       "      <td>0.136680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021107</td>\n",
       "      <td>0.042828</td>\n",
       "      <td>0.038525</td>\n",
       "      <td>0.177869</td>\n",
       "      <td>0.128074</td>\n",
       "      <td>0.068852</td>\n",
       "      <td>0.125820</td>\n",
       "      <td>0.072951</td>\n",
       "      <td>0.175820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.126844</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>0.020287</td>\n",
       "      <td>0.169672</td>\n",
       "      <td>0.138115</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>0.156762</td>\n",
       "      <td>0.223156</td>\n",
       "      <td>0.099385</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070287</td>\n",
       "      <td>0.071107</td>\n",
       "      <td>0.085656</td>\n",
       "      <td>0.211066</td>\n",
       "      <td>0.145902</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.137295</td>\n",
       "      <td>0.077049</td>\n",
       "      <td>0.206352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.105123</td>\n",
       "      <td>0.071107</td>\n",
       "      <td>0.068033</td>\n",
       "      <td>0.112910</td>\n",
       "      <td>0.087705</td>\n",
       "      <td>0.031762</td>\n",
       "      <td>0.079713</td>\n",
       "      <td>0.110246</td>\n",
       "      <td>0.099590</td>\n",
       "      <td>0.098566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155738</td>\n",
       "      <td>0.183811</td>\n",
       "      <td>0.116598</td>\n",
       "      <td>0.162090</td>\n",
       "      <td>0.189959</td>\n",
       "      <td>0.080123</td>\n",
       "      <td>0.158402</td>\n",
       "      <td>0.123156</td>\n",
       "      <td>0.202049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.121926</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.178689</td>\n",
       "      <td>0.180533</td>\n",
       "      <td>0.065779</td>\n",
       "      <td>0.159016</td>\n",
       "      <td>0.177664</td>\n",
       "      <td>0.090164</td>\n",
       "      <td>0.148770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071926</td>\n",
       "      <td>0.055328</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.115984</td>\n",
       "      <td>0.097131</td>\n",
       "      <td>0.053689</td>\n",
       "      <td>0.102869</td>\n",
       "      <td>0.072131</td>\n",
       "      <td>0.128484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.060041</td>\n",
       "      <td>0.025205</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>0.096926</td>\n",
       "      <td>0.094467</td>\n",
       "      <td>0.039344</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.101844</td>\n",
       "      <td>0.046721</td>\n",
       "      <td>0.057992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.066803</td>\n",
       "      <td>0.091598</td>\n",
       "      <td>0.106762</td>\n",
       "      <td>0.060041</td>\n",
       "      <td>0.099590</td>\n",
       "      <td>0.042828</td>\n",
       "      <td>0.119877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 497 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          32        64        65        96        97        98       128  \\\n",
       "0   0.152030  0.069506  0.028244  0.216019  0.236540  0.110768  0.146072   \n",
       "1   0.049602  0.027627  0.060067  0.021557  0.016116  0.090414  0.022394   \n",
       "2   0.380034  0.336761  0.322622  0.404456  0.434876  0.360326  0.452442   \n",
       "3   0.044057  0.063730  0.048361  0.123975  0.148566  0.029508  0.107992   \n",
       "4   0.137384  0.124695  0.082479  0.244021  0.198389  0.036115  0.171791   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "85  0.066393  0.027664  0.032787  0.065574  0.107992  0.030533  0.080123   \n",
       "86  0.126844  0.023566  0.020287  0.169672  0.138115  0.068033  0.156762   \n",
       "87  0.105123  0.071107  0.068033  0.112910  0.087705  0.031762  0.079713   \n",
       "88  0.121926  0.013934  0.025000  0.178689  0.180533  0.065779  0.159016   \n",
       "89  0.060041  0.025205  0.010861  0.096926  0.094467  0.039344  0.062500   \n",
       "\n",
       "         129       130       131  ...      1014      1015      1016      1017  \\\n",
       "0   0.234775  0.123786  0.224846  ...  0.092895  0.109223  0.091130  0.110989   \n",
       "1   0.053370  0.050649  0.114483  ...  0.114692  0.096693  0.043533  0.169527   \n",
       "2   0.464439  0.064267  0.492716  ...  0.339332  0.338046  0.392888  0.127249   \n",
       "3   0.155943  0.071107  0.087090  ...  0.045082  0.057582  0.068238  0.159016   \n",
       "4   0.170327  0.102733  0.158370  ...  0.027086  0.053197  0.029771  0.063202   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "85  0.150205  0.065164  0.136680  ...  0.021107  0.042828  0.038525  0.177869   \n",
       "86  0.223156  0.099385  0.187500  ...  0.070287  0.071107  0.085656  0.211066   \n",
       "87  0.110246  0.099590  0.098566  ...  0.155738  0.183811  0.116598  0.162090   \n",
       "88  0.177664  0.090164  0.148770  ...  0.071926  0.055328  0.032787  0.115984   \n",
       "89  0.101844  0.046721  0.057992  ...  0.011270  0.083197  0.066803  0.091598   \n",
       "\n",
       "        1018      1019      1020      1021      1022  Group_AccToParents  \n",
       "0   0.126434  0.059135  0.116726  0.058032  0.164387                   1  \n",
       "1   0.042905  0.028882  0.031812  0.038928  0.098577                   0  \n",
       "2   0.395458  0.368038  0.422022  0.341902  0.328620                   1  \n",
       "3   0.117418  0.093033  0.115574  0.086475  0.150410                   1  \n",
       "4   0.110786  0.061249  0.121279  0.102245  0.085652                   1  \n",
       "..       ...       ...       ...       ...       ...                 ...  \n",
       "85  0.128074  0.068852  0.125820  0.072951  0.175820                   1  \n",
       "86  0.145902  0.079508  0.137295  0.077049  0.206352                   1  \n",
       "87  0.189959  0.080123  0.158402  0.123156  0.202049                   1  \n",
       "88  0.097131  0.053689  0.102869  0.072131  0.128484                   1  \n",
       "89  0.106762  0.060041  0.099590  0.042828  0.119877                   0  \n",
       "\n",
       "[90 rows x 497 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Group_AccToParents'].values # dependant variable\n",
    "X = df.drop(['Group_AccToParents'],axis=1).values   # independant features\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear', random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel= 'linear', random_state=1, C=0.1)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.611\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', random_state=0)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.611\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.82264678e-01 -2.46356357e-01 -1.61989107e-01  2.03102281e-01\n",
      "  -3.90751863e-02  1.10828294e-01  1.25036855e-01 -1.02349548e-01\n",
      "   1.81476512e-01 -3.54700486e-02  3.10194690e-03 -3.83065065e-02\n",
      "   1.30639454e-01 -2.72338440e-01 -1.48288388e-01 -1.89644300e-01\n",
      "  -9.50992805e-02 -1.98478053e-01 -2.16623801e-01 -1.44611288e-01\n",
      "   9.22329747e-02  1.57791841e-01 -1.77657557e-02  4.95403365e-02\n",
      "   1.46797613e-02 -1.40013507e-01  1.59556844e-01 -6.02384260e-02\n",
      "  -1.67136751e-01 -1.49634134e-01 -1.93114104e-02 -4.05247159e-02\n",
      "  -9.22482751e-02  4.99064437e-02 -1.57698153e-01  1.05791427e-01\n",
      "  -6.08847576e-02 -4.39272807e-02  6.53146251e-02 -7.44479399e-02\n",
      "   6.03309791e-02  3.31876632e-02 -6.62620549e-02 -2.41845091e-02\n",
      "  -3.20552906e-02  1.06157440e-01  1.92170764e-01  2.25618483e-01\n",
      "   1.73422747e-01  2.27062931e-02  2.93362786e-04  3.88264352e-02\n",
      "  -2.58387007e-02 -5.94348552e-02  3.87257675e-02  1.03435497e-01\n",
      "   1.24419030e-01  7.46216808e-02  6.78564700e-02  9.00189107e-02\n",
      "   2.50670778e-01 -8.26552743e-02  2.49977812e-03 -1.37496109e-01\n",
      "   1.16962130e-01 -1.31331662e-01 -3.36000742e-02  1.14553239e-01\n",
      "   9.55066316e-02  1.19316283e-01  2.82884347e-01  2.38652557e-01\n",
      "  -5.92198976e-02  1.99652711e-01  1.78662100e-01  2.81315453e-01\n",
      "  -4.45250357e-02  6.95840541e-02  1.82876856e-01  2.17272796e-01\n",
      "   2.08520728e-01  1.45675338e-01  1.12970700e-01  3.67638845e-01\n",
      "  -1.12797149e-01  1.76958617e-03 -2.47187252e-01  4.77212730e-02\n",
      "  -4.00559756e-02  3.92419008e-02 -2.77640318e-02 -2.99127105e-02\n",
      "   2.19938148e-02 -1.72881200e-01 -1.66596225e-02  4.11973416e-03\n",
      "  -1.09974900e-02  9.68059795e-02 -1.45336277e-01 -1.49075757e-01\n",
      "   3.59526274e-02 -1.08121225e-01  3.08976973e-02  1.29870704e-01\n",
      "   2.80546152e-03  8.20491883e-02  1.21407820e-02 -1.06382884e-01\n",
      "  -3.05637653e-02  1.15540589e-01  1.11575441e-01  7.24318612e-02\n",
      "  -6.02418403e-02  1.31899346e-01  7.75791220e-02  5.35087272e-03\n",
      "   9.99777133e-02  2.40259581e-01  2.12367481e-01  3.11124816e-01\n",
      "  -9.05441078e-02  3.02697681e-02 -1.23033472e-01 -1.60124518e-01\n",
      "   3.30475664e-02  9.53645664e-02 -1.95589336e-01 -9.45349700e-02\n",
      "  -2.10538465e-02 -5.56292995e-02  6.84813708e-02  9.77310751e-02\n",
      "   1.46701363e-01 -1.43560464e-01  3.05086293e-01  8.97324439e-02\n",
      "  -1.03766576e-02  1.68985149e-02  3.43345201e-02  5.71438628e-02\n",
      "   4.32300495e-02  9.85333470e-02 -1.39914990e-01 -3.05658710e-02\n",
      "  -1.74562359e-01 -1.62618530e-01  2.08276690e-01 -1.92326929e-01\n",
      "  -5.14569198e-02 -8.39365361e-02  4.03208329e-01 -1.05118037e-01\n",
      "  -2.45107690e-01 -1.20724282e-01  4.58551211e-02  2.30703712e-01\n",
      "   9.11676163e-02 -1.08030216e-01  9.58310353e-02 -1.53765429e-01\n",
      "  -1.83586268e-03 -2.36873390e-02  1.82097538e-01  5.89906428e-02\n",
      "  -1.91229868e-02  9.26371587e-02 -6.88708928e-02  7.00541178e-02\n",
      "  -5.00249884e-02 -1.38233117e-01  4.05672150e-02 -1.68612829e-01\n",
      "  -1.44971718e-01  6.40467758e-02  4.84350522e-02 -1.44965384e-01\n",
      "   2.05663367e-03  5.54949033e-02  5.71901029e-02  4.63531418e-02\n",
      "   4.08224015e-02  7.84304465e-02 -1.49258711e-01  5.26268087e-02\n",
      "  -1.10645877e-01 -2.46498591e-01 -8.70092753e-02 -1.50781821e-01\n",
      "  -1.22301526e-01  5.89654386e-02 -2.80018111e-02  4.46901540e-03\n",
      "   2.94646330e-01  2.44547189e-01  1.27048873e-01  6.28866359e-02\n",
      "   2.30896854e-02  2.24661555e-01  9.68024815e-02 -5.10671013e-03\n",
      "  -1.86219504e-03  4.21145893e-02  1.88852378e-01  2.95208600e-01\n",
      "   1.13626188e-01  1.02380989e-01  3.06873355e-02 -2.78699413e-02\n",
      "  -4.98996750e-02  7.12192152e-02  1.22561493e-02 -3.64565522e-02\n",
      "  -7.58175991e-02  1.23285797e-01  1.54016474e-01  2.31764440e-01\n",
      "   9.14967611e-02  1.37186768e-01 -1.94937073e-02  1.02480594e-01\n",
      "  -1.17311647e-01 -1.78610430e-01  1.66132523e-01 -2.01530233e-01\n",
      "  -1.05809870e-01  7.58102363e-02  3.88278080e-02 -1.66606173e-01\n",
      "   3.04522442e-02  3.88408980e-02  2.01540243e-01 -6.38881987e-02\n",
      "  -4.45384634e-02  2.15897387e-01  3.67706758e-02 -2.48554621e-01\n",
      "   4.27030030e-02  1.24935996e-01 -1.27144435e-01 -1.13490314e-01\n",
      "   2.26119651e-01  2.00453646e-02 -3.15686255e-01 -7.41028603e-02\n",
      "  -1.29096363e-01  3.53379082e-02  2.76463637e-02  3.26580342e-02\n",
      "  -2.32957260e-01 -2.10657196e-01  2.06106560e-02  9.05746919e-02\n",
      "   1.40836643e-01  3.89774963e-01  5.46889180e-01  2.66470489e-01\n",
      "   2.94802891e-01  3.42482857e-02  5.56662910e-02 -2.42807913e-01\n",
      "  -4.55221842e-03 -1.08139944e-01 -2.91221516e-01  1.45661169e-02\n",
      "  -6.38940298e-02  2.29695846e-02  2.83683429e-01 -8.29180738e-03\n",
      "   1.70244610e-01 -1.15896506e-01 -1.62046347e-01 -1.13914445e-01\n",
      "   3.18870351e-01  1.55943149e-01  8.99965060e-02 -5.05169754e-02\n",
      "   2.24014426e-01  1.68671877e-02  6.26518199e-02  1.33771294e-01\n",
      "  -8.78627760e-02 -5.00979694e-02  6.40747202e-02 -4.11256092e-02\n",
      "  -2.18957007e-01 -7.48862972e-02  8.04861212e-02 -1.23460585e-01\n",
      "  -5.12693116e-02 -2.58976897e-02 -1.27533366e-01 -4.94389094e-02\n",
      "  -2.58075942e-01 -1.05213792e-01 -8.30485497e-02 -7.91767587e-02\n",
      "   7.93457711e-02 -7.52393329e-02  1.14683694e-01  4.27339290e-03\n",
      "   1.60878626e-01 -1.78099372e-01  2.81070640e-01  2.71901144e-02\n",
      "   9.49862736e-02 -4.50056403e-02 -2.16087991e-02 -1.82639431e-01\n",
      "  -8.75165747e-02  5.01226756e-02 -4.92531655e-02 -2.81598168e-02\n",
      "   1.78182926e-01 -1.02049834e-01  3.45205476e-02  3.46738697e-02\n",
      "   2.96837428e-02 -1.39831272e-01 -7.73236799e-03 -5.07080130e-02\n",
      "   3.82456466e-01  3.34654618e-01 -6.70456563e-03  9.32429372e-02\n",
      "   2.45909348e-01  1.46909624e-01 -1.65977231e-02 -1.77766017e-01\n",
      "   1.42707673e-01  1.03623228e-01  5.35859063e-02 -7.69184215e-04\n",
      "  -9.44072662e-02 -9.10886117e-02  9.03106829e-03  2.44336518e-01\n",
      "  -1.99531787e-01  1.51560530e-01 -2.86922748e-02 -1.01720885e-01\n",
      "  -1.15968787e-01 -1.11548816e-01 -7.61897949e-02  2.26949504e-02\n",
      "   1.85781635e-02  3.38408107e-03  1.99463278e-01  2.40990102e-02\n",
      "   1.15788346e-01  2.33510497e-02 -1.04864401e-01  1.90299017e-01\n",
      "   1.44186312e-01  3.83784489e-02  4.07954437e-03 -2.49364566e-02\n",
      "   8.24490951e-02  1.34031536e-01 -2.33574878e-01 -9.68484334e-02\n",
      "  -6.28928554e-02  1.05737018e-01 -1.36792561e-02  5.81422127e-02\n",
      "   4.88382135e-02 -3.15276558e-01 -1.19062904e-01 -3.91636196e-01\n",
      "  -1.97228788e-03  1.75804923e-01 -7.29563287e-02  3.75930036e-02\n",
      "   8.51066256e-02  1.70552428e-01 -1.29651116e-01 -1.76728322e-02\n",
      "   4.44095964e-02 -2.66140968e-01 -9.70600475e-03 -6.46267445e-02\n",
      "  -2.93200369e-01  7.71341454e-02  2.93130926e-02 -1.49146369e-01\n",
      "  -1.59070781e-01 -9.32140759e-02 -3.14718467e-01 -1.63184693e-01\n",
      "   1.17694016e-01 -7.16406389e-02  4.31768905e-02  5.97863729e-02\n",
      "  -1.31633295e-01 -5.59131481e-02 -8.92023047e-02 -4.72207578e-02\n",
      "  -1.15738890e-01 -1.22855406e-01 -4.38810186e-02 -1.17121951e-01\n",
      "  -5.39650283e-02  6.59369851e-02 -9.26808462e-02 -4.60955288e-02\n",
      "   1.86823641e-01  8.64543900e-02 -5.01457943e-02  8.48476741e-02\n",
      "  -1.36953840e-01  7.61019186e-03  7.02106227e-02  5.09126905e-03\n",
      "  -2.32892777e-02  4.41886773e-02 -4.31688436e-02 -1.21522970e-01\n",
      "   1.32358779e-01  8.25435815e-02  1.44235112e-01  1.21354729e-01\n",
      "  -1.59619790e-01  9.97661805e-02  8.33943189e-03  4.49618671e-02\n",
      "  -9.86459559e-02 -1.63361478e-01 -9.29574126e-02  1.51982707e-02\n",
      "   4.88386207e-02  9.06109696e-02  4.06735868e-02  1.33808274e-01\n",
      "   7.70303660e-02  2.36273973e-01 -1.74820571e-01  2.48421429e-02\n",
      "  -1.98509195e-01 -7.35592781e-02  1.24458152e-01  5.29964449e-02\n",
      "   9.93968265e-03 -6.73603978e-02 -5.26024236e-02 -1.16503986e-01\n",
      "   3.07286967e-02  1.43735437e-01  1.55014105e-02  2.96390208e-03\n",
      "   4.42046413e-02 -1.01374040e-01  5.77852404e-02  1.71310162e-01\n",
      "   8.98316440e-02  5.34276538e-02 -1.42782261e-01  1.37384943e-01\n",
      "   5.65991999e-02  3.14774129e-02  1.06213316e-01  6.09291346e-02\n",
      "  -2.98030093e-02 -1.41290924e-01 -2.66541567e-03 -1.01911528e-01\n",
      "  -3.99384004e-02  1.02265829e-02 -1.82218414e-01  6.31886679e-02\n",
      "   2.68697746e-02 -8.07419071e-02  6.07055610e-02 -8.23225113e-02\n",
      "  -1.41089284e-01 -2.54118788e-01 -7.72397118e-02 -5.67137786e-02\n",
      "  -1.82875549e-01 -6.52879647e-02 -1.10689192e-01 -9.99431118e-02\n",
      "  -2.54587294e-02 -8.33566969e-02 -3.28942091e-02  5.07967032e-02\n",
      "   1.04043327e-01  1.85993258e-01  2.54196985e-01 -1.13779505e-02\n",
      "  -1.62730303e-01 -1.63507643e-01  5.95077317e-02 -8.30683361e-02\n",
      "  -2.16810593e-01 -1.42213400e-01 -3.32959671e-02  9.12856815e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.444\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Review:  If you have time later there are couple possible typo-s in the comments, and you can add more explanation markdown cells. But overall, good job! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
