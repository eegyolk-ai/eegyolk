{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 14:00:31.034069: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 14:00:31.145993: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-12 14:00:31.175594: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-12 14:00:31.692678: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:00:31.692742: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:00:31.692751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import copy     # Can Copy and Deepcopy files so original file is untouched.\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../eegyolk') # path to helper functions\n",
    "import helper_functions as hf # library useful for eeg and erp data cleaning\n",
    "import epod_helper\n",
    "import initialization_functions\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,LeakyReLU,MaxPool1D,\\\n",
    "GlobalAveragePooling1D,Dense,Dropout,AveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "from sklearn.decomposition import PCA, FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_file</th>\n",
       "      <th>ParticipantID</th>\n",
       "      <th>test</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_months</th>\n",
       "      <th>dyslexic_parent</th>\n",
       "      <th>Group_AccToParents</th>\n",
       "      <th>path_eeg</th>\n",
       "      <th>path_epoch</th>\n",
       "      <th>path_eventmarkers</th>\n",
       "      <th>epoch_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105a</td>\n",
       "      <td>105</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>17</td>\n",
       "      <td>f</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>105a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107a</td>\n",
       "      <td>107</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>m</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>107a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106a</td>\n",
       "      <td>106</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>19</td>\n",
       "      <td>f</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>106a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109a</td>\n",
       "      <td>109</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>21</td>\n",
       "      <td>m</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>109a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110a</td>\n",
       "      <td>110</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>17</td>\n",
       "      <td>m</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>110a_epo.fif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eeg_file  ParticipantID test sex  age_months dyslexic_parent  \\\n",
       "0     105a            105    a   f          17               f   \n",
       "1     107a            107    a   f          16               m   \n",
       "2     106a            106    a   m          19               f   \n",
       "3     109a            109    a   m          21               m   \n",
       "4     110a            110    a   m          17               m   \n",
       "\n",
       "  Group_AccToParents                                         path_eeg  \\\n",
       "0            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "1            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "2            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "3            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "4            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "\n",
       "                                          path_epoch  \\\n",
       "0  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "1  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "2  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "3  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "4  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "\n",
       "                                path_eventmarkers    epoch_file  \n",
       "0  ../../volume-ceph/ePodium_projectfolder/events  105a_epo.fif  \n",
       "1  ../../volume-ceph/ePodium_projectfolder/events  107a_epo.fif  \n",
       "2  ../../volume-ceph/ePodium_projectfolder/events  106a_epo.fif  \n",
       "3  ../../volume-ceph/ePodium_projectfolder/events  109a_epo.fif  \n",
       "4  ../../volume-ceph/ePodium_projectfolder/events  110a_epo.fif  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Group_AccToParents'] = np.where(\n",
    "    (metadata['Group_AccToParents']=='At risk'), 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_files= metadata.loc[metadata['Group_AccToParents'] == 0]\n",
    "atrisk_files = metadata.loc[metadata['Group_AccToParents'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out file: 117a_epo.fif\n",
      "Checking out file: 118a_epo.fif\n",
      "Checking out file: 119a_epo.fif\n",
      "Checking out file: 124a_epo.fif\n",
      "Checking out file: 127a_epo.fif\n",
      "Checking out file: 126a_epo.fif\n",
      "Checking out file: 131a_epo.fif\n",
      "Checking out file: 135a_epo.fif\n",
      "Checking out file: 133a_epo.fif\n",
      "Checking out file: 138a_epo.fif\n",
      "Checking out file: 139a_epo.fif\n",
      "Checking out file: 144a_epo.fif\n",
      "Checking out file: 143a_epo.fif\n",
      "Checking out file: 146a_epo.fif\n",
      "Checking out file: 145a_epo.fif\n",
      "Checking out file: 154a_epo.fif\n",
      "Checking out file: 153a_epo.fif\n",
      "Checking out file: 168a_epo.fif\n",
      "Checking out file: 177a_epo.fif\n",
      "Checking out file: 190a_epo.fif\n",
      "Checking out file: 170a_epo.fif\n",
      "Checking out file: 174a_epo.fif\n",
      "Checking out file: 191a_epo.fif\n",
      "Checking out file: 169a_epo.fif\n",
      "Checking out file: 173a_epo.fif\n",
      "Checking out file: 166a_epo.fif\n",
      "Checking out file: 216a_epo.fif\n",
      "Checking out file: 175a_epo.fif\n",
      "Checking out file: 172a_epo.fif\n",
      "Checking out file: 183a_epo.fif\n",
      "Checking out file: 185a_epo.fif\n",
      "Checking out file: 187a_epo.fif\n",
      "Checking out file: 212a_epo.fif\n",
      "Checking out file: 215a_epo.fif\n",
      "Checking out file: 167a_epo.fif\n",
      "Checking out file: 196a_epo.fif\n",
      "Checking out file: 199a_epo.fif\n",
      "Checking out file: 180a_epo.fif\n",
      "Checking out file: 171a_epo.fif\n",
      "Checking out file: 176a_epo.fif\n",
      "Checking out file: 200a_epo.fif\n",
      "Checking out file: 220a_epo.fif\n",
      "Checking out file: 218a_epo.fif\n",
      "Checking out file: 205a_epo.fif\n",
      "Checking out file: 204a_epo.fif\n",
      "Checking out file: 206a_epo.fif\n",
      "Checking out file: 208a_epo.fif\n",
      "Checking out file: 202a_epo.fif\n",
      "Checking out file: 221a_epo.fif\n"
     ]
    }
   ],
   "source": [
    "control = initialization_functions.read_filtered_data(control_files, to_array=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out file: 105a_epo.fif\n",
      "Checking out file: 107a_epo.fif\n",
      "Checking out file: 106a_epo.fif\n",
      "Checking out file: 109a_epo.fif\n",
      "Checking out file: 110a_epo.fif\n",
      "Checking out file: 112a_epo.fif\n",
      "Checking out file: 111a_epo.fif\n",
      "Checking out file: 114a_epo.fif\n",
      "Checking out file: 115a_epo.fif\n",
      "Checking out file: 116a_epo.fif\n",
      "Checking out file: 123a_epo.fif\n",
      "Checking out file: 122a_epo.fif\n",
      "Checking out file: 125a_epo.fif\n",
      "Checking out file: 130a_epo.fif\n",
      "Checking out file: 128a_epo.fif\n",
      "Checking out file: 129a_epo.fif\n",
      "Checking out file: 137a_epo.fif\n",
      "Checking out file: 141a_epo.fif\n",
      "Checking out file: 142a_epo.fif\n",
      "Checking out file: 140a_epo.fif\n",
      "Checking out file: 148a_epo.fif\n",
      "Checking out file: 149a_epo.fif\n",
      "Checking out file: 155a_epo.fif\n",
      "Checking out file: 157a_epo.fif\n",
      "Checking out file: 158a_epo.fif\n",
      "Checking out file: 161a_epo.fif\n",
      "Checking out file: 159a_epo.fif\n",
      "Checking out file: 156a_epo.fif\n",
      "Checking out file: 192a_epo.fif\n",
      "Checking out file: 178a_epo.fif\n",
      "Checking out file: 162a_epo.fif\n",
      "Checking out file: 160a_epo.fif\n",
      "Checking out file: 181a_epo.fif\n",
      "Checking out file: 194a_epo.fif\n",
      "Checking out file: 193a_epo.fif\n",
      "Checking out file: 164a_epo.fif\n",
      "Checking out file: 211a_epo.fif\n",
      "Checking out file: 182a_epo.fif\n",
      "Checking out file: 197a_epo.fif\n",
      "Checking out file: 195a_epo.fif\n",
      "Checking out file: 188a_epo.fif\n",
      "Checking out file: 198a_epo.fif\n",
      "Checking out file: 213a_epo.fif\n",
      "Checking out file: 214a_epo.fif\n",
      "Checking out file: 217a_epo.fif\n",
      "Checking out file: 101a_epo.fif\n",
      "Checking out file: 219a_epo.fif\n",
      "Checking out file: 103a_epo.fif\n",
      "Checking out file: 104a_epo.fif\n",
      "Checking out file: 209a_epo.fif\n",
      "Checking out file: 210a_epo.fif\n",
      "Checking out file: 201a_epo.fif\n"
     ]
    }
   ],
   "source": [
    "atrisk = initialization_functions.read_filtered_data(atrisk_files, to_array=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which experiment you want to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard_events = ['GiepS_S'] # standards: 'GiepM_S','GiepS_S','GopM_S','GopS_S'\n",
    "deviant_events = ['GiepS_D'] # deviants: 'GiepM_D','GiepS_D','GopM_D','GopS_D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loaded files: 52\n",
      " loaded files: 49\n",
      "(5, 2049) 101\n",
      "[[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3], [4, 4, 4, 4, 4], [5, 5, 5, 5, 5], [6, 6, 6, 6, 6], [7, 7, 7, 7, 7], [8, 8, 8, 8, 8], [9, 9, 9, 9, 9], [10, 10, 10, 10, 10], [11, 11, 11, 11, 11], [12, 12, 12, 12, 12], [13, 13, 13, 13, 13], [14, 14, 14, 14, 14], [15, 15, 15, 15, 15], [16, 16, 16, 16, 16], [17, 17, 17, 17, 17], [18, 18, 18, 18, 18], [19, 19, 19, 19, 19], [20, 20, 20, 20, 20], [21, 21, 21, 21, 21], [22, 22, 22, 22, 22], [23, 23, 23, 23, 23], [24, 24, 24, 24, 24], [25, 25, 25, 25, 25], [26, 26, 26, 26, 26], [27, 27, 27, 27, 27], [28, 28, 28, 28, 28], [29, 29, 29, 29, 29], [30, 30, 30, 30, 30], [31, 31, 31, 31, 31], [32, 32, 32, 32, 32], [33, 33, 33, 33, 33], [34, 34, 34, 34, 34], [35, 35, 35, 35, 35], [36, 36, 36, 36, 36], [37, 37, 37, 37, 37], [38, 38, 38, 38, 38], [39, 39, 39, 39, 39], [40, 40, 40, 40, 40], [41, 41, 41, 41, 41], [42, 42, 42, 42, 42], [43, 43, 43, 43, 43], [44, 44, 44, 44, 44], [45, 45, 45, 45, 45], [46, 46, 46, 46, 46], [47, 47, 47, 47, 47], [48, 48, 48, 48, 48], [49, 49, 49, 49, 49], [50, 50, 50, 50, 50], [51, 51, 51, 51, 51], [52, 52, 52, 52, 52], [53, 53, 53, 53, 53], [54, 54, 54, 54, 54], [55, 55, 55, 55, 55], [56, 56, 56, 56, 56], [57, 57, 57, 57, 57], [58, 58, 58, 58, 58], [59, 59, 59, 59, 59], [60, 60, 60, 60, 60], [61, 61, 61, 61, 61], [62, 62, 62, 62, 62], [63, 63, 63, 63, 63], [64, 64, 64, 64, 64], [65, 65, 65, 65, 65], [66, 66, 66, 66, 66], [67, 67, 67, 67, 67], [68, 68, 68, 68, 68], [69, 69, 69, 69, 69], [70, 70, 70, 70, 70], [71, 71, 71, 71, 71], [72, 72, 72, 72, 72], [73, 73, 73, 73, 73], [74, 74, 74, 74, 74], [75, 75, 75, 75, 75], [76, 76, 76, 76, 76], [77, 77, 77, 77, 77], [78, 78, 78, 78, 78], [79, 79, 79, 79, 79], [80, 80, 80, 80, 80], [81, 81, 81, 81, 81], [82, 82, 82, 82, 82], [83, 83, 83, 83, 83], [84, 84, 84, 84, 84], [85, 85, 85, 85, 85], [86, 86, 86, 86, 86], [87, 87, 87, 87, 87], [88, 88, 88, 88, 88], [89, 89, 89, 89, 89], [90, 90, 90, 90, 90], [91, 91, 91, 91, 91], [92, 92, 92, 92, 92], [93, 93, 93, 93, 93], [94, 94, 94, 94, 94], [95, 95, 95, 95, 95], [96, 96, 96, 96, 96], [97, 97, 97, 97, 97], [98, 98, 98, 98, 98], [99, 99, 99, 99, 99], [100, 100, 100, 100, 100]]\n",
      "(505, 2049) (505,) (505,)\n"
     ]
    }
   ],
   "source": [
    "def create_mmr(epoch, standard_events, deviant_events): \n",
    "\n",
    "    std_evoked = epoch[standard_events].average() \n",
    "    dev_evoked = epoch[deviant_events].average()\n",
    " \n",
    "    # calculate the mismatch response between standard and deviant evoked\n",
    "    evoked_diff = mne.combine_evoked([std_evoked, dev_evoked], weights=[1, -1]).get_data(picks=[ 'FC5', 'Pz', 'O1', 'PO4', 'AF4']) # mismatch for all channels per participant\n",
    "    \n",
    "    #pca = UnsupervisedSpatialFilter(PCA(30), average=False)\n",
    "    #evoked_diff = pca.fit_transform(evoked_diff)\n",
    "    return evoked_diff\n",
    "\n",
    "def to_array(evoked_epochs):\n",
    "    tot_mmr = []\n",
    "    count = 0\n",
    "    \n",
    "    for epoch in evoked_epochs:\n",
    "        mmr = create_mmr(epoch, standard_events, deviant_events)\n",
    "        tot_mmr.append(mmr)\n",
    "        count += 1\n",
    "    print(f\" loaded files: {count}\")\n",
    "    return tot_mmr\n",
    "\n",
    "def input_erp(atrisk_files, control_files, atrisk, control):\n",
    "    atrisk_epochs = to_array(atrisk)\n",
    "    control_epochs = to_array(control)\n",
    "    \n",
    "    control_labels = control_files['Group_AccToParents'].tolist()\n",
    "    atrisk_labels = atrisk_files['Group_AccToParents'].tolist()\n",
    "    \n",
    "    control_labels=[len(i)*[0] for i in control_epochs]\n",
    "    atrisk_labels=[len(i)*[1] for i in atrisk_epochs]\n",
    "    \n",
    "    data_list = control_epochs+atrisk_epochs\n",
    "    label_list = control_labels+atrisk_labels\n",
    "    print(data_list[1].shape, len(data_list))\n",
    "    groups_list=[[i]*len(j) for i, j in enumerate(data_list)]\n",
    "   # groups_list=[i for i in range(len(data_list))]\n",
    "    print(groups_list)\n",
    "    data_array=np.vstack(data_list)\n",
    "    label_array=np.hstack(label_list)\n",
    "    group_array=np.hstack(groups_list)\n",
    "   # data_array=np.moveaxis(data_array,1,2)\n",
    "    \n",
    "    print(data_array.shape,label_array.shape,group_array.shape) #number of segments, length, channels\n",
    "    return data_array, label_array, group_array\n",
    "\n",
    "data_array, label_array, group_array = input_erp(atrisk_files, control_files, atrisk, control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 2047, 4)           16        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2047, 4)          16        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 2047, 4)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1023, 4)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1021, 5)           65        \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 1021, 5)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 510, 5)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 510, 5)            0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 5)                0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 95\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 14:01:09.775604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 14:01:09.805293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:01:09.805316: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-12 14:01:09.805736: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def cnnmodel():\n",
    "    clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(filters=4,kernel_size=3,strides=1,input_shape=(2049,1)))#1\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPool1D(pool_size=2,strides=2))#2\n",
    "    model.add(Conv1D(filters=5,kernel_size=3,strides=1))#3\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPool1D(pool_size=2,strides=2))#4\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Conv1D(filters=5,kernel_size=3,strides=1))#5\n",
    "    #model.add(LeakyReLU())\n",
    "    #model.add(AveragePooling1D(pool_size=2,strides=2))#6\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Conv1D(filters=5,kernel_size=3,strides=1))#7\n",
    "    #model.add(LeakyReLU())\n",
    "    #model.add(AveragePooling1D(pool_size=2,strides=2))#8\n",
    "    #model.add(Conv1D(filters=5,kernel_size=3,strides=1))#9\n",
    "    #model.add(LeakyReLU())\n",
    "    model.add(GlobalAveragePooling1D())#10\n",
    "    model.add(Dense(1,activation='relu'))#11\n",
    "    \n",
    "    model.compile('adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=cnnmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf=GroupKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   1,   1,   1,   1,   1,   2,   2,   2,\n",
       "         2,   2,   3,   3,   3,   3,   3,   4,   4,   4,   4,   4,   5,\n",
       "         5,   5,   5,   5,   6,   6,   6,   6,   6,   7,   7,   7,   7,\n",
       "         7,   8,   8,   8,   8,   8,   9,   9,   9,   9,   9,  10,  10,\n",
       "        10,  10,  10,  11,  11,  11,  11,  11,  12,  12,  12,  12,  12,\n",
       "        13,  13,  13,  13,  13,  14,  14,  14,  14,  14,  15,  15,  15,\n",
       "        15,  15,  16,  16,  16,  16,  16,  17,  17,  17,  17,  17,  18,\n",
       "        18,  18,  18,  18,  19,  19,  19,  19,  19,  20,  20,  20,  20,\n",
       "        20,  21,  21,  21,  21,  21,  22,  22,  22,  22,  22,  23,  23,\n",
       "        23,  23,  23,  24,  24,  24,  24,  24,  25,  25,  25,  25,  25,\n",
       "        26,  26,  26,  26,  26,  27,  27,  27,  27,  27,  28,  28,  28,\n",
       "        28,  28,  29,  29,  29,  29,  29,  30,  30,  30,  30,  30,  31,\n",
       "        31,  31,  31,  31,  32,  32,  32,  32,  32,  33,  33,  33,  33,\n",
       "        33,  34,  34,  34,  34,  34,  35,  35,  35,  35,  35,  36,  36,\n",
       "        36,  36,  36,  37,  37,  37,  37,  37,  38,  38,  38,  38,  38,\n",
       "        39,  39,  39,  39,  39,  40,  40,  40,  40,  40,  41,  41,  41,\n",
       "        41,  41,  42,  42,  42,  42,  42,  43,  43,  43,  43,  43,  44,\n",
       "        44,  44,  44,  44,  45,  45,  45,  45,  45,  46,  46,  46,  46,\n",
       "        46,  47,  47,  47,  47,  47,  48,  48,  48,  48,  48,  49,  49,\n",
       "        49,  49,  49,  50,  50,  50,  50,  50,  51,  51,  51,  51,  51,\n",
       "        52,  52,  52,  52,  52,  53,  53,  53,  53,  53,  54,  54,  54,\n",
       "        54,  54,  55,  55,  55,  55,  55,  56,  56,  56,  56,  56,  57,\n",
       "        57,  57,  57,  57,  58,  58,  58,  58,  58,  59,  59,  59,  59,\n",
       "        59,  60,  60,  60,  60,  60,  61,  61,  61,  61,  61,  62,  62,\n",
       "        62,  62,  62,  63,  63,  63,  63,  63,  64,  64,  64,  64,  64,\n",
       "        65,  65,  65,  65,  65,  66,  66,  66,  66,  66,  67,  67,  67,\n",
       "        67,  67,  68,  68,  68,  68,  68,  69,  69,  69,  69,  69,  70,\n",
       "        70,  70,  70,  70,  71,  71,  71,  71,  71,  72,  72,  72,  72,\n",
       "        72,  73,  73,  73,  73,  73,  74,  74,  74,  74,  74,  75,  75,\n",
       "        75,  75,  75,  76,  76,  76,  76,  76,  77,  77,  77,  77,  77,\n",
       "        78,  78,  78,  78,  78,  79,  79,  79,  79,  79,  80,  80,  80,\n",
       "        80,  80,  81,  81,  81,  81,  81,  82,  82,  82,  82,  82,  83,\n",
       "        83,  83,  83,  83,  84,  84,  84,  84,  84,  85,  85,  85,  85,\n",
       "        85,  86,  86,  86,  86,  86,  87,  87,  87,  87,  87,  88,  88,\n",
       "        88,  88,  88,  89,  89,  89,  89,  89,  90,  90,  90,  90,  90,\n",
       "        91,  91,  91,  91,  91,  92,  92,  92,  92,  92,  93,  93,  93,\n",
       "        93,  93,  94,  94,  94,  94,  94,  95,  95,  95,  95,  95,  96,\n",
       "        96,  96,  96,  96,  97,  97,  97,  97,  97,  98,  98,  98,  98,\n",
       "        98,  99,  99,  99,  99,  99, 100, 100, 100, 100, 100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reduce dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11/11 [==============================] - 1s 36ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6090 - val_accuracy: 0.4706\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6054 - val_accuracy: 0.4706\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6065 - val_accuracy: 0.4706\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6040 - val_accuracy: 0.4706\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6054 - val_accuracy: 0.4706\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6099 - val_accuracy: 0.4706\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6526 - val_accuracy: 0.4706\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6542 - val_accuracy: 0.4706\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.6636 - val_accuracy: 0.4706\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.7133 - val_accuracy: 0.4706\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.7554 - val_accuracy: 0.4706\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.7617 - val_accuracy: 0.4706\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.8011 - val_accuracy: 0.4706\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.8095 - val_accuracy: 0.4706\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.8291 - val_accuracy: 0.4706\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.8598 - val_accuracy: 0.4706\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.8657 - val_accuracy: 0.4706\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.8731 - val_accuracy: 0.4706\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.8830 - val_accuracy: 0.4706\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.9029 - val_accuracy: 0.4706\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.9499 - val_accuracy: 0.4706\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.9648 - val_accuracy: 0.4706\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 6.9849 - val_accuracy: 0.4706\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.0939 - val_accuracy: 0.4706\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.1203 - val_accuracy: 0.4706\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.2240 - val_accuracy: 0.4706\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.2811 - val_accuracy: 0.4706\n",
      "Epoch 28/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.2960 - val_accuracy: 0.4706\n",
      "Epoch 29/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.3165 - val_accuracy: 0.4706\n",
      "Epoch 30/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.3459 - val_accuracy: 0.4706\n",
      "Epoch 31/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.4753 - val_accuracy: 0.4706\n",
      "Epoch 32/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.5742 - val_accuracy: 0.4706\n",
      "Epoch 33/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.8700 - val_accuracy: 0.4706\n",
      "Epoch 34/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 7.9899 - val_accuracy: 0.4706\n",
      "Epoch 35/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1662 - val_accuracy: 0.4706\n",
      "Epoch 36/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 37/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 38/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 39/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 40/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 41/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 42/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 43/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 44/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 45/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 46/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 47/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 48/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 49/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 50/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 51/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 52/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 53/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 54/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 55/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 56/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 57/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 58/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 59/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 60/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 61/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 62/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 63/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 64/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 65/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 66/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 67/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 68/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 69/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 70/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 71/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 72/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 73/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 74/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 75/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 76/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 77/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 78/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 79/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 80/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 81/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 82/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 83/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 84/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 85/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 86/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 87/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 88/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 89/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 90/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 91/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 92/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 93/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 94/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 95/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 96/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 97/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 98/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 99/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 100/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 101/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 102/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 103/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 104/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 105/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 106/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 107/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 108/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 109/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 110/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 111/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 112/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 113/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 114/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 115/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 116/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 117/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 118/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 119/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 120/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.8276 - accuracy: 0.4925 - val_loss: 8.1661 - val_accuracy: 0.4706\n",
      "Epoch 121/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.1731 - accuracy: 0.4925 - val_loss: 3.6630 - val_accuracy: 0.4706\n",
      "Epoch 122/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.5875 - accuracy: 0.4925 - val_loss: 1.2514 - val_accuracy: 0.4765\n",
      "Epoch 123/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2034 - accuracy: 0.4925 - val_loss: 0.9846 - val_accuracy: 0.4765\n",
      "Epoch 124/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0480 - accuracy: 0.4925 - val_loss: 0.9213 - val_accuracy: 0.4765\n",
      "Epoch 125/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9798 - accuracy: 0.4955 - val_loss: 0.8889 - val_accuracy: 0.4765\n",
      "Epoch 126/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9371 - accuracy: 0.5015 - val_loss: 0.8708 - val_accuracy: 0.4824\n",
      "Epoch 127/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8965 - accuracy: 0.5015 - val_loss: 0.8584 - val_accuracy: 0.4765\n",
      "Epoch 128/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8864 - accuracy: 0.5104 - val_loss: 0.8485 - val_accuracy: 0.4706\n",
      "Epoch 129/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8621 - accuracy: 0.5075 - val_loss: 0.8426 - val_accuracy: 0.4706\n",
      "Epoch 130/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8500 - accuracy: 0.5194 - val_loss: 0.8382 - val_accuracy: 0.4647\n",
      "Epoch 131/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8413 - accuracy: 0.5015 - val_loss: 0.8360 - val_accuracy: 0.4588\n",
      "Epoch 132/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8336 - accuracy: 0.5075 - val_loss: 0.8335 - val_accuracy: 0.4588\n",
      "Epoch 133/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8317 - accuracy: 0.5134 - val_loss: 0.8323 - val_accuracy: 0.4529\n",
      "Epoch 134/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.8269 - accuracy: 0.5075 - val_loss: 0.8315 - val_accuracy: 0.4529\n",
      "Epoch 135/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8262 - accuracy: 0.4985 - val_loss: 0.8300 - val_accuracy: 0.4588\n",
      "Epoch 136/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8109 - accuracy: 0.5045 - val_loss: 0.8282 - val_accuracy: 0.4588\n",
      "Epoch 137/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8167 - accuracy: 0.5075 - val_loss: 0.8270 - val_accuracy: 0.4588\n",
      "Epoch 138/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7971 - accuracy: 0.5224 - val_loss: 0.8249 - val_accuracy: 0.4529\n",
      "Epoch 139/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8065 - accuracy: 0.5015 - val_loss: 0.8224 - val_accuracy: 0.4471\n",
      "Epoch 140/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8059 - accuracy: 0.5134 - val_loss: 0.8206 - val_accuracy: 0.4471\n",
      "Epoch 141/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7853 - accuracy: 0.5194 - val_loss: 0.8185 - val_accuracy: 0.4471\n",
      "Epoch 142/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8408 - accuracy: 0.5104 - val_loss: 0.8158 - val_accuracy: 0.4529\n",
      "Epoch 143/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7873 - accuracy: 0.5194 - val_loss: 0.8132 - val_accuracy: 0.4529\n",
      "Epoch 144/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7906 - accuracy: 0.5134 - val_loss: 0.8113 - val_accuracy: 0.4529\n",
      "Epoch 145/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7856 - accuracy: 0.5164 - val_loss: 0.8100 - val_accuracy: 0.4471\n",
      "Epoch 146/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7876 - accuracy: 0.5075 - val_loss: 0.8075 - val_accuracy: 0.4471\n",
      "Epoch 147/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7813 - accuracy: 0.5194 - val_loss: 0.8048 - val_accuracy: 0.4529\n",
      "Epoch 148/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7947 - accuracy: 0.5134 - val_loss: 0.8037 - val_accuracy: 0.4529\n",
      "Epoch 149/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7862 - accuracy: 0.5075 - val_loss: 0.8046 - val_accuracy: 0.4647\n",
      "Epoch 150/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7816 - accuracy: 0.5045 - val_loss: 0.8028 - val_accuracy: 0.4647\n",
      "Epoch 151/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7701 - accuracy: 0.5134 - val_loss: 0.8000 - val_accuracy: 0.4647\n",
      "Epoch 152/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7630 - accuracy: 0.5194 - val_loss: 0.7957 - val_accuracy: 0.4588\n",
      "Epoch 153/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7635 - accuracy: 0.5194 - val_loss: 0.7925 - val_accuracy: 0.4588\n",
      "Epoch 154/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.8173 - accuracy: 0.5045 - val_loss: 0.7895 - val_accuracy: 0.4529\n",
      "Epoch 155/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7666 - accuracy: 0.5015 - val_loss: 0.7871 - val_accuracy: 0.4471\n",
      "Epoch 156/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7696 - accuracy: 0.5164 - val_loss: 0.7859 - val_accuracy: 0.4588\n",
      "Epoch 157/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7610 - accuracy: 0.5164 - val_loss: 0.7835 - val_accuracy: 0.4588\n",
      "Epoch 158/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7698 - accuracy: 0.5224 - val_loss: 0.7809 - val_accuracy: 0.4529\n",
      "Epoch 159/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7607 - accuracy: 0.5045 - val_loss: 0.7804 - val_accuracy: 0.4647\n",
      "Epoch 160/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7598 - accuracy: 0.5045 - val_loss: 0.7788 - val_accuracy: 0.4588\n",
      "Epoch 161/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7573 - accuracy: 0.5194 - val_loss: 0.7756 - val_accuracy: 0.4529\n",
      "Epoch 162/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7605 - accuracy: 0.5045 - val_loss: 0.7727 - val_accuracy: 0.4529\n",
      "Epoch 163/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7501 - accuracy: 0.5164 - val_loss: 0.7700 - val_accuracy: 0.4471\n",
      "Epoch 164/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7509 - accuracy: 0.5224 - val_loss: 0.7675 - val_accuracy: 0.4412\n",
      "Epoch 165/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7488 - accuracy: 0.5254 - val_loss: 0.7657 - val_accuracy: 0.4412\n",
      "Epoch 166/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7364 - accuracy: 0.5254 - val_loss: 0.7639 - val_accuracy: 0.4471\n",
      "Epoch 167/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7477 - accuracy: 0.5075 - val_loss: 0.7618 - val_accuracy: 0.4471\n",
      "Epoch 168/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7440 - accuracy: 0.5104 - val_loss: 0.7600 - val_accuracy: 0.4471\n",
      "Epoch 169/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7434 - accuracy: 0.5075 - val_loss: 0.7583 - val_accuracy: 0.4471\n",
      "Epoch 170/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7396 - accuracy: 0.5045 - val_loss: 0.7569 - val_accuracy: 0.4529\n",
      "Epoch 171/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7419 - accuracy: 0.5015 - val_loss: 0.7550 - val_accuracy: 0.4588\n",
      "Epoch 172/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7317 - accuracy: 0.5134 - val_loss: 0.7531 - val_accuracy: 0.4529\n",
      "Epoch 173/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7380 - accuracy: 0.5254 - val_loss: 0.7511 - val_accuracy: 0.4529\n",
      "Epoch 174/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7330 - accuracy: 0.5254 - val_loss: 0.7497 - val_accuracy: 0.4529\n",
      "Epoch 175/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7255 - accuracy: 0.5224 - val_loss: 0.7479 - val_accuracy: 0.4471\n",
      "Epoch 176/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7347 - accuracy: 0.4985 - val_loss: 0.7458 - val_accuracy: 0.4412\n",
      "Epoch 177/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7280 - accuracy: 0.5134 - val_loss: 0.7437 - val_accuracy: 0.4412\n",
      "Epoch 178/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7232 - accuracy: 0.5164 - val_loss: 0.7418 - val_accuracy: 0.4471\n",
      "Epoch 179/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7235 - accuracy: 0.5045 - val_loss: 0.7399 - val_accuracy: 0.4529\n",
      "Epoch 180/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7302 - accuracy: 0.5015 - val_loss: 0.7384 - val_accuracy: 0.4529\n",
      "Epoch 181/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7155 - accuracy: 0.5284 - val_loss: 0.7368 - val_accuracy: 0.4647\n",
      "Epoch 182/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7229 - accuracy: 0.5164 - val_loss: 0.7362 - val_accuracy: 0.4765\n",
      "Epoch 183/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7228 - accuracy: 0.5104 - val_loss: 0.7351 - val_accuracy: 0.4765\n",
      "Epoch 184/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7178 - accuracy: 0.5104 - val_loss: 0.7333 - val_accuracy: 0.4765\n",
      "Epoch 185/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7180 - accuracy: 0.5224 - val_loss: 0.7312 - val_accuracy: 0.4706\n",
      "Epoch 186/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7115 - accuracy: 0.5224 - val_loss: 0.7295 - val_accuracy: 0.4647\n",
      "Epoch 187/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7153 - accuracy: 0.5075 - val_loss: 0.7277 - val_accuracy: 0.4588\n",
      "Epoch 188/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7118 - accuracy: 0.5164 - val_loss: 0.7264 - val_accuracy: 0.4588\n",
      "Epoch 189/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7142 - accuracy: 0.5015 - val_loss: 0.7250 - val_accuracy: 0.4588\n",
      "Epoch 190/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7089 - accuracy: 0.5224 - val_loss: 0.7237 - val_accuracy: 0.4647\n",
      "Epoch 191/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7147 - accuracy: 0.4985 - val_loss: 0.7221 - val_accuracy: 0.4941\n",
      "Epoch 192/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7088 - accuracy: 0.5045 - val_loss: 0.7209 - val_accuracy: 0.4765\n",
      "Epoch 193/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7107 - accuracy: 0.5224 - val_loss: 0.7195 - val_accuracy: 0.4765\n",
      "Epoch 194/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7096 - accuracy: 0.5075 - val_loss: 0.7183 - val_accuracy: 0.4882\n",
      "Epoch 195/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7058 - accuracy: 0.5164 - val_loss: 0.7171 - val_accuracy: 0.4824\n",
      "Epoch 196/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7028 - accuracy: 0.5254 - val_loss: 0.7159 - val_accuracy: 0.4824\n",
      "Epoch 197/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7050 - accuracy: 0.5224 - val_loss: 0.7147 - val_accuracy: 0.4941\n",
      "Epoch 198/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6973 - accuracy: 0.5284 - val_loss: 0.7137 - val_accuracy: 0.5000\n",
      "Epoch 199/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7024 - accuracy: 0.5045 - val_loss: 0.7126 - val_accuracy: 0.4941\n",
      "Epoch 200/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7067 - accuracy: 0.5164 - val_loss: 0.7115 - val_accuracy: 0.4941\n",
      "Epoch 201/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6987 - accuracy: 0.5164 - val_loss: 0.7104 - val_accuracy: 0.5118\n",
      "Epoch 202/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6998 - accuracy: 0.5254 - val_loss: 0.7096 - val_accuracy: 0.5118\n",
      "Epoch 203/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7013 - accuracy: 0.5164 - val_loss: 0.7089 - val_accuracy: 0.5059\n",
      "Epoch 204/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6999 - accuracy: 0.5284 - val_loss: 0.7079 - val_accuracy: 0.5000\n",
      "Epoch 205/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7004 - accuracy: 0.5284 - val_loss: 0.7072 - val_accuracy: 0.5118\n",
      "Epoch 206/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6972 - accuracy: 0.5254 - val_loss: 0.7062 - val_accuracy: 0.5118\n",
      "Epoch 207/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6982 - accuracy: 0.5493 - val_loss: 0.7054 - val_accuracy: 0.5118\n",
      "Epoch 208/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.7019 - accuracy: 0.5134 - val_loss: 0.7045 - val_accuracy: 0.5059\n",
      "Epoch 209/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6977 - accuracy: 0.5104 - val_loss: 0.7039 - val_accuracy: 0.5118\n",
      "Epoch 210/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6961 - accuracy: 0.5224 - val_loss: 0.7031 - val_accuracy: 0.5059\n",
      "Epoch 211/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6975 - accuracy: 0.5164 - val_loss: 0.7021 - val_accuracy: 0.5118\n",
      "Epoch 212/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6927 - accuracy: 0.5433 - val_loss: 0.7014 - val_accuracy: 0.5176\n",
      "Epoch 213/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6962 - accuracy: 0.5194 - val_loss: 0.7005 - val_accuracy: 0.5176\n",
      "Epoch 214/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6901 - accuracy: 0.5224 - val_loss: 0.6997 - val_accuracy: 0.5118\n",
      "Epoch 215/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6921 - accuracy: 0.5373 - val_loss: 0.6987 - val_accuracy: 0.5118\n",
      "Epoch 216/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6950 - accuracy: 0.5224 - val_loss: 0.6979 - val_accuracy: 0.5118\n",
      "Epoch 217/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6973 - val_accuracy: 0.5176\n",
      "Epoch 218/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6891 - accuracy: 0.5313 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
      "Epoch 219/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5313 - val_loss: 0.6962 - val_accuracy: 0.5118\n",
      "Epoch 220/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6979 - accuracy: 0.4955 - val_loss: 0.6956 - val_accuracy: 0.4941\n",
      "Epoch 221/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5254 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
      "Epoch 222/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6899 - accuracy: 0.5015 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 223/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6948 - accuracy: 0.4836 - val_loss: 0.6945 - val_accuracy: 0.5059\n",
      "Epoch 224/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5194 - val_loss: 0.6942 - val_accuracy: 0.5176\n",
      "Epoch 225/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.5075 - val_loss: 0.6938 - val_accuracy: 0.5059\n",
      "Epoch 226/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5075 - val_loss: 0.6933 - val_accuracy: 0.5059\n",
      "Epoch 227/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5104 - val_loss: 0.6928 - val_accuracy: 0.5176\n",
      "Epoch 228/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6853 - accuracy: 0.5313 - val_loss: 0.6925 - val_accuracy: 0.5176\n",
      "Epoch 229/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6906 - accuracy: 0.5313 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 230/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5433 - val_loss: 0.6916 - val_accuracy: 0.5176\n",
      "Epoch 231/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5373 - val_loss: 0.6916 - val_accuracy: 0.5235\n",
      "Epoch 232/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5433 - val_loss: 0.6914 - val_accuracy: 0.5235\n",
      "Epoch 233/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6901 - accuracy: 0.5284 - val_loss: 0.6911 - val_accuracy: 0.5118\n",
      "Epoch 234/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6929 - accuracy: 0.5224 - val_loss: 0.6909 - val_accuracy: 0.5118\n",
      "Epoch 235/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5403 - val_loss: 0.6907 - val_accuracy: 0.5176\n",
      "Epoch 236/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5642 - val_loss: 0.6905 - val_accuracy: 0.5176\n",
      "Epoch 237/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5194 - val_loss: 0.6903 - val_accuracy: 0.5294\n",
      "Epoch 238/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5313 - val_loss: 0.6899 - val_accuracy: 0.5176\n",
      "Epoch 239/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6884 - accuracy: 0.5254 - val_loss: 0.6898 - val_accuracy: 0.5294\n",
      "Epoch 240/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5343 - val_loss: 0.6894 - val_accuracy: 0.5059\n",
      "Epoch 241/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5672 - val_loss: 0.6893 - val_accuracy: 0.5059\n",
      "Epoch 242/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5254 - val_loss: 0.6893 - val_accuracy: 0.5059\n",
      "Epoch 243/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5224 - val_loss: 0.6892 - val_accuracy: 0.5118\n",
      "Epoch 244/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.5075 - val_loss: 0.6891 - val_accuracy: 0.5176\n",
      "Epoch 245/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6874 - accuracy: 0.5493 - val_loss: 0.6889 - val_accuracy: 0.5118\n",
      "Epoch 246/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5433 - val_loss: 0.6887 - val_accuracy: 0.5118\n",
      "Epoch 247/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.4925 - val_loss: 0.6886 - val_accuracy: 0.5059\n",
      "Epoch 248/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6874 - accuracy: 0.5134 - val_loss: 0.6884 - val_accuracy: 0.5176\n",
      "Epoch 249/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6844 - accuracy: 0.5373 - val_loss: 0.6884 - val_accuracy: 0.5176\n",
      "Epoch 250/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6821 - accuracy: 0.5164 - val_loss: 0.6884 - val_accuracy: 0.5235\n",
      "Epoch 251/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5164 - val_loss: 0.6881 - val_accuracy: 0.5235\n",
      "Epoch 252/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6907 - accuracy: 0.5134 - val_loss: 0.6879 - val_accuracy: 0.5235\n",
      "Epoch 253/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5373 - val_loss: 0.6878 - val_accuracy: 0.5235\n",
      "Epoch 254/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5313 - val_loss: 0.6877 - val_accuracy: 0.5235\n",
      "Epoch 255/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5343 - val_loss: 0.6875 - val_accuracy: 0.5353\n",
      "Epoch 256/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.5313 - val_loss: 0.6874 - val_accuracy: 0.5412\n",
      "Epoch 257/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5672 - val_loss: 0.6874 - val_accuracy: 0.5412\n",
      "Epoch 258/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5881 - val_loss: 0.6872 - val_accuracy: 0.5294\n",
      "Epoch 259/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.5522 - val_loss: 0.6872 - val_accuracy: 0.5294\n",
      "Epoch 260/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6858 - accuracy: 0.5433 - val_loss: 0.6872 - val_accuracy: 0.5235\n",
      "Epoch 261/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6862 - accuracy: 0.5552 - val_loss: 0.6871 - val_accuracy: 0.5235\n",
      "Epoch 262/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5373 - val_loss: 0.6870 - val_accuracy: 0.5176\n",
      "Epoch 263/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5433 - val_loss: 0.6870 - val_accuracy: 0.5176\n",
      "Epoch 264/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6874 - accuracy: 0.5373 - val_loss: 0.6869 - val_accuracy: 0.5176\n",
      "Epoch 265/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5164 - val_loss: 0.6867 - val_accuracy: 0.5176\n",
      "Epoch 266/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5373 - val_loss: 0.6867 - val_accuracy: 0.5118\n",
      "Epoch 267/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5522 - val_loss: 0.6869 - val_accuracy: 0.5176\n",
      "Epoch 268/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6844 - accuracy: 0.5642 - val_loss: 0.6867 - val_accuracy: 0.5176\n",
      "Epoch 269/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6840 - accuracy: 0.5642 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
      "Epoch 270/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5493 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
      "Epoch 271/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5343 - val_loss: 0.6871 - val_accuracy: 0.4941\n",
      "Epoch 272/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5463 - val_loss: 0.6871 - val_accuracy: 0.4941\n",
      "Epoch 273/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6844 - accuracy: 0.5313 - val_loss: 0.6869 - val_accuracy: 0.5176\n",
      "Epoch 274/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5134 - val_loss: 0.6869 - val_accuracy: 0.5059\n",
      "Epoch 275/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5403 - val_loss: 0.6870 - val_accuracy: 0.5000\n",
      "Epoch 276/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6868 - accuracy: 0.5582 - val_loss: 0.6870 - val_accuracy: 0.5059\n",
      "Epoch 277/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5463 - val_loss: 0.6868 - val_accuracy: 0.5176\n",
      "Epoch 278/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6883 - accuracy: 0.5373 - val_loss: 0.6868 - val_accuracy: 0.5176\n",
      "Epoch 279/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6922 - accuracy: 0.5224 - val_loss: 0.6867 - val_accuracy: 0.5235\n",
      "Epoch 280/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5493 - val_loss: 0.6866 - val_accuracy: 0.5118\n",
      "Epoch 281/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5582 - val_loss: 0.6864 - val_accuracy: 0.5235\n",
      "Epoch 282/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6867 - accuracy: 0.5642 - val_loss: 0.6862 - val_accuracy: 0.5235\n",
      "Epoch 283/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5582 - val_loss: 0.6862 - val_accuracy: 0.5000\n",
      "Epoch 284/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5672 - val_loss: 0.6863 - val_accuracy: 0.5000\n",
      "Epoch 285/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5493 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 286/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5672 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 287/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5552 - val_loss: 0.6864 - val_accuracy: 0.5059\n",
      "Epoch 288/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6864 - accuracy: 0.5194 - val_loss: 0.6866 - val_accuracy: 0.5059\n",
      "Epoch 289/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5313 - val_loss: 0.6866 - val_accuracy: 0.5118\n",
      "Epoch 290/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6879 - accuracy: 0.5254 - val_loss: 0.6868 - val_accuracy: 0.5059\n",
      "Epoch 291/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6895 - accuracy: 0.5284 - val_loss: 0.6870 - val_accuracy: 0.5000\n",
      "Epoch 292/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5373 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
      "Epoch 293/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5493 - val_loss: 0.6871 - val_accuracy: 0.4941\n",
      "Epoch 294/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.5373 - val_loss: 0.6867 - val_accuracy: 0.4882\n",
      "Epoch 295/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5672 - val_loss: 0.6865 - val_accuracy: 0.5059\n",
      "Epoch 296/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5284 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
      "Epoch 297/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5612 - val_loss: 0.6866 - val_accuracy: 0.5235\n",
      "Epoch 298/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5851 - val_loss: 0.6865 - val_accuracy: 0.5176\n",
      "Epoch 299/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5254 - val_loss: 0.6866 - val_accuracy: 0.4882\n",
      "Epoch 300/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5881 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
      "Epoch 301/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5194 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 302/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5373 - val_loss: 0.6863 - val_accuracy: 0.5000\n",
      "Epoch 303/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5761 - val_loss: 0.6864 - val_accuracy: 0.4882\n",
      "Epoch 304/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5373 - val_loss: 0.6865 - val_accuracy: 0.4824\n",
      "Epoch 305/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6913 - accuracy: 0.5552 - val_loss: 0.6866 - val_accuracy: 0.4941\n",
      "Epoch 306/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5463 - val_loss: 0.6864 - val_accuracy: 0.4824\n",
      "Epoch 307/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6864 - accuracy: 0.5284 - val_loss: 0.6864 - val_accuracy: 0.4941\n",
      "Epoch 308/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.5463 - val_loss: 0.6864 - val_accuracy: 0.4882\n",
      "Epoch 309/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5343 - val_loss: 0.6868 - val_accuracy: 0.4824\n",
      "Epoch 310/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5373 - val_loss: 0.6865 - val_accuracy: 0.4824\n",
      "Epoch 311/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.5313 - val_loss: 0.6866 - val_accuracy: 0.4824\n",
      "Epoch 312/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5522 - val_loss: 0.6864 - val_accuracy: 0.4882\n",
      "Epoch 313/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5731 - val_loss: 0.6864 - val_accuracy: 0.4941\n",
      "Epoch 314/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.5254 - val_loss: 0.6865 - val_accuracy: 0.4941\n",
      "Epoch 315/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6874 - accuracy: 0.5552 - val_loss: 0.6863 - val_accuracy: 0.5118\n",
      "Epoch 316/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5493 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 317/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5522 - val_loss: 0.6863 - val_accuracy: 0.5176\n",
      "Epoch 318/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.5672 - val_loss: 0.6862 - val_accuracy: 0.5294\n",
      "Epoch 319/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5851 - val_loss: 0.6862 - val_accuracy: 0.5118\n",
      "Epoch 320/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5493 - val_loss: 0.6862 - val_accuracy: 0.5118\n",
      "Epoch 321/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5433 - val_loss: 0.6862 - val_accuracy: 0.5059\n",
      "Epoch 322/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6864 - accuracy: 0.5403 - val_loss: 0.6862 - val_accuracy: 0.5059\n",
      "Epoch 323/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5642 - val_loss: 0.6865 - val_accuracy: 0.4824\n",
      "Epoch 324/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5761 - val_loss: 0.6864 - val_accuracy: 0.4882\n",
      "Epoch 325/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5672 - val_loss: 0.6863 - val_accuracy: 0.4882\n",
      "Epoch 326/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5672 - val_loss: 0.6862 - val_accuracy: 0.4941\n",
      "Epoch 327/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5463 - val_loss: 0.6863 - val_accuracy: 0.5000\n",
      "Epoch 328/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.5493 - val_loss: 0.6863 - val_accuracy: 0.4941\n",
      "Epoch 329/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6858 - accuracy: 0.5701 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 330/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5791 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
      "Epoch 331/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5642 - val_loss: 0.6866 - val_accuracy: 0.4824\n",
      "Epoch 332/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.5313 - val_loss: 0.6864 - val_accuracy: 0.4882\n",
      "Epoch 333/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5433 - val_loss: 0.6863 - val_accuracy: 0.5000\n",
      "Epoch 334/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6872 - accuracy: 0.5522 - val_loss: 0.6865 - val_accuracy: 0.4882\n",
      "Epoch 335/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6884 - accuracy: 0.5403 - val_loss: 0.6863 - val_accuracy: 0.5000\n",
      "Epoch 336/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5522 - val_loss: 0.6865 - val_accuracy: 0.4882\n",
      "Epoch 337/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5433 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 338/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5403 - val_loss: 0.6866 - val_accuracy: 0.5059\n",
      "Epoch 339/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6872 - accuracy: 0.5373 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 340/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5582 - val_loss: 0.6864 - val_accuracy: 0.5059\n",
      "Epoch 341/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.5284 - val_loss: 0.6865 - val_accuracy: 0.5059\n",
      "Epoch 342/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5642 - val_loss: 0.6866 - val_accuracy: 0.5000\n",
      "Epoch 343/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6869 - accuracy: 0.5284 - val_loss: 0.6866 - val_accuracy: 0.5118\n",
      "Epoch 344/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5403 - val_loss: 0.6865 - val_accuracy: 0.5118\n",
      "Epoch 345/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6874 - accuracy: 0.5493 - val_loss: 0.6864 - val_accuracy: 0.5059\n",
      "Epoch 346/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.5552 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 347/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.5343 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 348/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5313 - val_loss: 0.6863 - val_accuracy: 0.5118\n",
      "Epoch 349/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6861 - accuracy: 0.5373 - val_loss: 0.6864 - val_accuracy: 0.5059\n",
      "Epoch 350/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5433 - val_loss: 0.6864 - val_accuracy: 0.5118\n",
      "Epoch 351/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5940 - val_loss: 0.6864 - val_accuracy: 0.5118\n",
      "Epoch 352/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5493 - val_loss: 0.6865 - val_accuracy: 0.5059\n",
      "Epoch 353/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5493 - val_loss: 0.6865 - val_accuracy: 0.5118\n",
      "Epoch 354/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5493 - val_loss: 0.6865 - val_accuracy: 0.5059\n",
      "Epoch 355/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5582 - val_loss: 0.6865 - val_accuracy: 0.5118\n",
      "Epoch 356/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5463 - val_loss: 0.6864 - val_accuracy: 0.5118\n",
      "Epoch 357/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5582 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 358/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5552 - val_loss: 0.6864 - val_accuracy: 0.4941\n",
      "Epoch 359/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5642 - val_loss: 0.6866 - val_accuracy: 0.5059\n",
      "Epoch 360/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5313 - val_loss: 0.6866 - val_accuracy: 0.4941\n",
      "Epoch 361/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5642 - val_loss: 0.6864 - val_accuracy: 0.4941\n",
      "Epoch 362/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5194 - val_loss: 0.6862 - val_accuracy: 0.5059\n",
      "Epoch 363/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5731 - val_loss: 0.6863 - val_accuracy: 0.4941\n",
      "Epoch 364/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5761 - val_loss: 0.6865 - val_accuracy: 0.4941\n",
      "Epoch 365/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5433 - val_loss: 0.6864 - val_accuracy: 0.4941\n",
      "Epoch 366/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5433 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 367/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6822 - accuracy: 0.5552 - val_loss: 0.6862 - val_accuracy: 0.5176\n",
      "Epoch 368/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6846 - accuracy: 0.5761 - val_loss: 0.6863 - val_accuracy: 0.5118\n",
      "Epoch 369/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6871 - accuracy: 0.5373 - val_loss: 0.6864 - val_accuracy: 0.5118\n",
      "Epoch 370/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5373 - val_loss: 0.6864 - val_accuracy: 0.5235\n",
      "Epoch 371/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5701 - val_loss: 0.6866 - val_accuracy: 0.5294\n",
      "Epoch 372/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5642 - val_loss: 0.6868 - val_accuracy: 0.5000\n",
      "Epoch 373/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5313 - val_loss: 0.6870 - val_accuracy: 0.4824\n",
      "Epoch 374/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5403 - val_loss: 0.6865 - val_accuracy: 0.5059\n",
      "Epoch 375/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5463 - val_loss: 0.6862 - val_accuracy: 0.5118\n",
      "Epoch 376/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5433 - val_loss: 0.6863 - val_accuracy: 0.5000\n",
      "Epoch 377/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5493 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
      "Epoch 378/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5552 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 379/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6832 - accuracy: 0.5493 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 380/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5493 - val_loss: 0.6866 - val_accuracy: 0.4882\n",
      "Epoch 381/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5493 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
      "Epoch 382/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5433 - val_loss: 0.6864 - val_accuracy: 0.4882\n",
      "Epoch 383/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5194 - val_loss: 0.6864 - val_accuracy: 0.4882\n",
      "Epoch 384/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6884 - accuracy: 0.5493 - val_loss: 0.6861 - val_accuracy: 0.5059\n",
      "Epoch 385/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5612 - val_loss: 0.6862 - val_accuracy: 0.5000\n",
      "Epoch 386/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6804 - accuracy: 0.6000 - val_loss: 0.6862 - val_accuracy: 0.5176\n",
      "Epoch 387/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5731 - val_loss: 0.6866 - val_accuracy: 0.4882\n",
      "Epoch 388/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5612 - val_loss: 0.6869 - val_accuracy: 0.4882\n",
      "Epoch 389/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5313 - val_loss: 0.6872 - val_accuracy: 0.4882\n",
      "Epoch 390/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6819 - accuracy: 0.5343 - val_loss: 0.6870 - val_accuracy: 0.4882\n",
      "Epoch 391/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6842 - accuracy: 0.5582 - val_loss: 0.6866 - val_accuracy: 0.4941\n",
      "Epoch 392/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5313 - val_loss: 0.6863 - val_accuracy: 0.5059\n",
      "Epoch 393/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5552 - val_loss: 0.6862 - val_accuracy: 0.5059\n",
      "Epoch 394/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5642 - val_loss: 0.6862 - val_accuracy: 0.5000\n",
      "Epoch 395/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5612 - val_loss: 0.6862 - val_accuracy: 0.4882\n",
      "Epoch 396/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5582 - val_loss: 0.6863 - val_accuracy: 0.4882\n",
      "Epoch 397/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5493 - val_loss: 0.6864 - val_accuracy: 0.4765\n",
      "Epoch 398/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6797 - accuracy: 0.5493 - val_loss: 0.6866 - val_accuracy: 0.4882\n",
      "Epoch 399/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5493 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 400/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5373 - val_loss: 0.6869 - val_accuracy: 0.4824\n",
      "Epoch 401/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5433 - val_loss: 0.6870 - val_accuracy: 0.4882\n",
      "Epoch 402/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6769 - accuracy: 0.5612 - val_loss: 0.6868 - val_accuracy: 0.4824\n",
      "Epoch 403/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5433 - val_loss: 0.6867 - val_accuracy: 0.4941\n",
      "Epoch 404/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.5403 - val_loss: 0.6866 - val_accuracy: 0.4941\n",
      "Epoch 405/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6868 - accuracy: 0.5075 - val_loss: 0.6866 - val_accuracy: 0.4941\n",
      "Epoch 406/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5552 - val_loss: 0.6865 - val_accuracy: 0.5059\n",
      "Epoch 407/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5164 - val_loss: 0.6865 - val_accuracy: 0.5059\n",
      "Epoch 408/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5493 - val_loss: 0.6866 - val_accuracy: 0.4882\n",
      "Epoch 409/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5552 - val_loss: 0.6869 - val_accuracy: 0.4941\n",
      "Epoch 410/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5373 - val_loss: 0.6871 - val_accuracy: 0.4882\n",
      "Epoch 411/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5522 - val_loss: 0.6873 - val_accuracy: 0.4824\n",
      "Epoch 412/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5403 - val_loss: 0.6872 - val_accuracy: 0.4941\n",
      "Epoch 413/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5672 - val_loss: 0.6873 - val_accuracy: 0.5176\n",
      "Epoch 414/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5254 - val_loss: 0.6874 - val_accuracy: 0.5176\n",
      "Epoch 415/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5672 - val_loss: 0.6874 - val_accuracy: 0.5176\n",
      "Epoch 416/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5343 - val_loss: 0.6876 - val_accuracy: 0.5176\n",
      "Epoch 417/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5373 - val_loss: 0.6872 - val_accuracy: 0.5118\n",
      "Epoch 418/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5403 - val_loss: 0.6873 - val_accuracy: 0.5059\n",
      "Epoch 419/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6888 - accuracy: 0.5493 - val_loss: 0.6873 - val_accuracy: 0.5059\n",
      "Epoch 420/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5522 - val_loss: 0.6870 - val_accuracy: 0.5118\n",
      "Epoch 421/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5851 - val_loss: 0.6872 - val_accuracy: 0.4941\n",
      "Epoch 422/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5373 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
      "Epoch 423/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5373 - val_loss: 0.6871 - val_accuracy: 0.5059\n",
      "Epoch 424/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5164 - val_loss: 0.6870 - val_accuracy: 0.5235\n",
      "Epoch 425/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.5493 - val_loss: 0.6869 - val_accuracy: 0.5235\n",
      "Epoch 426/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5313 - val_loss: 0.6868 - val_accuracy: 0.5059\n",
      "Epoch 427/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5612 - val_loss: 0.6869 - val_accuracy: 0.5059\n",
      "Epoch 428/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5343 - val_loss: 0.6868 - val_accuracy: 0.4941\n",
      "Epoch 429/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5701 - val_loss: 0.6866 - val_accuracy: 0.5059\n",
      "Epoch 430/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5373 - val_loss: 0.6864 - val_accuracy: 0.4941\n",
      "Epoch 431/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5403 - val_loss: 0.6864 - val_accuracy: 0.5059\n",
      "Epoch 432/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5463 - val_loss: 0.6866 - val_accuracy: 0.5000\n",
      "Epoch 433/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5761 - val_loss: 0.6866 - val_accuracy: 0.5000\n",
      "Epoch 434/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5403 - val_loss: 0.6867 - val_accuracy: 0.4882\n",
      "Epoch 435/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5284 - val_loss: 0.6867 - val_accuracy: 0.4941\n",
      "Epoch 436/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5910 - val_loss: 0.6871 - val_accuracy: 0.4824\n",
      "Epoch 437/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5373 - val_loss: 0.6866 - val_accuracy: 0.4824\n",
      "Epoch 438/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5701 - val_loss: 0.6869 - val_accuracy: 0.4824\n",
      "Epoch 439/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.5373 - val_loss: 0.6869 - val_accuracy: 0.4941\n",
      "Epoch 440/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5731 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
      "Epoch 441/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5642 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
      "Epoch 442/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5791 - val_loss: 0.6872 - val_accuracy: 0.5000\n",
      "Epoch 443/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6893 - accuracy: 0.4925 - val_loss: 0.6867 - val_accuracy: 0.5118\n",
      "Epoch 444/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6856 - accuracy: 0.5522 - val_loss: 0.6866 - val_accuracy: 0.4941\n",
      "Epoch 445/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5612 - val_loss: 0.6868 - val_accuracy: 0.4824\n",
      "Epoch 446/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5701 - val_loss: 0.6867 - val_accuracy: 0.4824\n",
      "Epoch 447/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5433 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 448/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5672 - val_loss: 0.6867 - val_accuracy: 0.5059\n",
      "Epoch 449/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5522 - val_loss: 0.6868 - val_accuracy: 0.5000\n",
      "Epoch 450/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5224 - val_loss: 0.6873 - val_accuracy: 0.4765\n",
      "Epoch 451/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5463 - val_loss: 0.6871 - val_accuracy: 0.4941\n",
      "Epoch 452/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5284 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
      "Epoch 453/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6880 - accuracy: 0.5224 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
      "Epoch 454/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5433 - val_loss: 0.6871 - val_accuracy: 0.4941\n",
      "Epoch 455/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5851 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
      "Epoch 456/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5284 - val_loss: 0.6870 - val_accuracy: 0.5059\n",
      "Epoch 457/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5373 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
      "Epoch 458/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5433 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
      "Epoch 459/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5313 - val_loss: 0.6872 - val_accuracy: 0.5059\n",
      "Epoch 460/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5612 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 461/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6844 - accuracy: 0.5672 - val_loss: 0.6870 - val_accuracy: 0.5000\n",
      "Epoch 462/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5642 - val_loss: 0.6871 - val_accuracy: 0.4824\n",
      "Epoch 463/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5731 - val_loss: 0.6869 - val_accuracy: 0.4882\n",
      "Epoch 464/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5612 - val_loss: 0.6869 - val_accuracy: 0.4824\n",
      "Epoch 465/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5343 - val_loss: 0.6870 - val_accuracy: 0.4824\n",
      "Epoch 466/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5672 - val_loss: 0.6874 - val_accuracy: 0.4824\n",
      "Epoch 467/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.5761 - val_loss: 0.6874 - val_accuracy: 0.4824\n",
      "Epoch 468/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5612 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
      "Epoch 469/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5254 - val_loss: 0.6870 - val_accuracy: 0.5000\n",
      "Epoch 470/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5701 - val_loss: 0.6872 - val_accuracy: 0.5059\n",
      "Epoch 471/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5373 - val_loss: 0.6874 - val_accuracy: 0.5000\n",
      "Epoch 472/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6786 - accuracy: 0.5791 - val_loss: 0.6876 - val_accuracy: 0.4941\n",
      "Epoch 473/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6767 - accuracy: 0.5731 - val_loss: 0.6878 - val_accuracy: 0.4941\n",
      "Epoch 474/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5493 - val_loss: 0.6878 - val_accuracy: 0.4941\n",
      "Epoch 475/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6817 - accuracy: 0.5493 - val_loss: 0.6879 - val_accuracy: 0.4941\n",
      "Epoch 476/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5582 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 477/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5343 - val_loss: 0.6874 - val_accuracy: 0.5059\n",
      "Epoch 478/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5254 - val_loss: 0.6872 - val_accuracy: 0.5118\n",
      "Epoch 479/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5522 - val_loss: 0.6872 - val_accuracy: 0.4882\n",
      "Epoch 480/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5552 - val_loss: 0.6870 - val_accuracy: 0.4824\n",
      "Epoch 481/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5224 - val_loss: 0.6871 - val_accuracy: 0.4824\n",
      "Epoch 482/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5672 - val_loss: 0.6873 - val_accuracy: 0.4765\n",
      "Epoch 483/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5672 - val_loss: 0.6874 - val_accuracy: 0.4824\n",
      "Epoch 484/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.5254 - val_loss: 0.6870 - val_accuracy: 0.4706\n",
      "Epoch 485/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5224 - val_loss: 0.6868 - val_accuracy: 0.5235\n",
      "Epoch 486/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5463 - val_loss: 0.6870 - val_accuracy: 0.5059\n",
      "Epoch 487/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5761 - val_loss: 0.6869 - val_accuracy: 0.5059\n",
      "Epoch 488/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5612 - val_loss: 0.6871 - val_accuracy: 0.4824\n",
      "Epoch 489/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6804 - accuracy: 0.5582 - val_loss: 0.6873 - val_accuracy: 0.4882\n",
      "Epoch 490/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5522 - val_loss: 0.6873 - val_accuracy: 0.4882\n",
      "Epoch 491/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6885 - accuracy: 0.5522 - val_loss: 0.6872 - val_accuracy: 0.4765\n",
      "Epoch 492/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5612 - val_loss: 0.6870 - val_accuracy: 0.5059\n",
      "Epoch 493/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5761 - val_loss: 0.6869 - val_accuracy: 0.5118\n",
      "Epoch 494/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5672 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
      "Epoch 495/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5463 - val_loss: 0.6884 - val_accuracy: 0.4882\n",
      "Epoch 496/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6857 - accuracy: 0.5552 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 497/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5731 - val_loss: 0.6882 - val_accuracy: 0.4941\n",
      "Epoch 498/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5343 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
      "Epoch 499/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6841 - accuracy: 0.5254 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
      "Epoch 500/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6799 - accuracy: 0.5343 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
      "Epoch 501/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5313 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 502/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5433 - val_loss: 0.6877 - val_accuracy: 0.5118\n",
      "Epoch 503/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5433 - val_loss: 0.6877 - val_accuracy: 0.5059\n",
      "Epoch 504/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5821 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 505/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5373 - val_loss: 0.6879 - val_accuracy: 0.4941\n",
      "Epoch 506/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5701 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 507/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5493 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "Epoch 508/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.5134 - val_loss: 0.6879 - val_accuracy: 0.4941\n",
      "Epoch 509/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5373 - val_loss: 0.6882 - val_accuracy: 0.4941\n",
      "Epoch 510/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5433 - val_loss: 0.6880 - val_accuracy: 0.4882\n",
      "Epoch 511/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5493 - val_loss: 0.6880 - val_accuracy: 0.4882\n",
      "Epoch 512/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5642 - val_loss: 0.6879 - val_accuracy: 0.5000\n",
      "Epoch 513/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5433 - val_loss: 0.6878 - val_accuracy: 0.5118\n",
      "Epoch 514/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5582 - val_loss: 0.6876 - val_accuracy: 0.5059\n",
      "Epoch 515/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5522 - val_loss: 0.6877 - val_accuracy: 0.5118\n",
      "Epoch 516/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6864 - accuracy: 0.5403 - val_loss: 0.6877 - val_accuracy: 0.5059\n",
      "Epoch 517/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5373 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 518/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.5254 - val_loss: 0.6886 - val_accuracy: 0.4824\n",
      "Epoch 519/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5224 - val_loss: 0.6886 - val_accuracy: 0.4765\n",
      "Epoch 520/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5433 - val_loss: 0.6885 - val_accuracy: 0.4824\n",
      "Epoch 521/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5313 - val_loss: 0.6883 - val_accuracy: 0.4765\n",
      "Epoch 522/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5463 - val_loss: 0.6883 - val_accuracy: 0.4765\n",
      "Epoch 523/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5582 - val_loss: 0.6876 - val_accuracy: 0.4824\n",
      "Epoch 524/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5313 - val_loss: 0.6877 - val_accuracy: 0.4824\n",
      "Epoch 525/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5642 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
      "Epoch 526/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5463 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 527/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5881 - val_loss: 0.6875 - val_accuracy: 0.5176\n",
      "Epoch 528/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6859 - accuracy: 0.5343 - val_loss: 0.6878 - val_accuracy: 0.5059\n",
      "Epoch 529/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.5343 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 530/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5433 - val_loss: 0.6876 - val_accuracy: 0.5118\n",
      "Epoch 531/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6802 - accuracy: 0.5642 - val_loss: 0.6876 - val_accuracy: 0.5059\n",
      "Epoch 532/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5642 - val_loss: 0.6881 - val_accuracy: 0.4941\n",
      "Epoch 533/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5522 - val_loss: 0.6875 - val_accuracy: 0.4882\n",
      "Epoch 534/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5463 - val_loss: 0.6875 - val_accuracy: 0.4941\n",
      "Epoch 535/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5373 - val_loss: 0.6874 - val_accuracy: 0.4941\n",
      "Epoch 536/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6863 - accuracy: 0.5701 - val_loss: 0.6874 - val_accuracy: 0.5176\n",
      "Epoch 537/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5373 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
      "Epoch 538/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.5433 - val_loss: 0.6880 - val_accuracy: 0.4824\n",
      "Epoch 539/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.5552 - val_loss: 0.6882 - val_accuracy: 0.4882\n",
      "Epoch 540/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5701 - val_loss: 0.6881 - val_accuracy: 0.4765\n",
      "Epoch 541/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5522 - val_loss: 0.6878 - val_accuracy: 0.4941\n",
      "Epoch 542/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6850 - accuracy: 0.5642 - val_loss: 0.6876 - val_accuracy: 0.4941\n",
      "Epoch 543/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5224 - val_loss: 0.6875 - val_accuracy: 0.5059\n",
      "Epoch 544/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6896 - accuracy: 0.5343 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
      "Epoch 545/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5672 - val_loss: 0.6876 - val_accuracy: 0.4765\n",
      "Epoch 546/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5493 - val_loss: 0.6871 - val_accuracy: 0.5118\n",
      "Epoch 547/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.5134 - val_loss: 0.6874 - val_accuracy: 0.5000\n",
      "Epoch 548/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5582 - val_loss: 0.6874 - val_accuracy: 0.5000\n",
      "Epoch 549/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5313 - val_loss: 0.6874 - val_accuracy: 0.4941\n",
      "Epoch 550/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5463 - val_loss: 0.6877 - val_accuracy: 0.4824\n",
      "Epoch 551/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5254 - val_loss: 0.6878 - val_accuracy: 0.4824\n",
      "Epoch 552/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5463 - val_loss: 0.6874 - val_accuracy: 0.5059\n",
      "Epoch 553/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5582 - val_loss: 0.6871 - val_accuracy: 0.5176\n",
      "Epoch 554/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5582 - val_loss: 0.6871 - val_accuracy: 0.5176\n",
      "Epoch 555/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6880 - accuracy: 0.5403 - val_loss: 0.6873 - val_accuracy: 0.4941\n",
      "Epoch 556/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5642 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
      "Epoch 557/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5403 - val_loss: 0.6877 - val_accuracy: 0.4941\n",
      "Epoch 558/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6882 - accuracy: 0.5582 - val_loss: 0.6875 - val_accuracy: 0.5118\n",
      "Epoch 559/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5284 - val_loss: 0.6874 - val_accuracy: 0.5176\n",
      "Epoch 560/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5791 - val_loss: 0.6874 - val_accuracy: 0.5118\n",
      "Epoch 561/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5612 - val_loss: 0.6875 - val_accuracy: 0.5176\n",
      "Epoch 562/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6871 - accuracy: 0.5552 - val_loss: 0.6875 - val_accuracy: 0.5059\n",
      "Epoch 563/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5493 - val_loss: 0.6872 - val_accuracy: 0.5176\n",
      "Epoch 564/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6851 - accuracy: 0.5582 - val_loss: 0.6877 - val_accuracy: 0.4882\n",
      "Epoch 565/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6866 - accuracy: 0.5194 - val_loss: 0.6881 - val_accuracy: 0.4882\n",
      "Epoch 566/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5463 - val_loss: 0.6884 - val_accuracy: 0.4765\n",
      "Epoch 567/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5463 - val_loss: 0.6883 - val_accuracy: 0.4765\n",
      "Epoch 568/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5701 - val_loss: 0.6880 - val_accuracy: 0.4706\n",
      "Epoch 569/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.5254 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
      "Epoch 570/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.5403 - val_loss: 0.6873 - val_accuracy: 0.5176\n",
      "Epoch 571/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5313 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 572/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.5642 - val_loss: 0.6875 - val_accuracy: 0.4882\n",
      "Epoch 573/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5373 - val_loss: 0.6874 - val_accuracy: 0.5000\n",
      "Epoch 574/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5373 - val_loss: 0.6872 - val_accuracy: 0.5118\n",
      "Epoch 575/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5701 - val_loss: 0.6874 - val_accuracy: 0.4882\n",
      "Epoch 576/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5493 - val_loss: 0.6876 - val_accuracy: 0.5000\n",
      "Epoch 577/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6876 - val_accuracy: 0.5118\n",
      "Epoch 578/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.5373 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "Epoch 579/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5463 - val_loss: 0.6883 - val_accuracy: 0.4882\n",
      "Epoch 580/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5522 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
      "Epoch 581/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5493 - val_loss: 0.6888 - val_accuracy: 0.4941\n",
      "Epoch 582/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5552 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
      "Epoch 583/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5761 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "Epoch 584/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5612 - val_loss: 0.6879 - val_accuracy: 0.5118\n",
      "Epoch 585/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5463 - val_loss: 0.6878 - val_accuracy: 0.5118\n",
      "Epoch 586/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5433 - val_loss: 0.6879 - val_accuracy: 0.5176\n",
      "Epoch 587/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5343 - val_loss: 0.6879 - val_accuracy: 0.5118\n",
      "Epoch 588/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5522 - val_loss: 0.6876 - val_accuracy: 0.5118\n",
      "Epoch 589/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6872 - accuracy: 0.5433 - val_loss: 0.6877 - val_accuracy: 0.5176\n",
      "Epoch 590/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6802 - accuracy: 0.5791 - val_loss: 0.6882 - val_accuracy: 0.4941\n",
      "Epoch 591/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5463 - val_loss: 0.6884 - val_accuracy: 0.4882\n",
      "Epoch 592/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5403 - val_loss: 0.6882 - val_accuracy: 0.5059\n",
      "Epoch 593/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5433 - val_loss: 0.6877 - val_accuracy: 0.5118\n",
      "Epoch 594/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5672 - val_loss: 0.6877 - val_accuracy: 0.5118\n",
      "Epoch 595/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5313 - val_loss: 0.6880 - val_accuracy: 0.5059\n",
      "Epoch 596/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5552 - val_loss: 0.6887 - val_accuracy: 0.4882\n",
      "Epoch 597/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5522 - val_loss: 0.6883 - val_accuracy: 0.4941\n",
      "Epoch 598/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5642 - val_loss: 0.6882 - val_accuracy: 0.5118\n",
      "Epoch 599/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6833 - accuracy: 0.5701 - val_loss: 0.6889 - val_accuracy: 0.5059\n",
      "Epoch 600/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5672 - val_loss: 0.6885 - val_accuracy: 0.5118\n",
      "Epoch 601/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5522 - val_loss: 0.6883 - val_accuracy: 0.4941\n",
      "Epoch 602/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5701 - val_loss: 0.6883 - val_accuracy: 0.4882\n",
      "Epoch 603/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5343 - val_loss: 0.6881 - val_accuracy: 0.4882\n",
      "Epoch 604/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5194 - val_loss: 0.6877 - val_accuracy: 0.4941\n",
      "Epoch 605/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5672 - val_loss: 0.6872 - val_accuracy: 0.5059\n",
      "Epoch 606/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.5433 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
      "Epoch 607/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5493 - val_loss: 0.6876 - val_accuracy: 0.5000\n",
      "Epoch 608/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6760 - accuracy: 0.6000 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 609/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6902 - accuracy: 0.5104 - val_loss: 0.6879 - val_accuracy: 0.5176\n",
      "Epoch 610/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5493 - val_loss: 0.6879 - val_accuracy: 0.5059\n",
      "Epoch 611/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.5284 - val_loss: 0.6879 - val_accuracy: 0.4941\n",
      "Epoch 612/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5433 - val_loss: 0.6875 - val_accuracy: 0.5059\n",
      "Epoch 613/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5672 - val_loss: 0.6877 - val_accuracy: 0.5176\n",
      "Epoch 614/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5672 - val_loss: 0.6877 - val_accuracy: 0.5235\n",
      "Epoch 615/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5433 - val_loss: 0.6875 - val_accuracy: 0.5118\n",
      "Epoch 616/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6864 - accuracy: 0.5672 - val_loss: 0.6881 - val_accuracy: 0.4706\n",
      "Epoch 617/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5284 - val_loss: 0.6882 - val_accuracy: 0.4706\n",
      "Epoch 618/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5552 - val_loss: 0.6880 - val_accuracy: 0.4706\n",
      "Epoch 619/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5403 - val_loss: 0.6885 - val_accuracy: 0.4765\n",
      "Epoch 620/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5373 - val_loss: 0.6881 - val_accuracy: 0.4647\n",
      "Epoch 621/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5403 - val_loss: 0.6880 - val_accuracy: 0.4706\n",
      "Epoch 622/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5403 - val_loss: 0.6879 - val_accuracy: 0.4765\n",
      "Epoch 623/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5612 - val_loss: 0.6886 - val_accuracy: 0.4765\n",
      "Epoch 624/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5522 - val_loss: 0.6876 - val_accuracy: 0.4765\n",
      "Epoch 625/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5672 - val_loss: 0.6873 - val_accuracy: 0.4706\n",
      "Epoch 626/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5672 - val_loss: 0.6871 - val_accuracy: 0.4882\n",
      "Epoch 627/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5313 - val_loss: 0.6877 - val_accuracy: 0.4706\n",
      "Epoch 628/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6864 - accuracy: 0.5582 - val_loss: 0.6877 - val_accuracy: 0.4706\n",
      "Epoch 629/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5403 - val_loss: 0.6874 - val_accuracy: 0.4882\n",
      "Epoch 630/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5403 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
      "Epoch 631/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5522 - val_loss: 0.6879 - val_accuracy: 0.4765\n",
      "Epoch 632/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5343 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
      "Epoch 633/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5672 - val_loss: 0.6876 - val_accuracy: 0.5235\n",
      "Epoch 634/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5343 - val_loss: 0.6877 - val_accuracy: 0.5176\n",
      "Epoch 635/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5224 - val_loss: 0.6886 - val_accuracy: 0.5118\n",
      "Epoch 636/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6893 - accuracy: 0.5164 - val_loss: 0.6887 - val_accuracy: 0.5059\n",
      "Epoch 637/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5612 - val_loss: 0.6886 - val_accuracy: 0.5176\n",
      "Epoch 638/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5552 - val_loss: 0.6885 - val_accuracy: 0.5059\n",
      "Epoch 639/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5522 - val_loss: 0.6889 - val_accuracy: 0.4824\n",
      "Epoch 640/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5552 - val_loss: 0.6889 - val_accuracy: 0.5118\n",
      "Epoch 641/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5612 - val_loss: 0.6885 - val_accuracy: 0.5059\n",
      "Epoch 642/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5463 - val_loss: 0.6886 - val_accuracy: 0.5118\n",
      "Epoch 643/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5403 - val_loss: 0.6885 - val_accuracy: 0.5059\n",
      "Epoch 644/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5642 - val_loss: 0.6883 - val_accuracy: 0.5118\n",
      "Epoch 645/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5582 - val_loss: 0.6885 - val_accuracy: 0.5176\n",
      "Epoch 646/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5403 - val_loss: 0.6888 - val_accuracy: 0.5235\n",
      "Epoch 647/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5313 - val_loss: 0.6885 - val_accuracy: 0.5059\n",
      "Epoch 648/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5194 - val_loss: 0.6884 - val_accuracy: 0.5235\n",
      "Epoch 649/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5433 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 650/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.6000 - val_loss: 0.6885 - val_accuracy: 0.5118\n",
      "Epoch 651/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5552 - val_loss: 0.6887 - val_accuracy: 0.5118\n",
      "Epoch 652/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5373 - val_loss: 0.6884 - val_accuracy: 0.5059\n",
      "Epoch 653/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5493 - val_loss: 0.6884 - val_accuracy: 0.4882\n",
      "Epoch 654/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5313 - val_loss: 0.6887 - val_accuracy: 0.4882\n",
      "Epoch 655/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.5552 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 656/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5761 - val_loss: 0.6880 - val_accuracy: 0.5176\n",
      "Epoch 657/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5522 - val_loss: 0.6878 - val_accuracy: 0.5059\n",
      "Epoch 658/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5403 - val_loss: 0.6876 - val_accuracy: 0.5059\n",
      "Epoch 659/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5493 - val_loss: 0.6879 - val_accuracy: 0.4941\n",
      "Epoch 660/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5522 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
      "Epoch 661/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5552 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 662/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6889 - accuracy: 0.5612 - val_loss: 0.6879 - val_accuracy: 0.5059\n",
      "Epoch 663/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.5433 - val_loss: 0.6882 - val_accuracy: 0.4941\n",
      "Epoch 664/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5373 - val_loss: 0.6882 - val_accuracy: 0.4941\n",
      "Epoch 665/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.5582 - val_loss: 0.6884 - val_accuracy: 0.4941\n",
      "Epoch 666/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5343 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 667/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6847 - accuracy: 0.5642 - val_loss: 0.6885 - val_accuracy: 0.5059\n",
      "Epoch 668/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5761 - val_loss: 0.6886 - val_accuracy: 0.5118\n",
      "Epoch 669/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5433 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 670/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6854 - accuracy: 0.5493 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
      "Epoch 671/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6942 - accuracy: 0.4955 - val_loss: 0.6881 - val_accuracy: 0.5059\n",
      "Epoch 672/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6853 - accuracy: 0.5552 - val_loss: 0.6878 - val_accuracy: 0.5059\n",
      "Epoch 673/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5463 - val_loss: 0.6880 - val_accuracy: 0.5059\n",
      "Epoch 674/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.5552 - val_loss: 0.6882 - val_accuracy: 0.5059\n",
      "Epoch 675/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5701 - val_loss: 0.6885 - val_accuracy: 0.5118\n",
      "Epoch 676/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6784 - accuracy: 0.5612 - val_loss: 0.6886 - val_accuracy: 0.5059\n",
      "Epoch 677/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5522 - val_loss: 0.6884 - val_accuracy: 0.5118\n",
      "Epoch 678/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5731 - val_loss: 0.6884 - val_accuracy: 0.5000\n",
      "Epoch 679/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5612 - val_loss: 0.6885 - val_accuracy: 0.4941\n",
      "Epoch 680/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.5612 - val_loss: 0.6889 - val_accuracy: 0.4824\n",
      "Epoch 681/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6784 - accuracy: 0.5672 - val_loss: 0.6892 - val_accuracy: 0.4824\n",
      "Epoch 682/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5731 - val_loss: 0.6891 - val_accuracy: 0.4824\n",
      "Epoch 683/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5373 - val_loss: 0.6892 - val_accuracy: 0.4882\n",
      "Epoch 684/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5522 - val_loss: 0.6888 - val_accuracy: 0.5176\n",
      "Epoch 685/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5493 - val_loss: 0.6889 - val_accuracy: 0.5059\n",
      "Epoch 686/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6763 - accuracy: 0.5731 - val_loss: 0.6888 - val_accuracy: 0.5118\n",
      "Epoch 687/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5731 - val_loss: 0.6890 - val_accuracy: 0.4882\n",
      "Epoch 688/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5463 - val_loss: 0.6891 - val_accuracy: 0.4941\n",
      "Epoch 689/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5582 - val_loss: 0.6883 - val_accuracy: 0.5059\n",
      "Epoch 690/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6781 - accuracy: 0.5582 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "Epoch 691/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5701 - val_loss: 0.6891 - val_accuracy: 0.4706\n",
      "Epoch 692/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6888 - val_accuracy: 0.4941\n",
      "Epoch 693/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5373 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
      "Epoch 694/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5522 - val_loss: 0.6884 - val_accuracy: 0.5118\n",
      "Epoch 695/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6846 - accuracy: 0.5373 - val_loss: 0.6885 - val_accuracy: 0.5118\n",
      "Epoch 696/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.5522 - val_loss: 0.6883 - val_accuracy: 0.5176\n",
      "Epoch 697/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6881 - accuracy: 0.5224 - val_loss: 0.6882 - val_accuracy: 0.5118\n",
      "Epoch 698/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5313 - val_loss: 0.6883 - val_accuracy: 0.5059\n",
      "Epoch 699/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5433 - val_loss: 0.6883 - val_accuracy: 0.5059\n",
      "Epoch 700/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6763 - accuracy: 0.5522 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 701/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5343 - val_loss: 0.6889 - val_accuracy: 0.4824\n",
      "Epoch 702/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5552 - val_loss: 0.6884 - val_accuracy: 0.5059\n",
      "Epoch 703/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5821 - val_loss: 0.6890 - val_accuracy: 0.5118\n",
      "Epoch 704/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6779 - accuracy: 0.5642 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
      "Epoch 705/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5463 - val_loss: 0.6891 - val_accuracy: 0.5118\n",
      "Epoch 706/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5284 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 707/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5373 - val_loss: 0.6887 - val_accuracy: 0.4941\n",
      "Epoch 708/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5552 - val_loss: 0.6884 - val_accuracy: 0.5000\n",
      "Epoch 709/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5552 - val_loss: 0.6885 - val_accuracy: 0.4941\n",
      "Epoch 710/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5582 - val_loss: 0.6894 - val_accuracy: 0.4706\n",
      "Epoch 711/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5224 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
      "Epoch 712/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5612 - val_loss: 0.6888 - val_accuracy: 0.5176\n",
      "Epoch 713/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6789 - accuracy: 0.5373 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 714/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5343 - val_loss: 0.6886 - val_accuracy: 0.5059\n",
      "Epoch 715/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5075 - val_loss: 0.6887 - val_accuracy: 0.5059\n",
      "Epoch 716/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5701 - val_loss: 0.6887 - val_accuracy: 0.5059\n",
      "Epoch 717/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6883 - accuracy: 0.5582 - val_loss: 0.6884 - val_accuracy: 0.5059\n",
      "Epoch 718/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5612 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 719/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5672 - val_loss: 0.6879 - val_accuracy: 0.5000\n",
      "Epoch 720/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.5552 - val_loss: 0.6893 - val_accuracy: 0.4824\n",
      "Epoch 721/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5433 - val_loss: 0.6881 - val_accuracy: 0.5118\n",
      "Epoch 722/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5672 - val_loss: 0.6882 - val_accuracy: 0.4941\n",
      "Epoch 723/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5582 - val_loss: 0.6883 - val_accuracy: 0.4941\n",
      "Epoch 724/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5433 - val_loss: 0.6886 - val_accuracy: 0.4941\n",
      "Epoch 725/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6909 - accuracy: 0.5164 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "Epoch 726/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.5403 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "Epoch 727/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6837 - accuracy: 0.5522 - val_loss: 0.6882 - val_accuracy: 0.4941\n",
      "Epoch 728/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6898 - accuracy: 0.5313 - val_loss: 0.6879 - val_accuracy: 0.4941\n",
      "Epoch 729/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5403 - val_loss: 0.6879 - val_accuracy: 0.5059\n",
      "Epoch 730/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6854 - accuracy: 0.5403 - val_loss: 0.6877 - val_accuracy: 0.5059\n",
      "Epoch 731/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5672 - val_loss: 0.6877 - val_accuracy: 0.5118\n",
      "Epoch 732/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5373 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
      "Epoch 733/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5313 - val_loss: 0.6879 - val_accuracy: 0.5000\n",
      "Epoch 734/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6874 - accuracy: 0.5224 - val_loss: 0.6884 - val_accuracy: 0.4882\n",
      "Epoch 735/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6843 - accuracy: 0.5493 - val_loss: 0.6887 - val_accuracy: 0.4765\n",
      "Epoch 736/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5254 - val_loss: 0.6882 - val_accuracy: 0.5059\n",
      "Epoch 737/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5463 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "Epoch 738/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5522 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 739/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5194 - val_loss: 0.6887 - val_accuracy: 0.4941\n",
      "Epoch 740/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6766 - accuracy: 0.5582 - val_loss: 0.6892 - val_accuracy: 0.4706\n",
      "Epoch 741/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5493 - val_loss: 0.6897 - val_accuracy: 0.4765\n",
      "Epoch 742/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5701 - val_loss: 0.6883 - val_accuracy: 0.5059\n",
      "Epoch 743/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5433 - val_loss: 0.6883 - val_accuracy: 0.5059\n",
      "Epoch 744/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6812 - accuracy: 0.5731 - val_loss: 0.6886 - val_accuracy: 0.5059\n",
      "Epoch 745/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6784 - accuracy: 0.5731 - val_loss: 0.6894 - val_accuracy: 0.4706\n",
      "Epoch 746/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6784 - accuracy: 0.5582 - val_loss: 0.6896 - val_accuracy: 0.4706\n",
      "Epoch 747/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5403 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
      "Epoch 748/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6742 - accuracy: 0.5791 - val_loss: 0.6887 - val_accuracy: 0.5118\n",
      "Epoch 749/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6774 - accuracy: 0.5672 - val_loss: 0.6894 - val_accuracy: 0.4882\n",
      "Epoch 750/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5612 - val_loss: 0.6890 - val_accuracy: 0.5118\n",
      "Epoch 751/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5552 - val_loss: 0.6888 - val_accuracy: 0.5059\n",
      "Epoch 752/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5582 - val_loss: 0.6887 - val_accuracy: 0.5059\n",
      "Epoch 753/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6909 - accuracy: 0.5134 - val_loss: 0.6890 - val_accuracy: 0.5118\n",
      "Epoch 754/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5672 - val_loss: 0.6884 - val_accuracy: 0.5118\n",
      "Epoch 755/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5343 - val_loss: 0.6887 - val_accuracy: 0.5118\n",
      "Epoch 756/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6758 - accuracy: 0.5851 - val_loss: 0.6891 - val_accuracy: 0.5059\n",
      "Epoch 757/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5343 - val_loss: 0.6889 - val_accuracy: 0.5118\n",
      "Epoch 758/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5642 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 759/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5612 - val_loss: 0.6887 - val_accuracy: 0.5118\n",
      "Epoch 760/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5493 - val_loss: 0.6886 - val_accuracy: 0.5235\n",
      "Epoch 761/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6868 - accuracy: 0.5343 - val_loss: 0.6885 - val_accuracy: 0.5059\n",
      "Epoch 762/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5582 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 763/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5612 - val_loss: 0.6884 - val_accuracy: 0.5000\n",
      "Epoch 764/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5343 - val_loss: 0.6886 - val_accuracy: 0.4941\n",
      "Epoch 765/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5313 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 766/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5672 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 767/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5731 - val_loss: 0.6883 - val_accuracy: 0.5059\n",
      "Epoch 768/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6778 - accuracy: 0.5672 - val_loss: 0.6886 - val_accuracy: 0.5059\n",
      "Epoch 769/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5612 - val_loss: 0.6881 - val_accuracy: 0.5059\n",
      "Epoch 770/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5731 - val_loss: 0.6878 - val_accuracy: 0.5118\n",
      "Epoch 771/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5493 - val_loss: 0.6879 - val_accuracy: 0.5059\n",
      "Epoch 772/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5761 - val_loss: 0.6886 - val_accuracy: 0.4882\n",
      "Epoch 773/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5642 - val_loss: 0.6887 - val_accuracy: 0.4941\n",
      "Epoch 774/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5433 - val_loss: 0.6895 - val_accuracy: 0.4941\n",
      "Epoch 775/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5164 - val_loss: 0.6889 - val_accuracy: 0.4882\n",
      "Epoch 776/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6748 - accuracy: 0.5851 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 777/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5104 - val_loss: 0.6884 - val_accuracy: 0.5059\n",
      "Epoch 778/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5582 - val_loss: 0.6884 - val_accuracy: 0.5059\n",
      "Epoch 779/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5612 - val_loss: 0.6882 - val_accuracy: 0.5059\n",
      "Epoch 780/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5731 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 781/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6753 - accuracy: 0.5493 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 782/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5343 - val_loss: 0.6885 - val_accuracy: 0.5059\n",
      "Epoch 783/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5612 - val_loss: 0.6889 - val_accuracy: 0.4941\n",
      "Epoch 784/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5612 - val_loss: 0.6893 - val_accuracy: 0.5118\n",
      "Epoch 785/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5552 - val_loss: 0.6895 - val_accuracy: 0.4941\n",
      "Epoch 786/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5373 - val_loss: 0.6894 - val_accuracy: 0.5118\n",
      "Epoch 787/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.5582 - val_loss: 0.6903 - val_accuracy: 0.5176\n",
      "Epoch 788/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5463 - val_loss: 0.6901 - val_accuracy: 0.5235\n",
      "Epoch 789/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5552 - val_loss: 0.6897 - val_accuracy: 0.5059\n",
      "Epoch 790/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5343 - val_loss: 0.6897 - val_accuracy: 0.5059\n",
      "Epoch 791/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5522 - val_loss: 0.6892 - val_accuracy: 0.5059\n",
      "Epoch 792/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.5224 - val_loss: 0.6888 - val_accuracy: 0.5059\n",
      "Epoch 793/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5373 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
      "Epoch 794/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5731 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 795/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5433 - val_loss: 0.6901 - val_accuracy: 0.5118\n",
      "Epoch 796/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6797 - accuracy: 0.5522 - val_loss: 0.6894 - val_accuracy: 0.5059\n",
      "Epoch 797/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6776 - accuracy: 0.5582 - val_loss: 0.6884 - val_accuracy: 0.5118\n",
      "Epoch 798/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5552 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 799/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6884 - accuracy: 0.5433 - val_loss: 0.6884 - val_accuracy: 0.5235\n",
      "Epoch 800/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5433 - val_loss: 0.6886 - val_accuracy: 0.4941\n",
      "Epoch 801/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5612 - val_loss: 0.6890 - val_accuracy: 0.5059\n",
      "Epoch 802/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5612 - val_loss: 0.6888 - val_accuracy: 0.5059\n",
      "Epoch 803/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6824 - accuracy: 0.5761 - val_loss: 0.6878 - val_accuracy: 0.5059\n",
      "Epoch 804/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5552 - val_loss: 0.6901 - val_accuracy: 0.4882\n",
      "Epoch 805/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5373 - val_loss: 0.6885 - val_accuracy: 0.5176\n",
      "Epoch 806/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5791 - val_loss: 0.6887 - val_accuracy: 0.5176\n",
      "Epoch 807/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5642 - val_loss: 0.6887 - val_accuracy: 0.5059\n",
      "Epoch 808/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5642 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 809/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5343 - val_loss: 0.6887 - val_accuracy: 0.5118\n",
      "Epoch 810/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5821 - val_loss: 0.6893 - val_accuracy: 0.4882\n",
      "Epoch 811/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5493 - val_loss: 0.6891 - val_accuracy: 0.4882\n",
      "Epoch 812/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5582 - val_loss: 0.6887 - val_accuracy: 0.5176\n",
      "Epoch 813/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5403 - val_loss: 0.6882 - val_accuracy: 0.5059\n",
      "Epoch 814/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6779 - accuracy: 0.5672 - val_loss: 0.6880 - val_accuracy: 0.5176\n",
      "Epoch 815/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5612 - val_loss: 0.6889 - val_accuracy: 0.5176\n",
      "Epoch 816/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5582 - val_loss: 0.6882 - val_accuracy: 0.5176\n",
      "Epoch 817/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5522 - val_loss: 0.6884 - val_accuracy: 0.5059\n",
      "Epoch 818/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5701 - val_loss: 0.6881 - val_accuracy: 0.5235\n",
      "Epoch 819/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5672 - val_loss: 0.6892 - val_accuracy: 0.4941\n",
      "Epoch 820/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6786 - accuracy: 0.5493 - val_loss: 0.6901 - val_accuracy: 0.4882\n",
      "Epoch 821/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5552 - val_loss: 0.6892 - val_accuracy: 0.4765\n",
      "Epoch 822/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5672 - val_loss: 0.6888 - val_accuracy: 0.4765\n",
      "Epoch 823/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5463 - val_loss: 0.6873 - val_accuracy: 0.5235\n",
      "Epoch 824/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5254 - val_loss: 0.6871 - val_accuracy: 0.5118\n",
      "Epoch 825/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5672 - val_loss: 0.6890 - val_accuracy: 0.5059\n",
      "Epoch 826/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5224 - val_loss: 0.6891 - val_accuracy: 0.4882\n",
      "Epoch 827/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5701 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 828/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.5522 - val_loss: 0.6905 - val_accuracy: 0.4824\n",
      "Epoch 829/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.5134 - val_loss: 0.6883 - val_accuracy: 0.5059\n",
      "Epoch 830/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5463 - val_loss: 0.6881 - val_accuracy: 0.5059\n",
      "Epoch 831/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5284 - val_loss: 0.6883 - val_accuracy: 0.5118\n",
      "Epoch 832/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6902 - accuracy: 0.5403 - val_loss: 0.6897 - val_accuracy: 0.4882\n",
      "Epoch 833/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6875 - accuracy: 0.5313 - val_loss: 0.6888 - val_accuracy: 0.5059\n",
      "Epoch 834/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5433 - val_loss: 0.6886 - val_accuracy: 0.5059\n",
      "Epoch 835/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5642 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
      "Epoch 836/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5642 - val_loss: 0.6903 - val_accuracy: 0.5176\n",
      "Epoch 837/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5522 - val_loss: 0.6945 - val_accuracy: 0.5176\n",
      "Epoch 838/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5672 - val_loss: 0.6921 - val_accuracy: 0.5235\n",
      "Epoch 839/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5463 - val_loss: 0.6923 - val_accuracy: 0.5059\n",
      "Epoch 840/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6868 - accuracy: 0.5701 - val_loss: 0.6916 - val_accuracy: 0.5176\n",
      "Epoch 841/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5493 - val_loss: 0.6896 - val_accuracy: 0.5059\n",
      "Epoch 842/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5582 - val_loss: 0.6886 - val_accuracy: 0.5059\n",
      "Epoch 843/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5582 - val_loss: 0.6901 - val_accuracy: 0.5118\n",
      "Epoch 844/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5463 - val_loss: 0.6902 - val_accuracy: 0.5294\n",
      "Epoch 845/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5433 - val_loss: 0.6893 - val_accuracy: 0.5176\n",
      "Epoch 846/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6736 - accuracy: 0.5612 - val_loss: 0.6897 - val_accuracy: 0.4824\n",
      "Epoch 847/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5343 - val_loss: 0.6888 - val_accuracy: 0.5059\n",
      "Epoch 848/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5493 - val_loss: 0.6896 - val_accuracy: 0.5059\n",
      "Epoch 849/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5403 - val_loss: 0.6893 - val_accuracy: 0.5176\n",
      "Epoch 850/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5731 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 851/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5582 - val_loss: 0.6885 - val_accuracy: 0.4941\n",
      "Epoch 852/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5642 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
      "Epoch 853/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5642 - val_loss: 0.6884 - val_accuracy: 0.4941\n",
      "Epoch 854/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5493 - val_loss: 0.6883 - val_accuracy: 0.5235\n",
      "Epoch 855/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5463 - val_loss: 0.6887 - val_accuracy: 0.4941\n",
      "Epoch 856/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5493 - val_loss: 0.6887 - val_accuracy: 0.5059\n",
      "Epoch 857/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5284 - val_loss: 0.6896 - val_accuracy: 0.5118\n",
      "Epoch 858/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5313 - val_loss: 0.6898 - val_accuracy: 0.5176\n",
      "Epoch 859/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.5284 - val_loss: 0.6897 - val_accuracy: 0.5118\n",
      "Epoch 860/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5493 - val_loss: 0.6892 - val_accuracy: 0.5235\n",
      "Epoch 861/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6846 - accuracy: 0.5373 - val_loss: 0.6891 - val_accuracy: 0.5118\n",
      "Epoch 862/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5522 - val_loss: 0.6911 - val_accuracy: 0.5294\n",
      "Epoch 863/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5254 - val_loss: 0.6901 - val_accuracy: 0.5294\n",
      "Epoch 864/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5612 - val_loss: 0.6917 - val_accuracy: 0.5294\n",
      "Epoch 865/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5522 - val_loss: 0.6980 - val_accuracy: 0.5118\n",
      "Epoch 866/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6877 - accuracy: 0.5284 - val_loss: 0.6954 - val_accuracy: 0.5176\n",
      "Epoch 867/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.5254 - val_loss: 0.6992 - val_accuracy: 0.5059\n",
      "Epoch 868/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5463 - val_loss: 0.6935 - val_accuracy: 0.5118\n",
      "Epoch 869/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5522 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 870/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6862 - accuracy: 0.5463 - val_loss: 0.6888 - val_accuracy: 0.5059\n",
      "Epoch 871/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5373 - val_loss: 0.6894 - val_accuracy: 0.5176\n",
      "Epoch 872/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5313 - val_loss: 0.6895 - val_accuracy: 0.5235\n",
      "Epoch 873/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6754 - accuracy: 0.5731 - val_loss: 0.6902 - val_accuracy: 0.5294\n",
      "Epoch 874/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5433 - val_loss: 0.6890 - val_accuracy: 0.5294\n",
      "Epoch 875/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5254 - val_loss: 0.6905 - val_accuracy: 0.5235\n",
      "Epoch 876/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.5701 - val_loss: 0.6916 - val_accuracy: 0.5118\n",
      "Epoch 877/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6802 - accuracy: 0.5493 - val_loss: 0.6917 - val_accuracy: 0.5118\n",
      "Epoch 878/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5552 - val_loss: 0.6917 - val_accuracy: 0.5176\n",
      "Epoch 879/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5194 - val_loss: 0.6929 - val_accuracy: 0.5235\n",
      "Epoch 880/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5612 - val_loss: 0.6905 - val_accuracy: 0.5176\n",
      "Epoch 881/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5433 - val_loss: 0.6890 - val_accuracy: 0.5059\n",
      "Epoch 882/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5313 - val_loss: 0.6892 - val_accuracy: 0.5176\n",
      "Epoch 883/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5552 - val_loss: 0.6897 - val_accuracy: 0.5353\n",
      "Epoch 884/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5493 - val_loss: 0.6903 - val_accuracy: 0.5294\n",
      "Epoch 885/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5552 - val_loss: 0.6916 - val_accuracy: 0.5176\n",
      "Epoch 886/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5433 - val_loss: 0.6947 - val_accuracy: 0.5235\n",
      "Epoch 887/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5433 - val_loss: 0.6935 - val_accuracy: 0.5294\n",
      "Epoch 888/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5552 - val_loss: 0.6919 - val_accuracy: 0.5294\n",
      "Epoch 889/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5642 - val_loss: 0.6926 - val_accuracy: 0.5118\n",
      "Epoch 890/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5612 - val_loss: 0.6919 - val_accuracy: 0.5235\n",
      "Epoch 891/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5582 - val_loss: 0.6903 - val_accuracy: 0.5235\n",
      "Epoch 892/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5522 - val_loss: 0.6902 - val_accuracy: 0.5235\n",
      "Epoch 893/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6780 - accuracy: 0.5433 - val_loss: 0.6892 - val_accuracy: 0.5118\n",
      "Epoch 894/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6780 - accuracy: 0.5552 - val_loss: 0.6901 - val_accuracy: 0.5294\n",
      "Epoch 895/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5373 - val_loss: 0.6897 - val_accuracy: 0.5118\n",
      "Epoch 896/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6812 - accuracy: 0.5373 - val_loss: 0.6905 - val_accuracy: 0.5118\n",
      "Epoch 897/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6860 - accuracy: 0.5493 - val_loss: 0.6898 - val_accuracy: 0.5059\n",
      "Epoch 898/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6779 - accuracy: 0.5642 - val_loss: 0.6902 - val_accuracy: 0.5118\n",
      "Epoch 899/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5373 - val_loss: 0.6919 - val_accuracy: 0.5353\n",
      "Epoch 900/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6754 - accuracy: 0.5851 - val_loss: 0.6929 - val_accuracy: 0.5353\n",
      "Epoch 901/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5463 - val_loss: 0.6937 - val_accuracy: 0.5176\n",
      "Epoch 902/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5224 - val_loss: 0.6936 - val_accuracy: 0.5294\n",
      "Epoch 903/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6786 - accuracy: 0.5582 - val_loss: 0.6979 - val_accuracy: 0.5176\n",
      "Epoch 904/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5672 - val_loss: 0.7011 - val_accuracy: 0.5059\n",
      "Epoch 905/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6824 - accuracy: 0.5403 - val_loss: 0.6995 - val_accuracy: 0.5176\n",
      "Epoch 906/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5612 - val_loss: 0.7086 - val_accuracy: 0.5235\n",
      "Epoch 907/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5642 - val_loss: 0.7027 - val_accuracy: 0.5118\n",
      "Epoch 908/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6816 - accuracy: 0.5791 - val_loss: 0.7023 - val_accuracy: 0.5118\n",
      "Epoch 909/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5343 - val_loss: 0.6981 - val_accuracy: 0.5235\n",
      "Epoch 910/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5552 - val_loss: 0.6978 - val_accuracy: 0.5235\n",
      "Epoch 911/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5463 - val_loss: 0.6956 - val_accuracy: 0.5235\n",
      "Epoch 912/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6811 - accuracy: 0.5403 - val_loss: 0.6990 - val_accuracy: 0.5294\n",
      "Epoch 913/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5343 - val_loss: 0.6915 - val_accuracy: 0.5118\n",
      "Epoch 914/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5493 - val_loss: 0.6913 - val_accuracy: 0.5059\n",
      "Epoch 915/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5672 - val_loss: 0.6893 - val_accuracy: 0.5059\n",
      "Epoch 916/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6840 - accuracy: 0.5463 - val_loss: 0.6909 - val_accuracy: 0.5294\n",
      "Epoch 917/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5403 - val_loss: 0.6918 - val_accuracy: 0.5235\n",
      "Epoch 918/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6833 - accuracy: 0.5343 - val_loss: 0.6949 - val_accuracy: 0.5176\n",
      "Epoch 919/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6848 - accuracy: 0.5403 - val_loss: 0.7078 - val_accuracy: 0.5059\n",
      "Epoch 920/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6837 - accuracy: 0.5701 - val_loss: 0.6953 - val_accuracy: 0.5294\n",
      "Epoch 921/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5433 - val_loss: 0.6949 - val_accuracy: 0.5176\n",
      "Epoch 922/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6825 - accuracy: 0.5672 - val_loss: 0.6944 - val_accuracy: 0.5294\n",
      "Epoch 923/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5284 - val_loss: 0.6948 - val_accuracy: 0.5294\n",
      "Epoch 924/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6794 - accuracy: 0.5612 - val_loss: 0.6943 - val_accuracy: 0.5176\n",
      "Epoch 925/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6797 - accuracy: 0.5582 - val_loss: 0.6948 - val_accuracy: 0.5294\n",
      "Epoch 926/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6844 - accuracy: 0.5284 - val_loss: 0.6923 - val_accuracy: 0.5059\n",
      "Epoch 927/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.5433 - val_loss: 0.6961 - val_accuracy: 0.5353\n",
      "Epoch 928/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6833 - accuracy: 0.5493 - val_loss: 0.7020 - val_accuracy: 0.5235\n",
      "Epoch 929/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6784 - accuracy: 0.5701 - val_loss: 0.7014 - val_accuracy: 0.5118\n",
      "Epoch 930/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5612 - val_loss: 0.7040 - val_accuracy: 0.5176\n",
      "Epoch 931/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5313 - val_loss: 0.7095 - val_accuracy: 0.5294\n",
      "Epoch 932/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5403 - val_loss: 0.7141 - val_accuracy: 0.5294\n",
      "Epoch 933/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5045 - val_loss: 0.7144 - val_accuracy: 0.5176\n",
      "Epoch 934/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5433 - val_loss: 0.6977 - val_accuracy: 0.5294\n",
      "Epoch 935/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5552 - val_loss: 0.6971 - val_accuracy: 0.5294\n",
      "Epoch 936/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5612 - val_loss: 0.6963 - val_accuracy: 0.5118\n",
      "Epoch 937/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5224 - val_loss: 0.6973 - val_accuracy: 0.5235\n",
      "Epoch 938/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6777 - accuracy: 0.5642 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 939/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5433 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 940/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5493 - val_loss: 0.6920 - val_accuracy: 0.5118\n",
      "Epoch 941/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5791 - val_loss: 0.6925 - val_accuracy: 0.5176\n",
      "Epoch 942/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5373 - val_loss: 0.6914 - val_accuracy: 0.4941\n",
      "Epoch 943/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6823 - accuracy: 0.5552 - val_loss: 0.6920 - val_accuracy: 0.4824\n",
      "Epoch 944/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6827 - accuracy: 0.5313 - val_loss: 0.6913 - val_accuracy: 0.5176\n",
      "Epoch 945/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5582 - val_loss: 0.6924 - val_accuracy: 0.5059\n",
      "Epoch 946/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6785 - accuracy: 0.5493 - val_loss: 0.6935 - val_accuracy: 0.5118\n",
      "Epoch 947/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6803 - accuracy: 0.5522 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 948/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6767 - accuracy: 0.5672 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 949/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6774 - accuracy: 0.5522 - val_loss: 0.6946 - val_accuracy: 0.5176\n",
      "Epoch 950/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6764 - accuracy: 0.5582 - val_loss: 0.6931 - val_accuracy: 0.5059\n",
      "Epoch 951/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6805 - accuracy: 0.5552 - val_loss: 0.6937 - val_accuracy: 0.5176\n",
      "Epoch 952/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.5522 - val_loss: 0.6971 - val_accuracy: 0.5118\n",
      "Epoch 953/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5552 - val_loss: 0.6985 - val_accuracy: 0.5235\n",
      "Epoch 954/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5493 - val_loss: 0.6942 - val_accuracy: 0.5294\n",
      "Epoch 955/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5731 - val_loss: 0.6904 - val_accuracy: 0.5059\n",
      "Epoch 956/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5582 - val_loss: 0.6913 - val_accuracy: 0.5294\n",
      "Epoch 957/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5612 - val_loss: 0.6917 - val_accuracy: 0.5235\n",
      "Epoch 958/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5642 - val_loss: 0.6915 - val_accuracy: 0.5235\n",
      "Epoch 959/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6870 - accuracy: 0.5284 - val_loss: 0.6988 - val_accuracy: 0.4647\n",
      "Epoch 960/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5522 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 961/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.5463 - val_loss: 0.6904 - val_accuracy: 0.5059\n",
      "Epoch 962/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6791 - accuracy: 0.5672 - val_loss: 0.6910 - val_accuracy: 0.5059\n",
      "Epoch 963/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6829 - accuracy: 0.5373 - val_loss: 0.6913 - val_accuracy: 0.5059\n",
      "Epoch 964/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6826 - accuracy: 0.5403 - val_loss: 0.6915 - val_accuracy: 0.4824\n",
      "Epoch 965/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6795 - accuracy: 0.5701 - val_loss: 0.6915 - val_accuracy: 0.4941\n",
      "Epoch 966/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6763 - accuracy: 0.5582 - val_loss: 0.6978 - val_accuracy: 0.4647\n",
      "Epoch 967/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6796 - accuracy: 0.5672 - val_loss: 0.6979 - val_accuracy: 0.4765\n",
      "Epoch 968/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6776 - accuracy: 0.5642 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 969/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5761 - val_loss: 0.6898 - val_accuracy: 0.5235\n",
      "Epoch 970/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6772 - accuracy: 0.5612 - val_loss: 0.6894 - val_accuracy: 0.5118\n",
      "Epoch 971/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5463 - val_loss: 0.6892 - val_accuracy: 0.5176\n",
      "Epoch 972/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6806 - accuracy: 0.5433 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 973/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.5493 - val_loss: 0.6893 - val_accuracy: 0.5176\n",
      "Epoch 974/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6764 - accuracy: 0.5701 - val_loss: 0.6891 - val_accuracy: 0.5353\n",
      "Epoch 975/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5313 - val_loss: 0.6886 - val_accuracy: 0.5176\n",
      "Epoch 976/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6761 - accuracy: 0.5582 - val_loss: 0.6881 - val_accuracy: 0.5059\n",
      "Epoch 977/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6816 - accuracy: 0.5254 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 978/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6811 - accuracy: 0.5761 - val_loss: 0.6879 - val_accuracy: 0.5176\n",
      "Epoch 979/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5493 - val_loss: 0.6879 - val_accuracy: 0.5353\n",
      "Epoch 980/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5612 - val_loss: 0.6893 - val_accuracy: 0.5118\n",
      "Epoch 981/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6770 - accuracy: 0.5493 - val_loss: 0.6901 - val_accuracy: 0.5059\n",
      "Epoch 982/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6741 - accuracy: 0.5582 - val_loss: 0.6892 - val_accuracy: 0.4882\n",
      "Epoch 983/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5343 - val_loss: 0.6893 - val_accuracy: 0.4941\n",
      "Epoch 984/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6780 - accuracy: 0.5373 - val_loss: 0.6893 - val_accuracy: 0.4941\n",
      "Epoch 985/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5224 - val_loss: 0.6887 - val_accuracy: 0.5118\n",
      "Epoch 986/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6797 - accuracy: 0.5373 - val_loss: 0.6898 - val_accuracy: 0.5176\n",
      "Epoch 987/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5552 - val_loss: 0.6893 - val_accuracy: 0.5059\n",
      "Epoch 988/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5463 - val_loss: 0.6941 - val_accuracy: 0.5176\n",
      "Epoch 989/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6860 - accuracy: 0.5343 - val_loss: 0.6948 - val_accuracy: 0.5176\n",
      "Epoch 990/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6814 - accuracy: 0.5254 - val_loss: 0.6903 - val_accuracy: 0.5176\n",
      "Epoch 991/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5582 - val_loss: 0.6920 - val_accuracy: 0.5353\n",
      "Epoch 992/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5642 - val_loss: 0.6931 - val_accuracy: 0.4882\n",
      "Epoch 993/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6822 - accuracy: 0.5642 - val_loss: 0.6911 - val_accuracy: 0.5176\n",
      "Epoch 994/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6781 - accuracy: 0.5642 - val_loss: 0.6915 - val_accuracy: 0.5118\n",
      "Epoch 995/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6779 - accuracy: 0.5493 - val_loss: 0.6921 - val_accuracy: 0.5118\n",
      "Epoch 996/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5493 - val_loss: 0.6923 - val_accuracy: 0.4941\n",
      "Epoch 997/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5522 - val_loss: 0.6901 - val_accuracy: 0.4882\n",
      "Epoch 998/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5612 - val_loss: 0.6899 - val_accuracy: 0.4941\n",
      "Epoch 999/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6777 - accuracy: 0.5761 - val_loss: 0.6895 - val_accuracy: 0.4824\n",
      "Epoch 1000/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5373 - val_loss: 0.6903 - val_accuracy: 0.4941\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.4941\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11/11 [==============================] - 1s 24ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 28/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 29/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 30/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 31/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 32/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 34/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 35/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 36/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 37/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 38/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 39/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 40/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 41/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 42/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 43/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 44/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 45/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 46/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 47/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 48/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 49/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 50/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 51/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 52/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 53/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 54/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 55/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 56/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 57/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 58/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 59/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 60/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 61/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 62/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 63/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 64/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 65/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 66/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 67/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 68/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 69/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 70/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 71/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 72/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 73/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 74/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 75/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 76/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 77/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 78/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 79/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 80/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 81/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 82/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 83/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 84/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 85/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 86/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 87/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 88/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 89/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 90/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 91/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 92/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 93/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 94/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 95/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 96/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 97/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 98/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 99/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 100/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 101/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 102/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 103/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 104/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 105/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 106/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 107/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 108/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 109/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 110/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 111/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 112/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 113/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 114/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 115/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 116/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 117/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 118/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 119/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 120/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 121/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 122/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 123/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 124/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 125/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 126/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 127/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 128/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 129/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 130/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 131/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 132/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 133/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 134/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 135/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 136/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 137/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 138/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 139/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 140/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 141/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 142/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 143/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 144/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 145/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 146/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 147/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 148/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 149/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 150/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 151/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 152/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 153/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 154/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 155/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 156/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 157/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 158/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 159/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 160/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 162/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 163/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 164/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 165/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 166/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 167/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 168/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 169/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 170/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 171/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 172/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 173/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 174/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 175/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 176/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 177/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 178/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 179/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 180/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 181/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 182/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 183/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 184/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 185/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 186/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 187/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 188/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 189/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 190/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 191/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 192/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 193/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 194/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 195/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 196/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 197/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 198/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 199/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 200/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 201/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 202/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 203/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 204/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 205/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 206/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 207/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 208/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 209/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 210/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 211/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 212/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 213/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 214/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 215/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 216/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 217/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 218/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 219/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 220/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 221/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 222/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 223/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 224/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 225/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 226/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 227/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 228/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 229/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 230/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 231/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 232/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 233/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 234/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 235/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 236/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 237/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 238/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 239/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 240/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 241/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 242/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 243/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 244/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 245/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 246/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 247/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 248/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 249/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 250/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 251/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 252/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 253/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 254/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 255/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 256/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 257/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 258/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 259/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 260/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 261/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 262/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 263/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 264/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 265/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 266/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 267/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 268/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 269/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 270/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 271/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 272/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 273/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 274/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 275/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 276/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 277/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 278/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 279/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 280/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 281/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 282/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 283/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 284/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 285/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 286/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 287/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 288/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 289/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 290/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 291/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 292/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 293/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 294/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 295/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 296/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 297/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 298/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 299/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 300/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 301/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 302/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 303/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 304/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 305/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 306/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 307/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 308/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 309/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 310/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 311/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 312/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 313/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 314/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 315/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 316/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 317/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 318/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 319/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 320/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 321/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 322/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 323/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 324/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 325/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 326/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 327/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 328/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 329/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 330/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 331/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 332/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 333/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 334/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 335/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 336/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 337/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 338/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 339/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 340/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 341/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 342/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 343/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 344/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 345/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 346/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 347/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 348/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 349/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 350/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 351/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 352/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 353/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 354/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 355/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 356/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 357/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 358/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 359/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 360/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 361/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 362/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 363/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 364/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 365/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 366/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 367/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 368/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 369/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 370/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 371/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 372/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 373/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 374/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 375/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 376/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 377/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 378/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 379/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 380/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 381/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 382/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 383/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 384/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 385/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 386/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 387/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 388/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 389/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 390/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 391/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 392/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 393/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 394/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 395/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 396/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 397/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 398/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 399/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 400/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 401/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 402/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 403/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 404/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 405/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 406/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 407/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 408/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 409/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 410/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 411/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 412/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 413/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 414/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 415/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 416/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 417/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 418/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 419/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 420/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 421/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 422/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 423/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 424/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 425/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 426/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 427/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 428/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 429/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 430/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 431/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 432/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 433/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 434/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 435/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 436/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 437/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 438/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 439/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 440/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 441/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 442/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 443/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 444/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 445/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 446/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 447/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 448/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 449/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 450/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 451/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 452/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 453/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 454/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 455/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 456/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 457/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 458/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 459/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 460/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 461/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 462/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 463/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 464/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 465/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 466/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 467/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 468/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 469/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 470/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 471/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 472/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 473/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 474/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 475/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 476/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 477/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 478/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 479/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 480/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 481/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 482/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 483/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 484/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 485/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 486/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 487/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 488/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 489/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 490/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 491/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 492/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 493/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 494/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 495/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 496/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 497/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 498/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 499/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 500/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 501/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 502/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 503/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 504/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 505/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 506/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 507/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 508/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 509/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 510/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 511/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 512/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 513/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 514/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 515/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 516/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 517/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 518/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 519/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 520/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 521/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 522/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 523/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 524/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 525/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 526/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 527/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 528/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 529/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 530/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 531/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 532/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 533/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 534/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 535/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 536/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 537/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 538/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 539/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 540/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 541/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 542/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 543/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 544/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 545/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 546/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 547/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 548/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 549/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 550/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 551/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 552/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 553/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 554/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 555/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 556/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 557/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 558/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 559/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 560/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 561/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 562/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 563/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 564/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 565/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 566/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 567/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 568/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 569/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 570/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 571/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 572/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 573/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 574/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 575/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 576/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 577/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 578/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 579/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 580/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 581/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 582/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 583/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 584/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 585/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 586/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 587/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 588/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 589/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 590/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 591/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 592/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 593/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 594/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 595/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 596/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 597/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 598/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 599/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 600/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 601/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 602/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 603/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 604/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 605/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 606/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 607/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 608/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 609/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 610/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 611/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 612/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 613/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 614/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 615/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 616/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 617/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 618/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 619/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 620/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 621/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 622/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 623/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 624/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 625/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 626/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 627/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 628/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 629/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 630/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 631/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 632/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 633/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 634/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 635/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 636/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 637/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 638/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 639/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 640/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 641/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 642/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 643/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 644/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 645/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 646/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 647/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 648/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 649/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 650/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 651/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 652/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 653/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 654/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 655/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 656/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 657/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 658/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 659/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 660/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 661/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 662/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 663/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 664/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 665/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 666/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 667/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 668/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 669/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 670/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 671/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 672/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 673/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 674/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 675/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 676/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 677/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 678/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 679/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 680/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 681/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 682/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 683/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 684/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 685/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 686/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 687/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 688/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 689/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 690/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 691/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 692/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 693/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 694/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 695/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 696/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 697/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 698/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 699/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 700/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 701/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 702/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 703/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 704/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 705/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 706/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 707/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 708/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 709/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 710/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 711/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 712/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 713/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 714/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 715/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 716/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 717/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 718/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 719/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 720/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 721/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 722/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 723/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 724/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 725/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 726/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 727/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 728/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 729/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 730/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 731/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 732/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 733/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 734/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 735/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 736/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 737/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 738/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 739/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 740/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 741/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 742/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 743/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 744/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 745/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 746/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 747/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 748/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 749/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 750/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 751/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 752/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 753/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 754/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 755/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 756/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 757/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 758/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 759/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 760/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 761/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 762/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 763/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 764/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 765/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 766/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 767/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 768/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 769/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 770/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 771/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 772/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 773/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 774/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 775/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 776/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 777/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 778/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 779/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 780/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 781/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 782/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 783/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 784/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 785/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 786/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 787/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 788/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 789/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 790/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 791/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 792/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 793/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 794/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 795/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 796/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 797/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 798/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 799/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 800/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 801/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 802/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 803/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 804/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 805/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 806/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 807/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 808/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 809/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 810/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 811/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 812/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 813/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 814/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 815/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 816/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 817/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 818/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 819/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 820/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 821/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 822/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 823/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 824/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 825/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 826/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 827/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 828/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 829/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 830/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 831/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 832/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 833/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 834/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 835/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 836/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 837/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 838/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 839/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 840/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 841/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 842/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 843/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 844/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 845/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 846/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 847/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 848/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 849/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 850/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 851/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 852/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 853/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 854/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 855/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 856/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 857/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 858/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 859/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 860/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 861/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 862/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 863/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 864/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 865/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 866/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 867/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 868/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 869/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 870/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 871/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 872/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 873/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 874/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 875/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 876/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 877/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 878/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 879/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 880/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 881/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 882/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 883/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 884/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 885/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 886/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 887/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 888/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 889/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 890/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 891/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 892/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 893/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 894/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 895/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 896/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 897/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 898/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 899/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 900/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 901/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 902/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 903/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 904/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 905/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 906/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 907/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 908/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 909/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 910/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 911/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 912/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 913/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 914/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 915/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 916/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 917/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 918/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 919/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 920/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 921/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 922/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 923/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 924/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 925/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 926/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 927/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 928/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 929/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 930/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 931/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 932/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 933/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 934/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 935/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 936/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 937/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 938/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 939/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 940/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 941/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 942/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 943/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 944/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 945/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 946/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 947/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 948/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 949/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 950/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 951/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 952/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 953/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 954/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 955/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 956/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 957/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 958/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 959/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 960/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 961/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 962/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 963/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 964/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 965/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 966/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 967/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 968/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 969/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 970/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 971/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 972/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 973/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 974/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 975/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 976/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 977/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 978/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 979/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 980/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 981/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 982/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 983/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 984/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 985/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 986/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 987/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 988/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 989/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 990/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 991/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 992/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 993/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 994/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 995/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 996/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 997/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 998/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 999/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "Epoch 1000/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0578 - accuracy: 0.4776 - val_loss: 7.7125 - val_accuracy: 0.5000\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7.7125 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfHUlEQVR4nO3de5xVdb3/8dfb4aaAIhdLQRssUFHCgRE1tSC14xXylmIpREfTbupD84gnw/R0fsdHZGbHPJqJ5jHQSAmvJCSlkcqgeOGW6MEYvCHKJRW5+Pn9sb6Dm3GAvWA2e5h5Px+P/WCv77rsz3evYd6zvmvvtRQRmJmZFWuHchdgZmbbFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODrNNkHSbpP8octmFko4qdU1m5ebgMDOzXBwcZi2ApFblrsGaDweHbffSENH3JT0n6V1Jv5b0CUkPSVopaYqkXQuWHyJptqRlkqZJ2q9gXpWkp9N6dwHt6r3WCZJmpXWnS/pskTUeL+kZSSskLZJ0Zb35h6ftLUvzR6T2HSX9VNIrkpZLejy1DZJU28D7cFR6fqWkCZL+V9IKYISkgZL+ll7jNUn/LalNwfr7S3pE0tuS3pB0uaRPSnpPUpeC5fpLWiKpdTF9t+bHwWHNxSnA0UBv4ETgIeByoBvZz/n3ACT1BsYBF6Z5DwL3SWqTfolOBO4AOgO/S9slrVsF3Ap8E+gC3ARMktS2iPreBc4GOgHHA+dL+nLa7qdSvb9INR0IzErrjQEGAJ9LNV0KfFjkezIUmJBe805gHXAR0BU4FDgS+FaqoSMwBXgY2AP4DDA1Il4HpgFfKdjuWcD4iFhTZB3WzDg4rLn4RUS8ERGLgceAJyPimYhYBdwLVKXlTgceiIhH0i++McCOZL+YDwFaA9dFxJqImADMKHiNc4GbIuLJiFgXEbcDH6T1NikipkXE8xHxYUQ8RxZeX0izzwSmRMS49LpLI2KWpB2AkcAFEbE4veb0iPigyPfkbxExMb3m+xExMyKeiIi1EbGQLPjqajgBeD0ifhoRqyJiZUQ8mebdDnwNQFIFMIwsXK2FcnBYc/FGwfP3G5jukJ7vAbxSNyMiPgQWAd3TvMWx4ZU/Xyl4/ing4jTUs0zSMmDPtN4mSTpY0qNpiGc5cB7ZX/6kbbzUwGpdyYbKGppXjEX1augt6X5Jr6fhq/8sogaAPwB9JPUkO6pbHhFPbWFN1gw4OKyleZUsAACQJLJfmouB14Duqa3OXgXPFwE/johOBY+dImJcEa/7W2ASsGdE7AL8D1D3OouATzewzlvAqo3MexfYqaAfFWTDXIXqX/r6RmAe0CsidiYbyiusYe+GCk9HbXeTHXWchY82WjwHh7U0dwPHSzoyndy9mGy4aTrwN2At8D1JrSWdDAwsWPdXwHnp6EGS2qeT3h2LeN2OwNsRsUrSQLLhqTp3AkdJ+oqkVpK6SDowHQ3dClwraQ9JFZIOTedU/g60S6/fGvgBsLlzLR2BFcA/Je0LnF8w735gd0kXSmorqaOkgwvm/wYYAQzBwdHiOTisRYmI+WR/Of+C7C/6E4ETI2J1RKwGTib7Bfk22fmQewrWrQHOAf4beAdYkJYtxreAqyStBH5IFmB12/0HcBxZiL1NdmK8X5p9CfA82bmWt4FrgB0iYnna5i1kR0vvAht8yqoBl5AF1kqyELyroIaVZMNQJwKvAy8Cgwvm/5XspPzTEVE4fGctkHwjJzMrhqQ/Ab+NiFvKXYuVl4PDzDZL0kHAI2TnaFaWux4rLw9VmdkmSbqd7DseFzo0DHzEYWZmOfmIw8zMcmkRFz7r2rVrVFZWlrsMM7PtysyZM9+KiPrfD2oZwVFZWUlNTU25yzAz265IavCj1x6qMjOzXBwcZmaWi4PDzMxyaRHnOBqyZs0aamtrWbVqVblLaRbatWtHjx49aN3a9/Yxa+5abHDU1tbSsWNHKisr2fBiqJZXRLB06VJqa2vp2bNnucsxsxIr6VCVpGMkzZe0QNJlDcwfke5PMCs9/rVg3nBJL6bH8IL2AZKeT9u8Xlv4W3/VqlV06dLFodEIJNGlSxcfvZm1ECULjnR/gBuAY4E+wDBJfRpY9K6IODA9bknrdgZGAweTXdZ6tD66Z/SNZFco7ZUex2xFjVu6qtXj99Ks5SjlUNVAYEFEvAwgaTzZPZDnFLHuvwCPRMTbad1HgGMkTQN2jognUvtvgC+T3a+58S2vhTXvl2TTzdI/34Sxl5S7CjOr88m+cOx/NfpmSxkc3dnw1pW1ZEcQ9Z0i6fNkN6a5KCIWbWTd7ulR20D7x0g6l+we0ey1114NLVJWS99+hyNPzkbgXn/zLSoqdqBbl84APPXHCbRp02aj69bMep7f3DWR6//fFdukVjOzQuU+OX4fMC4iPpD0TeB24IuNseGIuBm4GaC6unrLruS4S4/GKKVBXbrCrBfmAnDllVfSoUMHLrnko7/W165dS6tWDe+e6qN6UX3UySWrbYstWQtff6DcVZhZiZXy5Phisns51+mR2taLiKUR8UGavAUYsJl1F6fnG93m9mzEiBGcd955HHzwwVx66aU89dRTHHrooVRVVfG5z32O+fPnAzBt2jROOOEEIAudkSNHMmjQIPbee2+uv/76cnbBzFqAUh5xzAB6SepJ9sv9DDa8zzKSdo+I19LkEGBuej4Z+M+CE+JfAkZFxNuSVkg6BHgSOJvsFqBb5Uf3zWbOqyu2djMb6LPHzow+cf/c69XW1jJ9+nQqKipYsWIFjz32GK1atWLKlClcfvnl/P73v//YOvPmzePRRx9l5cqV7LPPPpx//vn+PoWZlUzJgiMi1kr6DlkIVAC3RsRsSVcBNRExCfiepCHAWrL7KY9I674t6Wqy8AG4qu5EOdl9lm8DdiQ7KV6aE+Nlctppp1FRUQHA8uXLGT58OC+++CKSWLNmTYPrHH/88bRt25a2bduy22678cYbb9CjR+mG2cysZSvpOY6IeBB4sF7bDwuejwJGbWTdW4FbG2ivAQ5ozDq35MigVNq3b7/++RVXXMHgwYO59957WbhwIYMGDWpwnbZt265/XlFRwdq1a0tdppm1YL5WVRO2fPlyunfPPjR22223lbcYM7PEwdGEXXrppYwaNYqqqiofRZhZk9Ei7jleXV0d9W/kNHfuXPbbb78yVdQ8+T01a14kzYyI6vrtPuIwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4ymTw4MFMnjx5g7brrruO888/v8HlBw0aRN1Hio877jiWLVv2sWWuvPJKxowZs8nXnThxInPmfHRLlB/+8IdMmTIlZ/Vm1pI5OMpk2LBhjB8/foO28ePHM2zYsM2u++CDD9KpU6ctet36wXHVVVdx1FFHbdG2zKxlcnCUyamnnsoDDzzA6tWrAVi4cCGvvvoq48aNo7q6mv3335/Ro0c3uG5lZSVvvfUWAD/+8Y/p3bs3hx9++PrLrgP86le/4qCDDqJfv36ccsopvPfee0yfPp1Jkybx/e9/nwMPPJCXXnqJESNGMGHCBACmTp1KVVUVffv2ZeTIkXzwwQfrX2/06NH079+fvn37Mm/evFK+NWbWxJX7Rk5Nw0OXwevPN+42N3PLxs6dOzNw4EAeeughhg4dyvjx4/nKV77C5ZdfTufOnVm3bh1HHnkkzz33HJ/97Gcb3MbMmTMZP348s2bNYu3atfTv358BA7Jbmpx88smcc845APzgBz/g17/+Nd/97ncZMmQIJ5xwAqeeeuoG21q1ahUjRoxg6tSp9O7dm7PPPpsbb7yRCy+8EICuXbvy9NNP88tf/pIxY8Zwyy23NMKbZGbbIx9xlFHhcFXdMNXdd99N//79qaqqYvbs2RsMK9X32GOPcdJJJ7HTTjux8847M2TIkPXzXnjhBY444gj69u3LnXfeyezZszdZy/z58+nZsye9e/cGYPjw4fzlL39ZP//kk7M7Dg4YMICFCxduaZfNrBnwEQeU5GbuxRg6dCgXXXQRTz/9NO+99x6dO3dmzJgxzJgxg1133ZURI0awatWqLdr2iBEjmDhxIv369eO2225j2rRpW1Vr3aXbfdl2M/MRRxl16NCBwYMHM3LkSIYNG8aKFSto3749u+yyC2+88QYPPbTpe1R9/vOfZ+LEibz//vusXLmS++67b/28lStXsvvuu7NmzRruvPPO9e0dO3Zk5cqVH9vWPvvsw8KFC1mwYAEAd9xxB1/4whcaqadm1pw4OMps2LBhPPvsswwbNox+/fpRVVXFvvvuy5lnnslhhx22yXX79+/P6aefTr9+/Tj22GM56KCD1s+7+uqrOfjggznssMPYd99917efccYZ/OQnP6GqqoqXXnppfXu7du0YO3Ysp512Gn379mWHHXbgvPPOa/wOm9l2z5dVt0bj99SsefFl1c3MrFE4OMzMLJcWHRwtYZhuW/F7adZytNjgaNeuHUuXLvUvvEYQESxdupR27dqVuxQz2wZa7Pc4evToQW1tLUuWLCl3Kc1Cu3bt6NGjR7nLMLNtoMUGR+vWrenZs2e5yzAz2+602KEqMzPbMg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5lDQ4JB0jab6kBZIu28Ryp0gKSdVpuo2ksZKel/SspEEFy05L25yVHruVsg9mZrahkl3kUFIFcANwNFALzJA0KSLm1FuuI3AB8GRB8zkAEdE3BcNDkg6KiA/T/K9GxIb3gjUzs22ilEccA4EFEfFyRKwGxgNDG1juauAaYFVBWx/gTwAR8SawDPjYfW/NzGzbK2VwdAcWFUzXprb1JPUH9oyIB+qt+ywwRFIrST2BAcCeBfPHpmGqKySpoReXdK6kGkk1vueGmVnjKdvJcUk7ANcCFzcw+1ayoKkBrgOmA+vSvK9GRF/giPQ4q6HtR8TNEVEdEdXdunVr5OrNzFquUgbHYjY8SuiR2up0BA4ApklaCBwCTJJUHRFrI+KiiDgwIoYCnYC/A0TE4vTvSuC3ZENiZma2jZQyOGYAvST1lNQGOAOYVDczIpZHRNeIqIyISuAJYEhE1EjaSVJ7AElHA2sjYk4auuqa2lsDJwAvlLAPZmZWT8k+VRURayV9B5gMVAC3RsRsSVcBNRExaROr7wZMlvQh2VFK3XBU29TeOm1zCvCrUvXBzMw+ThFR7hpKrrq6Ompq/OldM7M8JM2MiI99otXfHDczs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OMzPLpajgkHSPpOMlOWjMzFq4YoPgl8CZwIuS/kvSPiWsyczMmrCigiMipkTEV4H+wEJgiqTpkr4uqXUpCzQzs6al6KEnSV2AEcC/As8APycLkkdKUpmZmTVJrYpZSNK9wD7AHcCJEfFamnWXpJpSFWdmZk1PUcEBXB8RjzY0IyKqG7EeMzNr4oodquojqVPdhKRdJX1rcytJOkbSfEkLJF22ieVOkRSSqtN0G0ljJT0v6VlJgwqWHZDaF0i6XpKK7IOZmTWCYoPjnIhYVjcREe8A52xqBUkVwA3AsUAfYJikPg0s1xG4AHiy8PXS6/QFjgZ+WvBR4BvT/F7pcUyRfTAzs0ZQbHBUFP5ln0KhzWbWGQgsiIiXI2I1MB4Y2sByVwPXAKsK2voAfwKIiDeBZUC1pN2BnSPiiYgI4DfAl4vsg5mZNYJig+NhshPhR0o6EhiX2jalO7CoYLo2ta0nqT+wZ0Q8UG/dZ4EhklpJ6gkMAPZM69duaptmZlZaxZ4c/zfgm8D5afoR4JateeE09HQt2Ud867sV2A+oAV4BpgPrcm7/XOBcgL322mtrSjUzswJFBUdEfEh2buHGHNteTHaUUKdHaqvTETgAmJZGwT4JTJI0JCJqgIvqFpQ0Hfg78E7azsa2WVjzzcDNANXV1ZGjbjMz24Rir1XVS9IESXMkvVz32MxqM4BeknpKagOcAUyqmxkRyyOia0RURkQl8AQwJCJqJO0kqX167aOBtRExJ31/ZIWkQ9I5l7OBP+TutZmZbbFih6rGAqOBnwGDga+zmdCJiLWSvgNMBiqAWyNitqSrgJqImLSJ1XcDJkv6kOyI4qyCed8CbgN2BB5KDzMz20aUfThpMwtJMyNigKTn00dk17eVvMJGUF1dHTU1/oK7mVke6ff8x77kXewRxwfpZPaL6ShiMdChMQs0M7PtQ7Efx70A2An4HtlHY78GDC9VUWZm1nRt9ogjfdnv9Ii4BPgn2fkNMzNroTZ7xBER64DDt0EtZma2HSj2HMczkiYBvwPerWuMiHtKUpWZmTVZxQZHO2Ap8MWCtgAcHGZmLUyx3xz3eQ0zMwOKvwPgWLIjjA1ExMhGr8jMzJq0Yoeq7i943g44CXi18csxM7Omrtihqt8XTksaBzxekorMzKxJK/YLgPX1IruelJmZtTDFnuNYyYbnOF4nu0eHmZm1MMUOVXUsdSFmZrZ9KPZ+HCdJ2qVgupOkL5esKjMza7KKPccxOiKW101ExDKy+3OYmVkLU2xwNLRcsR/lNTOzZqTY4KiRdK2kT6fHtcDMUhZmZmZNU7HB8V1gNXAXMB5YBXy7VEWZmVnTVeynqt4FLitxLWZmth0o9lNVj0jqVDC9q6TJJavKzMyarGKHqrqmT1IBEBHv4G+Om5m1SMUGx4eS9qqbkFRJA1fLNTOz5q/Yj9T+O/C4pD8DAo4Azi1ZVWZm1mQVe3L8YUnVZGHxDDAReL+EdZmZWRNV7EUO/xW4AOgBzAIOAf7GhreSNTOzFqDYcxwXAAcBr0TEYKAKWFaqoszMrOkqNjhWRcQqAEltI2IesE/pyjIzs6aq2JPjtel7HBOBRyS9A7xSqqLMzKzpKvbk+Enp6ZWSHgV2AR4uWVVmZtZk5b7CbUT8uRSFmJnZ9mFL7zluZmYtlIPDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLJeSBoekYyTNl7RA0kbvICjpFEmRLqSIpNaSbpf0vKS5kkYVLLswtc+SVFPK+s3M7ONyf4+jWJIqgBuAo4FaYIakSRExp95yHcmuhfVkQfNpQNuI6CtpJ2COpHERsTDNHxwRb5WqdjMz27hSHnEMBBZExMsRsRoYDwxtYLmrgWuAVQVtAbSX1ArYEVgNrChhrWZmVqRSBkd3YFHBdG1qW09Sf2DPiHig3roTgHeB14B/AGMi4u00L4A/SpopaaM3k5J0rqQaSTVLlizZyq6YmVmdsp0cl7QDcC1wcQOzBwLrgD2AnsDFkvZO8w6PiP7AscC3JX2+oe1HxM0RUR0R1d26dWv8DpiZtVClDI7FwJ4F0z1SW52OwAHANEkLyW4ONSmdID8TeDgi1kTEm8BfgWqAiFic/n0TuJcsZMzMbBspZXDMAHpJ6impDXAGMKluZkQsj4iuEVEZEZXAE8CQiKghG576IoCk9mShMk9S+3Qyva79S8ALJeyDmZnVU7LgiIi1wHeAycBc4O6ImC3pKklDNrP6DUAHSbPJAmhsRDwHfAJ4XNKzwFPAAxHhy7ubmW1Diohy11By1dXVUVPjr3yYmeUhaWZEVNdv9zfHzcwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnl4uAwM7NcShocko6RNF/SAkmXbWK5UySFpOo03VrS7ZKelzRX0qi82zQzs9IoWXBIqgBuAI4F+gDDJPVpYLmOwAXAkwXNpwFtI6IvMAD4pqTKYrdpZmalU8ojjoHAgoh4OSJWA+OBoQ0sdzVwDbCqoC2A9pJaATsCq4EVObZpZmYlUsrg6A4sKpiuTW3rSeoP7BkRD9RbdwLwLvAa8A9gTES8Xcw2C7Z9rqQaSTVLlizZqo6YmdlHynZyXNIOwLXAxQ3MHgisA/YAegIXS9o7z/Yj4uaIqI6I6m7dum11vWZmlmlVwm0vBvYsmO6R2up0BA4ApkkC+CQwSdIQ4Ezg4YhYA7wp6a9ANdnRxqa2aWZmJVbKI44ZQC9JPSW1Ac4AJtXNjIjlEdE1IiojohJ4AhgSETVkw1NfBJDUHjgEmLe5bZqZWemVLDgiYi3wHWAyMBe4OyJmS7oqHVVsyg1AB0mzycJibEQ8t7FtlqoPZmb2cYqIctdQctXV1VFTU1PuMszMtiuSZkZEdf12f3PczMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5eLgMDOzXBwcZmaWi4PDzMxycXCYmVkuDg4zM8vFwWFmZrk4OMzMLBcHh5mZ5VLKOwBu935032zmvLqi3GWYmW2RPnvszOgT92/07fqIw8zMcvERxyaUIqnNzLZ3PuIwM7NcHBxmZpaLg8PMzHJxcJiZWS4ODjMzy8XBYWZmuTg4zMwsFweHmZnloogodw0lJ2kJ8MoWrt4VeKsRy9keuM8tg/vcMmxNnz8VEd3qN7aI4NgakmoiorrcdWxL7nPL4D63DKXos4eqzMwsFweHmZnl4uDYvJvLXUAZuM8tg/vcMjR6n32Ow8zMcvERh5mZ5eLgMDOzXBwcGyHpGEnzJS2QdFm562kskvaU9KikOZJmS7ogtXeW9IikF9O/u6Z2Sbo+vQ/PSepf3h5sOUkVkp6RdH+a7inpydS3uyS1Se1t0/SCNL+yrIVvIUmdJE2QNE/SXEmHNvf9LOmi9HP9gqRxkto1t/0s6VZJb0p6oaAt936VNDwt/6Kk4XlqcHA0QFIFcANwLNAHGCapT3mrajRrgYsjog9wCPDt1LfLgKkR0QuYmqYhew96pce5wI3bvuRGcwEwt2D6GuBnEfEZ4B3gG6n9G8A7qf1nabnt0c+BhyNiX6AfWd+b7X6W1B34HlAdEQcAFcAZNL/9fBtwTL22XPtVUmdgNHAwMBAYXRc2RYkIP+o9gEOByQXTo4BR5a6rRH39A3A0MB/YPbXtDsxPz28ChhUsv3657ekB9Ej/ob4I3A+I7Nu0rervc2AycGh63iotp3L3IWd/dwH+r37dzXk/A92BRUDntN/uB/6lOe5noBJ4YUv3KzAMuKmgfYPlNvfwEUfD6n4A69SmtmYlHZpXAU8Cn4iI19Ks14FPpOfN5b24DrgU+DBNdwGWRcTaNF3Yr/V9TvOXp+W3Jz2BJcDYNDx3i6T2NOP9HBGLgTHAP4DXyPbbTJr3fq6Td79u1f52cLRQkjoAvwcujIgVhfMi+xOk2XxOW9IJwJsRMbPctWxDrYD+wI0RUQW8y0fDF0Cz3M+7AkPJQnMPoD0fH9Jp9rbFfnVwNGwxsGfBdI/U1ixIak0WGndGxD2p+Q1Ju6f5uwNvpvbm8F4cBgyRtBAYTzZc9XOgk6RWaZnCfq3vc5q/C7B0WxbcCGqB2oh4Mk1PIAuS5ryfjwL+LyKWRMQa4B6yfd+c93OdvPt1q/a3g6NhM4Be6dMYbchOsE0qc02NQpKAXwNzI+LaglmTgLpPVgwnO/dR1352+nTGIcDygkPi7UJEjIqIHhFRSbYv/xQRXwUeBU5Ni9Xvc917cWpafrv6yzwiXgcWSdonNR0JzKEZ72eyIapDJO2Ufs7r+txs93OBvPt1MvAlSbumI7UvpbbilPskT1N9AMcBfwdeAv693PU0Yr8OJzuMfQ6YlR7HkY3tTgVeBKYAndPyIvuE2UvA82SfWCl7P7ai/4OA+9PzvYGngAXA74C2qb1dml6Q5u9d7rq3sK8HAjVpX08Edm3u+xn4ETAPeAG4A2jb3PYzMI7sHM4asiPLb2zJfgVGpr4vAL6epwZfcsTMzHLxUJWZmeXi4DAzs1wcHGZmlouDw8zMcnFwmJlZLg4OsyZM0qC6q/maNRUODjMzy8XBYdYIJH1N0lOSZkm6Kd3745+SfpbuDzFVUre07IGSnkj3R7i34N4Jn5E0RdKzkp6W9Om0+Q766L4ad6ZvRZuVjYPDbCtJ2g84HTgsIg4E1gFfJbvIXk1E7A/8mez+BwC/Af4tIj5L9m3euvY7gRsioh/wObJvB0N2BeMLye4NszfZ9ZfMyqbV5hcxs804EhgAzEgHAzuSXWTuQ+CutMz/AvdI2gXoFBF/Tu23A7+T1BHoHhH3AkTEKoC0vaciojZNzyK7F8PjJe+V2UY4OMy2noDbI2LUBo3SFfWW29Lr+3xQ8Hwd/n9rZeahKrOtNxU4VdJusP7+z58i+/9Vd1XWM4HHI2I58I6kI1L7WcCfI2IlUCvpy2kbbSXttC07YVYs/+VitpUiYo6kHwB/lLQD2VVLv01286SBad6bZOdBILvs9f+kYHgZ+HpqPwu4SdJVaRunbcNumBXNV8c1KxFJ/4yIDuWuw6yxeajKzMxy8RGHmZnl4iMOMzPLxcFhZma5ODjMzCwXB4eZmeXi4DAzs1z+PzwbMfDOMbArAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11/11 [==============================] - 1s 27ms/step - loss: 7.2334 - accuracy: 0.4853 - val_loss: 6.8751 - val_accuracy: 0.4848\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.8644 - accuracy: 0.4853 - val_loss: 6.1861 - val_accuracy: 0.4848\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 6.6300 - accuracy: 0.4853 - val_loss: 5.7002 - val_accuracy: 0.4848\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 6.1070 - accuracy: 0.4853 - val_loss: 4.5808 - val_accuracy: 0.4848\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.9911 - accuracy: 0.4853 - val_loss: 3.0434 - val_accuracy: 0.4848\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.4558 - accuracy: 0.4853 - val_loss: 1.8776 - val_accuracy: 0.4848\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8822 - accuracy: 0.4853 - val_loss: 1.1578 - val_accuracy: 0.4848\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.1168 - accuracy: 0.4853 - val_loss: 1.0572 - val_accuracy: 0.4848\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.0070 - accuracy: 0.4853 - val_loss: 1.0171 - val_accuracy: 0.4848\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.9472 - accuracy: 0.4853 - val_loss: 0.9911 - val_accuracy: 0.4848\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9373 - accuracy: 0.4882 - val_loss: 0.9709 - val_accuracy: 0.4848\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.9129 - accuracy: 0.4853 - val_loss: 0.9538 - val_accuracy: 0.4848\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.9023 - accuracy: 0.4824 - val_loss: 0.9391 - val_accuracy: 0.4848\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8804 - accuracy: 0.4941 - val_loss: 0.9261 - val_accuracy: 0.4909\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.8669 - accuracy: 0.4971 - val_loss: 0.9131 - val_accuracy: 0.4909\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.8547 - accuracy: 0.4941 - val_loss: 0.9020 - val_accuracy: 0.4909\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.8559 - accuracy: 0.5000 - val_loss: 0.8914 - val_accuracy: 0.4909\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.8385 - accuracy: 0.5000 - val_loss: 0.8818 - val_accuracy: 0.4909\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.8440 - accuracy: 0.4882 - val_loss: 0.8728 - val_accuracy: 0.4909\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.8270 - accuracy: 0.5059 - val_loss: 0.8637 - val_accuracy: 0.4848\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8265 - accuracy: 0.4971 - val_loss: 0.8559 - val_accuracy: 0.4909\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8096 - accuracy: 0.5059 - val_loss: 0.8484 - val_accuracy: 0.4909\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8096 - accuracy: 0.4912 - val_loss: 0.8412 - val_accuracy: 0.4909\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.8013 - accuracy: 0.5029 - val_loss: 0.8345 - val_accuracy: 0.4848\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7920 - accuracy: 0.5029 - val_loss: 0.8282 - val_accuracy: 0.4909\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7904 - accuracy: 0.5088 - val_loss: 0.8220 - val_accuracy: 0.4970\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7975 - accuracy: 0.4971 - val_loss: 0.8164 - val_accuracy: 0.4970\n",
      "Epoch 28/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7871 - accuracy: 0.5029 - val_loss: 0.8109 - val_accuracy: 0.5030\n",
      "Epoch 29/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7787 - accuracy: 0.5088 - val_loss: 0.8054 - val_accuracy: 0.5030\n",
      "Epoch 30/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7794 - accuracy: 0.5059 - val_loss: 0.8007 - val_accuracy: 0.5152\n",
      "Epoch 31/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7752 - accuracy: 0.5118 - val_loss: 0.7956 - val_accuracy: 0.5152\n",
      "Epoch 32/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7614 - accuracy: 0.5118 - val_loss: 0.7907 - val_accuracy: 0.5152\n",
      "Epoch 33/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7586 - accuracy: 0.4971 - val_loss: 0.7864 - val_accuracy: 0.5152\n",
      "Epoch 34/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7660 - accuracy: 0.4971 - val_loss: 0.7822 - val_accuracy: 0.5152\n",
      "Epoch 35/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7555 - accuracy: 0.5235 - val_loss: 0.7785 - val_accuracy: 0.5212\n",
      "Epoch 36/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7642 - accuracy: 0.4824 - val_loss: 0.7747 - val_accuracy: 0.5212\n",
      "Epoch 37/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7553 - accuracy: 0.5235 - val_loss: 0.7707 - val_accuracy: 0.5212\n",
      "Epoch 38/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7613 - accuracy: 0.4882 - val_loss: 0.7670 - val_accuracy: 0.5212\n",
      "Epoch 39/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7379 - accuracy: 0.5294 - val_loss: 0.7634 - val_accuracy: 0.5212\n",
      "Epoch 40/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7494 - accuracy: 0.5118 - val_loss: 0.7597 - val_accuracy: 0.5273\n",
      "Epoch 41/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7437 - accuracy: 0.5059 - val_loss: 0.7563 - val_accuracy: 0.5273\n",
      "Epoch 42/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7548 - accuracy: 0.4912 - val_loss: 0.7536 - val_accuracy: 0.5212\n",
      "Epoch 43/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7796 - accuracy: 0.5029 - val_loss: 0.7508 - val_accuracy: 0.5212\n",
      "Epoch 44/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7460 - accuracy: 0.5206 - val_loss: 0.7477 - val_accuracy: 0.5212\n",
      "Epoch 45/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7265 - accuracy: 0.5324 - val_loss: 0.7446 - val_accuracy: 0.5212\n",
      "Epoch 46/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7324 - accuracy: 0.5235 - val_loss: 0.7415 - val_accuracy: 0.5333\n",
      "Epoch 47/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7252 - accuracy: 0.5206 - val_loss: 0.7392 - val_accuracy: 0.5333\n",
      "Epoch 48/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7302 - accuracy: 0.5088 - val_loss: 0.7363 - val_accuracy: 0.5333\n",
      "Epoch 49/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7232 - accuracy: 0.5206 - val_loss: 0.7338 - val_accuracy: 0.5394\n",
      "Epoch 50/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7240 - accuracy: 0.5176 - val_loss: 0.7312 - val_accuracy: 0.5394\n",
      "Epoch 51/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7346 - accuracy: 0.5059 - val_loss: 0.7289 - val_accuracy: 0.5394\n",
      "Epoch 52/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7646 - accuracy: 0.5118 - val_loss: 0.7260 - val_accuracy: 0.5394\n",
      "Epoch 53/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7245 - accuracy: 0.4941 - val_loss: 0.7234 - val_accuracy: 0.5394\n",
      "Epoch 54/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7186 - accuracy: 0.5265 - val_loss: 0.7214 - val_accuracy: 0.5394\n",
      "Epoch 55/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7193 - accuracy: 0.4971 - val_loss: 0.7192 - val_accuracy: 0.5394\n",
      "Epoch 56/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7190 - accuracy: 0.5118 - val_loss: 0.7169 - val_accuracy: 0.5455\n",
      "Epoch 57/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7159 - accuracy: 0.5353 - val_loss: 0.7149 - val_accuracy: 0.5455\n",
      "Epoch 58/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7474 - accuracy: 0.5147 - val_loss: 0.7129 - val_accuracy: 0.5576\n",
      "Epoch 59/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7147 - accuracy: 0.5324 - val_loss: 0.7112 - val_accuracy: 0.5576\n",
      "Epoch 60/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7099 - accuracy: 0.5176 - val_loss: 0.7095 - val_accuracy: 0.5576\n",
      "Epoch 61/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7181 - accuracy: 0.5088 - val_loss: 0.7077 - val_accuracy: 0.5576\n",
      "Epoch 62/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7109 - accuracy: 0.5029 - val_loss: 0.7060 - val_accuracy: 0.5636\n",
      "Epoch 63/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7109 - accuracy: 0.5324 - val_loss: 0.7042 - val_accuracy: 0.5576\n",
      "Epoch 64/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7041 - accuracy: 0.5324 - val_loss: 0.7025 - val_accuracy: 0.5576\n",
      "Epoch 65/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6967 - accuracy: 0.5235 - val_loss: 0.7012 - val_accuracy: 0.5636\n",
      "Epoch 66/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7045 - accuracy: 0.5294 - val_loss: 0.6997 - val_accuracy: 0.5697\n",
      "Epoch 67/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6976 - accuracy: 0.5735 - val_loss: 0.6987 - val_accuracy: 0.5697\n",
      "Epoch 68/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7051 - accuracy: 0.5324 - val_loss: 0.6978 - val_accuracy: 0.5697\n",
      "Epoch 69/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7063 - accuracy: 0.5147 - val_loss: 0.6967 - val_accuracy: 0.5697\n",
      "Epoch 70/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7381 - accuracy: 0.5441 - val_loss: 0.6956 - val_accuracy: 0.5697\n",
      "Epoch 71/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7072 - accuracy: 0.5088 - val_loss: 0.6950 - val_accuracy: 0.5636\n",
      "Epoch 72/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7120 - accuracy: 0.5324 - val_loss: 0.6940 - val_accuracy: 0.5636\n",
      "Epoch 73/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6951 - accuracy: 0.5382 - val_loss: 0.6929 - val_accuracy: 0.5636\n",
      "Epoch 74/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7030 - accuracy: 0.5382 - val_loss: 0.6920 - val_accuracy: 0.5697\n",
      "Epoch 75/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7006 - accuracy: 0.5206 - val_loss: 0.6910 - val_accuracy: 0.5697\n",
      "Epoch 76/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7027 - accuracy: 0.5147 - val_loss: 0.6901 - val_accuracy: 0.5697\n",
      "Epoch 77/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.5265 - val_loss: 0.6893 - val_accuracy: 0.5697\n",
      "Epoch 78/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7453 - accuracy: 0.5000 - val_loss: 0.6884 - val_accuracy: 0.5697\n",
      "Epoch 79/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6861 - accuracy: 0.5353 - val_loss: 0.6874 - val_accuracy: 0.5697\n",
      "Epoch 80/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6997 - accuracy: 0.5294 - val_loss: 0.6867 - val_accuracy: 0.5636\n",
      "Epoch 81/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6998 - accuracy: 0.5176 - val_loss: 0.6861 - val_accuracy: 0.5758\n",
      "Epoch 82/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7090 - accuracy: 0.5147 - val_loss: 0.6856 - val_accuracy: 0.5758\n",
      "Epoch 83/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6997 - accuracy: 0.5441 - val_loss: 0.6854 - val_accuracy: 0.5818\n",
      "Epoch 84/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7013 - accuracy: 0.4912 - val_loss: 0.6853 - val_accuracy: 0.5818\n",
      "Epoch 85/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6969 - accuracy: 0.5294 - val_loss: 0.6850 - val_accuracy: 0.5818\n",
      "Epoch 86/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6847 - accuracy: 0.5294 - val_loss: 0.6844 - val_accuracy: 0.5697\n",
      "Epoch 87/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6946 - accuracy: 0.5147 - val_loss: 0.6841 - val_accuracy: 0.5697\n",
      "Epoch 88/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6955 - accuracy: 0.5265 - val_loss: 0.6838 - val_accuracy: 0.5758\n",
      "Epoch 89/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6989 - accuracy: 0.5412 - val_loss: 0.6834 - val_accuracy: 0.5636\n",
      "Epoch 90/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7000 - accuracy: 0.5147 - val_loss: 0.6833 - val_accuracy: 0.5636\n",
      "Epoch 91/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6930 - accuracy: 0.5735 - val_loss: 0.6830 - val_accuracy: 0.5636\n",
      "Epoch 92/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6917 - accuracy: 0.5441 - val_loss: 0.6827 - val_accuracy: 0.5697\n",
      "Epoch 93/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.5176 - val_loss: 0.6823 - val_accuracy: 0.5697\n",
      "Epoch 94/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6928 - accuracy: 0.5353 - val_loss: 0.6820 - val_accuracy: 0.5758\n",
      "Epoch 95/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6987 - accuracy: 0.5294 - val_loss: 0.6818 - val_accuracy: 0.5758\n",
      "Epoch 96/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7102 - accuracy: 0.4912 - val_loss: 0.6818 - val_accuracy: 0.5758\n",
      "Epoch 97/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6952 - accuracy: 0.5324 - val_loss: 0.6816 - val_accuracy: 0.5758\n",
      "Epoch 98/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6982 - accuracy: 0.5147 - val_loss: 0.6813 - val_accuracy: 0.5697\n",
      "Epoch 99/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6940 - accuracy: 0.5059 - val_loss: 0.6812 - val_accuracy: 0.5758\n",
      "Epoch 100/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.5735 - val_loss: 0.6810 - val_accuracy: 0.5758\n",
      "Epoch 101/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6995 - accuracy: 0.5029 - val_loss: 0.6806 - val_accuracy: 0.5697\n",
      "Epoch 102/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7362 - accuracy: 0.5588 - val_loss: 0.6808 - val_accuracy: 0.5697\n",
      "Epoch 103/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7057 - accuracy: 0.4912 - val_loss: 0.6807 - val_accuracy: 0.5636\n",
      "Epoch 104/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7026 - accuracy: 0.5176 - val_loss: 0.6807 - val_accuracy: 0.5758\n",
      "Epoch 105/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6980 - accuracy: 0.5324 - val_loss: 0.6806 - val_accuracy: 0.5636\n",
      "Epoch 106/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6949 - accuracy: 0.5206 - val_loss: 0.6804 - val_accuracy: 0.5697\n",
      "Epoch 107/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6859 - accuracy: 0.5353 - val_loss: 0.6802 - val_accuracy: 0.5697\n",
      "Epoch 108/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5647 - val_loss: 0.6801 - val_accuracy: 0.5697\n",
      "Epoch 109/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7517 - accuracy: 0.4941 - val_loss: 0.6801 - val_accuracy: 0.5697\n",
      "Epoch 110/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7033 - accuracy: 0.5029 - val_loss: 0.6802 - val_accuracy: 0.5758\n",
      "Epoch 111/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5529 - val_loss: 0.6803 - val_accuracy: 0.5697\n",
      "Epoch 112/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7346 - accuracy: 0.5294 - val_loss: 0.6800 - val_accuracy: 0.5576\n",
      "Epoch 113/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6952 - accuracy: 0.5324 - val_loss: 0.6801 - val_accuracy: 0.5697\n",
      "Epoch 114/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6920 - accuracy: 0.5353 - val_loss: 0.6801 - val_accuracy: 0.5636\n",
      "Epoch 115/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7085 - accuracy: 0.5059 - val_loss: 0.6802 - val_accuracy: 0.5636\n",
      "Epoch 116/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6889 - accuracy: 0.5088 - val_loss: 0.6799 - val_accuracy: 0.5697\n",
      "Epoch 117/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6957 - accuracy: 0.5265 - val_loss: 0.6799 - val_accuracy: 0.5697\n",
      "Epoch 118/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6901 - accuracy: 0.5382 - val_loss: 0.6798 - val_accuracy: 0.5697\n",
      "Epoch 119/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7025 - accuracy: 0.5176 - val_loss: 0.6809 - val_accuracy: 0.5697\n",
      "Epoch 120/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7001 - accuracy: 0.5088 - val_loss: 0.6811 - val_accuracy: 0.5758\n",
      "Epoch 121/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6942 - accuracy: 0.5176 - val_loss: 0.6813 - val_accuracy: 0.5697\n",
      "Epoch 122/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6888 - accuracy: 0.5176 - val_loss: 0.6810 - val_accuracy: 0.5697\n",
      "Epoch 123/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7040 - accuracy: 0.5147 - val_loss: 0.6809 - val_accuracy: 0.5636\n",
      "Epoch 124/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6975 - accuracy: 0.4941 - val_loss: 0.6806 - val_accuracy: 0.5758\n",
      "Epoch 125/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6875 - accuracy: 0.5412 - val_loss: 0.6803 - val_accuracy: 0.5636\n",
      "Epoch 126/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6954 - accuracy: 0.5059 - val_loss: 0.6800 - val_accuracy: 0.5697\n",
      "Epoch 127/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7015 - accuracy: 0.4971 - val_loss: 0.6799 - val_accuracy: 0.5697\n",
      "Epoch 128/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7005 - accuracy: 0.5324 - val_loss: 0.6798 - val_accuracy: 0.5697\n",
      "Epoch 129/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6896 - accuracy: 0.5735 - val_loss: 0.6795 - val_accuracy: 0.5697\n",
      "Epoch 130/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6907 - accuracy: 0.5265 - val_loss: 0.6793 - val_accuracy: 0.5636\n",
      "Epoch 131/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6953 - accuracy: 0.5206 - val_loss: 0.6793 - val_accuracy: 0.5636\n",
      "Epoch 132/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7064 - accuracy: 0.5118 - val_loss: 0.6793 - val_accuracy: 0.5758\n",
      "Epoch 133/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6947 - accuracy: 0.5471 - val_loss: 0.6796 - val_accuracy: 0.5636\n",
      "Epoch 134/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6991 - accuracy: 0.4941 - val_loss: 0.6797 - val_accuracy: 0.5636\n",
      "Epoch 135/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7065 - accuracy: 0.5029 - val_loss: 0.6796 - val_accuracy: 0.5636\n",
      "Epoch 136/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7041 - accuracy: 0.4941 - val_loss: 0.6803 - val_accuracy: 0.5697\n",
      "Epoch 137/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7338 - accuracy: 0.5265 - val_loss: 0.6803 - val_accuracy: 0.5818\n",
      "Epoch 138/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6970 - accuracy: 0.5029 - val_loss: 0.6803 - val_accuracy: 0.5818\n",
      "Epoch 139/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7034 - accuracy: 0.5147 - val_loss: 0.6802 - val_accuracy: 0.5758\n",
      "Epoch 140/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7027 - accuracy: 0.4941 - val_loss: 0.6798 - val_accuracy: 0.5758\n",
      "Epoch 141/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6943 - accuracy: 0.5088 - val_loss: 0.6794 - val_accuracy: 0.5697\n",
      "Epoch 142/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6900 - accuracy: 0.5265 - val_loss: 0.6792 - val_accuracy: 0.5636\n",
      "Epoch 143/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6957 - accuracy: 0.5118 - val_loss: 0.6789 - val_accuracy: 0.5636\n",
      "Epoch 144/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6941 - accuracy: 0.5176 - val_loss: 0.6786 - val_accuracy: 0.5636\n",
      "Epoch 145/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6994 - accuracy: 0.5294 - val_loss: 0.6787 - val_accuracy: 0.5636\n",
      "Epoch 146/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.5588 - val_loss: 0.6784 - val_accuracy: 0.5758\n",
      "Epoch 147/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.5059 - val_loss: 0.6787 - val_accuracy: 0.5636\n",
      "Epoch 148/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6786 - val_accuracy: 0.5636\n",
      "Epoch 149/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6942 - accuracy: 0.5059 - val_loss: 0.6784 - val_accuracy: 0.5697\n",
      "Epoch 150/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6948 - accuracy: 0.5471 - val_loss: 0.6783 - val_accuracy: 0.5697\n",
      "Epoch 151/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6902 - accuracy: 0.5324 - val_loss: 0.6783 - val_accuracy: 0.5697\n",
      "Epoch 152/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7024 - accuracy: 0.5176 - val_loss: 0.6783 - val_accuracy: 0.5636\n",
      "Epoch 153/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7025 - accuracy: 0.5118 - val_loss: 0.6787 - val_accuracy: 0.5636\n",
      "Epoch 154/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.5000 - val_loss: 0.6785 - val_accuracy: 0.5758\n",
      "Epoch 155/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5265 - val_loss: 0.6786 - val_accuracy: 0.5636\n",
      "Epoch 156/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6963 - accuracy: 0.5235 - val_loss: 0.6785 - val_accuracy: 0.5636\n",
      "Epoch 157/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6941 - accuracy: 0.5147 - val_loss: 0.6784 - val_accuracy: 0.5758\n",
      "Epoch 158/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6900 - accuracy: 0.5206 - val_loss: 0.6783 - val_accuracy: 0.5697\n",
      "Epoch 159/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.5647 - val_loss: 0.6783 - val_accuracy: 0.5758\n",
      "Epoch 160/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6912 - accuracy: 0.4971 - val_loss: 0.6783 - val_accuracy: 0.5758\n",
      "Epoch 161/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6940 - accuracy: 0.4971 - val_loss: 0.6784 - val_accuracy: 0.5697\n",
      "Epoch 162/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6968 - accuracy: 0.5088 - val_loss: 0.6782 - val_accuracy: 0.5636\n",
      "Epoch 163/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6975 - accuracy: 0.4971 - val_loss: 0.6786 - val_accuracy: 0.5636\n",
      "Epoch 164/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6974 - accuracy: 0.5294 - val_loss: 0.6786 - val_accuracy: 0.5636\n",
      "Epoch 165/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7019 - accuracy: 0.5235 - val_loss: 0.6795 - val_accuracy: 0.5636\n",
      "Epoch 166/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6943 - accuracy: 0.5353 - val_loss: 0.6794 - val_accuracy: 0.5697\n",
      "Epoch 167/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6930 - accuracy: 0.5412 - val_loss: 0.6793 - val_accuracy: 0.5758\n",
      "Epoch 168/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5147 - val_loss: 0.6792 - val_accuracy: 0.5758\n",
      "Epoch 169/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6961 - accuracy: 0.5029 - val_loss: 0.6792 - val_accuracy: 0.5758\n",
      "Epoch 170/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5265 - val_loss: 0.6792 - val_accuracy: 0.5758\n",
      "Epoch 171/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6887 - accuracy: 0.5353 - val_loss: 0.6797 - val_accuracy: 0.5758\n",
      "Epoch 172/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6950 - accuracy: 0.5235 - val_loss: 0.6795 - val_accuracy: 0.5636\n",
      "Epoch 173/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5294 - val_loss: 0.6792 - val_accuracy: 0.5697\n",
      "Epoch 174/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6975 - accuracy: 0.5059 - val_loss: 0.6791 - val_accuracy: 0.5636\n",
      "Epoch 175/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6971 - accuracy: 0.5088 - val_loss: 0.6793 - val_accuracy: 0.5636\n",
      "Epoch 176/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6968 - accuracy: 0.5265 - val_loss: 0.6791 - val_accuracy: 0.5636\n",
      "Epoch 177/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.5000 - val_loss: 0.6786 - val_accuracy: 0.5636\n",
      "Epoch 178/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6958 - accuracy: 0.5118 - val_loss: 0.6788 - val_accuracy: 0.5818\n",
      "Epoch 179/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6893 - accuracy: 0.5441 - val_loss: 0.6786 - val_accuracy: 0.5758\n",
      "Epoch 180/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5324 - val_loss: 0.6788 - val_accuracy: 0.5818\n",
      "Epoch 181/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6905 - accuracy: 0.5265 - val_loss: 0.6793 - val_accuracy: 0.5758\n",
      "Epoch 182/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5324 - val_loss: 0.6794 - val_accuracy: 0.5758\n",
      "Epoch 183/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6861 - accuracy: 0.5353 - val_loss: 0.6789 - val_accuracy: 0.5697\n",
      "Epoch 184/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6963 - accuracy: 0.5176 - val_loss: 0.6789 - val_accuracy: 0.5697\n",
      "Epoch 185/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5176 - val_loss: 0.6785 - val_accuracy: 0.5697\n",
      "Epoch 186/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6996 - accuracy: 0.5265 - val_loss: 0.6781 - val_accuracy: 0.5818\n",
      "Epoch 187/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6938 - accuracy: 0.5176 - val_loss: 0.6784 - val_accuracy: 0.5758\n",
      "Epoch 188/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6999 - accuracy: 0.5147 - val_loss: 0.6788 - val_accuracy: 0.5636\n",
      "Epoch 189/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5353 - val_loss: 0.6786 - val_accuracy: 0.5636\n",
      "Epoch 190/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6896 - accuracy: 0.5471 - val_loss: 0.6783 - val_accuracy: 0.5758\n",
      "Epoch 191/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5176 - val_loss: 0.6784 - val_accuracy: 0.5818\n",
      "Epoch 192/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5382 - val_loss: 0.6783 - val_accuracy: 0.5818\n",
      "Epoch 193/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7013 - accuracy: 0.5206 - val_loss: 0.6784 - val_accuracy: 0.5818\n",
      "Epoch 194/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.5235 - val_loss: 0.6780 - val_accuracy: 0.5758\n",
      "Epoch 195/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.7229 - accuracy: 0.5324 - val_loss: 0.6781 - val_accuracy: 0.5818\n",
      "Epoch 196/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6927 - accuracy: 0.5382 - val_loss: 0.6783 - val_accuracy: 0.5758\n",
      "Epoch 197/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6895 - accuracy: 0.5176 - val_loss: 0.6783 - val_accuracy: 0.5758\n",
      "Epoch 198/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5412 - val_loss: 0.6783 - val_accuracy: 0.5758\n",
      "Epoch 199/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6993 - accuracy: 0.5324 - val_loss: 0.6782 - val_accuracy: 0.5697\n",
      "Epoch 200/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6870 - accuracy: 0.5441 - val_loss: 0.6781 - val_accuracy: 0.5697\n",
      "Epoch 201/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6871 - accuracy: 0.5294 - val_loss: 0.6783 - val_accuracy: 0.5818\n",
      "Epoch 202/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5294 - val_loss: 0.6784 - val_accuracy: 0.5818\n",
      "Epoch 203/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6997 - accuracy: 0.4912 - val_loss: 0.6782 - val_accuracy: 0.5758\n",
      "Epoch 204/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6985 - accuracy: 0.5029 - val_loss: 0.6781 - val_accuracy: 0.5636\n",
      "Epoch 205/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5147 - val_loss: 0.6783 - val_accuracy: 0.5879\n",
      "Epoch 206/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5294 - val_loss: 0.6784 - val_accuracy: 0.5758\n",
      "Epoch 207/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6988 - accuracy: 0.5088 - val_loss: 0.6783 - val_accuracy: 0.5697\n",
      "Epoch 208/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5118 - val_loss: 0.6783 - val_accuracy: 0.5758\n",
      "Epoch 209/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5294 - val_loss: 0.6783 - val_accuracy: 0.5758\n",
      "Epoch 210/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6884 - accuracy: 0.5324 - val_loss: 0.6789 - val_accuracy: 0.5818\n",
      "Epoch 211/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6927 - accuracy: 0.5353 - val_loss: 0.6784 - val_accuracy: 0.5636\n",
      "Epoch 212/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5176 - val_loss: 0.6788 - val_accuracy: 0.5939\n",
      "Epoch 213/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7003 - accuracy: 0.5088 - val_loss: 0.6795 - val_accuracy: 0.5636\n",
      "Epoch 214/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.5059 - val_loss: 0.6790 - val_accuracy: 0.5818\n",
      "Epoch 215/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6960 - accuracy: 0.5118 - val_loss: 0.6788 - val_accuracy: 0.5818\n",
      "Epoch 216/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.5294 - val_loss: 0.6787 - val_accuracy: 0.5697\n",
      "Epoch 217/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6898 - accuracy: 0.5147 - val_loss: 0.6792 - val_accuracy: 0.5879\n",
      "Epoch 218/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5765 - val_loss: 0.6789 - val_accuracy: 0.5818\n",
      "Epoch 219/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6969 - accuracy: 0.5147 - val_loss: 0.6796 - val_accuracy: 0.5818\n",
      "Epoch 220/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5324 - val_loss: 0.6796 - val_accuracy: 0.5758\n",
      "Epoch 221/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5235 - val_loss: 0.6789 - val_accuracy: 0.5758\n",
      "Epoch 222/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6894 - accuracy: 0.5059 - val_loss: 0.6786 - val_accuracy: 0.5818\n",
      "Epoch 223/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.5265 - val_loss: 0.6785 - val_accuracy: 0.5697\n",
      "Epoch 224/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5500 - val_loss: 0.6783 - val_accuracy: 0.5576\n",
      "Epoch 225/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6909 - accuracy: 0.5176 - val_loss: 0.6782 - val_accuracy: 0.5576\n",
      "Epoch 226/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5529 - val_loss: 0.6785 - val_accuracy: 0.5636\n",
      "Epoch 227/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5559 - val_loss: 0.6785 - val_accuracy: 0.5636\n",
      "Epoch 228/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7006 - accuracy: 0.5118 - val_loss: 0.6790 - val_accuracy: 0.5758\n",
      "Epoch 229/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6901 - accuracy: 0.5118 - val_loss: 0.6792 - val_accuracy: 0.5879\n",
      "Epoch 230/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6993 - accuracy: 0.4735 - val_loss: 0.6793 - val_accuracy: 0.5818\n",
      "Epoch 231/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5412 - val_loss: 0.6792 - val_accuracy: 0.5818\n",
      "Epoch 232/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6925 - accuracy: 0.5176 - val_loss: 0.6789 - val_accuracy: 0.5879\n",
      "Epoch 233/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6902 - accuracy: 0.5000 - val_loss: 0.6790 - val_accuracy: 0.5697\n",
      "Epoch 234/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6927 - accuracy: 0.4971 - val_loss: 0.6789 - val_accuracy: 0.5697\n",
      "Epoch 235/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6980 - accuracy: 0.5294 - val_loss: 0.6792 - val_accuracy: 0.5818\n",
      "Epoch 236/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.4971 - val_loss: 0.6792 - val_accuracy: 0.5697\n",
      "Epoch 237/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5294 - val_loss: 0.6793 - val_accuracy: 0.5758\n",
      "Epoch 238/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5588 - val_loss: 0.6797 - val_accuracy: 0.5758\n",
      "Epoch 239/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5324 - val_loss: 0.6797 - val_accuracy: 0.5697\n",
      "Epoch 240/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5235 - val_loss: 0.6794 - val_accuracy: 0.5758\n",
      "Epoch 241/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5382 - val_loss: 0.6797 - val_accuracy: 0.5758\n",
      "Epoch 242/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6883 - accuracy: 0.5206 - val_loss: 0.6794 - val_accuracy: 0.5636\n",
      "Epoch 243/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5382 - val_loss: 0.6795 - val_accuracy: 0.5455\n",
      "Epoch 244/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5294 - val_loss: 0.6795 - val_accuracy: 0.5455\n",
      "Epoch 245/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.7006 - accuracy: 0.5147 - val_loss: 0.6798 - val_accuracy: 0.5515\n",
      "Epoch 246/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6894 - accuracy: 0.5265 - val_loss: 0.6798 - val_accuracy: 0.5576\n",
      "Epoch 247/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5529 - val_loss: 0.6799 - val_accuracy: 0.5515\n",
      "Epoch 248/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5676 - val_loss: 0.6803 - val_accuracy: 0.5333\n",
      "Epoch 249/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6802 - val_accuracy: 0.5394\n",
      "Epoch 250/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5471 - val_loss: 0.6805 - val_accuracy: 0.5394\n",
      "Epoch 251/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6944 - accuracy: 0.5147 - val_loss: 0.6808 - val_accuracy: 0.5697\n",
      "Epoch 252/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6910 - accuracy: 0.5441 - val_loss: 0.6805 - val_accuracy: 0.5394\n",
      "Epoch 253/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6945 - accuracy: 0.5147 - val_loss: 0.6814 - val_accuracy: 0.5636\n",
      "Epoch 254/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6962 - accuracy: 0.5206 - val_loss: 0.6817 - val_accuracy: 0.5758\n",
      "Epoch 255/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.5235 - val_loss: 0.6809 - val_accuracy: 0.5697\n",
      "Epoch 256/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.5471 - val_loss: 0.6812 - val_accuracy: 0.5515\n",
      "Epoch 257/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6901 - accuracy: 0.5088 - val_loss: 0.6807 - val_accuracy: 0.5697\n",
      "Epoch 258/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6945 - accuracy: 0.5176 - val_loss: 0.6802 - val_accuracy: 0.5455\n",
      "Epoch 259/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5500 - val_loss: 0.6801 - val_accuracy: 0.5455\n",
      "Epoch 260/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5353 - val_loss: 0.6807 - val_accuracy: 0.5576\n",
      "Epoch 261/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6981 - accuracy: 0.4853 - val_loss: 0.6812 - val_accuracy: 0.5697\n",
      "Epoch 262/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6942 - accuracy: 0.5206 - val_loss: 0.6814 - val_accuracy: 0.5697\n",
      "Epoch 263/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.4794 - val_loss: 0.6808 - val_accuracy: 0.5758\n",
      "Epoch 264/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5412 - val_loss: 0.6806 - val_accuracy: 0.5576\n",
      "Epoch 265/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6883 - accuracy: 0.5324 - val_loss: 0.6801 - val_accuracy: 0.5636\n",
      "Epoch 266/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6897 - accuracy: 0.5324 - val_loss: 0.6802 - val_accuracy: 0.5636\n",
      "Epoch 267/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6893 - accuracy: 0.5353 - val_loss: 0.6806 - val_accuracy: 0.5333\n",
      "Epoch 268/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5353 - val_loss: 0.6806 - val_accuracy: 0.5758\n",
      "Epoch 269/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6907 - accuracy: 0.5412 - val_loss: 0.6799 - val_accuracy: 0.5515\n",
      "Epoch 270/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6860 - accuracy: 0.5294 - val_loss: 0.6799 - val_accuracy: 0.5515\n",
      "Epoch 271/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.5529 - val_loss: 0.6800 - val_accuracy: 0.5576\n",
      "Epoch 272/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6946 - accuracy: 0.4882 - val_loss: 0.6799 - val_accuracy: 0.5515\n",
      "Epoch 273/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5147 - val_loss: 0.6801 - val_accuracy: 0.5636\n",
      "Epoch 274/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6902 - accuracy: 0.5118 - val_loss: 0.6799 - val_accuracy: 0.5697\n",
      "Epoch 275/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5441 - val_loss: 0.6801 - val_accuracy: 0.5455\n",
      "Epoch 276/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.5206 - val_loss: 0.6809 - val_accuracy: 0.5636\n",
      "Epoch 277/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6910 - accuracy: 0.5294 - val_loss: 0.6809 - val_accuracy: 0.5636\n",
      "Epoch 278/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.5088 - val_loss: 0.6806 - val_accuracy: 0.5515\n",
      "Epoch 279/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6896 - accuracy: 0.5206 - val_loss: 0.6804 - val_accuracy: 0.5455\n",
      "Epoch 280/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6959 - accuracy: 0.5265 - val_loss: 0.6815 - val_accuracy: 0.5636\n",
      "Epoch 281/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5529 - val_loss: 0.6808 - val_accuracy: 0.5576\n",
      "Epoch 282/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5471 - val_loss: 0.6806 - val_accuracy: 0.5455\n",
      "Epoch 283/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.5353 - val_loss: 0.6806 - val_accuracy: 0.5455\n",
      "Epoch 284/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5529 - val_loss: 0.6807 - val_accuracy: 0.5515\n",
      "Epoch 285/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.5676 - val_loss: 0.6808 - val_accuracy: 0.5576\n",
      "Epoch 286/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5265 - val_loss: 0.6805 - val_accuracy: 0.5333\n",
      "Epoch 287/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6872 - accuracy: 0.5471 - val_loss: 0.6806 - val_accuracy: 0.5515\n",
      "Epoch 288/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.5441 - val_loss: 0.6805 - val_accuracy: 0.5697\n",
      "Epoch 289/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6764 - accuracy: 0.5471 - val_loss: 0.6807 - val_accuracy: 0.5636\n",
      "Epoch 290/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5118 - val_loss: 0.6804 - val_accuracy: 0.5697\n",
      "Epoch 291/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.5324 - val_loss: 0.6809 - val_accuracy: 0.5697\n",
      "Epoch 292/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6981 - accuracy: 0.5206 - val_loss: 0.6807 - val_accuracy: 0.5636\n",
      "Epoch 293/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.5412 - val_loss: 0.6806 - val_accuracy: 0.5515\n",
      "Epoch 294/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5412 - val_loss: 0.6810 - val_accuracy: 0.5636\n",
      "Epoch 295/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5206 - val_loss: 0.6808 - val_accuracy: 0.5636\n",
      "Epoch 296/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6899 - accuracy: 0.5294 - val_loss: 0.6813 - val_accuracy: 0.5515\n",
      "Epoch 297/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5412 - val_loss: 0.6812 - val_accuracy: 0.5697\n",
      "Epoch 298/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5529 - val_loss: 0.6805 - val_accuracy: 0.5576\n",
      "Epoch 299/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6920 - accuracy: 0.5029 - val_loss: 0.6808 - val_accuracy: 0.5455\n",
      "Epoch 300/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5412 - val_loss: 0.6803 - val_accuracy: 0.5636\n",
      "Epoch 301/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6905 - accuracy: 0.4971 - val_loss: 0.6806 - val_accuracy: 0.5455\n",
      "Epoch 302/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6854 - accuracy: 0.5235 - val_loss: 0.6808 - val_accuracy: 0.5515\n",
      "Epoch 303/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6919 - accuracy: 0.5382 - val_loss: 0.6812 - val_accuracy: 0.5515\n",
      "Epoch 304/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5147 - val_loss: 0.6816 - val_accuracy: 0.5394\n",
      "Epoch 305/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5471 - val_loss: 0.6817 - val_accuracy: 0.5333\n",
      "Epoch 306/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5529 - val_loss: 0.6811 - val_accuracy: 0.5515\n",
      "Epoch 307/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5412 - val_loss: 0.6806 - val_accuracy: 0.5333\n",
      "Epoch 308/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6942 - accuracy: 0.5382 - val_loss: 0.6806 - val_accuracy: 0.5394\n",
      "Epoch 309/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.5412 - val_loss: 0.6811 - val_accuracy: 0.5576\n",
      "Epoch 310/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.5324 - val_loss: 0.6822 - val_accuracy: 0.5576\n",
      "Epoch 311/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.5235 - val_loss: 0.6819 - val_accuracy: 0.5455\n",
      "Epoch 312/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5441 - val_loss: 0.6816 - val_accuracy: 0.5515\n",
      "Epoch 313/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5412 - val_loss: 0.6816 - val_accuracy: 0.5394\n",
      "Epoch 314/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5559 - val_loss: 0.6822 - val_accuracy: 0.5333\n",
      "Epoch 315/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5382 - val_loss: 0.6829 - val_accuracy: 0.5636\n",
      "Epoch 316/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6921 - accuracy: 0.5382 - val_loss: 0.6830 - val_accuracy: 0.5758\n",
      "Epoch 317/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6951 - accuracy: 0.5176 - val_loss: 0.6824 - val_accuracy: 0.5515\n",
      "Epoch 318/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5353 - val_loss: 0.6821 - val_accuracy: 0.5394\n",
      "Epoch 319/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6841 - accuracy: 0.5324 - val_loss: 0.6814 - val_accuracy: 0.5576\n",
      "Epoch 320/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6883 - accuracy: 0.5206 - val_loss: 0.6810 - val_accuracy: 0.5333\n",
      "Epoch 321/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5412 - val_loss: 0.6814 - val_accuracy: 0.5515\n",
      "Epoch 322/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6844 - accuracy: 0.5382 - val_loss: 0.6821 - val_accuracy: 0.5273\n",
      "Epoch 323/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5765 - val_loss: 0.6822 - val_accuracy: 0.5273\n",
      "Epoch 324/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6886 - accuracy: 0.5294 - val_loss: 0.6819 - val_accuracy: 0.5273\n",
      "Epoch 325/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6895 - accuracy: 0.5147 - val_loss: 0.6822 - val_accuracy: 0.5212\n",
      "Epoch 326/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6891 - accuracy: 0.5353 - val_loss: 0.6819 - val_accuracy: 0.5455\n",
      "Epoch 327/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5529 - val_loss: 0.6818 - val_accuracy: 0.5697\n",
      "Epoch 328/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6857 - accuracy: 0.5441 - val_loss: 0.6815 - val_accuracy: 0.5333\n",
      "Epoch 329/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6903 - accuracy: 0.5235 - val_loss: 0.6811 - val_accuracy: 0.5333\n",
      "Epoch 330/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6939 - accuracy: 0.5118 - val_loss: 0.6816 - val_accuracy: 0.5576\n",
      "Epoch 331/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6950 - accuracy: 0.5294 - val_loss: 0.6817 - val_accuracy: 0.5333\n",
      "Epoch 332/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5382 - val_loss: 0.6832 - val_accuracy: 0.5333\n",
      "Epoch 333/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6906 - accuracy: 0.5353 - val_loss: 0.6848 - val_accuracy: 0.5697\n",
      "Epoch 334/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.7001 - accuracy: 0.5235 - val_loss: 0.6839 - val_accuracy: 0.5455\n",
      "Epoch 335/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.5588 - val_loss: 0.6831 - val_accuracy: 0.5333\n",
      "Epoch 336/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.5324 - val_loss: 0.6824 - val_accuracy: 0.5576\n",
      "Epoch 337/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5500 - val_loss: 0.6825 - val_accuracy: 0.5394\n",
      "Epoch 338/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6851 - accuracy: 0.5353 - val_loss: 0.6822 - val_accuracy: 0.5455\n",
      "Epoch 339/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6830 - val_accuracy: 0.5455\n",
      "Epoch 340/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6927 - accuracy: 0.5412 - val_loss: 0.6827 - val_accuracy: 0.5394\n",
      "Epoch 341/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6876 - accuracy: 0.5294 - val_loss: 0.6822 - val_accuracy: 0.5394\n",
      "Epoch 342/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6821 - accuracy: 0.5765 - val_loss: 0.6826 - val_accuracy: 0.5394\n",
      "Epoch 343/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5265 - val_loss: 0.6855 - val_accuracy: 0.5576\n",
      "Epoch 344/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.5441 - val_loss: 0.6842 - val_accuracy: 0.5697\n",
      "Epoch 345/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6848 - accuracy: 0.5412 - val_loss: 0.6821 - val_accuracy: 0.5394\n",
      "Epoch 346/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6800 - accuracy: 0.5824 - val_loss: 0.6819 - val_accuracy: 0.5394\n",
      "Epoch 347/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5235 - val_loss: 0.6817 - val_accuracy: 0.5394\n",
      "Epoch 348/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6893 - accuracy: 0.5706 - val_loss: 0.6823 - val_accuracy: 0.5515\n",
      "Epoch 349/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5588 - val_loss: 0.6819 - val_accuracy: 0.5333\n",
      "Epoch 350/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6945 - accuracy: 0.5294 - val_loss: 0.6822 - val_accuracy: 0.5394\n",
      "Epoch 351/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6877 - accuracy: 0.5588 - val_loss: 0.6821 - val_accuracy: 0.5333\n",
      "Epoch 352/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5441 - val_loss: 0.6824 - val_accuracy: 0.5455\n",
      "Epoch 353/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6885 - accuracy: 0.5206 - val_loss: 0.6827 - val_accuracy: 0.5576\n",
      "Epoch 354/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6889 - accuracy: 0.5118 - val_loss: 0.6822 - val_accuracy: 0.5333\n",
      "Epoch 355/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5176 - val_loss: 0.6820 - val_accuracy: 0.5394\n",
      "Epoch 356/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6850 - accuracy: 0.5441 - val_loss: 0.6820 - val_accuracy: 0.5394\n",
      "Epoch 357/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6869 - accuracy: 0.5471 - val_loss: 0.6817 - val_accuracy: 0.5394\n",
      "Epoch 358/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5265 - val_loss: 0.6820 - val_accuracy: 0.5394\n",
      "Epoch 359/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6884 - accuracy: 0.5265 - val_loss: 0.6829 - val_accuracy: 0.5333\n",
      "Epoch 360/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6896 - accuracy: 0.5500 - val_loss: 0.6834 - val_accuracy: 0.5394\n",
      "Epoch 361/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6964 - accuracy: 0.5294 - val_loss: 0.6819 - val_accuracy: 0.5515\n",
      "Epoch 362/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5382 - val_loss: 0.6825 - val_accuracy: 0.5394\n",
      "Epoch 363/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6739 - accuracy: 0.6000 - val_loss: 0.6816 - val_accuracy: 0.5273\n",
      "Epoch 364/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6865 - accuracy: 0.5088 - val_loss: 0.6818 - val_accuracy: 0.5273\n",
      "Epoch 365/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6905 - accuracy: 0.5118 - val_loss: 0.6823 - val_accuracy: 0.5455\n",
      "Epoch 366/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6832 - accuracy: 0.5412 - val_loss: 0.6822 - val_accuracy: 0.5333\n",
      "Epoch 367/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6889 - accuracy: 0.5471 - val_loss: 0.6832 - val_accuracy: 0.5333\n",
      "Epoch 368/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6874 - accuracy: 0.5147 - val_loss: 0.6835 - val_accuracy: 0.5333\n",
      "Epoch 369/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6867 - accuracy: 0.5706 - val_loss: 0.6836 - val_accuracy: 0.5576\n",
      "Epoch 370/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6771 - accuracy: 0.5529 - val_loss: 0.6822 - val_accuracy: 0.5394\n",
      "Epoch 371/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6938 - accuracy: 0.5588 - val_loss: 0.6815 - val_accuracy: 0.5333\n",
      "Epoch 372/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6846 - accuracy: 0.5265 - val_loss: 0.6836 - val_accuracy: 0.5515\n",
      "Epoch 373/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5706 - val_loss: 0.6845 - val_accuracy: 0.5394\n",
      "Epoch 374/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.5118 - val_loss: 0.6876 - val_accuracy: 0.5091\n",
      "Epoch 375/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6868 - accuracy: 0.5235 - val_loss: 0.6818 - val_accuracy: 0.5273\n",
      "Epoch 376/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.5529 - val_loss: 0.6826 - val_accuracy: 0.5394\n",
      "Epoch 377/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6881 - accuracy: 0.5529 - val_loss: 0.6819 - val_accuracy: 0.5273\n",
      "Epoch 378/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6893 - accuracy: 0.5471 - val_loss: 0.6820 - val_accuracy: 0.5455\n",
      "Epoch 379/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6898 - accuracy: 0.5500 - val_loss: 0.6828 - val_accuracy: 0.5394\n",
      "Epoch 380/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5235 - val_loss: 0.6834 - val_accuracy: 0.5636\n",
      "Epoch 381/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.5529 - val_loss: 0.6836 - val_accuracy: 0.5576\n",
      "Epoch 382/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6924 - accuracy: 0.4912 - val_loss: 0.6845 - val_accuracy: 0.5394\n",
      "Epoch 383/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6918 - accuracy: 0.5294 - val_loss: 0.6881 - val_accuracy: 0.5091\n",
      "Epoch 384/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5147 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 385/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6792 - accuracy: 0.5706 - val_loss: 0.6831 - val_accuracy: 0.5455\n",
      "Epoch 386/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5235 - val_loss: 0.6817 - val_accuracy: 0.5212\n",
      "Epoch 387/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6847 - val_accuracy: 0.5455\n",
      "Epoch 388/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6837 - accuracy: 0.5324 - val_loss: 0.6858 - val_accuracy: 0.5576\n",
      "Epoch 389/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5088 - val_loss: 0.6845 - val_accuracy: 0.5394\n",
      "Epoch 390/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6864 - accuracy: 0.5235 - val_loss: 0.6835 - val_accuracy: 0.5273\n",
      "Epoch 391/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6928 - accuracy: 0.5353 - val_loss: 0.6873 - val_accuracy: 0.5212\n",
      "Epoch 392/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6950 - accuracy: 0.5147 - val_loss: 0.6912 - val_accuracy: 0.5030\n",
      "Epoch 393/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.5441 - val_loss: 0.6881 - val_accuracy: 0.5091\n",
      "Epoch 394/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6888 - accuracy: 0.5353 - val_loss: 0.6848 - val_accuracy: 0.5576\n",
      "Epoch 395/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6953 - accuracy: 0.5412 - val_loss: 0.6904 - val_accuracy: 0.5091\n",
      "Epoch 396/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5441 - val_loss: 0.6981 - val_accuracy: 0.5030\n",
      "Epoch 397/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5294 - val_loss: 0.7001 - val_accuracy: 0.5152\n",
      "Epoch 398/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5206 - val_loss: 0.6821 - val_accuracy: 0.5515\n",
      "Epoch 399/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5500 - val_loss: 0.6818 - val_accuracy: 0.5636\n",
      "Epoch 400/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5559 - val_loss: 0.6818 - val_accuracy: 0.5333\n",
      "Epoch 401/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6908 - accuracy: 0.5206 - val_loss: 0.6845 - val_accuracy: 0.5333\n",
      "Epoch 402/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5647 - val_loss: 0.6827 - val_accuracy: 0.5394\n",
      "Epoch 403/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6872 - accuracy: 0.5176 - val_loss: 0.6817 - val_accuracy: 0.5273\n",
      "Epoch 404/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5353 - val_loss: 0.6817 - val_accuracy: 0.5394\n",
      "Epoch 405/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5618 - val_loss: 0.6817 - val_accuracy: 0.5333\n",
      "Epoch 406/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5382 - val_loss: 0.6817 - val_accuracy: 0.5333\n",
      "Epoch 407/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6906 - accuracy: 0.5265 - val_loss: 0.6819 - val_accuracy: 0.5515\n",
      "Epoch 408/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5206 - val_loss: 0.6830 - val_accuracy: 0.5455\n",
      "Epoch 409/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5265 - val_loss: 0.6860 - val_accuracy: 0.5455\n",
      "Epoch 410/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5706 - val_loss: 0.6834 - val_accuracy: 0.5394\n",
      "Epoch 411/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5471 - val_loss: 0.6868 - val_accuracy: 0.5394\n",
      "Epoch 412/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6898 - accuracy: 0.5441 - val_loss: 0.6864 - val_accuracy: 0.5515\n",
      "Epoch 413/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5353 - val_loss: 0.6862 - val_accuracy: 0.5576\n",
      "Epoch 414/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5559 - val_loss: 0.6854 - val_accuracy: 0.5636\n",
      "Epoch 415/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6897 - accuracy: 0.5588 - val_loss: 0.6892 - val_accuracy: 0.5091\n",
      "Epoch 416/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6896 - accuracy: 0.5382 - val_loss: 0.6898 - val_accuracy: 0.5091\n",
      "Epoch 417/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6884 - accuracy: 0.5353 - val_loss: 0.6870 - val_accuracy: 0.5212\n",
      "Epoch 418/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5529 - val_loss: 0.6911 - val_accuracy: 0.5091\n",
      "Epoch 419/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5794 - val_loss: 0.6912 - val_accuracy: 0.5091\n",
      "Epoch 420/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.5176 - val_loss: 0.6912 - val_accuracy: 0.5091\n",
      "Epoch 421/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5529 - val_loss: 0.6862 - val_accuracy: 0.5394\n",
      "Epoch 422/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6805 - accuracy: 0.5559 - val_loss: 0.6830 - val_accuracy: 0.5273\n",
      "Epoch 423/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6924 - accuracy: 0.5265 - val_loss: 0.6825 - val_accuracy: 0.5394\n",
      "Epoch 424/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6905 - val_accuracy: 0.5091\n",
      "Epoch 425/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5559 - val_loss: 0.6946 - val_accuracy: 0.5030\n",
      "Epoch 426/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.5088 - val_loss: 0.6930 - val_accuracy: 0.5697\n",
      "Epoch 463/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6825 - accuracy: 0.5588 - val_loss: 0.6873 - val_accuracy: 0.5576\n",
      "Epoch 464/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6895 - accuracy: 0.5235 - val_loss: 0.6846 - val_accuracy: 0.5455\n",
      "Epoch 465/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6911 - accuracy: 0.5412 - val_loss: 0.6842 - val_accuracy: 0.5576\n",
      "Epoch 466/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6887 - accuracy: 0.5265 - val_loss: 0.6840 - val_accuracy: 0.5394\n",
      "Epoch 467/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.5441 - val_loss: 0.6846 - val_accuracy: 0.5515\n",
      "Epoch 468/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5059 - val_loss: 0.6858 - val_accuracy: 0.5636\n",
      "Epoch 469/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6885 - accuracy: 0.5235 - val_loss: 0.6864 - val_accuracy: 0.5697\n",
      "Epoch 470/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6879 - accuracy: 0.5088 - val_loss: 0.6842 - val_accuracy: 0.5576\n",
      "Epoch 471/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6823 - accuracy: 0.5441 - val_loss: 0.6861 - val_accuracy: 0.5394\n",
      "Epoch 472/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6888 - accuracy: 0.5471 - val_loss: 0.6828 - val_accuracy: 0.5455\n",
      "Epoch 473/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6842 - accuracy: 0.5471 - val_loss: 0.6828 - val_accuracy: 0.5576\n",
      "Epoch 474/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6914 - accuracy: 0.5294 - val_loss: 0.6846 - val_accuracy: 0.5455\n",
      "Epoch 475/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6881 - accuracy: 0.5471 - val_loss: 0.6940 - val_accuracy: 0.5455\n",
      "Epoch 476/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5676 - val_loss: 0.6937 - val_accuracy: 0.5394\n",
      "Epoch 477/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5618 - val_loss: 0.6891 - val_accuracy: 0.5515\n",
      "Epoch 478/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.5441 - val_loss: 0.6845 - val_accuracy: 0.5515\n",
      "Epoch 479/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6831 - accuracy: 0.5382 - val_loss: 0.6845 - val_accuracy: 0.5455\n",
      "Epoch 480/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5559 - val_loss: 0.6826 - val_accuracy: 0.5576\n",
      "Epoch 481/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6872 - accuracy: 0.5147 - val_loss: 0.6825 - val_accuracy: 0.5333\n",
      "Epoch 482/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6865 - accuracy: 0.5235 - val_loss: 0.6851 - val_accuracy: 0.5394\n",
      "Epoch 483/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6921 - accuracy: 0.5118 - val_loss: 0.6819 - val_accuracy: 0.5333\n",
      "Epoch 484/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6910 - accuracy: 0.5353 - val_loss: 0.6845 - val_accuracy: 0.5455\n",
      "Epoch 485/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6863 - accuracy: 0.5353 - val_loss: 0.6854 - val_accuracy: 0.5636\n",
      "Epoch 486/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5294 - val_loss: 0.6823 - val_accuracy: 0.5333\n",
      "Epoch 487/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.5676 - val_loss: 0.6828 - val_accuracy: 0.5273\n",
      "Epoch 488/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6870 - accuracy: 0.5265 - val_loss: 0.6847 - val_accuracy: 0.5273\n",
      "Epoch 489/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6857 - accuracy: 0.5471 - val_loss: 0.6818 - val_accuracy: 0.5212\n",
      "Epoch 490/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.5324 - val_loss: 0.6825 - val_accuracy: 0.5394\n",
      "Epoch 491/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6868 - accuracy: 0.5382 - val_loss: 0.6822 - val_accuracy: 0.5394\n",
      "Epoch 492/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6933 - accuracy: 0.5441 - val_loss: 0.6892 - val_accuracy: 0.5091\n",
      "Epoch 493/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6847 - accuracy: 0.5294 - val_loss: 0.6840 - val_accuracy: 0.5455\n",
      "Epoch 494/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6851 - accuracy: 0.5529 - val_loss: 0.6824 - val_accuracy: 0.5333\n",
      "Epoch 495/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6913 - accuracy: 0.5412 - val_loss: 0.6847 - val_accuracy: 0.5455\n",
      "Epoch 496/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5324 - val_loss: 0.6906 - val_accuracy: 0.5212\n",
      "Epoch 497/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5324 - val_loss: 0.6934 - val_accuracy: 0.5091\n",
      "Epoch 498/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6877 - accuracy: 0.5412 - val_loss: 0.7007 - val_accuracy: 0.5030\n",
      "Epoch 499/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6901 - accuracy: 0.5059 - val_loss: 0.6963 - val_accuracy: 0.5091\n",
      "Epoch 500/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6870 - accuracy: 0.5412 - val_loss: 0.7066 - val_accuracy: 0.5030\n",
      "Epoch 501/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5265 - val_loss: 0.7100 - val_accuracy: 0.5030\n",
      "Epoch 502/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.5471 - val_loss: 0.7035 - val_accuracy: 0.5030\n",
      "Epoch 503/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5529 - val_loss: 0.7090 - val_accuracy: 0.5030\n",
      "Epoch 504/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5471 - val_loss: 0.7057 - val_accuracy: 0.5030\n",
      "Epoch 505/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6789 - accuracy: 0.5735 - val_loss: 0.6962 - val_accuracy: 0.5152\n",
      "Epoch 506/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6802 - accuracy: 0.5794 - val_loss: 0.6907 - val_accuracy: 0.5212\n",
      "Epoch 507/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6880 - accuracy: 0.5382 - val_loss: 0.6952 - val_accuracy: 0.5152\n",
      "Epoch 508/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6889 - accuracy: 0.5500 - val_loss: 0.7099 - val_accuracy: 0.5030\n",
      "Epoch 509/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6895 - accuracy: 0.5235 - val_loss: 0.7105 - val_accuracy: 0.4970\n",
      "Epoch 510/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5618 - val_loss: 0.7103 - val_accuracy: 0.4970\n",
      "Epoch 511/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6901 - accuracy: 0.4882 - val_loss: 0.7188 - val_accuracy: 0.5030\n",
      "Epoch 512/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5176 - val_loss: 0.6958 - val_accuracy: 0.5091\n",
      "Epoch 513/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6858 - accuracy: 0.5382 - val_loss: 0.6832 - val_accuracy: 0.5636\n",
      "Epoch 514/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.5588 - val_loss: 0.6851 - val_accuracy: 0.5515\n",
      "Epoch 515/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5265 - val_loss: 0.6876 - val_accuracy: 0.5394\n",
      "Epoch 516/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6912 - accuracy: 0.4794 - val_loss: 0.6850 - val_accuracy: 0.5455\n",
      "Epoch 517/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6847 - accuracy: 0.5324 - val_loss: 0.6864 - val_accuracy: 0.5515\n",
      "Epoch 518/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6854 - accuracy: 0.5588 - val_loss: 0.6873 - val_accuracy: 0.5455\n",
      "Epoch 519/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5088 - val_loss: 0.6830 - val_accuracy: 0.5394\n",
      "Epoch 520/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6947 - accuracy: 0.5029 - val_loss: 0.6847 - val_accuracy: 0.5636\n",
      "Epoch 521/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6854 - accuracy: 0.5412 - val_loss: 0.6830 - val_accuracy: 0.5576\n",
      "Epoch 522/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5353 - val_loss: 0.6834 - val_accuracy: 0.5455\n",
      "Epoch 523/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6831 - accuracy: 0.5529 - val_loss: 0.6833 - val_accuracy: 0.5394\n",
      "Epoch 524/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.5441 - val_loss: 0.6833 - val_accuracy: 0.5515\n",
      "Epoch 525/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6857 - accuracy: 0.5618 - val_loss: 0.6835 - val_accuracy: 0.5515\n",
      "Epoch 526/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6870 - accuracy: 0.5500 - val_loss: 0.6834 - val_accuracy: 0.5515\n",
      "Epoch 527/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6832 - accuracy: 0.5324 - val_loss: 0.6829 - val_accuracy: 0.5394\n",
      "Epoch 528/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6897 - accuracy: 0.5294 - val_loss: 0.6838 - val_accuracy: 0.5394\n",
      "Epoch 529/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6849 - accuracy: 0.5029 - val_loss: 0.6822 - val_accuracy: 0.5333\n",
      "Epoch 530/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6918 - accuracy: 0.5618 - val_loss: 0.6829 - val_accuracy: 0.5515\n",
      "Epoch 531/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6807 - accuracy: 0.5382 - val_loss: 0.6838 - val_accuracy: 0.5394\n",
      "Epoch 532/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5471 - val_loss: 0.6834 - val_accuracy: 0.5636\n",
      "Epoch 533/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6894 - accuracy: 0.5441 - val_loss: 0.6838 - val_accuracy: 0.5455\n",
      "Epoch 534/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6821 - accuracy: 0.5588 - val_loss: 0.6843 - val_accuracy: 0.5394\n",
      "Epoch 535/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6829 - accuracy: 0.5441 - val_loss: 0.6826 - val_accuracy: 0.5333\n",
      "Epoch 536/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6883 - accuracy: 0.5118 - val_loss: 0.6844 - val_accuracy: 0.5515\n",
      "Epoch 537/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6852 - accuracy: 0.5324 - val_loss: 0.6935 - val_accuracy: 0.5152\n",
      "Epoch 538/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5441 - val_loss: 0.6888 - val_accuracy: 0.5515\n",
      "Epoch 539/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6860 - accuracy: 0.5529 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 540/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6893 - accuracy: 0.5618 - val_loss: 0.7087 - val_accuracy: 0.5030\n",
      "Epoch 541/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.5676 - val_loss: 0.6883 - val_accuracy: 0.5455\n",
      "Epoch 542/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5324 - val_loss: 0.6859 - val_accuracy: 0.5636\n",
      "Epoch 543/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6924 - accuracy: 0.5147 - val_loss: 0.6929 - val_accuracy: 0.5152\n",
      "Epoch 544/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6844 - accuracy: 0.5647 - val_loss: 0.6870 - val_accuracy: 0.5515\n",
      "Epoch 545/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6858 - accuracy: 0.5618 - val_loss: 0.6851 - val_accuracy: 0.5576\n",
      "Epoch 546/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.5588 - val_loss: 0.6861 - val_accuracy: 0.5636\n",
      "Epoch 547/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6863 - accuracy: 0.5588 - val_loss: 0.6826 - val_accuracy: 0.5394\n",
      "Epoch 548/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6856 - accuracy: 0.5353 - val_loss: 0.6828 - val_accuracy: 0.5394\n",
      "Epoch 549/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5353 - val_loss: 0.6844 - val_accuracy: 0.5515\n",
      "Epoch 550/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6867 - accuracy: 0.5353 - val_loss: 0.6834 - val_accuracy: 0.5515\n",
      "Epoch 551/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.5382 - val_loss: 0.6862 - val_accuracy: 0.5394\n",
      "Epoch 552/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6840 - accuracy: 0.5559 - val_loss: 0.6859 - val_accuracy: 0.5636\n",
      "Epoch 553/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6831 - accuracy: 0.5618 - val_loss: 0.6839 - val_accuracy: 0.5515\n",
      "Epoch 554/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6897 - accuracy: 0.5029 - val_loss: 0.6831 - val_accuracy: 0.5394\n",
      "Epoch 555/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6891 - accuracy: 0.5294 - val_loss: 0.6829 - val_accuracy: 0.5394\n",
      "Epoch 556/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6876 - accuracy: 0.5529 - val_loss: 0.6833 - val_accuracy: 0.5515\n",
      "Epoch 557/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5353 - val_loss: 0.6839 - val_accuracy: 0.5455\n",
      "Epoch 558/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5441 - val_loss: 0.6852 - val_accuracy: 0.5394\n",
      "Epoch 559/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6825 - accuracy: 0.5618 - val_loss: 0.6844 - val_accuracy: 0.5455\n",
      "Epoch 560/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5206 - val_loss: 0.6853 - val_accuracy: 0.5576\n",
      "Epoch 561/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.5382 - val_loss: 0.6889 - val_accuracy: 0.5273\n",
      "Epoch 562/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6872 - accuracy: 0.5294 - val_loss: 0.6876 - val_accuracy: 0.5152\n",
      "Epoch 563/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6913 - accuracy: 0.5059 - val_loss: 0.6863 - val_accuracy: 0.5333\n",
      "Epoch 564/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5471 - val_loss: 0.6861 - val_accuracy: 0.5576\n",
      "Epoch 565/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5353 - val_loss: 0.6846 - val_accuracy: 0.5697\n",
      "Epoch 566/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5147 - val_loss: 0.6852 - val_accuracy: 0.5455\n",
      "Epoch 567/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5471 - val_loss: 0.6881 - val_accuracy: 0.5091\n",
      "Epoch 568/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6864 - accuracy: 0.5353 - val_loss: 0.6885 - val_accuracy: 0.5212\n",
      "Epoch 569/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5412 - val_loss: 0.6966 - val_accuracy: 0.5030\n",
      "Epoch 570/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5412 - val_loss: 0.6844 - val_accuracy: 0.5394\n",
      "Epoch 571/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5706 - val_loss: 0.6860 - val_accuracy: 0.5515\n",
      "Epoch 572/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5382 - val_loss: 0.6875 - val_accuracy: 0.5818\n",
      "Epoch 573/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5588 - val_loss: 0.7021 - val_accuracy: 0.5152\n",
      "Epoch 574/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6888 - accuracy: 0.5441 - val_loss: 0.6970 - val_accuracy: 0.5091\n",
      "Epoch 575/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6847 - accuracy: 0.5294 - val_loss: 0.6895 - val_accuracy: 0.5273\n",
      "Epoch 576/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.4971 - val_loss: 0.6994 - val_accuracy: 0.5152\n",
      "Epoch 577/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6870 - accuracy: 0.5559 - val_loss: 0.6998 - val_accuracy: 0.5152\n",
      "Epoch 578/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6839 - accuracy: 0.5324 - val_loss: 0.6977 - val_accuracy: 0.5152\n",
      "Epoch 579/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6848 - accuracy: 0.5500 - val_loss: 0.6901 - val_accuracy: 0.5152\n",
      "Epoch 580/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5500 - val_loss: 0.6895 - val_accuracy: 0.5636\n",
      "Epoch 581/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5118 - val_loss: 0.6864 - val_accuracy: 0.5455\n",
      "Epoch 582/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5412 - val_loss: 0.6853 - val_accuracy: 0.5818\n",
      "Epoch 583/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5441 - val_loss: 0.6847 - val_accuracy: 0.5455\n",
      "Epoch 584/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6841 - val_accuracy: 0.5333\n",
      "Epoch 585/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6909 - accuracy: 0.5382 - val_loss: 0.6832 - val_accuracy: 0.5333\n",
      "Epoch 586/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6873 - accuracy: 0.5500 - val_loss: 0.6863 - val_accuracy: 0.5697\n",
      "Epoch 587/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5176 - val_loss: 0.6873 - val_accuracy: 0.5455\n",
      "Epoch 588/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5500 - val_loss: 0.6829 - val_accuracy: 0.5152\n",
      "Epoch 589/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5471 - val_loss: 0.6829 - val_accuracy: 0.5333\n",
      "Epoch 590/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5412 - val_loss: 0.6856 - val_accuracy: 0.5636\n",
      "Epoch 591/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5676 - val_loss: 0.6877 - val_accuracy: 0.5394\n",
      "Epoch 592/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5147 - val_loss: 0.6830 - val_accuracy: 0.5455\n",
      "Epoch 593/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6868 - accuracy: 0.5265 - val_loss: 0.6831 - val_accuracy: 0.5333\n",
      "Epoch 594/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6894 - accuracy: 0.5471 - val_loss: 0.6864 - val_accuracy: 0.5697\n",
      "Epoch 595/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6879 - accuracy: 0.5471 - val_loss: 0.6840 - val_accuracy: 0.5333\n",
      "Epoch 596/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5647 - val_loss: 0.6861 - val_accuracy: 0.5576\n",
      "Epoch 597/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6982 - val_accuracy: 0.5091\n",
      "Epoch 598/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5588 - val_loss: 0.6953 - val_accuracy: 0.5152\n",
      "Epoch 599/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.5324 - val_loss: 0.6864 - val_accuracy: 0.5576\n",
      "Epoch 600/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5500 - val_loss: 0.6878 - val_accuracy: 0.5455\n",
      "Epoch 601/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6819 - accuracy: 0.5412 - val_loss: 0.6853 - val_accuracy: 0.5576\n",
      "Epoch 602/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5294 - val_loss: 0.6836 - val_accuracy: 0.5333\n",
      "Epoch 603/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6901 - accuracy: 0.5147 - val_loss: 0.6909 - val_accuracy: 0.5152\n",
      "Epoch 604/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5324 - val_loss: 0.6865 - val_accuracy: 0.5576\n",
      "Epoch 605/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5588 - val_loss: 0.6828 - val_accuracy: 0.5333\n",
      "Epoch 606/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5235 - val_loss: 0.6833 - val_accuracy: 0.5455\n",
      "Epoch 607/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5412 - val_loss: 0.6858 - val_accuracy: 0.5333\n",
      "Epoch 608/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6894 - accuracy: 0.5500 - val_loss: 0.6871 - val_accuracy: 0.5394\n",
      "Epoch 609/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.5382 - val_loss: 0.6864 - val_accuracy: 0.5394\n",
      "Epoch 610/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5206 - val_loss: 0.6839 - val_accuracy: 0.5697\n",
      "Epoch 611/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5235 - val_loss: 0.6871 - val_accuracy: 0.5455\n",
      "Epoch 612/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5500 - val_loss: 0.6838 - val_accuracy: 0.5455\n",
      "Epoch 613/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5382 - val_loss: 0.6833 - val_accuracy: 0.5394\n",
      "Epoch 614/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5471 - val_loss: 0.6857 - val_accuracy: 0.5758\n",
      "Epoch 615/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6844 - accuracy: 0.5206 - val_loss: 0.6848 - val_accuracy: 0.5455\n",
      "Epoch 616/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5412 - val_loss: 0.6824 - val_accuracy: 0.5212\n",
      "Epoch 617/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5353 - val_loss: 0.6825 - val_accuracy: 0.5333\n",
      "Epoch 618/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5441 - val_loss: 0.6836 - val_accuracy: 0.5333\n",
      "Epoch 619/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6885 - accuracy: 0.5088 - val_loss: 0.6834 - val_accuracy: 0.5818\n",
      "Epoch 620/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5588 - val_loss: 0.6831 - val_accuracy: 0.5333\n",
      "Epoch 621/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5382 - val_loss: 0.6833 - val_accuracy: 0.5394\n",
      "Epoch 622/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5765 - val_loss: 0.6828 - val_accuracy: 0.5455\n",
      "Epoch 623/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5324 - val_loss: 0.6847 - val_accuracy: 0.5576\n",
      "Epoch 624/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5794 - val_loss: 0.6841 - val_accuracy: 0.5455\n",
      "Epoch 625/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5441 - val_loss: 0.6842 - val_accuracy: 0.5636\n",
      "Epoch 626/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5382 - val_loss: 0.6841 - val_accuracy: 0.5394\n",
      "Epoch 627/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6889 - accuracy: 0.5588 - val_loss: 0.6834 - val_accuracy: 0.5394\n",
      "Epoch 628/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6856 - accuracy: 0.5294 - val_loss: 0.6876 - val_accuracy: 0.5152\n",
      "Epoch 629/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5206 - val_loss: 0.6838 - val_accuracy: 0.5455\n",
      "Epoch 630/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6855 - accuracy: 0.5676 - val_loss: 0.6863 - val_accuracy: 0.5394\n",
      "Epoch 631/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6914 - accuracy: 0.5735 - val_loss: 0.6840 - val_accuracy: 0.5455\n",
      "Epoch 632/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5382 - val_loss: 0.6843 - val_accuracy: 0.5394\n",
      "Epoch 633/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5500 - val_loss: 0.6839 - val_accuracy: 0.5333\n",
      "Epoch 634/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5235 - val_loss: 0.6837 - val_accuracy: 0.5333\n",
      "Epoch 635/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5559 - val_loss: 0.6835 - val_accuracy: 0.5394\n",
      "Epoch 636/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5353 - val_loss: 0.6859 - val_accuracy: 0.5576\n",
      "Epoch 637/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6874 - accuracy: 0.5353 - val_loss: 0.6876 - val_accuracy: 0.5636\n",
      "Epoch 638/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5412 - val_loss: 0.6854 - val_accuracy: 0.5515\n",
      "Epoch 639/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6911 - accuracy: 0.5235 - val_loss: 0.6836 - val_accuracy: 0.5333\n",
      "Epoch 640/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5471 - val_loss: 0.6848 - val_accuracy: 0.5455\n",
      "Epoch 641/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6880 - accuracy: 0.5176 - val_loss: 0.6835 - val_accuracy: 0.5333\n",
      "Epoch 642/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6888 - accuracy: 0.5647 - val_loss: 0.6845 - val_accuracy: 0.5636\n",
      "Epoch 643/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.5324 - val_loss: 0.6851 - val_accuracy: 0.5394\n",
      "Epoch 644/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5441 - val_loss: 0.6846 - val_accuracy: 0.5394\n",
      "Epoch 645/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5176 - val_loss: 0.6848 - val_accuracy: 0.5212\n",
      "Epoch 646/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.5088 - val_loss: 0.6860 - val_accuracy: 0.5455\n",
      "Epoch 647/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5500 - val_loss: 0.6855 - val_accuracy: 0.5455\n",
      "Epoch 648/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.5441 - val_loss: 0.6835 - val_accuracy: 0.5455\n",
      "Epoch 649/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5353 - val_loss: 0.6933 - val_accuracy: 0.5091\n",
      "Epoch 650/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5176 - val_loss: 0.6858 - val_accuracy: 0.5576\n",
      "Epoch 651/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6872 - accuracy: 0.5588 - val_loss: 0.6836 - val_accuracy: 0.5394\n",
      "Epoch 652/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5529 - val_loss: 0.6857 - val_accuracy: 0.5515\n",
      "Epoch 653/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6884 - accuracy: 0.5294 - val_loss: 0.6853 - val_accuracy: 0.5515\n",
      "Epoch 654/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5412 - val_loss: 0.6841 - val_accuracy: 0.5273\n",
      "Epoch 655/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6888 - accuracy: 0.5382 - val_loss: 0.6841 - val_accuracy: 0.5333\n",
      "Epoch 656/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5618 - val_loss: 0.6845 - val_accuracy: 0.5212\n",
      "Epoch 657/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.5118 - val_loss: 0.6844 - val_accuracy: 0.5455\n",
      "Epoch 658/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5500 - val_loss: 0.6863 - val_accuracy: 0.5455\n",
      "Epoch 659/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6849 - accuracy: 0.5382 - val_loss: 0.6856 - val_accuracy: 0.5455\n",
      "Epoch 660/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.5265 - val_loss: 0.6859 - val_accuracy: 0.5455\n",
      "Epoch 661/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5206 - val_loss: 0.6853 - val_accuracy: 0.5515\n",
      "Epoch 662/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.5235 - val_loss: 0.6881 - val_accuracy: 0.5152\n",
      "Epoch 663/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5412 - val_loss: 0.6849 - val_accuracy: 0.5455\n",
      "Epoch 664/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5471 - val_loss: 0.6845 - val_accuracy: 0.5212\n",
      "Epoch 665/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5588 - val_loss: 0.6870 - val_accuracy: 0.5212\n",
      "Epoch 666/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6904 - accuracy: 0.5176 - val_loss: 0.6891 - val_accuracy: 0.5212\n",
      "Epoch 667/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5676 - val_loss: 0.6849 - val_accuracy: 0.5455\n",
      "Epoch 668/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6884 - accuracy: 0.5324 - val_loss: 0.6855 - val_accuracy: 0.5333\n",
      "Epoch 669/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.5235 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 670/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5471 - val_loss: 0.6858 - val_accuracy: 0.5515\n",
      "Epoch 671/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5500 - val_loss: 0.6868 - val_accuracy: 0.5394\n",
      "Epoch 672/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5265 - val_loss: 0.6870 - val_accuracy: 0.5515\n",
      "Epoch 673/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.5029 - val_loss: 0.6875 - val_accuracy: 0.5515\n",
      "Epoch 674/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5265 - val_loss: 0.6858 - val_accuracy: 0.5455\n",
      "Epoch 675/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5353 - val_loss: 0.6878 - val_accuracy: 0.5576\n",
      "Epoch 676/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5441 - val_loss: 0.6905 - val_accuracy: 0.5091\n",
      "Epoch 677/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5647 - val_loss: 0.6846 - val_accuracy: 0.5394\n",
      "Epoch 678/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5500 - val_loss: 0.6839 - val_accuracy: 0.5394\n",
      "Epoch 679/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6837 - accuracy: 0.5647 - val_loss: 0.6893 - val_accuracy: 0.5030\n",
      "Epoch 680/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6858 - accuracy: 0.5176 - val_loss: 0.6926 - val_accuracy: 0.5091\n",
      "Epoch 681/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6877 - accuracy: 0.5412 - val_loss: 0.6841 - val_accuracy: 0.5273\n",
      "Epoch 682/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6899 - accuracy: 0.5412 - val_loss: 0.6847 - val_accuracy: 0.5152\n",
      "Epoch 683/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.5235 - val_loss: 0.6854 - val_accuracy: 0.5394\n",
      "Epoch 684/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6831 - accuracy: 0.5588 - val_loss: 0.6856 - val_accuracy: 0.5333\n",
      "Epoch 685/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5441 - val_loss: 0.6856 - val_accuracy: 0.5455\n",
      "Epoch 686/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6824 - accuracy: 0.5471 - val_loss: 0.6861 - val_accuracy: 0.5212\n",
      "Epoch 687/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5559 - val_loss: 0.6851 - val_accuracy: 0.5455\n",
      "Epoch 688/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6898 - accuracy: 0.5118 - val_loss: 0.6846 - val_accuracy: 0.5455\n",
      "Epoch 689/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6853 - accuracy: 0.5353 - val_loss: 0.6846 - val_accuracy: 0.5333\n",
      "Epoch 690/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6874 - accuracy: 0.5559 - val_loss: 0.6843 - val_accuracy: 0.5212\n",
      "Epoch 691/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6893 - accuracy: 0.5000 - val_loss: 0.6876 - val_accuracy: 0.5273\n",
      "Epoch 692/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6842 - accuracy: 0.5382 - val_loss: 0.6889 - val_accuracy: 0.5576\n",
      "Epoch 693/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6885 - accuracy: 0.5529 - val_loss: 0.6894 - val_accuracy: 0.5030\n",
      "Epoch 694/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6892 - accuracy: 0.5176 - val_loss: 0.6907 - val_accuracy: 0.5152\n",
      "Epoch 695/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5441 - val_loss: 0.6932 - val_accuracy: 0.5333\n",
      "Epoch 696/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5559 - val_loss: 0.6877 - val_accuracy: 0.5636\n",
      "Epoch 697/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5471 - val_loss: 0.6859 - val_accuracy: 0.5394\n",
      "Epoch 698/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5382 - val_loss: 0.6854 - val_accuracy: 0.5515\n",
      "Epoch 699/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5500 - val_loss: 0.6861 - val_accuracy: 0.5212\n",
      "Epoch 700/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5265 - val_loss: 0.6855 - val_accuracy: 0.5394\n",
      "Epoch 701/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6829 - accuracy: 0.5618 - val_loss: 0.6868 - val_accuracy: 0.5455\n",
      "Epoch 702/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6832 - accuracy: 0.5294 - val_loss: 0.6836 - val_accuracy: 0.5394\n",
      "Epoch 703/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5235 - val_loss: 0.6864 - val_accuracy: 0.5515\n",
      "Epoch 704/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5118 - val_loss: 0.6876 - val_accuracy: 0.5697\n",
      "Epoch 705/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.5118 - val_loss: 0.6873 - val_accuracy: 0.5394\n",
      "Epoch 706/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5618 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 707/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5382 - val_loss: 0.6900 - val_accuracy: 0.5152\n",
      "Epoch 708/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5735 - val_loss: 0.6922 - val_accuracy: 0.5091\n",
      "Epoch 709/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6850 - accuracy: 0.5412 - val_loss: 0.6893 - val_accuracy: 0.5394\n",
      "Epoch 710/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5471 - val_loss: 0.6893 - val_accuracy: 0.5273\n",
      "Epoch 711/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5765 - val_loss: 0.6890 - val_accuracy: 0.5212\n",
      "Epoch 712/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6807 - accuracy: 0.5588 - val_loss: 0.6863 - val_accuracy: 0.5455\n",
      "Epoch 713/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6854 - accuracy: 0.5559 - val_loss: 0.6857 - val_accuracy: 0.5697\n",
      "Epoch 714/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5147 - val_loss: 0.6874 - val_accuracy: 0.5394\n",
      "Epoch 715/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6780 - accuracy: 0.5588 - val_loss: 0.6869 - val_accuracy: 0.5333\n",
      "Epoch 716/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5559 - val_loss: 0.6850 - val_accuracy: 0.5576\n",
      "Epoch 717/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5412 - val_loss: 0.6852 - val_accuracy: 0.5515\n",
      "Epoch 718/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5235 - val_loss: 0.6871 - val_accuracy: 0.5636\n",
      "Epoch 719/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5353 - val_loss: 0.6830 - val_accuracy: 0.5636\n",
      "Epoch 720/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6844 - accuracy: 0.5294 - val_loss: 0.6825 - val_accuracy: 0.5576\n",
      "Epoch 721/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6865 - accuracy: 0.5294 - val_loss: 0.6844 - val_accuracy: 0.5394\n",
      "Epoch 722/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5676 - val_loss: 0.6848 - val_accuracy: 0.5455\n",
      "Epoch 723/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6841 - accuracy: 0.5118 - val_loss: 0.6852 - val_accuracy: 0.5576\n",
      "Epoch 724/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6849 - accuracy: 0.5000 - val_loss: 0.6871 - val_accuracy: 0.5091\n",
      "Epoch 725/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6882 - accuracy: 0.5471 - val_loss: 0.6843 - val_accuracy: 0.5455\n",
      "Epoch 726/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6822 - accuracy: 0.5441 - val_loss: 0.6842 - val_accuracy: 0.5455\n",
      "Epoch 727/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5324 - val_loss: 0.6847 - val_accuracy: 0.5515\n",
      "Epoch 728/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5471 - val_loss: 0.6873 - val_accuracy: 0.5152\n",
      "Epoch 729/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6827 - accuracy: 0.5324 - val_loss: 0.6859 - val_accuracy: 0.5515\n",
      "Epoch 730/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5235 - val_loss: 0.6879 - val_accuracy: 0.5212\n",
      "Epoch 731/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5794 - val_loss: 0.6856 - val_accuracy: 0.5394\n",
      "Epoch 732/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6764 - accuracy: 0.5618 - val_loss: 0.6840 - val_accuracy: 0.5333\n",
      "Epoch 733/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5382 - val_loss: 0.6846 - val_accuracy: 0.5394\n",
      "Epoch 734/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5088 - val_loss: 0.6854 - val_accuracy: 0.5455\n",
      "Epoch 735/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6814 - accuracy: 0.5147 - val_loss: 0.6867 - val_accuracy: 0.5636\n",
      "Epoch 736/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5265 - val_loss: 0.6841 - val_accuracy: 0.5273\n",
      "Epoch 737/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5500 - val_loss: 0.6850 - val_accuracy: 0.5455\n",
      "Epoch 738/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6874 - accuracy: 0.5265 - val_loss: 0.6901 - val_accuracy: 0.5273\n",
      "Epoch 739/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5412 - val_loss: 0.6858 - val_accuracy: 0.5455\n",
      "Epoch 740/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6848 - accuracy: 0.5441 - val_loss: 0.6860 - val_accuracy: 0.5515\n",
      "Epoch 741/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5559 - val_loss: 0.6899 - val_accuracy: 0.5030\n",
      "Epoch 742/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5382 - val_loss: 0.6894 - val_accuracy: 0.4970\n",
      "Epoch 743/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6875 - accuracy: 0.5441 - val_loss: 0.6894 - val_accuracy: 0.4970\n",
      "Epoch 744/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6880 - accuracy: 0.5324 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
      "Epoch 745/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6843 - accuracy: 0.5471 - val_loss: 0.6965 - val_accuracy: 0.5091\n",
      "Epoch 746/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.5441 - val_loss: 0.6881 - val_accuracy: 0.5455\n",
      "Epoch 747/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5618 - val_loss: 0.6850 - val_accuracy: 0.5394\n",
      "Epoch 748/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6872 - accuracy: 0.5382 - val_loss: 0.6862 - val_accuracy: 0.5515\n",
      "Epoch 749/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5147 - val_loss: 0.6852 - val_accuracy: 0.5515\n",
      "Epoch 750/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5147 - val_loss: 0.6834 - val_accuracy: 0.5333\n",
      "Epoch 751/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5500 - val_loss: 0.6839 - val_accuracy: 0.5333\n",
      "Epoch 752/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5824 - val_loss: 0.6853 - val_accuracy: 0.5152\n",
      "Epoch 753/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6837 - accuracy: 0.5471 - val_loss: 0.6863 - val_accuracy: 0.5455\n",
      "Epoch 754/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5353 - val_loss: 0.6885 - val_accuracy: 0.5455\n",
      "Epoch 755/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6878 - accuracy: 0.5176 - val_loss: 0.6859 - val_accuracy: 0.5636\n",
      "Epoch 756/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6859 - accuracy: 0.5412 - val_loss: 0.6845 - val_accuracy: 0.5212\n",
      "Epoch 757/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5412 - val_loss: 0.6846 - val_accuracy: 0.5212\n",
      "Epoch 758/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5618 - val_loss: 0.6847 - val_accuracy: 0.5212\n",
      "Epoch 759/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5412 - val_loss: 0.6853 - val_accuracy: 0.5091\n",
      "Epoch 760/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5324 - val_loss: 0.6861 - val_accuracy: 0.5576\n",
      "Epoch 761/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5441 - val_loss: 0.6871 - val_accuracy: 0.5091\n",
      "Epoch 762/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6844 - accuracy: 0.5029 - val_loss: 0.6871 - val_accuracy: 0.5212\n",
      "Epoch 763/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5618 - val_loss: 0.6869 - val_accuracy: 0.5636\n",
      "Epoch 764/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5559 - val_loss: 0.6877 - val_accuracy: 0.5636\n",
      "Epoch 765/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5294 - val_loss: 0.6875 - val_accuracy: 0.5394\n",
      "Epoch 766/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5500 - val_loss: 0.6871 - val_accuracy: 0.5758\n",
      "Epoch 767/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5353 - val_loss: 0.6895 - val_accuracy: 0.5515\n",
      "Epoch 768/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6861 - accuracy: 0.5441 - val_loss: 0.6932 - val_accuracy: 0.4848\n",
      "Epoch 769/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6875 - accuracy: 0.5176 - val_loss: 0.6942 - val_accuracy: 0.4909\n",
      "Epoch 770/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5618 - val_loss: 0.6913 - val_accuracy: 0.4970\n",
      "Epoch 771/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5765 - val_loss: 0.6891 - val_accuracy: 0.5455\n",
      "Epoch 772/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5588 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 773/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5588 - val_loss: 0.6880 - val_accuracy: 0.5273\n",
      "Epoch 774/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5294 - val_loss: 0.6864 - val_accuracy: 0.4970\n",
      "Epoch 775/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5588 - val_loss: 0.6861 - val_accuracy: 0.5273\n",
      "Epoch 776/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5647 - val_loss: 0.6870 - val_accuracy: 0.5515\n",
      "Epoch 777/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5382 - val_loss: 0.6873 - val_accuracy: 0.5515\n",
      "Epoch 778/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6783 - accuracy: 0.5735 - val_loss: 0.6888 - val_accuracy: 0.5273\n",
      "Epoch 779/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5647 - val_loss: 0.6875 - val_accuracy: 0.5212\n",
      "Epoch 780/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5588 - val_loss: 0.6874 - val_accuracy: 0.5152\n",
      "Epoch 781/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5559 - val_loss: 0.6868 - val_accuracy: 0.5212\n",
      "Epoch 782/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5353 - val_loss: 0.6963 - val_accuracy: 0.5152\n",
      "Epoch 783/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6802 - accuracy: 0.5588 - val_loss: 0.7028 - val_accuracy: 0.5152\n",
      "Epoch 784/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.5441 - val_loss: 0.7026 - val_accuracy: 0.5152\n",
      "Epoch 785/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.5324 - val_loss: 0.7009 - val_accuracy: 0.5152\n",
      "Epoch 786/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5618 - val_loss: 0.6953 - val_accuracy: 0.5152\n",
      "Epoch 787/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5471 - val_loss: 0.7028 - val_accuracy: 0.5152\n",
      "Epoch 788/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6881 - accuracy: 0.5118 - val_loss: 0.6991 - val_accuracy: 0.5152\n",
      "Epoch 789/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5235 - val_loss: 0.7033 - val_accuracy: 0.5152\n",
      "Epoch 790/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5294 - val_loss: 0.6879 - val_accuracy: 0.5152\n",
      "Epoch 791/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6835 - accuracy: 0.5618 - val_loss: 0.6881 - val_accuracy: 0.5152\n",
      "Epoch 792/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5441 - val_loss: 0.6898 - val_accuracy: 0.5212\n",
      "Epoch 793/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.5176 - val_loss: 0.6892 - val_accuracy: 0.5152\n",
      "Epoch 794/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5853 - val_loss: 0.6913 - val_accuracy: 0.5152\n",
      "Epoch 795/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6817 - accuracy: 0.5618 - val_loss: 0.6904 - val_accuracy: 0.5152\n",
      "Epoch 796/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5735 - val_loss: 0.6871 - val_accuracy: 0.5152\n",
      "Epoch 797/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5412 - val_loss: 0.6867 - val_accuracy: 0.5333\n",
      "Epoch 798/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6852 - accuracy: 0.5147 - val_loss: 0.6902 - val_accuracy: 0.5030\n",
      "Epoch 799/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6899 - accuracy: 0.5559 - val_loss: 0.6851 - val_accuracy: 0.5333\n",
      "Epoch 800/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6779 - accuracy: 0.5676 - val_loss: 0.6870 - val_accuracy: 0.5394\n",
      "Epoch 801/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5853 - val_loss: 0.6850 - val_accuracy: 0.5879\n",
      "Epoch 802/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5588 - val_loss: 0.6853 - val_accuracy: 0.5394\n",
      "Epoch 803/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6797 - accuracy: 0.5588 - val_loss: 0.6845 - val_accuracy: 0.5515\n",
      "Epoch 804/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6824 - accuracy: 0.5559 - val_loss: 0.6870 - val_accuracy: 0.5455\n",
      "Epoch 805/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5382 - val_loss: 0.6863 - val_accuracy: 0.5455\n",
      "Epoch 806/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5588 - val_loss: 0.6844 - val_accuracy: 0.5212\n",
      "Epoch 807/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5206 - val_loss: 0.6847 - val_accuracy: 0.5515\n",
      "Epoch 808/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5618 - val_loss: 0.6855 - val_accuracy: 0.5273\n",
      "Epoch 809/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6884 - accuracy: 0.5206 - val_loss: 0.6913 - val_accuracy: 0.5212\n",
      "Epoch 810/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6858 - accuracy: 0.5353 - val_loss: 0.6936 - val_accuracy: 0.5152\n",
      "Epoch 811/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6841 - accuracy: 0.5559 - val_loss: 0.6908 - val_accuracy: 0.5152\n",
      "Epoch 812/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5324 - val_loss: 0.6913 - val_accuracy: 0.5152\n",
      "Epoch 813/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5324 - val_loss: 0.6888 - val_accuracy: 0.5515\n",
      "Epoch 814/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5706 - val_loss: 0.6857 - val_accuracy: 0.5515\n",
      "Epoch 815/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5529 - val_loss: 0.6860 - val_accuracy: 0.5030\n",
      "Epoch 816/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5676 - val_loss: 0.6852 - val_accuracy: 0.5879\n",
      "Epoch 817/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5529 - val_loss: 0.6852 - val_accuracy: 0.5636\n",
      "Epoch 818/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5853 - val_loss: 0.6849 - val_accuracy: 0.5333\n",
      "Epoch 819/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5412 - val_loss: 0.6849 - val_accuracy: 0.5697\n",
      "Epoch 820/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5676 - val_loss: 0.6850 - val_accuracy: 0.5697\n",
      "Epoch 821/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6790 - accuracy: 0.5647 - val_loss: 0.6849 - val_accuracy: 0.5576\n",
      "Epoch 822/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5471 - val_loss: 0.6866 - val_accuracy: 0.5515\n",
      "Epoch 823/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5382 - val_loss: 0.6879 - val_accuracy: 0.5212\n",
      "Epoch 824/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6803 - accuracy: 0.5529 - val_loss: 0.6856 - val_accuracy: 0.5636\n",
      "Epoch 825/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6888 - accuracy: 0.5471 - val_loss: 0.6862 - val_accuracy: 0.5818\n",
      "Epoch 826/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5353 - val_loss: 0.6871 - val_accuracy: 0.5091\n",
      "Epoch 827/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6845 - accuracy: 0.5618 - val_loss: 0.6903 - val_accuracy: 0.5152\n",
      "Epoch 828/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5529 - val_loss: 0.6993 - val_accuracy: 0.5152\n",
      "Epoch 829/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5676 - val_loss: 0.6961 - val_accuracy: 0.5152\n",
      "Epoch 830/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6858 - accuracy: 0.5412 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 831/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5412 - val_loss: 0.6883 - val_accuracy: 0.4909\n",
      "Epoch 832/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5206 - val_loss: 0.6846 - val_accuracy: 0.5515\n",
      "Epoch 833/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6863 - accuracy: 0.5206 - val_loss: 0.6848 - val_accuracy: 0.5939\n",
      "Epoch 834/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5265 - val_loss: 0.6835 - val_accuracy: 0.5394\n",
      "Epoch 835/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6887 - accuracy: 0.5118 - val_loss: 0.6874 - val_accuracy: 0.5515\n",
      "Epoch 836/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6909 - accuracy: 0.5353 - val_loss: 0.6871 - val_accuracy: 0.5515\n",
      "Epoch 837/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5529 - val_loss: 0.6896 - val_accuracy: 0.5273\n",
      "Epoch 838/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6908 - accuracy: 0.5059 - val_loss: 0.6849 - val_accuracy: 0.5879\n",
      "Epoch 839/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5794 - val_loss: 0.6851 - val_accuracy: 0.5152\n",
      "Epoch 840/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5647 - val_loss: 0.6864 - val_accuracy: 0.5697\n",
      "Epoch 841/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5441 - val_loss: 0.6849 - val_accuracy: 0.5152\n",
      "Epoch 842/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5706 - val_loss: 0.6875 - val_accuracy: 0.5394\n",
      "Epoch 843/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5294 - val_loss: 0.6915 - val_accuracy: 0.5455\n",
      "Epoch 844/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5529 - val_loss: 0.6908 - val_accuracy: 0.5394\n",
      "Epoch 845/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5441 - val_loss: 0.6884 - val_accuracy: 0.5515\n",
      "Epoch 846/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5471 - val_loss: 0.6938 - val_accuracy: 0.5212\n",
      "Epoch 847/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5500 - val_loss: 0.7011 - val_accuracy: 0.4970\n",
      "Epoch 848/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6854 - accuracy: 0.5441 - val_loss: 0.6995 - val_accuracy: 0.4970\n",
      "Epoch 849/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5176 - val_loss: 0.6894 - val_accuracy: 0.5212\n",
      "Epoch 850/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5382 - val_loss: 0.6903 - val_accuracy: 0.5394\n",
      "Epoch 851/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5265 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
      "Epoch 852/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6804 - accuracy: 0.5353 - val_loss: 0.6954 - val_accuracy: 0.5030\n",
      "Epoch 853/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6855 - accuracy: 0.5412 - val_loss: 0.6948 - val_accuracy: 0.4909\n",
      "Epoch 854/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6841 - accuracy: 0.5559 - val_loss: 0.6897 - val_accuracy: 0.5091\n",
      "Epoch 855/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6865 - accuracy: 0.5235 - val_loss: 0.6902 - val_accuracy: 0.5091\n",
      "Epoch 856/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6771 - accuracy: 0.5529 - val_loss: 0.6877 - val_accuracy: 0.5515\n",
      "Epoch 857/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6848 - accuracy: 0.5059 - val_loss: 0.6887 - val_accuracy: 0.5394\n",
      "Epoch 858/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6816 - accuracy: 0.5441 - val_loss: 0.6909 - val_accuracy: 0.4970\n",
      "Epoch 859/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6827 - accuracy: 0.5676 - val_loss: 0.6901 - val_accuracy: 0.5212\n",
      "Epoch 860/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6806 - accuracy: 0.5353 - val_loss: 0.6916 - val_accuracy: 0.5091\n",
      "Epoch 861/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6860 - accuracy: 0.5118 - val_loss: 0.6920 - val_accuracy: 0.5030\n",
      "Epoch 862/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6829 - accuracy: 0.5353 - val_loss: 0.6952 - val_accuracy: 0.5030\n",
      "Epoch 863/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.5794 - val_loss: 0.6957 - val_accuracy: 0.5091\n",
      "Epoch 864/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.5618 - val_loss: 0.7026 - val_accuracy: 0.4970\n",
      "Epoch 865/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6830 - accuracy: 0.5559 - val_loss: 0.6928 - val_accuracy: 0.4970\n",
      "Epoch 866/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6819 - accuracy: 0.5471 - val_loss: 0.6959 - val_accuracy: 0.5030\n",
      "Epoch 867/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6862 - accuracy: 0.5147 - val_loss: 0.6968 - val_accuracy: 0.5030\n",
      "Epoch 868/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6805 - accuracy: 0.5735 - val_loss: 0.6919 - val_accuracy: 0.4970\n",
      "Epoch 869/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6830 - accuracy: 0.5500 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 870/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6884 - accuracy: 0.5471 - val_loss: 0.7029 - val_accuracy: 0.5152\n",
      "Epoch 871/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6821 - accuracy: 0.5676 - val_loss: 0.7024 - val_accuracy: 0.4909\n",
      "Epoch 872/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6819 - accuracy: 0.5765 - val_loss: 0.7045 - val_accuracy: 0.4970\n",
      "Epoch 873/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6858 - accuracy: 0.5206 - val_loss: 0.6976 - val_accuracy: 0.4909\n",
      "Epoch 874/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6829 - accuracy: 0.5559 - val_loss: 0.7013 - val_accuracy: 0.5030\n",
      "Epoch 875/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5265 - val_loss: 0.7019 - val_accuracy: 0.5152\n",
      "Epoch 876/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5618 - val_loss: 0.7005 - val_accuracy: 0.5152\n",
      "Epoch 877/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5030\n",
      "Epoch 878/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5559 - val_loss: 0.6911 - val_accuracy: 0.5030\n",
      "Epoch 879/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5324 - val_loss: 0.6893 - val_accuracy: 0.5273\n",
      "Epoch 880/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.5412 - val_loss: 0.6946 - val_accuracy: 0.4848\n",
      "Epoch 881/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5353 - val_loss: 0.6860 - val_accuracy: 0.5636\n",
      "Epoch 882/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5353 - val_loss: 0.6862 - val_accuracy: 0.5455\n",
      "Epoch 883/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5500 - val_loss: 0.6860 - val_accuracy: 0.5515\n",
      "Epoch 884/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6888 - accuracy: 0.5529 - val_loss: 0.6863 - val_accuracy: 0.5394\n",
      "Epoch 885/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6859 - accuracy: 0.5294 - val_loss: 0.6907 - val_accuracy: 0.5636\n",
      "Epoch 886/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5412 - val_loss: 0.6884 - val_accuracy: 0.5212\n",
      "Epoch 887/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6884 - accuracy: 0.5147 - val_loss: 0.6907 - val_accuracy: 0.5152\n",
      "Epoch 888/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5500 - val_loss: 0.6909 - val_accuracy: 0.5273\n",
      "Epoch 889/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5618 - val_loss: 0.6871 - val_accuracy: 0.5394\n",
      "Epoch 890/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6856 - accuracy: 0.5441 - val_loss: 0.6865 - val_accuracy: 0.5515\n",
      "Epoch 891/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5324 - val_loss: 0.6850 - val_accuracy: 0.5394\n",
      "Epoch 892/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6848 - accuracy: 0.5206 - val_loss: 0.6844 - val_accuracy: 0.5152\n",
      "Epoch 893/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5882 - val_loss: 0.6864 - val_accuracy: 0.5394\n",
      "Epoch 894/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5265 - val_loss: 0.6883 - val_accuracy: 0.5576\n",
      "Epoch 895/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5471 - val_loss: 0.6881 - val_accuracy: 0.5333\n",
      "Epoch 896/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5118 - val_loss: 0.6887 - val_accuracy: 0.5212\n",
      "Epoch 897/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5441 - val_loss: 0.6868 - val_accuracy: 0.5455\n",
      "Epoch 898/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6780 - accuracy: 0.5588 - val_loss: 0.6860 - val_accuracy: 0.5515\n",
      "Epoch 899/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6820 - accuracy: 0.5824 - val_loss: 0.6892 - val_accuracy: 0.5394\n",
      "Epoch 900/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5353 - val_loss: 0.6869 - val_accuracy: 0.5394\n",
      "Epoch 901/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6821 - accuracy: 0.5706 - val_loss: 0.6857 - val_accuracy: 0.5273\n",
      "Epoch 902/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5441 - val_loss: 0.6857 - val_accuracy: 0.5455\n",
      "Epoch 903/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6827 - accuracy: 0.5618 - val_loss: 0.6849 - val_accuracy: 0.4970\n",
      "Epoch 904/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6809 - accuracy: 0.5529 - val_loss: 0.6850 - val_accuracy: 0.5212\n",
      "Epoch 905/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6864 - accuracy: 0.5412 - val_loss: 0.6873 - val_accuracy: 0.5515\n",
      "Epoch 906/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.5529 - val_loss: 0.6887 - val_accuracy: 0.5091\n",
      "Epoch 907/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6837 - accuracy: 0.5559 - val_loss: 0.6888 - val_accuracy: 0.5515\n",
      "Epoch 908/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5647 - val_loss: 0.6886 - val_accuracy: 0.5333\n",
      "Epoch 909/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5000 - val_loss: 0.6942 - val_accuracy: 0.4909\n",
      "Epoch 910/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5676 - val_loss: 0.6886 - val_accuracy: 0.5152\n",
      "Epoch 911/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5500 - val_loss: 0.6864 - val_accuracy: 0.5273\n",
      "Epoch 912/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5588 - val_loss: 0.6865 - val_accuracy: 0.5515\n",
      "Epoch 913/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6787 - accuracy: 0.5676 - val_loss: 0.6862 - val_accuracy: 0.5515\n",
      "Epoch 914/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.6812 - accuracy: 0.5500 - val_loss: 0.6860 - val_accuracy: 0.5212\n",
      "Epoch 915/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6826 - accuracy: 0.5471 - val_loss: 0.6846 - val_accuracy: 0.5758\n",
      "Epoch 916/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6819 - accuracy: 0.5824 - val_loss: 0.6861 - val_accuracy: 0.5455\n",
      "Epoch 917/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6789 - accuracy: 0.5588 - val_loss: 0.6871 - val_accuracy: 0.5576\n",
      "Epoch 918/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5441 - val_loss: 0.6865 - val_accuracy: 0.5455\n",
      "Epoch 919/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5382 - val_loss: 0.6865 - val_accuracy: 0.5333\n",
      "Epoch 920/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6891 - accuracy: 0.5559 - val_loss: 0.7010 - val_accuracy: 0.4848\n",
      "Epoch 921/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5324 - val_loss: 0.6967 - val_accuracy: 0.4909\n",
      "Epoch 922/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5471 - val_loss: 0.6892 - val_accuracy: 0.5273\n",
      "Epoch 923/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5618 - val_loss: 0.6865 - val_accuracy: 0.5697\n",
      "Epoch 924/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5324 - val_loss: 0.6854 - val_accuracy: 0.5455\n",
      "Epoch 925/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6780 - accuracy: 0.5882 - val_loss: 0.6875 - val_accuracy: 0.5091\n",
      "Epoch 926/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5206 - val_loss: 0.6891 - val_accuracy: 0.5333\n",
      "Epoch 927/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5529 - val_loss: 0.6869 - val_accuracy: 0.5455\n",
      "Epoch 928/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5971 - val_loss: 0.6865 - val_accuracy: 0.5394\n",
      "Epoch 929/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6782 - accuracy: 0.5647 - val_loss: 0.6871 - val_accuracy: 0.5455\n",
      "Epoch 930/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6842 - accuracy: 0.5676 - val_loss: 0.6885 - val_accuracy: 0.5576\n",
      "Epoch 931/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5529 - val_loss: 0.6872 - val_accuracy: 0.5333\n",
      "Epoch 932/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5529 - val_loss: 0.6862 - val_accuracy: 0.5152\n",
      "Epoch 933/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6873 - accuracy: 0.5471 - val_loss: 0.6869 - val_accuracy: 0.5030\n",
      "Epoch 934/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5353 - val_loss: 0.6927 - val_accuracy: 0.5030\n",
      "Epoch 935/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5765 - val_loss: 0.6896 - val_accuracy: 0.5212\n",
      "Epoch 936/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5353 - val_loss: 0.6891 - val_accuracy: 0.5273\n",
      "Epoch 937/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5265 - val_loss: 0.6968 - val_accuracy: 0.4909\n",
      "Epoch 938/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5471 - val_loss: 0.6932 - val_accuracy: 0.5091\n",
      "Epoch 939/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5382 - val_loss: 0.6879 - val_accuracy: 0.5394\n",
      "Epoch 940/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5500 - val_loss: 0.6878 - val_accuracy: 0.5333\n",
      "Epoch 941/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5353 - val_loss: 0.6903 - val_accuracy: 0.5091\n",
      "Epoch 942/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6826 - accuracy: 0.5529 - val_loss: 0.6871 - val_accuracy: 0.5091\n",
      "Epoch 943/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.5618 - val_loss: 0.6877 - val_accuracy: 0.5455\n",
      "Epoch 944/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5324 - val_loss: 0.6864 - val_accuracy: 0.5455\n",
      "Epoch 945/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5059 - val_loss: 0.6896 - val_accuracy: 0.5576\n",
      "Epoch 946/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6798 - accuracy: 0.5500 - val_loss: 0.6933 - val_accuracy: 0.4909\n",
      "Epoch 947/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6868 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5030\n",
      "Epoch 948/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5500 - val_loss: 0.6863 - val_accuracy: 0.5273\n",
      "Epoch 949/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5294 - val_loss: 0.6865 - val_accuracy: 0.5333\n",
      "Epoch 950/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5529 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 951/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5529 - val_loss: 0.7026 - val_accuracy: 0.5152\n",
      "Epoch 952/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5647 - val_loss: 0.7010 - val_accuracy: 0.5152\n",
      "Epoch 953/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5647 - val_loss: 0.6947 - val_accuracy: 0.5152\n",
      "Epoch 954/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6865 - accuracy: 0.5412 - val_loss: 0.6906 - val_accuracy: 0.4970\n",
      "Epoch 955/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5324 - val_loss: 0.6918 - val_accuracy: 0.5152\n",
      "Epoch 956/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5471 - val_loss: 0.6959 - val_accuracy: 0.5152\n",
      "Epoch 957/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5353 - val_loss: 0.6938 - val_accuracy: 0.5152\n",
      "Epoch 958/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6780 - accuracy: 0.5765 - val_loss: 0.6912 - val_accuracy: 0.5152\n",
      "Epoch 959/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5647 - val_loss: 0.6880 - val_accuracy: 0.5333\n",
      "Epoch 960/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6889 - accuracy: 0.5265 - val_loss: 0.6894 - val_accuracy: 0.5152\n",
      "Epoch 961/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5500 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 962/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6864 - accuracy: 0.5441 - val_loss: 0.6942 - val_accuracy: 0.5152\n",
      "Epoch 963/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5912 - val_loss: 0.6930 - val_accuracy: 0.5152\n",
      "Epoch 964/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5471 - val_loss: 0.6974 - val_accuracy: 0.5152\n",
      "Epoch 965/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6824 - accuracy: 0.5559 - val_loss: 0.6959 - val_accuracy: 0.5152\n",
      "Epoch 966/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6900 - accuracy: 0.5176 - val_loss: 0.6963 - val_accuracy: 0.5152\n",
      "Epoch 967/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.5559 - val_loss: 0.6988 - val_accuracy: 0.5152\n",
      "Epoch 968/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5500 - val_loss: 0.6994 - val_accuracy: 0.5152\n",
      "Epoch 969/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5441 - val_loss: 0.6904 - val_accuracy: 0.5152\n",
      "Epoch 970/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6766 - accuracy: 0.5706 - val_loss: 0.6872 - val_accuracy: 0.5273\n",
      "Epoch 971/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6848 - accuracy: 0.5706 - val_loss: 0.6865 - val_accuracy: 0.5515\n",
      "Epoch 972/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5765 - val_loss: 0.6852 - val_accuracy: 0.5455\n",
      "Epoch 973/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5706 - val_loss: 0.6860 - val_accuracy: 0.5818\n",
      "Epoch 974/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5206 - val_loss: 0.6897 - val_accuracy: 0.5152\n",
      "Epoch 975/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5912 - val_loss: 0.7003 - val_accuracy: 0.5152\n",
      "Epoch 976/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.5529 - val_loss: 0.6980 - val_accuracy: 0.5152\n",
      "Epoch 977/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6868 - accuracy: 0.5176 - val_loss: 0.6885 - val_accuracy: 0.5333\n",
      "Epoch 978/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5500 - val_loss: 0.6864 - val_accuracy: 0.5152\n",
      "Epoch 979/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.6847 - accuracy: 0.5265 - val_loss: 0.6870 - val_accuracy: 0.5333\n",
      "Epoch 980/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6898 - accuracy: 0.5382 - val_loss: 0.6864 - val_accuracy: 0.5758\n",
      "Epoch 981/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5294 - val_loss: 0.6867 - val_accuracy: 0.5515\n",
      "Epoch 982/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6862 - accuracy: 0.5206 - val_loss: 0.6885 - val_accuracy: 0.5273\n",
      "Epoch 983/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5618 - val_loss: 0.6883 - val_accuracy: 0.5636\n",
      "Epoch 984/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5235 - val_loss: 0.6880 - val_accuracy: 0.5333\n",
      "Epoch 985/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6867 - accuracy: 0.5294 - val_loss: 0.6881 - val_accuracy: 0.5212\n",
      "Epoch 986/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5324 - val_loss: 0.6873 - val_accuracy: 0.5333\n",
      "Epoch 987/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5412 - val_loss: 0.6871 - val_accuracy: 0.5455\n",
      "Epoch 988/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5294 - val_loss: 0.6871 - val_accuracy: 0.5333\n",
      "Epoch 989/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5588 - val_loss: 0.6883 - val_accuracy: 0.5152\n",
      "Epoch 990/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5618 - val_loss: 0.6912 - val_accuracy: 0.5152\n",
      "Epoch 991/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6827 - accuracy: 0.5706 - val_loss: 0.7006 - val_accuracy: 0.5152\n",
      "Epoch 992/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6860 - accuracy: 0.5294 - val_loss: 0.6974 - val_accuracy: 0.5152\n",
      "Epoch 993/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6790 - accuracy: 0.5441 - val_loss: 0.6958 - val_accuracy: 0.5152\n",
      "Epoch 994/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5588 - val_loss: 0.6937 - val_accuracy: 0.5152\n",
      "Epoch 995/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5559 - val_loss: 0.6916 - val_accuracy: 0.5152\n",
      "Epoch 996/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.5147 - val_loss: 0.6912 - val_accuracy: 0.5091\n",
      "Epoch 997/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.5206 - val_loss: 0.6946 - val_accuracy: 0.5152\n",
      "Epoch 998/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.6822 - accuracy: 0.5441 - val_loss: 0.6894 - val_accuracy: 0.5152\n",
      "Epoch 999/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5559 - val_loss: 0.6882 - val_accuracy: 0.5152\n",
      "Epoch 1000/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5529 - val_loss: 0.6884 - val_accuracy: 0.5333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m val_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(val_features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, val_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mreshape(val_features\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m=\u001b[39mcnnmodel()\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m val_accuracy\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mevaluate(val_features,val_labels)[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# summarize history for accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_accuracy=[]\n",
    "val_loss=[]\n",
    "train_accuracy=[]\n",
    "train_loss=[]\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features,train_labels=data_array[train_index],label_array[train_index]\n",
    "    val_features,val_labels=data_array[val_index],label_array[val_index]\n",
    "    scaler=StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "    model=cnnmodel()\n",
    "    history = model.fit(train_features,train_labels,epochs=1000,batch_size=32,validation_data=(val_features,val_labels))\n",
    "    val_accuracy.append(model.evaluate(val_features,val_labels)[1])\n",
    "    \n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(val_accuracy)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras import optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 64)                4800      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,706\n",
      "Trainable params: 5,578\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def rnnmodel():\n",
    "    model = Sequential()\n",
    "    #model.add(LSTM(128,  input_shape=(2049,32),activation='relu', return_sequences=True))\n",
    "\n",
    "    model.add(layers.SimpleRNN(64, input_shape=(2049,10)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(10))\n",
    "\n",
    "    optimizer = optimizers.Adam(clipvalue=0.5)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    " \n",
    "model=rnnmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  4  5  7  8 10 11 13 14 16 17 19 20 23 24 26 28 29 31 32 34 35\n",
      " 36 38 40 41 43 44 46 47 48 49 50 51 52 53 55 56 58 59 61 62 64 65 67 68\n",
      " 70 71 74 75 77 79 80 82 83 85 86 87 89 91 92 94 95 97 98]\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 291ms/step - loss: 2.9010 - accuracy: 0.0448 - val_loss: 0.9546 - val_accuracy: 0.0882\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 1.7246 - accuracy: 0.0746 - val_loss: 0.8129 - val_accuracy: 0.0588\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 1.2865 - accuracy: 0.0746 - val_loss: 0.7510 - val_accuracy: 0.1176\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 1s 274ms/step - loss: 0.9976 - accuracy: 0.1045 - val_loss: 0.7132 - val_accuracy: 0.0882\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.8445 - accuracy: 0.0896 - val_loss: 0.6937 - val_accuracy: 0.0588\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.7380 - accuracy: 0.1343 - val_loss: 0.6860 - val_accuracy: 0.0588\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.6396 - accuracy: 0.1642 - val_loss: 0.6774 - val_accuracy: 0.0882\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.5805 - accuracy: 0.1343 - val_loss: 0.6574 - val_accuracy: 0.0588\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.5510 - accuracy: 0.1791 - val_loss: 0.6353 - val_accuracy: 0.0588\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.5061 - accuracy: 0.1493 - val_loss: 0.6159 - val_accuracy: 0.0882\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4811 - accuracy: 0.1045 - val_loss: 0.6017 - val_accuracy: 0.0588\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.4533 - accuracy: 0.1642 - val_loss: 0.5941 - val_accuracy: 0.0588\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.4279 - accuracy: 0.1194 - val_loss: 0.5805 - val_accuracy: 0.0588\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.4167 - accuracy: 0.1343 - val_loss: 0.5630 - val_accuracy: 0.0588\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.4012 - accuracy: 0.1194 - val_loss: 0.5522 - val_accuracy: 0.0588\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.3914 - accuracy: 0.1343 - val_loss: 0.5457 - val_accuracy: 0.0588\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3766 - accuracy: 0.1045 - val_loss: 0.5445 - val_accuracy: 0.0588\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.3586 - accuracy: 0.0896 - val_loss: 0.5370 - val_accuracy: 0.0882\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.3431 - accuracy: 0.1343 - val_loss: 0.5300 - val_accuracy: 0.0882\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.3230 - accuracy: 0.1343 - val_loss: 0.5185 - val_accuracy: 0.0588\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3422 - accuracy: 0.1045 - val_loss: 0.5043 - val_accuracy: 0.0294\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.3095 - accuracy: 0.0597 - val_loss: 0.4922 - val_accuracy: 0.0588\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.3105 - accuracy: 0.0896 - val_loss: 0.4885 - val_accuracy: 0.0294\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2983 - accuracy: 0.1194 - val_loss: 0.4875 - val_accuracy: 0.0588\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.3086 - accuracy: 0.1493 - val_loss: 0.4884 - val_accuracy: 0.0882\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.3130 - accuracy: 0.1343 - val_loss: 0.4882 - val_accuracy: 0.0882\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.2719 - accuracy: 0.1194 - val_loss: 0.4820 - val_accuracy: 0.0882\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.2738 - accuracy: 0.1194 - val_loss: 0.4776 - val_accuracy: 0.0882\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.2704 - accuracy: 0.1343 - val_loss: 0.4779 - val_accuracy: 0.0588\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2663 - accuracy: 0.1045 - val_loss: 0.4776 - val_accuracy: 0.0882\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2810 - accuracy: 0.1493 - val_loss: 0.4852 - val_accuracy: 0.0588\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2408 - accuracy: 0.1045 - val_loss: 0.4863 - val_accuracy: 0.0588\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2399 - accuracy: 0.1343 - val_loss: 0.4826 - val_accuracy: 0.0588\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.2559 - accuracy: 0.1642 - val_loss: 0.4858 - val_accuracy: 0.0588\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.2461 - accuracy: 0.1343 - val_loss: 0.4949 - val_accuracy: 0.0588\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2523 - accuracy: 0.1343 - val_loss: 0.5080 - val_accuracy: 0.0588\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2406 - accuracy: 0.1194 - val_loss: 0.5135 - val_accuracy: 0.0588\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.2615 - accuracy: 0.0896 - val_loss: 0.5061 - val_accuracy: 0.0588\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.2439 - accuracy: 0.1343 - val_loss: 0.4904 - val_accuracy: 0.0588\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.2342 - accuracy: 0.1045 - val_loss: 0.4922 - val_accuracy: 0.0588\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.2392 - accuracy: 0.1493 - val_loss: 0.4773 - val_accuracy: 0.0588\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.2324 - accuracy: 0.1493 - val_loss: 0.4649 - val_accuracy: 0.0588\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.2327 - accuracy: 0.1642 - val_loss: 0.4673 - val_accuracy: 0.0588\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.2317 - accuracy: 0.1194 - val_loss: 0.4683 - val_accuracy: 0.0588\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2458 - accuracy: 0.1045 - val_loss: 0.4670 - val_accuracy: 0.0588\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.2217 - accuracy: 0.1343 - val_loss: 0.4666 - val_accuracy: 0.0294\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.2276 - accuracy: 0.1045 - val_loss: 0.4766 - val_accuracy: 0.0294\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.2162 - accuracy: 0.1642 - val_loss: 0.4814 - val_accuracy: 0.0294\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.2154 - accuracy: 0.0746 - val_loss: 0.4745 - val_accuracy: 0.0294\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.2084 - accuracy: 0.1493 - val_loss: 0.4705 - val_accuracy: 0.0294\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4705 - accuracy: 0.0294\n",
      "[  2   3   5   6   8   9  11  12  14  15  17  18  20  21  22  23  25  26\n",
      "  27  29  30  32  33  35  37  38  39  41  42  44  45  47  50  53  54  56\n",
      "  57  59  60  62  63  65  66  68  69  71  72  73  74  76  77  78  80  81\n",
      "  83  84  86  88  89  90  92  93  95  96  98  99 100]\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 262ms/step - loss: 2.0518 - accuracy: 0.1791 - val_loss: 0.8104 - val_accuracy: 0.1176\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 1.3413 - accuracy: 0.1642 - val_loss: 0.6832 - val_accuracy: 0.1176\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 1.0350 - accuracy: 0.1194 - val_loss: 0.6189 - val_accuracy: 0.0882\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.8623 - accuracy: 0.1493 - val_loss: 0.5768 - val_accuracy: 0.1176\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.7743 - accuracy: 0.1194 - val_loss: 0.5502 - val_accuracy: 0.0882\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 1s 284ms/step - loss: 0.6513 - accuracy: 0.1343 - val_loss: 0.5264 - val_accuracy: 0.0588\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.6021 - accuracy: 0.1791 - val_loss: 0.5020 - val_accuracy: 0.1176\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.5392 - accuracy: 0.1493 - val_loss: 0.4767 - val_accuracy: 0.0882\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.4989 - accuracy: 0.1045 - val_loss: 0.4556 - val_accuracy: 0.0882\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.4692 - accuracy: 0.1791 - val_loss: 0.4468 - val_accuracy: 0.0882\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.4467 - accuracy: 0.1194 - val_loss: 0.4462 - val_accuracy: 0.0588\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.4366 - accuracy: 0.1493 - val_loss: 0.4383 - val_accuracy: 0.0588\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.4050 - accuracy: 0.1045 - val_loss: 0.4219 - val_accuracy: 0.0588\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.3913 - accuracy: 0.1642 - val_loss: 0.4070 - val_accuracy: 0.0294\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.3835 - accuracy: 0.1791 - val_loss: 0.3978 - val_accuracy: 0.0588\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3771 - accuracy: 0.1493 - val_loss: 0.3892 - val_accuracy: 0.0294\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.3455 - accuracy: 0.1642 - val_loss: 0.3806 - val_accuracy: 0.0294\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.3333 - accuracy: 0.2239 - val_loss: 0.3733 - val_accuracy: 0.0294\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.3452 - accuracy: 0.1343 - val_loss: 0.3659 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.3194 - accuracy: 0.1343 - val_loss: 0.3571 - val_accuracy: 0.0294\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.3100 - accuracy: 0.1343 - val_loss: 0.3516 - val_accuracy: 0.0882\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2959 - accuracy: 0.1343 - val_loss: 0.3480 - val_accuracy: 0.0294\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.2704 - accuracy: 0.1940 - val_loss: 0.3520 - val_accuracy: 0.0588\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2712 - accuracy: 0.1642 - val_loss: 0.3540 - val_accuracy: 0.0588\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 1s 269ms/step - loss: 0.2616 - accuracy: 0.1642 - val_loss: 0.3542 - val_accuracy: 0.0588\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.2532 - accuracy: 0.1343 - val_loss: 0.3434 - val_accuracy: 0.0294\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2297 - accuracy: 0.1493 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2328 - accuracy: 0.1791 - val_loss: 0.3360 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.2172 - accuracy: 0.1343 - val_loss: 0.3319 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2282 - accuracy: 0.1194 - val_loss: 0.3351 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.2446 - accuracy: 0.1045 - val_loss: 0.3295 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.2342 - accuracy: 0.0746 - val_loss: 0.3233 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.2100 - accuracy: 0.0896 - val_loss: 0.3244 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.2128 - accuracy: 0.1493 - val_loss: 0.3210 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.2069 - accuracy: 0.1343 - val_loss: 0.3173 - val_accuracy: 0.0882\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.1992 - accuracy: 0.1045 - val_loss: 0.3160 - val_accuracy: 0.0294\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2153 - accuracy: 0.0896 - val_loss: 0.3150 - val_accuracy: 0.0294\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.1897 - accuracy: 0.1194 - val_loss: 0.3077 - val_accuracy: 0.0294\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.1962 - accuracy: 0.0896 - val_loss: 0.3043 - val_accuracy: 0.0294\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.1831 - accuracy: 0.1194 - val_loss: 0.3014 - val_accuracy: 0.0294\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.1945 - accuracy: 0.0746 - val_loss: 0.2977 - val_accuracy: 0.0294\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.1982 - accuracy: 0.1194 - val_loss: 0.3087 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.1830 - accuracy: 0.1343 - val_loss: 0.3081 - val_accuracy: 0.0294\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.1700 - accuracy: 0.0746 - val_loss: 0.3098 - val_accuracy: 0.0588\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.1884 - accuracy: 0.0746 - val_loss: 0.3101 - val_accuracy: 0.0588\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.1921 - accuracy: 0.1194 - val_loss: 0.3009 - val_accuracy: 0.0588\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.1984 - accuracy: 0.1493 - val_loss: 0.2957 - val_accuracy: 0.0294\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.1824 - accuracy: 0.1642 - val_loss: 0.2908 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.1804 - accuracy: 0.0746 - val_loss: 0.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.1774 - accuracy: 0.1493 - val_loss: 0.3283 - val_accuracy: 0.0294\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3283 - accuracy: 0.0294\n",
      "[  0   1   3   4   6   7   9  10  12  13  15  16  18  19  21  22  24  25\n",
      "  27  28  30  31  33  34  36  37  39  40  42  43  45  46  48  49  51  52\n",
      "  54  55  57  58  60  61  63  64  66  67  69  70  72  73  75  76  78  79\n",
      "  81  82  84  85  87  88  90  91  93  94  96  97  99 100]\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 258ms/step - loss: 2.0829 - accuracy: 0.1029 - val_loss: 0.6688 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 1.3774 - accuracy: 0.1324 - val_loss: 0.5984 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 1.0013 - accuracy: 0.1176 - val_loss: 0.5668 - val_accuracy: 0.0303\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.7909 - accuracy: 0.1324 - val_loss: 0.5480 - val_accuracy: 0.0303\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.6904 - accuracy: 0.0882 - val_loss: 0.5419 - val_accuracy: 0.0303\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.6088 - accuracy: 0.0441 - val_loss: 0.5232 - val_accuracy: 0.0303\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.5710 - accuracy: 0.0882 - val_loss: 0.5052 - val_accuracy: 0.0303\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 1s 263ms/step - loss: 0.5143 - accuracy: 0.0735 - val_loss: 0.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.4663 - accuracy: 0.0735 - val_loss: 0.5004 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.4544 - accuracy: 0.1176 - val_loss: 0.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.4291 - accuracy: 0.0441 - val_loss: 0.4849 - val_accuracy: 0.0303\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.4077 - accuracy: 0.0588 - val_loss: 0.4519 - val_accuracy: 0.0303\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.3975 - accuracy: 0.1176 - val_loss: 0.4365 - val_accuracy: 0.0303\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3670 - accuracy: 0.0441 - val_loss: 0.4221 - val_accuracy: 0.0303\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.3578 - accuracy: 0.1029 - val_loss: 0.4052 - val_accuracy: 0.0303\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.3357 - accuracy: 0.1176 - val_loss: 0.3866 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 283ms/step - loss: 0.3487 - accuracy: 0.1029 - val_loss: 0.3745 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.3117 - accuracy: 0.0882 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.3129 - accuracy: 0.0882 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2874 - accuracy: 0.0735 - val_loss: 0.3436 - val_accuracy: 0.0303\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.2795 - accuracy: 0.0735 - val_loss: 0.3419 - val_accuracy: 0.0303\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.2753 - accuracy: 0.0735 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.2659 - accuracy: 0.0882 - val_loss: 0.3373 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2768 - accuracy: 0.0441 - val_loss: 0.3276 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.2671 - accuracy: 0.0882 - val_loss: 0.3232 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.2358 - accuracy: 0.1324 - val_loss: 0.3250 - val_accuracy: 0.0303\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.2365 - accuracy: 0.0588 - val_loss: 0.3221 - val_accuracy: 0.0606\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.2428 - accuracy: 0.1176 - val_loss: 0.3201 - val_accuracy: 0.0606\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.2356 - accuracy: 0.0441 - val_loss: 0.3227 - val_accuracy: 0.0909\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2231 - accuracy: 0.0735 - val_loss: 0.3305 - val_accuracy: 0.0303\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2221 - accuracy: 0.0441 - val_loss: 0.3354 - val_accuracy: 0.0606\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.2310 - accuracy: 0.0588 - val_loss: 0.3385 - val_accuracy: 0.0606\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 1s 259ms/step - loss: 0.2112 - accuracy: 0.0882 - val_loss: 0.3338 - val_accuracy: 0.0606\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.2030 - accuracy: 0.0588 - val_loss: 0.3347 - val_accuracy: 0.0606\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2024 - accuracy: 0.1324 - val_loss: 0.3264 - val_accuracy: 0.0606\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.2023 - accuracy: 0.0735 - val_loss: 0.3169 - val_accuracy: 0.0303\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.1906 - accuracy: 0.0588 - val_loss: 0.3108 - val_accuracy: 0.0303\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.2050 - accuracy: 0.0735 - val_loss: 0.3140 - val_accuracy: 0.0606\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2529 - accuracy: 0.0588 - val_loss: 0.2900 - val_accuracy: 0.0909\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2325 - accuracy: 0.1176 - val_loss: 0.3050 - val_accuracy: 0.0303\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.2409 - accuracy: 0.0294 - val_loss: 0.3151 - val_accuracy: 0.0303\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.2091 - accuracy: 0.0735 - val_loss: 0.3614 - val_accuracy: 0.0303\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.1992 - accuracy: 0.0735 - val_loss: 0.3645 - val_accuracy: 0.0909\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.2620 - accuracy: 0.1176 - val_loss: 0.3769 - val_accuracy: 0.0909\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2360 - accuracy: 0.1176 - val_loss: 0.3618 - val_accuracy: 0.2121\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2389 - accuracy: 0.1324 - val_loss: 0.3357 - val_accuracy: 0.1515\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2138 - accuracy: 0.1324 - val_loss: 0.3235 - val_accuracy: 0.0606\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.2052 - accuracy: 0.1324 - val_loss: 0.3305 - val_accuracy: 0.0606\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2005 - accuracy: 0.1029 - val_loss: 0.3348 - val_accuracy: 0.0909\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.2169 - accuracy: 0.1324 - val_loss: 0.3217 - val_accuracy: 0.0909\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3217 - accuracy: 0.0909\n"
     ]
    }
   ],
   "source": [
    "val_accuracy=[]\n",
    "val_loss=[]\n",
    "train_accuracy=[]\n",
    "train_loss=[]\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features,train_labels=data_array[train_index],label_array[train_index]\n",
    "    val_features,val_labels=data_array[val_index],label_array[val_index]\n",
    "    scaler=StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "    model=rnnmodel()\n",
    "    history = model.fit(train_features,train_labels,epochs=50,batch_size=16,validation_data=(val_features,val_labels))\n",
    "    val_accuracy.append(model.evaluate(val_features,val_labels)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(estimators)\n\u001b[1;32m     31\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 32\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStandardized: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (results\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, results\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 378\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    334\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 870\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:870\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:809\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:844\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    843\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 844\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    899\u001b[0m     _assert_all_finite(\n\u001b[1;32m    900\u001b[0m         array,\n\u001b[1;32m    901\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    902\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    903\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "# Binary Classification with Sonar Dataset: Standardized\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(label_array)\n",
    "encoded_Y = encoder.transform(label_array)\n",
    "\n",
    "\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(2049,32), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# evaluate baseline model with standardized dataset\n",
    "data_array = scaler.fit_transform(data_array.reshape(-1, data_array.shape[-1])).reshape(data_array.shape)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(model=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, data_array, encoded_Y, cv=kfold,error_score='raise')\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.9.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/nprins/.local/lib/python3.8/site-packages (from scikeras) (1.1.2)\n",
      "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nprins/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/nprins/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/nprins/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/nprins/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.23.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=0.21->scikeras) (2.4.6)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
