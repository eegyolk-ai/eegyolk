{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 12:33:14.587989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-05 12:33:14.701272: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-05 12:33:14.730998: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-05 12:33:15.249059: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-05 12:33:15.249133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-05 12:33:15.249142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import copy     # Can Copy and Deepcopy files so original file is untouched.\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../eegyolk') # path to helper functions\n",
    "import helper_functions as hf # library useful for eeg and erp data cleaning\n",
    "import epod_helper\n",
    "import initialization_functions\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,LeakyReLU,MaxPool1D,\\\n",
    "GlobalAveragePooling1D,Dense,Dropout,AveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_file</th>\n",
       "      <th>ParticipantID</th>\n",
       "      <th>test</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_months</th>\n",
       "      <th>dyslexic_parent</th>\n",
       "      <th>Group_AccToParents</th>\n",
       "      <th>path_eeg</th>\n",
       "      <th>path_epoch</th>\n",
       "      <th>path_eventmarkers</th>\n",
       "      <th>epoch_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105a</td>\n",
       "      <td>105</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>17</td>\n",
       "      <td>f</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>105a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107a</td>\n",
       "      <td>107</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>16</td>\n",
       "      <td>m</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>107a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106a</td>\n",
       "      <td>106</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>19</td>\n",
       "      <td>f</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>106a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109a</td>\n",
       "      <td>109</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>21</td>\n",
       "      <td>m</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>109a_epo.fif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110a</td>\n",
       "      <td>110</td>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>17</td>\n",
       "      <td>m</td>\n",
       "      <td>At risk</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/dataset</td>\n",
       "      <td>../../volume-ceph/nadine_storage/processed_epochs</td>\n",
       "      <td>../../volume-ceph/ePodium_projectfolder/events</td>\n",
       "      <td>110a_epo.fif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eeg_file  ParticipantID test sex  age_months dyslexic_parent  \\\n",
       "0     105a            105    a   f          17               f   \n",
       "1     107a            107    a   f          16               m   \n",
       "2     106a            106    a   m          19               f   \n",
       "3     109a            109    a   m          21               m   \n",
       "4     110a            110    a   m          17               m   \n",
       "\n",
       "  Group_AccToParents                                         path_eeg  \\\n",
       "0            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "1            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "2            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "3            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "4            At risk  ../../volume-ceph/ePodium_projectfolder/dataset   \n",
       "\n",
       "                                          path_epoch  \\\n",
       "0  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "1  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "2  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "3  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "4  ../../volume-ceph/nadine_storage/processed_epochs   \n",
       "\n",
       "                                path_eventmarkers    epoch_file  \n",
       "0  ../../volume-ceph/ePodium_projectfolder/events  105a_epo.fif  \n",
       "1  ../../volume-ceph/ePodium_projectfolder/events  107a_epo.fif  \n",
       "2  ../../volume-ceph/ePodium_projectfolder/events  106a_epo.fif  \n",
       "3  ../../volume-ceph/ePodium_projectfolder/events  109a_epo.fif  \n",
       "4  ../../volume-ceph/ePodium_projectfolder/events  110a_epo.fif  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['Group_AccToParents'] = np.where(\n",
    "    (metadata['Group_AccToParents']=='At risk'), 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_files= metadata.loc[metadata['Group_AccToParents'] == 0]\n",
    "atrisk_files = metadata.loc[metadata['Group_AccToParents'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out file: 117a_epo.fif\n",
      "Checking out file: 118a_epo.fif\n",
      "Checking out file: 119a_epo.fif\n",
      "Checking out file: 124a_epo.fif\n",
      "Checking out file: 127a_epo.fif\n",
      "Checking out file: 126a_epo.fif\n",
      "Checking out file: 131a_epo.fif\n",
      "Checking out file: 135a_epo.fif\n",
      "Checking out file: 133a_epo.fif\n",
      "Checking out file: 138a_epo.fif\n",
      "Checking out file: 139a_epo.fif\n",
      "Checking out file: 144a_epo.fif\n",
      "Checking out file: 143a_epo.fif\n",
      "Checking out file: 146a_epo.fif\n",
      "Checking out file: 145a_epo.fif\n",
      "Checking out file: 154a_epo.fif\n",
      "Checking out file: 153a_epo.fif\n",
      "Checking out file: 168a_epo.fif\n",
      "Checking out file: 177a_epo.fif\n",
      "Checking out file: 190a_epo.fif\n",
      "Checking out file: 170a_epo.fif\n",
      "Checking out file: 174a_epo.fif\n",
      "Checking out file: 191a_epo.fif\n",
      "Checking out file: 169a_epo.fif\n",
      "Checking out file: 173a_epo.fif\n",
      "Checking out file: 166a_epo.fif\n",
      "Checking out file: 216a_epo.fif\n",
      "Checking out file: 175a_epo.fif\n",
      "Checking out file: 172a_epo.fif\n",
      "Checking out file: 183a_epo.fif\n",
      "Checking out file: 185a_epo.fif\n",
      "Checking out file: 187a_epo.fif\n",
      "Checking out file: 212a_epo.fif\n",
      "Checking out file: 215a_epo.fif\n",
      "Checking out file: 167a_epo.fif\n",
      "Checking out file: 196a_epo.fif\n",
      "Checking out file: 199a_epo.fif\n",
      "Checking out file: 180a_epo.fif\n",
      "Checking out file: 171a_epo.fif\n",
      "Checking out file: 176a_epo.fif\n",
      "Checking out file: 200a_epo.fif\n",
      "Checking out file: 220a_epo.fif\n",
      "Checking out file: 218a_epo.fif\n",
      "Checking out file: 205a_epo.fif\n",
      "Checking out file: 204a_epo.fif\n",
      "Checking out file: 206a_epo.fif\n",
      "Checking out file: 208a_epo.fif\n",
      "Checking out file: 202a_epo.fif\n",
      "Checking out file: 221a_epo.fif\n"
     ]
    }
   ],
   "source": [
    "control = initialization_functions.read_filtered_data(control_files, to_array=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out file: 105a_epo.fif\n",
      "Checking out file: 107a_epo.fif\n",
      "Checking out file: 106a_epo.fif\n",
      "Checking out file: 109a_epo.fif\n",
      "Checking out file: 110a_epo.fif\n",
      "Checking out file: 112a_epo.fif\n",
      "Checking out file: 111a_epo.fif\n",
      "Checking out file: 114a_epo.fif\n",
      "Checking out file: 115a_epo.fif\n",
      "Checking out file: 116a_epo.fif\n",
      "Checking out file: 123a_epo.fif\n",
      "Checking out file: 122a_epo.fif\n",
      "Checking out file: 125a_epo.fif\n",
      "Checking out file: 130a_epo.fif\n",
      "Checking out file: 128a_epo.fif\n",
      "Checking out file: 129a_epo.fif\n",
      "Checking out file: 137a_epo.fif\n",
      "Checking out file: 141a_epo.fif\n",
      "Checking out file: 142a_epo.fif\n",
      "Checking out file: 140a_epo.fif\n",
      "Checking out file: 148a_epo.fif\n",
      "Checking out file: 149a_epo.fif\n",
      "Checking out file: 155a_epo.fif\n",
      "Checking out file: 157a_epo.fif\n",
      "Checking out file: 158a_epo.fif\n",
      "Checking out file: 161a_epo.fif\n",
      "Checking out file: 159a_epo.fif\n",
      "Checking out file: 156a_epo.fif\n",
      "Checking out file: 192a_epo.fif\n",
      "Checking out file: 178a_epo.fif\n",
      "Checking out file: 162a_epo.fif\n",
      "Checking out file: 160a_epo.fif\n",
      "Checking out file: 181a_epo.fif\n",
      "Checking out file: 194a_epo.fif\n",
      "Checking out file: 193a_epo.fif\n",
      "Checking out file: 164a_epo.fif\n",
      "Checking out file: 211a_epo.fif\n",
      "Checking out file: 182a_epo.fif\n",
      "Checking out file: 197a_epo.fif\n",
      "Checking out file: 195a_epo.fif\n",
      "Checking out file: 188a_epo.fif\n",
      "Checking out file: 198a_epo.fif\n",
      "Checking out file: 213a_epo.fif\n",
      "Checking out file: 214a_epo.fif\n",
      "Checking out file: 217a_epo.fif\n",
      "Checking out file: 101a_epo.fif\n",
      "Checking out file: 219a_epo.fif\n",
      "Checking out file: 103a_epo.fif\n",
      "Checking out file: 104a_epo.fif\n",
      "Checking out file: 209a_epo.fif\n",
      "Checking out file: 210a_epo.fif\n",
      "Checking out file: 201a_epo.fif\n"
     ]
    }
   ],
   "source": [
    "atrisk = initialization_functions.read_filtered_data(atrisk_files, to_array=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation for model input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define which experiment you want to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard_events = ['GiepS_S'] # standards: 'GiepM_S','GiepS_S','GopM_S','GopS_S'\n",
    "deviant_events = ['GiepS_D'] # deviants: 'GiepM_D','GiepS_D','GopM_D','GopS_D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "\n",
    "from sklearn.decomposition import PCA, FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loaded files: 52\n",
      " loaded files: 49\n",
      "(10, 2049) 101\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6], [7, 7, 7, 7, 7, 7, 7, 7, 7, 7], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [9, 9, 9, 9, 9, 9, 9, 9, 9, 9], [10, 10, 10, 10, 10, 10, 10, 10, 10, 10], [11, 11, 11, 11, 11, 11, 11, 11, 11, 11], [12, 12, 12, 12, 12, 12, 12, 12, 12, 12], [13, 13, 13, 13, 13, 13, 13, 13, 13, 13], [14, 14, 14, 14, 14, 14, 14, 14, 14, 14], [15, 15, 15, 15, 15, 15, 15, 15, 15, 15], [16, 16, 16, 16, 16, 16, 16, 16, 16, 16], [17, 17, 17, 17, 17, 17, 17, 17, 17, 17], [18, 18, 18, 18, 18, 18, 18, 18, 18, 18], [19, 19, 19, 19, 19, 19, 19, 19, 19, 19], [20, 20, 20, 20, 20, 20, 20, 20, 20, 20], [21, 21, 21, 21, 21, 21, 21, 21, 21, 21], [22, 22, 22, 22, 22, 22, 22, 22, 22, 22], [23, 23, 23, 23, 23, 23, 23, 23, 23, 23], [24, 24, 24, 24, 24, 24, 24, 24, 24, 24], [25, 25, 25, 25, 25, 25, 25, 25, 25, 25], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26], [27, 27, 27, 27, 27, 27, 27, 27, 27, 27], [28, 28, 28, 28, 28, 28, 28, 28, 28, 28], [29, 29, 29, 29, 29, 29, 29, 29, 29, 29], [30, 30, 30, 30, 30, 30, 30, 30, 30, 30], [31, 31, 31, 31, 31, 31, 31, 31, 31, 31], [32, 32, 32, 32, 32, 32, 32, 32, 32, 32], [33, 33, 33, 33, 33, 33, 33, 33, 33, 33], [34, 34, 34, 34, 34, 34, 34, 34, 34, 34], [35, 35, 35, 35, 35, 35, 35, 35, 35, 35], [36, 36, 36, 36, 36, 36, 36, 36, 36, 36], [37, 37, 37, 37, 37, 37, 37, 37, 37, 37], [38, 38, 38, 38, 38, 38, 38, 38, 38, 38], [39, 39, 39, 39, 39, 39, 39, 39, 39, 39], [40, 40, 40, 40, 40, 40, 40, 40, 40, 40], [41, 41, 41, 41, 41, 41, 41, 41, 41, 41], [42, 42, 42, 42, 42, 42, 42, 42, 42, 42], [43, 43, 43, 43, 43, 43, 43, 43, 43, 43], [44, 44, 44, 44, 44, 44, 44, 44, 44, 44], [45, 45, 45, 45, 45, 45, 45, 45, 45, 45], [46, 46, 46, 46, 46, 46, 46, 46, 46, 46], [47, 47, 47, 47, 47, 47, 47, 47, 47, 47], [48, 48, 48, 48, 48, 48, 48, 48, 48, 48], [49, 49, 49, 49, 49, 49, 49, 49, 49, 49], [50, 50, 50, 50, 50, 50, 50, 50, 50, 50], [51, 51, 51, 51, 51, 51, 51, 51, 51, 51], [52, 52, 52, 52, 52, 52, 52, 52, 52, 52], [53, 53, 53, 53, 53, 53, 53, 53, 53, 53], [54, 54, 54, 54, 54, 54, 54, 54, 54, 54], [55, 55, 55, 55, 55, 55, 55, 55, 55, 55], [56, 56, 56, 56, 56, 56, 56, 56, 56, 56], [57, 57, 57, 57, 57, 57, 57, 57, 57, 57], [58, 58, 58, 58, 58, 58, 58, 58, 58, 58], [59, 59, 59, 59, 59, 59, 59, 59, 59, 59], [60, 60, 60, 60, 60, 60, 60, 60, 60, 60], [61, 61, 61, 61, 61, 61, 61, 61, 61, 61], [62, 62, 62, 62, 62, 62, 62, 62, 62, 62], [63, 63, 63, 63, 63, 63, 63, 63, 63, 63], [64, 64, 64, 64, 64, 64, 64, 64, 64, 64], [65, 65, 65, 65, 65, 65, 65, 65, 65, 65], [66, 66, 66, 66, 66, 66, 66, 66, 66, 66], [67, 67, 67, 67, 67, 67, 67, 67, 67, 67], [68, 68, 68, 68, 68, 68, 68, 68, 68, 68], [69, 69, 69, 69, 69, 69, 69, 69, 69, 69], [70, 70, 70, 70, 70, 70, 70, 70, 70, 70], [71, 71, 71, 71, 71, 71, 71, 71, 71, 71], [72, 72, 72, 72, 72, 72, 72, 72, 72, 72], [73, 73, 73, 73, 73, 73, 73, 73, 73, 73], [74, 74, 74, 74, 74, 74, 74, 74, 74, 74], [75, 75, 75, 75, 75, 75, 75, 75, 75, 75], [76, 76, 76, 76, 76, 76, 76, 76, 76, 76], [77, 77, 77, 77, 77, 77, 77, 77, 77, 77], [78, 78, 78, 78, 78, 78, 78, 78, 78, 78], [79, 79, 79, 79, 79, 79, 79, 79, 79, 79], [80, 80, 80, 80, 80, 80, 80, 80, 80, 80], [81, 81, 81, 81, 81, 81, 81, 81, 81, 81], [82, 82, 82, 82, 82, 82, 82, 82, 82, 82], [83, 83, 83, 83, 83, 83, 83, 83, 83, 83], [84, 84, 84, 84, 84, 84, 84, 84, 84, 84], [85, 85, 85, 85, 85, 85, 85, 85, 85, 85], [86, 86, 86, 86, 86, 86, 86, 86, 86, 86], [87, 87, 87, 87, 87, 87, 87, 87, 87, 87], [88, 88, 88, 88, 88, 88, 88, 88, 88, 88], [89, 89, 89, 89, 89, 89, 89, 89, 89, 89], [90, 90, 90, 90, 90, 90, 90, 90, 90, 90], [91, 91, 91, 91, 91, 91, 91, 91, 91, 91], [92, 92, 92, 92, 92, 92, 92, 92, 92, 92], [93, 93, 93, 93, 93, 93, 93, 93, 93, 93], [94, 94, 94, 94, 94, 94, 94, 94, 94, 94], [95, 95, 95, 95, 95, 95, 95, 95, 95, 95], [96, 96, 96, 96, 96, 96, 96, 96, 96, 96], [97, 97, 97, 97, 97, 97, 97, 97, 97, 97], [98, 98, 98, 98, 98, 98, 98, 98, 98, 98], [99, 99, 99, 99, 99, 99, 99, 99, 99, 99], [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]]\n",
      "(1010, 2049) (1010,) (1010,)\n"
     ]
    }
   ],
   "source": [
    "def create_mmr(epoch, standard_events, deviant_events): \n",
    "\n",
    "    std_evoked = epoch[standard_events].average() \n",
    "    dev_evoked = epoch[deviant_events].average()\n",
    " \n",
    "    # calculate the mismatch response between standard and deviant evoked\n",
    "    evoked_diff = mne.combine_evoked([std_evoked, dev_evoked], weights=[1, -1]).get_data(picks=['P7', 'P3', 'Pz', 'PO3', 'O1', 'Oz', 'O2', 'PO4', 'P4', 'P8']) # mismatch for all channels per participant\n",
    "    \n",
    "    #pca = UnsupervisedSpatialFilter(PCA(30), average=False)\n",
    "    #evoked_diff = pca.fit_transform(evoked_diff)\n",
    "    return evoked_diff\n",
    "\n",
    "def to_array(evoked_epochs):\n",
    "    tot_mmr = []\n",
    "    count = 0\n",
    "    \n",
    "    for epoch in evoked_epochs:\n",
    "        mmr = create_mmr(epoch, standard_events, deviant_events)\n",
    "        tot_mmr.append(mmr)\n",
    "        count += 1\n",
    "    print(f\" loaded files: {count}\")\n",
    "    return tot_mmr\n",
    "\n",
    "def input_erp(atrisk_files, control_files, atrisk, control):\n",
    "    atrisk_epochs = to_array(atrisk)\n",
    "    control_epochs = to_array(control)\n",
    "    \n",
    "    control_labels = control_files['Group_AccToParents'].tolist()\n",
    "    atrisk_labels = atrisk_files['Group_AccToParents'].tolist()\n",
    "    \n",
    "    control_labels=[len(i)*[0] for i in control_epochs]\n",
    "    atrisk_labels=[len(i)*[1] for i in atrisk_epochs]\n",
    "    \n",
    "    data_list = control_epochs+atrisk_epochs\n",
    "    label_list = control_labels+atrisk_labels\n",
    "    print(data_list[1].shape, len(data_list))\n",
    "    groups_list=[[i]*len(j) for i, j in enumerate(data_list)]\n",
    "   # groups_list=[i for i in range(len(data_list))]\n",
    "    print(groups_list)\n",
    "    data_array=np.vstack(data_list)\n",
    "    label_array=np.hstack(label_list)\n",
    "    group_array=np.hstack(groups_list)\n",
    "   # data_array=np.moveaxis(data_array,1,2)\n",
    "    \n",
    "    print(data_array.shape,label_array.shape,group_array.shape) #number of segments, length, channels\n",
    "    return data_array, label_array, group_array\n",
    "\n",
    "data_array, label_array, group_array = input_erp(atrisk_files, control_files, atrisk, control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 2047, 4)           16        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2047, 4)          16        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 2047, 4)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1023, 4)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1021, 5)           65        \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 1021, 5)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 510, 5)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 510, 5)            0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 5)                0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 95\n",
      "Non-trainable params: 8\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnnmodel():\n",
    "    clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(filters=4,kernel_size=3,strides=1,input_shape=(2049,1)))#1\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPool1D(pool_size=2,strides=2))#2\n",
    "    model.add(Conv1D(filters=5,kernel_size=3,strides=1))#3\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPool1D(pool_size=2,strides=2))#4\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Conv1D(filters=5,kernel_size=3,strides=1))#5\n",
    "    #model.add(LeakyReLU())\n",
    "    #model.add(AveragePooling1D(pool_size=2,strides=2))#6\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Conv1D(filters=5,kernel_size=3,strides=1))#7\n",
    "    #model.add(LeakyReLU())\n",
    "    #model.add(AveragePooling1D(pool_size=2,strides=2))#8\n",
    "    #model.add(Conv1D(filters=5,kernel_size=3,strides=1))#9\n",
    "    #model.add(LeakyReLU())\n",
    "    model.add(GlobalAveragePooling1D())#10\n",
    "    model.add(Dense(1,activation='relu'))#11\n",
    "    \n",
    "    model.compile('adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=cnnmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf=GroupKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 100, 100, 100])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reduce dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 17ms/step - loss: 4.6247 - accuracy: 0.4940 - val_loss: 1.0394 - val_accuracy: 0.4824\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2.6926 - accuracy: 0.4940 - val_loss: 0.9941 - val_accuracy: 0.4824\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.1676 - accuracy: 0.4925 - val_loss: 0.9811 - val_accuracy: 0.4824\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.9993 - accuracy: 0.4925 - val_loss: 0.9729 - val_accuracy: 0.4853\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.3669 - accuracy: 0.4925 - val_loss: 0.9707 - val_accuracy: 0.4824\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0992 - accuracy: 0.4910 - val_loss: 0.9641 - val_accuracy: 0.4853\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.0007 - accuracy: 0.4925 - val_loss: 0.9569 - val_accuracy: 0.4853\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9791 - accuracy: 0.4910 - val_loss: 0.9499 - val_accuracy: 0.4853\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9627 - accuracy: 0.4925 - val_loss: 0.9431 - val_accuracy: 0.4853\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9420 - accuracy: 0.4896 - val_loss: 0.9368 - val_accuracy: 0.4853\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.9278 - accuracy: 0.4940 - val_loss: 0.9313 - val_accuracy: 0.4853\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.9186 - accuracy: 0.4925 - val_loss: 0.9261 - val_accuracy: 0.4882\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9110 - accuracy: 0.4925 - val_loss: 0.9211 - val_accuracy: 0.4912\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9016 - accuracy: 0.4970 - val_loss: 0.9167 - val_accuracy: 0.4912\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8915 - accuracy: 0.4985 - val_loss: 0.9125 - val_accuracy: 0.4912\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8866 - accuracy: 0.4970 - val_loss: 0.9087 - val_accuracy: 0.4971\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8861 - accuracy: 0.4985 - val_loss: 0.9052 - val_accuracy: 0.4971\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8811 - accuracy: 0.5075 - val_loss: 0.9022 - val_accuracy: 0.4941\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8815 - accuracy: 0.5030 - val_loss: 0.8992 - val_accuracy: 0.4941\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8765 - accuracy: 0.5015 - val_loss: 0.8966 - val_accuracy: 0.5000\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8747 - accuracy: 0.5060 - val_loss: 0.8941 - val_accuracy: 0.5000\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8730 - accuracy: 0.5030 - val_loss: 0.8915 - val_accuracy: 0.5000\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8714 - accuracy: 0.4985 - val_loss: 0.8892 - val_accuracy: 0.5000\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8673 - accuracy: 0.5030 - val_loss: 0.8868 - val_accuracy: 0.5029\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8638 - accuracy: 0.5015 - val_loss: 0.8848 - val_accuracy: 0.5029\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8652 - accuracy: 0.5060 - val_loss: 0.8826 - val_accuracy: 0.5029\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8603 - accuracy: 0.5075 - val_loss: 0.8804 - val_accuracy: 0.5029\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8573 - accuracy: 0.5015 - val_loss: 0.8782 - val_accuracy: 0.5029\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8595 - accuracy: 0.5000 - val_loss: 0.8763 - val_accuracy: 0.5029\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8526 - accuracy: 0.5030 - val_loss: 0.8742 - val_accuracy: 0.5029\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8573 - accuracy: 0.5015 - val_loss: 0.8723 - val_accuracy: 0.5029\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8503 - accuracy: 0.5030 - val_loss: 0.8705 - val_accuracy: 0.5029\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8548 - accuracy: 0.5030 - val_loss: 0.8688 - val_accuracy: 0.5029\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8487 - accuracy: 0.5075 - val_loss: 0.8666 - val_accuracy: 0.5029\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8409 - accuracy: 0.5045 - val_loss: 0.8645 - val_accuracy: 0.5029\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8455 - accuracy: 0.5030 - val_loss: 0.8625 - val_accuracy: 0.5059\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8412 - accuracy: 0.5000 - val_loss: 0.8603 - val_accuracy: 0.5059\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8367 - accuracy: 0.5119 - val_loss: 0.8585 - val_accuracy: 0.5029\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8343 - accuracy: 0.5045 - val_loss: 0.8559 - val_accuracy: 0.5029\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8398 - accuracy: 0.5030 - val_loss: 0.8536 - val_accuracy: 0.5059\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8401 - accuracy: 0.5075 - val_loss: 0.8515 - val_accuracy: 0.5059\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8332 - accuracy: 0.5045 - val_loss: 0.8492 - val_accuracy: 0.5059\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8316 - accuracy: 0.5045 - val_loss: 0.8471 - val_accuracy: 0.5059\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8278 - accuracy: 0.5000 - val_loss: 0.8447 - val_accuracy: 0.5059\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8269 - accuracy: 0.5075 - val_loss: 0.8423 - val_accuracy: 0.5088\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8266 - accuracy: 0.5045 - val_loss: 0.8396 - val_accuracy: 0.5118\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8240 - accuracy: 0.5060 - val_loss: 0.8374 - val_accuracy: 0.5147\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8157 - accuracy: 0.5149 - val_loss: 0.8355 - val_accuracy: 0.5147\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8163 - accuracy: 0.5164 - val_loss: 0.8329 - val_accuracy: 0.5147\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8145 - accuracy: 0.5119 - val_loss: 0.8305 - val_accuracy: 0.5147\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8124 - accuracy: 0.5179 - val_loss: 0.8283 - val_accuracy: 0.5147\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8158 - accuracy: 0.5134 - val_loss: 0.8259 - val_accuracy: 0.5147\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8086 - accuracy: 0.5090 - val_loss: 0.8235 - val_accuracy: 0.5176\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8100 - accuracy: 0.5075 - val_loss: 0.8212 - val_accuracy: 0.5176\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8085 - accuracy: 0.5179 - val_loss: 0.8186 - val_accuracy: 0.5206\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8127 - accuracy: 0.5119 - val_loss: 0.8166 - val_accuracy: 0.5176\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.8030 - accuracy: 0.5134 - val_loss: 0.8145 - val_accuracy: 0.5206\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8042 - accuracy: 0.5104 - val_loss: 0.8124 - val_accuracy: 0.5206\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7969 - accuracy: 0.5119 - val_loss: 0.8102 - val_accuracy: 0.5235\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7927 - accuracy: 0.5149 - val_loss: 0.8079 - val_accuracy: 0.5265\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7953 - accuracy: 0.5149 - val_loss: 0.8059 - val_accuracy: 0.5265\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7923 - accuracy: 0.5149 - val_loss: 0.8039 - val_accuracy: 0.5235\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7901 - accuracy: 0.5134 - val_loss: 0.8020 - val_accuracy: 0.5206\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7901 - accuracy: 0.5090 - val_loss: 0.7998 - val_accuracy: 0.5206\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7863 - accuracy: 0.5179 - val_loss: 0.7977 - val_accuracy: 0.5235\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7877 - accuracy: 0.5060 - val_loss: 0.7959 - val_accuracy: 0.5235\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7839 - accuracy: 0.5134 - val_loss: 0.7939 - val_accuracy: 0.5206\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7805 - accuracy: 0.5194 - val_loss: 0.7917 - val_accuracy: 0.5235\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7835 - accuracy: 0.5164 - val_loss: 0.7899 - val_accuracy: 0.5235\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7852 - accuracy: 0.5060 - val_loss: 0.7879 - val_accuracy: 0.5235\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7829 - accuracy: 0.5104 - val_loss: 0.7863 - val_accuracy: 0.5176\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7724 - accuracy: 0.5060 - val_loss: 0.7843 - val_accuracy: 0.5235\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7723 - accuracy: 0.5149 - val_loss: 0.7821 - val_accuracy: 0.5206\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7750 - accuracy: 0.5149 - val_loss: 0.7803 - val_accuracy: 0.5176\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7708 - accuracy: 0.5149 - val_loss: 0.7785 - val_accuracy: 0.5206\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7686 - accuracy: 0.5209 - val_loss: 0.7777 - val_accuracy: 0.5206\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7701 - accuracy: 0.5119 - val_loss: 0.7767 - val_accuracy: 0.5206\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7667 - accuracy: 0.5164 - val_loss: 0.7748 - val_accuracy: 0.5265\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.7646 - accuracy: 0.5179 - val_loss: 0.7732 - val_accuracy: 0.5235\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7670 - accuracy: 0.5179 - val_loss: 0.7717 - val_accuracy: 0.5235\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7613 - accuracy: 0.5090 - val_loss: 0.7698 - val_accuracy: 0.5324\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7588 - accuracy: 0.5179 - val_loss: 0.7685 - val_accuracy: 0.5412\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7569 - accuracy: 0.5104 - val_loss: 0.7665 - val_accuracy: 0.5382\n",
      "Epoch 84/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7594 - accuracy: 0.5224 - val_loss: 0.7649 - val_accuracy: 0.5382\n",
      "Epoch 85/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7582 - accuracy: 0.5149 - val_loss: 0.7638 - val_accuracy: 0.5382\n",
      "Epoch 86/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7564 - accuracy: 0.5134 - val_loss: 0.7629 - val_accuracy: 0.5353\n",
      "Epoch 87/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7592 - accuracy: 0.5224 - val_loss: 0.7628 - val_accuracy: 0.5382\n",
      "Epoch 88/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7524 - accuracy: 0.5164 - val_loss: 0.7614 - val_accuracy: 0.5353\n",
      "Epoch 89/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7510 - accuracy: 0.5179 - val_loss: 0.7599 - val_accuracy: 0.5353\n",
      "Epoch 90/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7572 - accuracy: 0.5209 - val_loss: 0.7631 - val_accuracy: 0.5353\n",
      "Epoch 91/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7530 - accuracy: 0.5284 - val_loss: 0.7632 - val_accuracy: 0.5324\n",
      "Epoch 92/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7513 - accuracy: 0.5254 - val_loss: 0.7625 - val_accuracy: 0.5324\n",
      "Epoch 93/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7523 - accuracy: 0.5179 - val_loss: 0.7608 - val_accuracy: 0.5353\n",
      "Epoch 94/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7399 - accuracy: 0.5269 - val_loss: 0.7591 - val_accuracy: 0.5382\n",
      "Epoch 95/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7474 - accuracy: 0.5179 - val_loss: 0.7573 - val_accuracy: 0.5324\n",
      "Epoch 96/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7421 - accuracy: 0.5179 - val_loss: 0.7549 - val_accuracy: 0.5353\n",
      "Epoch 97/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7437 - accuracy: 0.5075 - val_loss: 0.7528 - val_accuracy: 0.5324\n",
      "Epoch 98/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7441 - accuracy: 0.5149 - val_loss: 0.7527 - val_accuracy: 0.5265\n",
      "Epoch 99/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7387 - accuracy: 0.5328 - val_loss: 0.7517 - val_accuracy: 0.5294\n",
      "Epoch 100/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7556 - accuracy: 0.5269 - val_loss: 0.7497 - val_accuracy: 0.5294\n",
      "Epoch 101/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7395 - accuracy: 0.5179 - val_loss: 0.7483 - val_accuracy: 0.5324\n",
      "Epoch 102/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7410 - accuracy: 0.5239 - val_loss: 0.7478 - val_accuracy: 0.5294\n",
      "Epoch 103/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7371 - accuracy: 0.5239 - val_loss: 0.7481 - val_accuracy: 0.5265\n",
      "Epoch 104/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7554 - accuracy: 0.5164 - val_loss: 0.7460 - val_accuracy: 0.5294\n",
      "Epoch 105/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7370 - accuracy: 0.5209 - val_loss: 0.7442 - val_accuracy: 0.5294\n",
      "Epoch 106/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7371 - accuracy: 0.5209 - val_loss: 0.7437 - val_accuracy: 0.5294\n",
      "Epoch 107/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7377 - accuracy: 0.5284 - val_loss: 0.7466 - val_accuracy: 0.5235\n",
      "Epoch 108/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7541 - accuracy: 0.5090 - val_loss: 0.7448 - val_accuracy: 0.5265\n",
      "Epoch 109/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7340 - accuracy: 0.5254 - val_loss: 0.7427 - val_accuracy: 0.5265\n",
      "Epoch 110/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7289 - accuracy: 0.5403 - val_loss: 0.7416 - val_accuracy: 0.5265\n",
      "Epoch 111/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7334 - accuracy: 0.5104 - val_loss: 0.7411 - val_accuracy: 0.5235\n",
      "Epoch 112/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7481 - accuracy: 0.5149 - val_loss: 0.7400 - val_accuracy: 0.5235\n",
      "Epoch 113/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7328 - accuracy: 0.5164 - val_loss: 0.7387 - val_accuracy: 0.5265\n",
      "Epoch 114/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7482 - accuracy: 0.5149 - val_loss: 0.7382 - val_accuracy: 0.5265\n",
      "Epoch 115/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7335 - accuracy: 0.5179 - val_loss: 0.7394 - val_accuracy: 0.5235\n",
      "Epoch 116/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7487 - accuracy: 0.5194 - val_loss: 0.7388 - val_accuracy: 0.5235\n",
      "Epoch 117/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7238 - accuracy: 0.5164 - val_loss: 0.7369 - val_accuracy: 0.5235\n",
      "Epoch 118/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7237 - accuracy: 0.5209 - val_loss: 0.7360 - val_accuracy: 0.5206\n",
      "Epoch 119/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7370 - accuracy: 0.5149 - val_loss: 0.8097 - val_accuracy: 0.4794\n",
      "Epoch 120/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7771 - accuracy: 0.5134 - val_loss: 1.2492 - val_accuracy: 0.4353\n",
      "Epoch 121/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7920 - accuracy: 0.5104 - val_loss: 0.9909 - val_accuracy: 0.4382\n",
      "Epoch 122/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7896 - accuracy: 0.5119 - val_loss: 0.9114 - val_accuracy: 0.4441\n",
      "Epoch 123/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7876 - accuracy: 0.5030 - val_loss: 0.8704 - val_accuracy: 0.4441\n",
      "Epoch 124/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7774 - accuracy: 0.5104 - val_loss: 0.8475 - val_accuracy: 0.4559\n",
      "Epoch 125/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7686 - accuracy: 0.5090 - val_loss: 0.8317 - val_accuracy: 0.4588\n",
      "Epoch 126/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7672 - accuracy: 0.5104 - val_loss: 0.8186 - val_accuracy: 0.4588\n",
      "Epoch 127/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7588 - accuracy: 0.5254 - val_loss: 0.8081 - val_accuracy: 0.4706\n",
      "Epoch 128/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7545 - accuracy: 0.5149 - val_loss: 0.7991 - val_accuracy: 0.4765\n",
      "Epoch 129/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7509 - accuracy: 0.5090 - val_loss: 0.7919 - val_accuracy: 0.4765\n",
      "Epoch 130/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7402 - accuracy: 0.5164 - val_loss: 0.7856 - val_accuracy: 0.4794\n",
      "Epoch 131/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7417 - accuracy: 0.5388 - val_loss: 0.7792 - val_accuracy: 0.4853\n",
      "Epoch 132/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7405 - accuracy: 0.5164 - val_loss: 0.7742 - val_accuracy: 0.4882\n",
      "Epoch 133/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7366 - accuracy: 0.5104 - val_loss: 0.7696 - val_accuracy: 0.4941\n",
      "Epoch 134/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7335 - accuracy: 0.5194 - val_loss: 0.7653 - val_accuracy: 0.4971\n",
      "Epoch 135/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7252 - accuracy: 0.5209 - val_loss: 0.7609 - val_accuracy: 0.4971\n",
      "Epoch 136/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7295 - accuracy: 0.5179 - val_loss: 0.7577 - val_accuracy: 0.5000\n",
      "Epoch 137/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7314 - accuracy: 0.5284 - val_loss: 0.7545 - val_accuracy: 0.5029\n",
      "Epoch 138/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7288 - accuracy: 0.5060 - val_loss: 0.7517 - val_accuracy: 0.4971\n",
      "Epoch 139/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7243 - accuracy: 0.5373 - val_loss: 0.7485 - val_accuracy: 0.4971\n",
      "Epoch 140/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7284 - accuracy: 0.5119 - val_loss: 0.7461 - val_accuracy: 0.5059\n",
      "Epoch 141/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7222 - accuracy: 0.5209 - val_loss: 0.7437 - val_accuracy: 0.5059\n",
      "Epoch 142/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7250 - accuracy: 0.5209 - val_loss: 0.7416 - val_accuracy: 0.5029\n",
      "Epoch 143/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7159 - accuracy: 0.5269 - val_loss: 0.7398 - val_accuracy: 0.4971\n",
      "Epoch 144/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7122 - accuracy: 0.5254 - val_loss: 0.7379 - val_accuracy: 0.5059\n",
      "Epoch 145/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7107 - accuracy: 0.5299 - val_loss: 0.7364 - val_accuracy: 0.5059\n",
      "Epoch 146/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7105 - accuracy: 0.5328 - val_loss: 0.7343 - val_accuracy: 0.5088\n",
      "Epoch 147/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7122 - accuracy: 0.5179 - val_loss: 0.7329 - val_accuracy: 0.5118\n",
      "Epoch 148/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7108 - accuracy: 0.5284 - val_loss: 0.7316 - val_accuracy: 0.5118\n",
      "Epoch 149/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7141 - accuracy: 0.5284 - val_loss: 0.7317 - val_accuracy: 0.5147\n",
      "Epoch 150/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7108 - accuracy: 0.5343 - val_loss: 0.7309 - val_accuracy: 0.5147\n",
      "Epoch 151/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7115 - accuracy: 0.5388 - val_loss: 0.7306 - val_accuracy: 0.5118\n",
      "Epoch 152/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7088 - accuracy: 0.5284 - val_loss: 0.7295 - val_accuracy: 0.5088\n",
      "Epoch 153/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7035 - accuracy: 0.5403 - val_loss: 0.7282 - val_accuracy: 0.5118\n",
      "Epoch 154/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7074 - accuracy: 0.5358 - val_loss: 0.7272 - val_accuracy: 0.5176\n",
      "Epoch 155/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7132 - accuracy: 0.5209 - val_loss: 0.7272 - val_accuracy: 0.5176\n",
      "Epoch 156/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6999 - accuracy: 0.5373 - val_loss: 0.7265 - val_accuracy: 0.5176\n",
      "Epoch 157/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6968 - accuracy: 0.5493 - val_loss: 0.7256 - val_accuracy: 0.5147\n",
      "Epoch 158/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7037 - accuracy: 0.5597 - val_loss: 0.7291 - val_accuracy: 0.5118\n",
      "Epoch 159/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7015 - accuracy: 0.5284 - val_loss: 0.7319 - val_accuracy: 0.5118\n",
      "Epoch 160/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7006 - accuracy: 0.5448 - val_loss: 0.7306 - val_accuracy: 0.5118\n",
      "Epoch 161/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7063 - accuracy: 0.5403 - val_loss: 0.7289 - val_accuracy: 0.5088\n",
      "Epoch 162/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7014 - accuracy: 0.5373 - val_loss: 0.7272 - val_accuracy: 0.5088\n",
      "Epoch 163/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7054 - accuracy: 0.5328 - val_loss: 0.7265 - val_accuracy: 0.5147\n",
      "Epoch 164/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7103 - accuracy: 0.5478 - val_loss: 0.7262 - val_accuracy: 0.5147\n",
      "Epoch 165/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7045 - accuracy: 0.5299 - val_loss: 0.7262 - val_accuracy: 0.5147\n",
      "Epoch 166/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7070 - accuracy: 0.5448 - val_loss: 0.7254 - val_accuracy: 0.5118\n",
      "Epoch 167/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7020 - accuracy: 0.5493 - val_loss: 0.7241 - val_accuracy: 0.5118\n",
      "Epoch 168/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7006 - accuracy: 0.5284 - val_loss: 0.7238 - val_accuracy: 0.5118\n",
      "Epoch 169/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7031 - accuracy: 0.5403 - val_loss: 0.7241 - val_accuracy: 0.5147\n",
      "Epoch 170/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7007 - accuracy: 0.5299 - val_loss: 0.7241 - val_accuracy: 0.5118\n",
      "Epoch 171/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7080 - accuracy: 0.5299 - val_loss: 0.7234 - val_accuracy: 0.5088\n",
      "Epoch 172/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7189 - accuracy: 0.5194 - val_loss: 0.7853 - val_accuracy: 0.4647\n",
      "Epoch 173/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7356 - accuracy: 0.5119 - val_loss: 0.8248 - val_accuracy: 0.4382\n",
      "Epoch 174/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7473 - accuracy: 0.5134 - val_loss: 0.8140 - val_accuracy: 0.4412\n",
      "Epoch 175/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7368 - accuracy: 0.5164 - val_loss: 0.8005 - val_accuracy: 0.4500\n",
      "Epoch 176/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7359 - accuracy: 0.5224 - val_loss: 0.7893 - val_accuracy: 0.4588\n",
      "Epoch 177/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7246 - accuracy: 0.5254 - val_loss: 0.7805 - val_accuracy: 0.4647\n",
      "Epoch 178/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7253 - accuracy: 0.5164 - val_loss: 0.7732 - val_accuracy: 0.4676\n",
      "Epoch 179/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7294 - accuracy: 0.5194 - val_loss: 0.7663 - val_accuracy: 0.4735\n",
      "Epoch 180/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7223 - accuracy: 0.5239 - val_loss: 0.7611 - val_accuracy: 0.4824\n",
      "Epoch 181/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7204 - accuracy: 0.5164 - val_loss: 0.7561 - val_accuracy: 0.4824\n",
      "Epoch 182/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7176 - accuracy: 0.5239 - val_loss: 0.7515 - val_accuracy: 0.4882\n",
      "Epoch 183/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7140 - accuracy: 0.5448 - val_loss: 0.7478 - val_accuracy: 0.4912\n",
      "Epoch 184/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7147 - accuracy: 0.5358 - val_loss: 0.7446 - val_accuracy: 0.4941\n",
      "Epoch 185/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7092 - accuracy: 0.5388 - val_loss: 0.7411 - val_accuracy: 0.4971\n",
      "Epoch 186/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7141 - accuracy: 0.5209 - val_loss: 0.7381 - val_accuracy: 0.4971\n",
      "Epoch 187/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7157 - accuracy: 0.5104 - val_loss: 0.7352 - val_accuracy: 0.4941\n",
      "Epoch 188/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7054 - accuracy: 0.5343 - val_loss: 0.7329 - val_accuracy: 0.4941\n",
      "Epoch 189/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7056 - accuracy: 0.5328 - val_loss: 0.7317 - val_accuracy: 0.4971\n",
      "Epoch 190/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7068 - accuracy: 0.5328 - val_loss: 0.7303 - val_accuracy: 0.5000\n",
      "Epoch 191/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7067 - accuracy: 0.5358 - val_loss: 0.7286 - val_accuracy: 0.5029\n",
      "Epoch 192/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7036 - accuracy: 0.5343 - val_loss: 0.7273 - val_accuracy: 0.4971\n",
      "Epoch 193/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7081 - accuracy: 0.5149 - val_loss: 0.7259 - val_accuracy: 0.5059\n",
      "Epoch 194/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7012 - accuracy: 0.5478 - val_loss: 0.7242 - val_accuracy: 0.5088\n",
      "Epoch 195/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7004 - accuracy: 0.5343 - val_loss: 0.7229 - val_accuracy: 0.5147\n",
      "Epoch 196/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7012 - accuracy: 0.5299 - val_loss: 0.7220 - val_accuracy: 0.5088\n",
      "Epoch 197/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6983 - accuracy: 0.5373 - val_loss: 0.7211 - val_accuracy: 0.5088\n",
      "Epoch 198/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6901 - accuracy: 0.5493 - val_loss: 0.7205 - val_accuracy: 0.5059\n",
      "Epoch 199/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7001 - accuracy: 0.5373 - val_loss: 0.7197 - val_accuracy: 0.5118\n",
      "Epoch 200/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6963 - accuracy: 0.5313 - val_loss: 0.7213 - val_accuracy: 0.5088\n",
      "Epoch 201/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6989 - accuracy: 0.5328 - val_loss: 0.7200 - val_accuracy: 0.5059\n",
      "Epoch 202/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6994 - accuracy: 0.5493 - val_loss: 0.7201 - val_accuracy: 0.5059\n",
      "Epoch 203/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6963 - accuracy: 0.5478 - val_loss: 0.7198 - val_accuracy: 0.5088\n",
      "Epoch 204/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7001 - accuracy: 0.5418 - val_loss: 0.7187 - val_accuracy: 0.5118\n",
      "Epoch 205/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7033 - accuracy: 0.5269 - val_loss: 0.7184 - val_accuracy: 0.5176\n",
      "Epoch 206/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6974 - accuracy: 0.5358 - val_loss: 0.7172 - val_accuracy: 0.5147\n",
      "Epoch 207/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6957 - accuracy: 0.5433 - val_loss: 0.7162 - val_accuracy: 0.5176\n",
      "Epoch 208/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7104 - accuracy: 0.5507 - val_loss: 0.7154 - val_accuracy: 0.5206\n",
      "Epoch 209/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6965 - accuracy: 0.5493 - val_loss: 0.7154 - val_accuracy: 0.5176\n",
      "Epoch 210/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7148 - accuracy: 0.5582 - val_loss: 0.7146 - val_accuracy: 0.5235\n",
      "Epoch 211/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6929 - accuracy: 0.5313 - val_loss: 0.7142 - val_accuracy: 0.5265\n",
      "Epoch 212/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5284 - val_loss: 0.7136 - val_accuracy: 0.5206\n",
      "Epoch 213/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7182 - accuracy: 0.5597 - val_loss: 0.7130 - val_accuracy: 0.5206\n",
      "Epoch 214/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6914 - accuracy: 0.5507 - val_loss: 0.7131 - val_accuracy: 0.5206\n",
      "Epoch 215/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6977 - accuracy: 0.5552 - val_loss: 0.7137 - val_accuracy: 0.5176\n",
      "Epoch 216/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6945 - accuracy: 0.5388 - val_loss: 0.7137 - val_accuracy: 0.5206\n",
      "Epoch 217/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6968 - accuracy: 0.5597 - val_loss: 0.7134 - val_accuracy: 0.5176\n",
      "Epoch 218/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6979 - accuracy: 0.5478 - val_loss: 0.7132 - val_accuracy: 0.5176\n",
      "Epoch 219/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6966 - accuracy: 0.5612 - val_loss: 0.7138 - val_accuracy: 0.5206\n",
      "Epoch 220/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6927 - accuracy: 0.5507 - val_loss: 0.7140 - val_accuracy: 0.5176\n",
      "Epoch 221/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6924 - accuracy: 0.5537 - val_loss: 0.7132 - val_accuracy: 0.5206\n",
      "Epoch 222/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6958 - accuracy: 0.5388 - val_loss: 0.7130 - val_accuracy: 0.5147\n",
      "Epoch 223/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6955 - accuracy: 0.5582 - val_loss: 0.7128 - val_accuracy: 0.5147\n",
      "Epoch 224/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6967 - accuracy: 0.5388 - val_loss: 0.7126 - val_accuracy: 0.5118\n",
      "Epoch 225/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6920 - accuracy: 0.5627 - val_loss: 0.7132 - val_accuracy: 0.5147\n",
      "Epoch 226/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6917 - accuracy: 0.5522 - val_loss: 0.7152 - val_accuracy: 0.5118\n",
      "Epoch 227/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6926 - accuracy: 0.5522 - val_loss: 0.7151 - val_accuracy: 0.5088\n",
      "Epoch 228/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7133 - accuracy: 0.5343 - val_loss: 0.7140 - val_accuracy: 0.5088\n",
      "Epoch 229/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7153 - accuracy: 0.5522 - val_loss: 0.7128 - val_accuracy: 0.5147\n",
      "Epoch 230/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7156 - accuracy: 0.5448 - val_loss: 0.7119 - val_accuracy: 0.5118\n",
      "Epoch 231/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6982 - accuracy: 0.5403 - val_loss: 0.7120 - val_accuracy: 0.5176\n",
      "Epoch 232/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.5463 - val_loss: 0.7115 - val_accuracy: 0.5147\n",
      "Epoch 233/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7125 - accuracy: 0.5373 - val_loss: 0.7105 - val_accuracy: 0.5206\n",
      "Epoch 234/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7162 - accuracy: 0.5433 - val_loss: 0.7097 - val_accuracy: 0.5206\n",
      "Epoch 235/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5478 - val_loss: 0.7092 - val_accuracy: 0.5206\n",
      "Epoch 236/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6861 - accuracy: 0.5627 - val_loss: 0.7089 - val_accuracy: 0.5206\n",
      "Epoch 237/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7172 - accuracy: 0.5358 - val_loss: 0.7106 - val_accuracy: 0.5088\n",
      "Epoch 238/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6898 - accuracy: 0.5373 - val_loss: 0.7097 - val_accuracy: 0.5147\n",
      "Epoch 239/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6887 - accuracy: 0.5463 - val_loss: 0.7086 - val_accuracy: 0.5176\n",
      "Epoch 240/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7116 - accuracy: 0.5433 - val_loss: 0.7081 - val_accuracy: 0.5147\n",
      "Epoch 241/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7055 - accuracy: 0.5522 - val_loss: 0.7076 - val_accuracy: 0.5118\n",
      "Epoch 242/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7076 - accuracy: 0.5463 - val_loss: 0.7070 - val_accuracy: 0.5059\n",
      "Epoch 243/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6888 - accuracy: 0.5537 - val_loss: 0.7068 - val_accuracy: 0.5059\n",
      "Epoch 244/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5522 - val_loss: 0.7078 - val_accuracy: 0.5118\n",
      "Epoch 245/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6872 - accuracy: 0.5567 - val_loss: 0.7080 - val_accuracy: 0.5176\n",
      "Epoch 246/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6878 - accuracy: 0.5493 - val_loss: 0.7073 - val_accuracy: 0.5059\n",
      "Epoch 247/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6887 - accuracy: 0.5493 - val_loss: 0.7067 - val_accuracy: 0.5088\n",
      "Epoch 248/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7114 - accuracy: 0.5552 - val_loss: 0.7060 - val_accuracy: 0.5059\n",
      "Epoch 249/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7125 - accuracy: 0.5448 - val_loss: 0.7053 - val_accuracy: 0.5118\n",
      "Epoch 250/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6886 - accuracy: 0.5403 - val_loss: 0.7052 - val_accuracy: 0.5147\n",
      "Epoch 251/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6917 - accuracy: 0.5403 - val_loss: 0.7050 - val_accuracy: 0.5147\n",
      "Epoch 252/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6908 - accuracy: 0.5448 - val_loss: 0.7070 - val_accuracy: 0.5147\n",
      "Epoch 253/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7070 - accuracy: 0.5313 - val_loss: 0.7065 - val_accuracy: 0.5147\n",
      "Epoch 254/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7126 - accuracy: 0.5373 - val_loss: 0.7058 - val_accuracy: 0.5029\n",
      "Epoch 255/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6883 - accuracy: 0.5701 - val_loss: 0.7069 - val_accuracy: 0.5118\n",
      "Epoch 256/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7023 - accuracy: 0.5478 - val_loss: 0.7060 - val_accuracy: 0.5088\n",
      "Epoch 257/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6895 - accuracy: 0.5328 - val_loss: 0.7053 - val_accuracy: 0.5029\n",
      "Epoch 258/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7064 - accuracy: 0.5687 - val_loss: 0.7044 - val_accuracy: 0.5029\n",
      "Epoch 259/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6907 - accuracy: 0.5582 - val_loss: 0.7066 - val_accuracy: 0.5118\n",
      "Epoch 260/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6945 - accuracy: 0.5433 - val_loss: 0.7088 - val_accuracy: 0.5118\n",
      "Epoch 261/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6906 - accuracy: 0.5507 - val_loss: 0.7082 - val_accuracy: 0.5118\n",
      "Epoch 262/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5433 - val_loss: 0.7075 - val_accuracy: 0.5118\n",
      "Epoch 263/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6895 - accuracy: 0.5507 - val_loss: 0.7062 - val_accuracy: 0.5118\n",
      "Epoch 264/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7072 - accuracy: 0.5522 - val_loss: 0.7051 - val_accuracy: 0.5118\n",
      "Epoch 265/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6877 - accuracy: 0.5493 - val_loss: 0.7039 - val_accuracy: 0.5029\n",
      "Epoch 266/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6894 - accuracy: 0.5597 - val_loss: 0.7034 - val_accuracy: 0.5000\n",
      "Epoch 267/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5507 - val_loss: 0.7034 - val_accuracy: 0.5000\n",
      "Epoch 268/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.5582 - val_loss: 0.7032 - val_accuracy: 0.5000\n",
      "Epoch 269/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6898 - accuracy: 0.5493 - val_loss: 0.7035 - val_accuracy: 0.5029\n",
      "Epoch 270/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6850 - accuracy: 0.5597 - val_loss: 0.7034 - val_accuracy: 0.5059\n",
      "Epoch 271/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.5493 - val_loss: 0.7026 - val_accuracy: 0.5000\n",
      "Epoch 272/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6987 - accuracy: 0.5463 - val_loss: 0.7071 - val_accuracy: 0.5176\n",
      "Epoch 273/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6919 - accuracy: 0.5507 - val_loss: 0.7059 - val_accuracy: 0.5118\n",
      "Epoch 274/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6927 - accuracy: 0.5358 - val_loss: 0.7053 - val_accuracy: 0.5088\n",
      "Epoch 275/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6887 - accuracy: 0.5537 - val_loss: 0.7047 - val_accuracy: 0.5088\n",
      "Epoch 276/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5657 - val_loss: 0.7033 - val_accuracy: 0.5118\n",
      "Epoch 277/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6908 - accuracy: 0.5552 - val_loss: 0.7044 - val_accuracy: 0.5088\n",
      "Epoch 278/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6917 - accuracy: 0.5463 - val_loss: 0.7043 - val_accuracy: 0.5088\n",
      "Epoch 279/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6953 - accuracy: 0.5403 - val_loss: 0.7098 - val_accuracy: 0.5059\n",
      "Epoch 280/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6888 - accuracy: 0.5373 - val_loss: 0.7120 - val_accuracy: 0.4912\n",
      "Epoch 281/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6864 - accuracy: 0.5343 - val_loss: 0.7106 - val_accuracy: 0.5029\n",
      "Epoch 282/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6901 - accuracy: 0.5552 - val_loss: 0.7074 - val_accuracy: 0.5029\n",
      "Epoch 283/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6893 - accuracy: 0.5418 - val_loss: 0.7047 - val_accuracy: 0.5118\n",
      "Epoch 284/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6865 - accuracy: 0.5597 - val_loss: 0.7038 - val_accuracy: 0.5088\n",
      "Epoch 285/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6885 - accuracy: 0.5358 - val_loss: 0.7015 - val_accuracy: 0.5088\n",
      "Epoch 286/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6870 - accuracy: 0.5433 - val_loss: 0.7012 - val_accuracy: 0.5000\n",
      "Epoch 287/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6891 - accuracy: 0.5373 - val_loss: 0.7001 - val_accuracy: 0.5059\n",
      "Epoch 288/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5597 - val_loss: 0.6995 - val_accuracy: 0.5088\n",
      "Epoch 289/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6903 - accuracy: 0.5567 - val_loss: 0.6986 - val_accuracy: 0.5029\n",
      "Epoch 290/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6856 - accuracy: 0.5731 - val_loss: 0.6981 - val_accuracy: 0.5029\n",
      "Epoch 291/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6920 - accuracy: 0.5373 - val_loss: 0.6990 - val_accuracy: 0.5088\n",
      "Epoch 292/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6886 - accuracy: 0.5493 - val_loss: 0.6988 - val_accuracy: 0.5118\n",
      "Epoch 293/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6893 - accuracy: 0.5493 - val_loss: 0.6979 - val_accuracy: 0.5029\n",
      "Epoch 294/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.5552 - val_loss: 0.6977 - val_accuracy: 0.5029\n",
      "Epoch 295/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6889 - accuracy: 0.5403 - val_loss: 0.6970 - val_accuracy: 0.5088\n",
      "Epoch 296/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6873 - accuracy: 0.5373 - val_loss: 0.6976 - val_accuracy: 0.5029\n",
      "Epoch 297/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6869 - accuracy: 0.5522 - val_loss: 0.6971 - val_accuracy: 0.5059\n",
      "Epoch 298/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6928 - accuracy: 0.5433 - val_loss: 0.6977 - val_accuracy: 0.5059\n",
      "Epoch 299/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5567 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
      "Epoch 300/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5597 - val_loss: 0.6974 - val_accuracy: 0.5029\n",
      "Epoch 301/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6870 - accuracy: 0.5582 - val_loss: 0.6971 - val_accuracy: 0.5029\n",
      "Epoch 302/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5672 - val_loss: 0.6967 - val_accuracy: 0.5088\n",
      "Epoch 303/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6827 - accuracy: 0.5791 - val_loss: 0.6965 - val_accuracy: 0.5088\n",
      "Epoch 304/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6855 - accuracy: 0.5463 - val_loss: 0.6965 - val_accuracy: 0.5088\n",
      "Epoch 305/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6892 - accuracy: 0.5657 - val_loss: 0.6977 - val_accuracy: 0.5029\n",
      "Epoch 306/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6841 - accuracy: 0.5537 - val_loss: 0.6979 - val_accuracy: 0.5059\n",
      "Epoch 307/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.5522 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
      "Epoch 308/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5493 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 309/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6866 - accuracy: 0.5507 - val_loss: 0.6974 - val_accuracy: 0.4971\n",
      "Epoch 310/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6889 - accuracy: 0.5493 - val_loss: 0.6972 - val_accuracy: 0.4941\n",
      "Epoch 311/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5463 - val_loss: 0.6971 - val_accuracy: 0.4971\n",
      "Epoch 312/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6864 - accuracy: 0.5493 - val_loss: 0.6976 - val_accuracy: 0.4971\n",
      "Epoch 313/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6851 - accuracy: 0.5687 - val_loss: 0.6961 - val_accuracy: 0.4971\n",
      "Epoch 314/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6879 - accuracy: 0.5552 - val_loss: 0.6968 - val_accuracy: 0.4971\n",
      "Epoch 315/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6864 - accuracy: 0.5418 - val_loss: 0.6967 - val_accuracy: 0.4971\n",
      "Epoch 316/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5522 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
      "Epoch 317/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5672 - val_loss: 0.6965 - val_accuracy: 0.4941\n",
      "Epoch 318/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5567 - val_loss: 0.6967 - val_accuracy: 0.5000\n",
      "Epoch 319/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5687 - val_loss: 0.6961 - val_accuracy: 0.4941\n",
      "Epoch 320/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5821 - val_loss: 0.6959 - val_accuracy: 0.5000\n",
      "Epoch 321/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5507 - val_loss: 0.6962 - val_accuracy: 0.4941\n",
      "Epoch 322/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6881 - accuracy: 0.5493 - val_loss: 0.6961 - val_accuracy: 0.4912\n",
      "Epoch 323/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5582 - val_loss: 0.6970 - val_accuracy: 0.4971\n",
      "Epoch 324/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6872 - accuracy: 0.5388 - val_loss: 0.6976 - val_accuracy: 0.4882\n",
      "Epoch 325/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6849 - accuracy: 0.5433 - val_loss: 0.6961 - val_accuracy: 0.4941\n",
      "Epoch 326/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6878 - accuracy: 0.5507 - val_loss: 0.6955 - val_accuracy: 0.5029\n",
      "Epoch 327/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5672 - val_loss: 0.6959 - val_accuracy: 0.4912\n",
      "Epoch 328/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5746 - val_loss: 0.6970 - val_accuracy: 0.4971\n",
      "Epoch 329/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5731 - val_loss: 0.6965 - val_accuracy: 0.4971\n",
      "Epoch 330/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5463 - val_loss: 0.6954 - val_accuracy: 0.5000\n",
      "Epoch 331/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5716 - val_loss: 0.6949 - val_accuracy: 0.5059\n",
      "Epoch 332/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6850 - accuracy: 0.5478 - val_loss: 0.6951 - val_accuracy: 0.5000\n",
      "Epoch 333/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5627 - val_loss: 0.6956 - val_accuracy: 0.4912\n",
      "Epoch 334/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6850 - accuracy: 0.5597 - val_loss: 0.6961 - val_accuracy: 0.4971\n",
      "Epoch 335/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5612 - val_loss: 0.6962 - val_accuracy: 0.4971\n",
      "Epoch 336/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5627 - val_loss: 0.6968 - val_accuracy: 0.4941\n",
      "Epoch 337/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.5522 - val_loss: 0.6982 - val_accuracy: 0.5059\n",
      "Epoch 338/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6883 - accuracy: 0.5567 - val_loss: 0.6981 - val_accuracy: 0.5029\n",
      "Epoch 339/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5507 - val_loss: 0.6965 - val_accuracy: 0.4912\n",
      "Epoch 340/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.5448 - val_loss: 0.6981 - val_accuracy: 0.5000\n",
      "Epoch 341/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5522 - val_loss: 0.6962 - val_accuracy: 0.4941\n",
      "Epoch 342/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6871 - accuracy: 0.5507 - val_loss: 0.6956 - val_accuracy: 0.4912\n",
      "Epoch 343/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6847 - accuracy: 0.5388 - val_loss: 0.6978 - val_accuracy: 0.4912\n",
      "Epoch 344/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5716 - val_loss: 0.6960 - val_accuracy: 0.4941\n",
      "Epoch 345/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5522 - val_loss: 0.6958 - val_accuracy: 0.4912\n",
      "Epoch 346/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5657 - val_loss: 0.6954 - val_accuracy: 0.4882\n",
      "Epoch 347/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5791 - val_loss: 0.6966 - val_accuracy: 0.4912\n",
      "Epoch 348/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5761 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 349/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6819 - accuracy: 0.5806 - val_loss: 0.6950 - val_accuracy: 0.4941\n",
      "Epoch 350/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5582 - val_loss: 0.6939 - val_accuracy: 0.4971\n",
      "Epoch 351/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5582 - val_loss: 0.6939 - val_accuracy: 0.4971\n",
      "Epoch 352/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5746 - val_loss: 0.6971 - val_accuracy: 0.4941\n",
      "Epoch 353/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5537 - val_loss: 0.6957 - val_accuracy: 0.4882\n",
      "Epoch 354/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6848 - accuracy: 0.5597 - val_loss: 0.6956 - val_accuracy: 0.4941\n",
      "Epoch 355/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5642 - val_loss: 0.6973 - val_accuracy: 0.4971\n",
      "Epoch 356/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6862 - accuracy: 0.5537 - val_loss: 0.6965 - val_accuracy: 0.4971\n",
      "Epoch 357/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5433 - val_loss: 0.6959 - val_accuracy: 0.4941\n",
      "Epoch 358/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5687 - val_loss: 0.6944 - val_accuracy: 0.4912\n",
      "Epoch 359/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5657 - val_loss: 0.6950 - val_accuracy: 0.4912\n",
      "Epoch 360/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5463 - val_loss: 0.6956 - val_accuracy: 0.4941\n",
      "Epoch 361/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5746 - val_loss: 0.6973 - val_accuracy: 0.5029\n",
      "Epoch 362/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5746 - val_loss: 0.6942 - val_accuracy: 0.4941\n",
      "Epoch 363/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5358 - val_loss: 0.6957 - val_accuracy: 0.4882\n",
      "Epoch 364/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5716 - val_loss: 0.6946 - val_accuracy: 0.4912\n",
      "Epoch 365/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5478 - val_loss: 0.6951 - val_accuracy: 0.4882\n",
      "Epoch 366/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5701 - val_loss: 0.6940 - val_accuracy: 0.4882\n",
      "Epoch 367/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5507 - val_loss: 0.6954 - val_accuracy: 0.4941\n",
      "Epoch 368/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5687 - val_loss: 0.6941 - val_accuracy: 0.4882\n",
      "Epoch 369/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5537 - val_loss: 0.6925 - val_accuracy: 0.4941\n",
      "Epoch 370/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5478 - val_loss: 0.6925 - val_accuracy: 0.4941\n",
      "Epoch 371/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6846 - accuracy: 0.5597 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 372/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6836 - accuracy: 0.5642 - val_loss: 0.6943 - val_accuracy: 0.4941\n",
      "Epoch 373/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6843 - accuracy: 0.5612 - val_loss: 0.6966 - val_accuracy: 0.5000\n",
      "Epoch 374/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6845 - accuracy: 0.5522 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 375/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5463 - val_loss: 0.6944 - val_accuracy: 0.4971\n",
      "Epoch 376/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6844 - accuracy: 0.5507 - val_loss: 0.6943 - val_accuracy: 0.4971\n",
      "Epoch 377/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6819 - accuracy: 0.5642 - val_loss: 0.6957 - val_accuracy: 0.4971\n",
      "Epoch 378/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6854 - accuracy: 0.5507 - val_loss: 0.6958 - val_accuracy: 0.4941\n",
      "Epoch 379/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5746 - val_loss: 0.6956 - val_accuracy: 0.4912\n",
      "Epoch 380/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5612 - val_loss: 0.6952 - val_accuracy: 0.4971\n",
      "Epoch 381/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5597 - val_loss: 0.6947 - val_accuracy: 0.4912\n",
      "Epoch 382/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5507 - val_loss: 0.6932 - val_accuracy: 0.4971\n",
      "Epoch 383/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5657 - val_loss: 0.6956 - val_accuracy: 0.4971\n",
      "Epoch 384/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5597 - val_loss: 0.6935 - val_accuracy: 0.4912\n",
      "Epoch 385/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6871 - accuracy: 0.5463 - val_loss: 0.6937 - val_accuracy: 0.4882\n",
      "Epoch 386/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.5552 - val_loss: 0.6920 - val_accuracy: 0.4912\n",
      "Epoch 387/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5552 - val_loss: 0.6957 - val_accuracy: 0.4912\n",
      "Epoch 388/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5627 - val_loss: 0.6969 - val_accuracy: 0.4941\n",
      "Epoch 389/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6828 - accuracy: 0.5582 - val_loss: 0.6951 - val_accuracy: 0.4971\n",
      "Epoch 390/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6836 - accuracy: 0.5567 - val_loss: 0.6939 - val_accuracy: 0.4941\n",
      "Epoch 391/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.5537 - val_loss: 0.6971 - val_accuracy: 0.4971\n",
      "Epoch 392/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5537 - val_loss: 0.6953 - val_accuracy: 0.4971\n",
      "Epoch 393/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5612 - val_loss: 0.6935 - val_accuracy: 0.4912\n",
      "Epoch 394/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6837 - accuracy: 0.5507 - val_loss: 0.6939 - val_accuracy: 0.4882\n",
      "Epoch 395/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5537 - val_loss: 0.6943 - val_accuracy: 0.4853\n",
      "Epoch 396/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5597 - val_loss: 0.6924 - val_accuracy: 0.4912\n",
      "Epoch 397/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5701 - val_loss: 0.6928 - val_accuracy: 0.4971\n",
      "Epoch 398/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5597 - val_loss: 0.6957 - val_accuracy: 0.4882\n",
      "Epoch 399/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5716 - val_loss: 0.6939 - val_accuracy: 0.4882\n",
      "Epoch 400/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5373 - val_loss: 0.6926 - val_accuracy: 0.4971\n",
      "Epoch 401/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5522 - val_loss: 0.6925 - val_accuracy: 0.4912\n",
      "Epoch 402/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5582 - val_loss: 0.6946 - val_accuracy: 0.5029\n",
      "Epoch 403/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5627 - val_loss: 0.6928 - val_accuracy: 0.4971\n",
      "Epoch 404/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6879 - accuracy: 0.5209 - val_loss: 0.6952 - val_accuracy: 0.4971\n",
      "Epoch 405/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5552 - val_loss: 0.6969 - val_accuracy: 0.4971\n",
      "Epoch 406/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5657 - val_loss: 0.6938 - val_accuracy: 0.4882\n",
      "Epoch 407/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5552 - val_loss: 0.6918 - val_accuracy: 0.4853\n",
      "Epoch 408/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5731 - val_loss: 0.6927 - val_accuracy: 0.4971\n",
      "Epoch 409/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6854 - accuracy: 0.5493 - val_loss: 0.6933 - val_accuracy: 0.4971\n",
      "Epoch 410/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5881 - val_loss: 0.6927 - val_accuracy: 0.4971\n",
      "Epoch 411/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6750 - accuracy: 0.5851 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 412/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5612 - val_loss: 0.6949 - val_accuracy: 0.4971\n",
      "Epoch 413/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5567 - val_loss: 0.6941 - val_accuracy: 0.4882\n",
      "Epoch 414/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5627 - val_loss: 0.6931 - val_accuracy: 0.4941\n",
      "Epoch 415/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5493 - val_loss: 0.6913 - val_accuracy: 0.4794\n",
      "Epoch 416/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5239 - val_loss: 0.6898 - val_accuracy: 0.4882\n",
      "Epoch 417/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5537 - val_loss: 0.6959 - val_accuracy: 0.4882\n",
      "Epoch 418/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5687 - val_loss: 0.6922 - val_accuracy: 0.4912\n",
      "Epoch 419/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6819 - accuracy: 0.5478 - val_loss: 0.6918 - val_accuracy: 0.4824\n",
      "Epoch 420/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5493 - val_loss: 0.6943 - val_accuracy: 0.4853\n",
      "Epoch 421/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6871 - accuracy: 0.5343 - val_loss: 0.6942 - val_accuracy: 0.4941\n",
      "Epoch 422/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.5507 - val_loss: 0.6953 - val_accuracy: 0.4853\n",
      "Epoch 423/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5687 - val_loss: 0.6940 - val_accuracy: 0.4941\n",
      "Epoch 424/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5657 - val_loss: 0.6916 - val_accuracy: 0.4794\n",
      "Epoch 425/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5567 - val_loss: 0.6938 - val_accuracy: 0.4912\n",
      "Epoch 426/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5433 - val_loss: 0.6945 - val_accuracy: 0.5000\n",
      "Epoch 427/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5642 - val_loss: 0.6937 - val_accuracy: 0.4912\n",
      "Epoch 428/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5672 - val_loss: 0.6953 - val_accuracy: 0.4941\n",
      "Epoch 429/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5567 - val_loss: 0.6918 - val_accuracy: 0.4794\n",
      "Epoch 430/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5537 - val_loss: 0.6939 - val_accuracy: 0.4912\n",
      "Epoch 431/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5672 - val_loss: 0.6934 - val_accuracy: 0.4971\n",
      "Epoch 432/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5388 - val_loss: 0.6935 - val_accuracy: 0.4912\n",
      "Epoch 433/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5761 - val_loss: 0.6932 - val_accuracy: 0.4971\n",
      "Epoch 434/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5687 - val_loss: 0.6949 - val_accuracy: 0.4882\n",
      "Epoch 435/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5701 - val_loss: 0.6937 - val_accuracy: 0.4824\n",
      "Epoch 436/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5433 - val_loss: 0.6943 - val_accuracy: 0.4912\n",
      "Epoch 437/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5567 - val_loss: 0.6950 - val_accuracy: 0.4882\n",
      "Epoch 438/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5657 - val_loss: 0.6921 - val_accuracy: 0.4853\n",
      "Epoch 439/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.5552 - val_loss: 0.6925 - val_accuracy: 0.4882\n",
      "Epoch 440/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5522 - val_loss: 0.6946 - val_accuracy: 0.4912\n",
      "Epoch 441/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6847 - accuracy: 0.5463 - val_loss: 0.6930 - val_accuracy: 0.4853\n",
      "Epoch 442/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5478 - val_loss: 0.6963 - val_accuracy: 0.4794\n",
      "Epoch 443/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5612 - val_loss: 0.6918 - val_accuracy: 0.4853\n",
      "Epoch 444/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5552 - val_loss: 0.6917 - val_accuracy: 0.4882\n",
      "Epoch 445/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5597 - val_loss: 0.6947 - val_accuracy: 0.4912\n",
      "Epoch 446/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5627 - val_loss: 0.6935 - val_accuracy: 0.4971\n",
      "Epoch 447/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6770 - accuracy: 0.5597 - val_loss: 0.6927 - val_accuracy: 0.4912\n",
      "Epoch 448/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6866 - accuracy: 0.5388 - val_loss: 0.6919 - val_accuracy: 0.4853\n",
      "Epoch 449/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6845 - accuracy: 0.5507 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 450/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5642 - val_loss: 0.6951 - val_accuracy: 0.4912\n",
      "Epoch 451/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5537 - val_loss: 0.6941 - val_accuracy: 0.4971\n",
      "Epoch 452/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5657 - val_loss: 0.6908 - val_accuracy: 0.4824\n",
      "Epoch 453/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5567 - val_loss: 0.6930 - val_accuracy: 0.4941\n",
      "Epoch 454/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5716 - val_loss: 0.6896 - val_accuracy: 0.4794\n",
      "Epoch 455/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5701 - val_loss: 0.6915 - val_accuracy: 0.4853\n",
      "Epoch 456/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5448 - val_loss: 0.6931 - val_accuracy: 0.4971\n",
      "Epoch 457/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5537 - val_loss: 0.6933 - val_accuracy: 0.4941\n",
      "Epoch 458/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.5642 - val_loss: 0.6967 - val_accuracy: 0.4882\n",
      "Epoch 459/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6837 - accuracy: 0.5403 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 460/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5478 - val_loss: 0.6944 - val_accuracy: 0.4941\n",
      "Epoch 461/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5567 - val_loss: 0.6947 - val_accuracy: 0.4941\n",
      "Epoch 462/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6763 - accuracy: 0.5716 - val_loss: 0.6936 - val_accuracy: 0.4941\n",
      "Epoch 463/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5597 - val_loss: 0.6917 - val_accuracy: 0.4794\n",
      "Epoch 464/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5567 - val_loss: 0.6924 - val_accuracy: 0.4824\n",
      "Epoch 465/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5731 - val_loss: 0.6924 - val_accuracy: 0.4853\n",
      "Epoch 466/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5642 - val_loss: 0.6934 - val_accuracy: 0.4853\n",
      "Epoch 467/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6845 - accuracy: 0.5493 - val_loss: 0.6927 - val_accuracy: 0.4824\n",
      "Epoch 468/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5552 - val_loss: 0.6937 - val_accuracy: 0.4971\n",
      "Epoch 469/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5731 - val_loss: 0.6962 - val_accuracy: 0.4794\n",
      "Epoch 470/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5507 - val_loss: 0.6913 - val_accuracy: 0.4853\n",
      "Epoch 471/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5701 - val_loss: 0.6942 - val_accuracy: 0.4941\n",
      "Epoch 472/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6845 - accuracy: 0.5657 - val_loss: 0.6939 - val_accuracy: 0.4941\n",
      "Epoch 473/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6851 - accuracy: 0.5388 - val_loss: 0.6912 - val_accuracy: 0.4824\n",
      "Epoch 474/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5687 - val_loss: 0.6931 - val_accuracy: 0.4912\n",
      "Epoch 475/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5567 - val_loss: 0.6945 - val_accuracy: 0.4971\n",
      "Epoch 476/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5687 - val_loss: 0.6936 - val_accuracy: 0.4765\n",
      "Epoch 477/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5493 - val_loss: 0.6932 - val_accuracy: 0.4971\n",
      "Epoch 478/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5448 - val_loss: 0.6926 - val_accuracy: 0.4912\n",
      "Epoch 479/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5463 - val_loss: 0.6912 - val_accuracy: 0.4765\n",
      "Epoch 480/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5493 - val_loss: 0.6938 - val_accuracy: 0.4912\n",
      "Epoch 481/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5507 - val_loss: 0.6923 - val_accuracy: 0.4794\n",
      "Epoch 482/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5567 - val_loss: 0.6925 - val_accuracy: 0.4941\n",
      "Epoch 483/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5537 - val_loss: 0.6960 - val_accuracy: 0.4824\n",
      "Epoch 484/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5687 - val_loss: 0.6956 - val_accuracy: 0.4853\n",
      "Epoch 485/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5627 - val_loss: 0.6916 - val_accuracy: 0.4794\n",
      "Epoch 486/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6855 - accuracy: 0.5478 - val_loss: 0.6970 - val_accuracy: 0.4912\n",
      "Epoch 487/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5507 - val_loss: 0.6896 - val_accuracy: 0.4735\n",
      "Epoch 488/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5627 - val_loss: 0.6968 - val_accuracy: 0.4735\n",
      "Epoch 489/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6840 - accuracy: 0.5448 - val_loss: 0.6959 - val_accuracy: 0.4853\n",
      "Epoch 490/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5612 - val_loss: 0.6924 - val_accuracy: 0.4882\n",
      "Epoch 491/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5552 - val_loss: 0.6917 - val_accuracy: 0.4912\n",
      "Epoch 492/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5463 - val_loss: 0.6957 - val_accuracy: 0.4912\n",
      "Epoch 493/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5627 - val_loss: 0.6930 - val_accuracy: 0.4824\n",
      "Epoch 494/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5701 - val_loss: 0.6997 - val_accuracy: 0.4912\n",
      "Epoch 495/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5612 - val_loss: 0.6943 - val_accuracy: 0.4912\n",
      "Epoch 496/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5418 - val_loss: 0.6954 - val_accuracy: 0.4882\n",
      "Epoch 497/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5537 - val_loss: 0.6944 - val_accuracy: 0.4941\n",
      "Epoch 498/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5388 - val_loss: 0.6945 - val_accuracy: 0.4941\n",
      "Epoch 499/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5642 - val_loss: 0.6979 - val_accuracy: 0.5000\n",
      "Epoch 500/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5522 - val_loss: 0.6961 - val_accuracy: 0.4794\n",
      "Epoch 501/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5836 - val_loss: 0.6922 - val_accuracy: 0.4882\n",
      "Epoch 502/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5403 - val_loss: 0.6925 - val_accuracy: 0.4853\n",
      "Epoch 503/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5746 - val_loss: 0.6949 - val_accuracy: 0.4941\n",
      "Epoch 504/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6845 - accuracy: 0.5284 - val_loss: 0.6916 - val_accuracy: 0.4941\n",
      "Epoch 505/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5612 - val_loss: 0.6944 - val_accuracy: 0.4912\n",
      "Epoch 506/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5657 - val_loss: 0.6940 - val_accuracy: 0.4941\n",
      "Epoch 507/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5567 - val_loss: 0.6922 - val_accuracy: 0.4882\n",
      "Epoch 508/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5597 - val_loss: 0.6947 - val_accuracy: 0.4882\n",
      "Epoch 509/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5597 - val_loss: 0.6965 - val_accuracy: 0.4912\n",
      "Epoch 510/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6834 - accuracy: 0.5373 - val_loss: 0.6927 - val_accuracy: 0.4882\n",
      "Epoch 511/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5567 - val_loss: 0.6922 - val_accuracy: 0.4912\n",
      "Epoch 512/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5612 - val_loss: 0.6955 - val_accuracy: 0.4941\n",
      "Epoch 513/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5478 - val_loss: 0.6926 - val_accuracy: 0.4882\n",
      "Epoch 514/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5478 - val_loss: 0.6901 - val_accuracy: 0.4794\n",
      "Epoch 515/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5537 - val_loss: 0.6905 - val_accuracy: 0.4706\n",
      "Epoch 516/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5642 - val_loss: 0.6920 - val_accuracy: 0.4941\n",
      "Epoch 517/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5627 - val_loss: 0.6992 - val_accuracy: 0.5000\n",
      "Epoch 518/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5776 - val_loss: 0.6970 - val_accuracy: 0.4853\n",
      "Epoch 519/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6789 - accuracy: 0.5537 - val_loss: 0.6922 - val_accuracy: 0.4882\n",
      "Epoch 520/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5612 - val_loss: 0.6946 - val_accuracy: 0.4912\n",
      "Epoch 521/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5657 - val_loss: 0.6925 - val_accuracy: 0.4912\n",
      "Epoch 522/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5657 - val_loss: 0.6944 - val_accuracy: 0.4912\n",
      "Epoch 523/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5522 - val_loss: 0.6970 - val_accuracy: 0.4912\n",
      "Epoch 524/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5657 - val_loss: 0.6930 - val_accuracy: 0.4912\n",
      "Epoch 525/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5373 - val_loss: 0.6986 - val_accuracy: 0.5000\n",
      "Epoch 526/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5552 - val_loss: 0.6986 - val_accuracy: 0.4765\n",
      "Epoch 527/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5612 - val_loss: 0.6978 - val_accuracy: 0.4735\n",
      "Epoch 528/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5552 - val_loss: 0.6973 - val_accuracy: 0.4765\n",
      "Epoch 529/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5343 - val_loss: 0.6935 - val_accuracy: 0.4647\n",
      "Epoch 530/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5597 - val_loss: 0.6944 - val_accuracy: 0.4912\n",
      "Epoch 531/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5672 - val_loss: 0.6937 - val_accuracy: 0.4912\n",
      "Epoch 532/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6868 - accuracy: 0.5328 - val_loss: 0.6924 - val_accuracy: 0.5088\n",
      "Epoch 533/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5597 - val_loss: 0.6904 - val_accuracy: 0.4971\n",
      "Epoch 534/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6826 - accuracy: 0.5463 - val_loss: 0.7009 - val_accuracy: 0.4941\n",
      "Epoch 535/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5612 - val_loss: 0.6913 - val_accuracy: 0.4853\n",
      "Epoch 536/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5582 - val_loss: 0.6951 - val_accuracy: 0.4941\n",
      "Epoch 537/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5328 - val_loss: 0.6973 - val_accuracy: 0.4882\n",
      "Epoch 538/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5701 - val_loss: 0.6956 - val_accuracy: 0.4971\n",
      "Epoch 539/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5507 - val_loss: 0.6929 - val_accuracy: 0.5059\n",
      "Epoch 540/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5627 - val_loss: 0.6972 - val_accuracy: 0.5059\n",
      "Epoch 541/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6799 - accuracy: 0.5612 - val_loss: 0.6957 - val_accuracy: 0.4882\n",
      "Epoch 542/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6824 - accuracy: 0.5448 - val_loss: 0.6941 - val_accuracy: 0.4824\n",
      "Epoch 543/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5478 - val_loss: 0.7002 - val_accuracy: 0.4971\n",
      "Epoch 544/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5731 - val_loss: 0.6913 - val_accuracy: 0.4853\n",
      "Epoch 545/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5716 - val_loss: 0.6983 - val_accuracy: 0.5088\n",
      "Epoch 546/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6842 - accuracy: 0.5493 - val_loss: 0.6960 - val_accuracy: 0.5000\n",
      "Epoch 547/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6819 - accuracy: 0.5522 - val_loss: 0.6991 - val_accuracy: 0.5059\n",
      "Epoch 548/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5373 - val_loss: 0.6950 - val_accuracy: 0.4882\n",
      "Epoch 549/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5552 - val_loss: 0.6906 - val_accuracy: 0.4971\n",
      "Epoch 550/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6871 - accuracy: 0.5463 - val_loss: 0.6940 - val_accuracy: 0.4971\n",
      "Epoch 551/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5582 - val_loss: 0.6984 - val_accuracy: 0.4912\n",
      "Epoch 552/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5731 - val_loss: 0.6963 - val_accuracy: 0.5000\n",
      "Epoch 553/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5687 - val_loss: 0.6950 - val_accuracy: 0.4971\n",
      "Epoch 554/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6846 - accuracy: 0.5448 - val_loss: 0.6994 - val_accuracy: 0.4912\n",
      "Epoch 555/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5716 - val_loss: 0.6952 - val_accuracy: 0.4941\n",
      "Epoch 556/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5552 - val_loss: 0.6971 - val_accuracy: 0.4853\n",
      "Epoch 557/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5463 - val_loss: 0.7014 - val_accuracy: 0.4971\n",
      "Epoch 558/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5463 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
      "Epoch 559/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6856 - accuracy: 0.5418 - val_loss: 0.6940 - val_accuracy: 0.4853\n",
      "Epoch 560/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6848 - accuracy: 0.5463 - val_loss: 0.6973 - val_accuracy: 0.4941\n",
      "Epoch 561/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5672 - val_loss: 0.7023 - val_accuracy: 0.4971\n",
      "Epoch 562/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6812 - accuracy: 0.5507 - val_loss: 0.6944 - val_accuracy: 0.4853\n",
      "Epoch 563/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5507 - val_loss: 0.6915 - val_accuracy: 0.4882\n",
      "Epoch 564/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5597 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 565/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6787 - accuracy: 0.5552 - val_loss: 0.6960 - val_accuracy: 0.4971\n",
      "Epoch 566/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5597 - val_loss: 0.6959 - val_accuracy: 0.4912\n",
      "Epoch 567/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6823 - accuracy: 0.5582 - val_loss: 0.6952 - val_accuracy: 0.4971\n",
      "Epoch 568/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6760 - accuracy: 0.5791 - val_loss: 0.6953 - val_accuracy: 0.4941\n",
      "Epoch 569/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5493 - val_loss: 0.6893 - val_accuracy: 0.4912\n",
      "Epoch 570/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6832 - accuracy: 0.5418 - val_loss: 0.6991 - val_accuracy: 0.4882\n",
      "Epoch 571/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5627 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 572/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5657 - val_loss: 0.6919 - val_accuracy: 0.5029\n",
      "Epoch 573/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.5746 - val_loss: 0.6895 - val_accuracy: 0.5000\n",
      "Epoch 574/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5552 - val_loss: 0.6907 - val_accuracy: 0.4941\n",
      "Epoch 575/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5567 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 576/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6808 - accuracy: 0.5612 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 577/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5731 - val_loss: 0.6953 - val_accuracy: 0.4971\n",
      "Epoch 578/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5597 - val_loss: 0.6934 - val_accuracy: 0.4882\n",
      "Epoch 579/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5567 - val_loss: 0.6988 - val_accuracy: 0.4882\n",
      "Epoch 580/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5582 - val_loss: 0.6957 - val_accuracy: 0.4912\n",
      "Epoch 581/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5582 - val_loss: 0.6935 - val_accuracy: 0.4941\n",
      "Epoch 582/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5448 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 583/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5507 - val_loss: 0.6898 - val_accuracy: 0.5118\n",
      "Epoch 584/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6809 - accuracy: 0.5612 - val_loss: 0.6894 - val_accuracy: 0.5088\n",
      "Epoch 585/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6864 - accuracy: 0.5299 - val_loss: 0.7007 - val_accuracy: 0.4912\n",
      "Epoch 586/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.5687 - val_loss: 0.6929 - val_accuracy: 0.5029\n",
      "Epoch 587/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5612 - val_loss: 0.6970 - val_accuracy: 0.4971\n",
      "Epoch 588/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6837 - accuracy: 0.5373 - val_loss: 0.6889 - val_accuracy: 0.4912\n",
      "Epoch 589/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5701 - val_loss: 0.6931 - val_accuracy: 0.4971\n",
      "Epoch 590/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5731 - val_loss: 0.6860 - val_accuracy: 0.5176\n",
      "Epoch 591/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5657 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 592/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5433 - val_loss: 0.6927 - val_accuracy: 0.4971\n",
      "Epoch 593/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6769 - accuracy: 0.5687 - val_loss: 0.6938 - val_accuracy: 0.4971\n",
      "Epoch 594/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5761 - val_loss: 0.6916 - val_accuracy: 0.5059\n",
      "Epoch 595/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5687 - val_loss: 0.6954 - val_accuracy: 0.4941\n",
      "Epoch 596/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5552 - val_loss: 0.6911 - val_accuracy: 0.4971\n",
      "Epoch 597/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6862 - accuracy: 0.5418 - val_loss: 0.6887 - val_accuracy: 0.5088\n",
      "Epoch 598/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5418 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 599/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5418 - val_loss: 0.6862 - val_accuracy: 0.5029\n",
      "Epoch 600/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5358 - val_loss: 0.6979 - val_accuracy: 0.5118\n",
      "Epoch 601/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5731 - val_loss: 0.6916 - val_accuracy: 0.5088\n",
      "Epoch 602/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5463 - val_loss: 0.6885 - val_accuracy: 0.5088\n",
      "Epoch 603/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5567 - val_loss: 0.6963 - val_accuracy: 0.4941\n",
      "Epoch 604/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5537 - val_loss: 0.6994 - val_accuracy: 0.4853\n",
      "Epoch 605/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5597 - val_loss: 0.6975 - val_accuracy: 0.4882\n",
      "Epoch 606/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6876 - accuracy: 0.5493 - val_loss: 0.6863 - val_accuracy: 0.5118\n",
      "Epoch 607/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5433 - val_loss: 0.6916 - val_accuracy: 0.5029\n",
      "Epoch 608/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5567 - val_loss: 0.6957 - val_accuracy: 0.4765\n",
      "Epoch 609/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5582 - val_loss: 0.7036 - val_accuracy: 0.4941\n",
      "Epoch 610/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5478 - val_loss: 0.6995 - val_accuracy: 0.4735\n",
      "Epoch 611/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5582 - val_loss: 0.6918 - val_accuracy: 0.5029\n",
      "Epoch 612/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5701 - val_loss: 0.6980 - val_accuracy: 0.4941\n",
      "Epoch 613/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5642 - val_loss: 0.6948 - val_accuracy: 0.5029\n",
      "Epoch 614/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5493 - val_loss: 0.7041 - val_accuracy: 0.4853\n",
      "Epoch 615/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6854 - accuracy: 0.5627 - val_loss: 0.7001 - val_accuracy: 0.4971\n",
      "Epoch 616/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5507 - val_loss: 0.7082 - val_accuracy: 0.4794\n",
      "Epoch 617/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5537 - val_loss: 0.6878 - val_accuracy: 0.5147\n",
      "Epoch 618/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5672 - val_loss: 0.6897 - val_accuracy: 0.4912\n",
      "Epoch 619/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5522 - val_loss: 0.6904 - val_accuracy: 0.4912\n",
      "Epoch 620/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5567 - val_loss: 0.6886 - val_accuracy: 0.4853\n",
      "Epoch 621/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5701 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 622/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6769 - accuracy: 0.5806 - val_loss: 0.6920 - val_accuracy: 0.4735\n",
      "Epoch 623/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5582 - val_loss: 0.6951 - val_accuracy: 0.4706\n",
      "Epoch 624/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5522 - val_loss: 0.6923 - val_accuracy: 0.4706\n",
      "Epoch 625/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5463 - val_loss: 0.6899 - val_accuracy: 0.4765\n",
      "Epoch 626/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5642 - val_loss: 0.6865 - val_accuracy: 0.4882\n",
      "Epoch 627/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5522 - val_loss: 0.6894 - val_accuracy: 0.4794\n",
      "Epoch 628/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5657 - val_loss: 0.6900 - val_accuracy: 0.4971\n",
      "Epoch 629/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5418 - val_loss: 0.6958 - val_accuracy: 0.4824\n",
      "Epoch 630/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5612 - val_loss: 0.7004 - val_accuracy: 0.4588\n",
      "Epoch 631/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5657 - val_loss: 0.6939 - val_accuracy: 0.4647\n",
      "Epoch 632/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5522 - val_loss: 0.6933 - val_accuracy: 0.4912\n",
      "Epoch 633/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5478 - val_loss: 0.6925 - val_accuracy: 0.4824\n",
      "Epoch 634/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5358 - val_loss: 0.7031 - val_accuracy: 0.4941\n",
      "Epoch 635/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5552 - val_loss: 0.7009 - val_accuracy: 0.5000\n",
      "Epoch 636/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5493 - val_loss: 0.6937 - val_accuracy: 0.4853\n",
      "Epoch 637/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5567 - val_loss: 0.6854 - val_accuracy: 0.4853\n",
      "Epoch 638/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5567 - val_loss: 0.7038 - val_accuracy: 0.4794\n",
      "Epoch 639/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5373 - val_loss: 0.7036 - val_accuracy: 0.4794\n",
      "Epoch 640/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5493 - val_loss: 0.6940 - val_accuracy: 0.4647\n",
      "Epoch 641/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5716 - val_loss: 0.6992 - val_accuracy: 0.4882\n",
      "Epoch 642/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5373 - val_loss: 0.7024 - val_accuracy: 0.4765\n",
      "Epoch 643/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5731 - val_loss: 0.7045 - val_accuracy: 0.4824\n",
      "Epoch 644/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5567 - val_loss: 0.7021 - val_accuracy: 0.5029\n",
      "Epoch 645/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6819 - accuracy: 0.5522 - val_loss: 0.7069 - val_accuracy: 0.4794\n",
      "Epoch 646/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5478 - val_loss: 0.6930 - val_accuracy: 0.5029\n",
      "Epoch 647/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5761 - val_loss: 0.7092 - val_accuracy: 0.4941\n",
      "Epoch 648/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5597 - val_loss: 0.7014 - val_accuracy: 0.4941\n",
      "Epoch 649/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5627 - val_loss: 0.6963 - val_accuracy: 0.5029\n",
      "Epoch 650/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5597 - val_loss: 0.6991 - val_accuracy: 0.4941\n",
      "Epoch 651/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5687 - val_loss: 0.6902 - val_accuracy: 0.5059\n",
      "Epoch 652/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5507 - val_loss: 0.6893 - val_accuracy: 0.5059\n",
      "Epoch 653/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5612 - val_loss: 0.6961 - val_accuracy: 0.4971\n",
      "Epoch 654/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5537 - val_loss: 0.6972 - val_accuracy: 0.4912\n",
      "Epoch 655/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5567 - val_loss: 0.6867 - val_accuracy: 0.4882\n",
      "Epoch 656/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5567 - val_loss: 0.6861 - val_accuracy: 0.4882\n",
      "Epoch 657/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5433 - val_loss: 0.6920 - val_accuracy: 0.4735\n",
      "Epoch 658/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5537 - val_loss: 0.6931 - val_accuracy: 0.5059\n",
      "Epoch 659/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5746 - val_loss: 0.6878 - val_accuracy: 0.4912\n",
      "Epoch 660/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5597 - val_loss: 0.6983 - val_accuracy: 0.4676\n",
      "Epoch 661/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5642 - val_loss: 0.6956 - val_accuracy: 0.4735\n",
      "Epoch 662/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6819 - accuracy: 0.5537 - val_loss: 0.6888 - val_accuracy: 0.4794\n",
      "Epoch 663/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5612 - val_loss: 0.6948 - val_accuracy: 0.4765\n",
      "Epoch 664/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5358 - val_loss: 0.6925 - val_accuracy: 0.4853\n",
      "Epoch 665/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5328 - val_loss: 0.6929 - val_accuracy: 0.4882\n",
      "Epoch 666/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5657 - val_loss: 0.7055 - val_accuracy: 0.5147\n",
      "Epoch 667/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5612 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 668/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6845 - accuracy: 0.5493 - val_loss: 0.6928 - val_accuracy: 0.4647\n",
      "Epoch 669/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5701 - val_loss: 0.7185 - val_accuracy: 0.4794\n",
      "Epoch 670/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6838 - accuracy: 0.5463 - val_loss: 0.7085 - val_accuracy: 0.4647\n",
      "Epoch 671/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5567 - val_loss: 0.7114 - val_accuracy: 0.4529\n",
      "Epoch 672/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5657 - val_loss: 0.7016 - val_accuracy: 0.4912\n",
      "Epoch 673/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.5537 - val_loss: 0.7000 - val_accuracy: 0.4735\n",
      "Epoch 674/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5701 - val_loss: 0.7087 - val_accuracy: 0.4794\n",
      "Epoch 675/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5478 - val_loss: 0.6944 - val_accuracy: 0.4735\n",
      "Epoch 676/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5612 - val_loss: 0.6947 - val_accuracy: 0.4912\n",
      "Epoch 677/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5582 - val_loss: 0.6958 - val_accuracy: 0.4912\n",
      "Epoch 678/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5791 - val_loss: 0.7031 - val_accuracy: 0.4824\n",
      "Epoch 679/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5627 - val_loss: 0.7071 - val_accuracy: 0.4824\n",
      "Epoch 680/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5672 - val_loss: 0.7074 - val_accuracy: 0.4794\n",
      "Epoch 681/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5522 - val_loss: 0.7089 - val_accuracy: 0.4794\n",
      "Epoch 682/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5701 - val_loss: 0.6971 - val_accuracy: 0.4794\n",
      "Epoch 683/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5776 - val_loss: 0.7265 - val_accuracy: 0.4882\n",
      "Epoch 684/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6841 - accuracy: 0.5507 - val_loss: 0.7039 - val_accuracy: 0.4588\n",
      "Epoch 685/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5701 - val_loss: 0.7081 - val_accuracy: 0.4794\n",
      "Epoch 686/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6843 - accuracy: 0.5403 - val_loss: 0.6979 - val_accuracy: 0.4706\n",
      "Epoch 687/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6837 - accuracy: 0.5552 - val_loss: 0.7230 - val_accuracy: 0.4765\n",
      "Epoch 688/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6844 - accuracy: 0.5448 - val_loss: 0.6988 - val_accuracy: 0.4824\n",
      "Epoch 689/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5433 - val_loss: 0.7051 - val_accuracy: 0.4735\n",
      "Epoch 690/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5627 - val_loss: 0.7139 - val_accuracy: 0.4588\n",
      "Epoch 691/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5612 - val_loss: 0.7025 - val_accuracy: 0.5000\n",
      "Epoch 692/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5657 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
      "Epoch 693/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5582 - val_loss: 0.7196 - val_accuracy: 0.4559\n",
      "Epoch 694/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5746 - val_loss: 0.7144 - val_accuracy: 0.4500\n",
      "Epoch 695/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5522 - val_loss: 0.7063 - val_accuracy: 0.4676\n",
      "Epoch 696/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5418 - val_loss: 0.7006 - val_accuracy: 0.4706\n",
      "Epoch 697/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5761 - val_loss: 0.6946 - val_accuracy: 0.4647\n",
      "Epoch 698/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5552 - val_loss: 0.6880 - val_accuracy: 0.4853\n",
      "Epoch 699/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5358 - val_loss: 0.6981 - val_accuracy: 0.4941\n",
      "Epoch 700/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5463 - val_loss: 0.6874 - val_accuracy: 0.4882\n",
      "Epoch 701/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5582 - val_loss: 0.6933 - val_accuracy: 0.4735\n",
      "Epoch 702/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5612 - val_loss: 0.6965 - val_accuracy: 0.4824\n",
      "Epoch 703/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5478 - val_loss: 0.6993 - val_accuracy: 0.4735\n",
      "Epoch 704/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5448 - val_loss: 0.6970 - val_accuracy: 0.4618\n",
      "Epoch 705/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5627 - val_loss: 0.6936 - val_accuracy: 0.4824\n",
      "Epoch 706/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5478 - val_loss: 0.6959 - val_accuracy: 0.4735\n",
      "Epoch 707/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5537 - val_loss: 0.6906 - val_accuracy: 0.5353\n",
      "Epoch 708/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5567 - val_loss: 0.6967 - val_accuracy: 0.5206\n",
      "Epoch 709/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6841 - accuracy: 0.5522 - val_loss: 0.7099 - val_accuracy: 0.5324\n",
      "Epoch 710/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5672 - val_loss: 0.7035 - val_accuracy: 0.5088\n",
      "Epoch 711/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5507 - val_loss: 0.7020 - val_accuracy: 0.5118\n",
      "Epoch 712/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.5612 - val_loss: 0.6963 - val_accuracy: 0.4794\n",
      "Epoch 713/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.5657 - val_loss: 0.6934 - val_accuracy: 0.4706\n",
      "Epoch 714/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5657 - val_loss: 0.6954 - val_accuracy: 0.4588\n",
      "Epoch 715/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5358 - val_loss: 0.6995 - val_accuracy: 0.4824\n",
      "Epoch 716/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5612 - val_loss: 0.7021 - val_accuracy: 0.4853\n",
      "Epoch 717/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5507 - val_loss: 0.6902 - val_accuracy: 0.4824\n",
      "Epoch 718/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5493 - val_loss: 0.7104 - val_accuracy: 0.4618\n",
      "Epoch 719/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5761 - val_loss: 0.7054 - val_accuracy: 0.4853\n",
      "Epoch 720/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5507 - val_loss: 0.7004 - val_accuracy: 0.4676\n",
      "Epoch 721/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5313 - val_loss: 0.7098 - val_accuracy: 0.4882\n",
      "Epoch 722/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5627 - val_loss: 0.7040 - val_accuracy: 0.4765\n",
      "Epoch 723/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5478 - val_loss: 0.6993 - val_accuracy: 0.4853\n",
      "Epoch 724/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6764 - accuracy: 0.5687 - val_loss: 0.6958 - val_accuracy: 0.5029\n",
      "Epoch 725/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5776 - val_loss: 0.7011 - val_accuracy: 0.4824\n",
      "Epoch 726/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5687 - val_loss: 0.7066 - val_accuracy: 0.4794\n",
      "Epoch 727/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5463 - val_loss: 0.7011 - val_accuracy: 0.4941\n",
      "Epoch 728/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6788 - accuracy: 0.5478 - val_loss: 0.6981 - val_accuracy: 0.4765\n",
      "Epoch 729/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6841 - accuracy: 0.5448 - val_loss: 0.7158 - val_accuracy: 0.4618\n",
      "Epoch 730/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5463 - val_loss: 0.7203 - val_accuracy: 0.4735\n",
      "Epoch 731/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5567 - val_loss: 0.7021 - val_accuracy: 0.4941\n",
      "Epoch 732/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5433 - val_loss: 0.7058 - val_accuracy: 0.4971\n",
      "Epoch 733/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5657 - val_loss: 0.7215 - val_accuracy: 0.4676\n",
      "Epoch 734/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5493 - val_loss: 0.7018 - val_accuracy: 0.4912\n",
      "Epoch 735/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5522 - val_loss: 0.6978 - val_accuracy: 0.5059\n",
      "Epoch 736/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5582 - val_loss: 0.7032 - val_accuracy: 0.4882\n",
      "Epoch 737/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5731 - val_loss: 0.7062 - val_accuracy: 0.4882\n",
      "Epoch 738/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5716 - val_loss: 0.7128 - val_accuracy: 0.4882\n",
      "Epoch 739/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5791 - val_loss: 0.7052 - val_accuracy: 0.4765\n",
      "Epoch 740/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5701 - val_loss: 0.6929 - val_accuracy: 0.5029\n",
      "Epoch 741/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5537 - val_loss: 0.6954 - val_accuracy: 0.4853\n",
      "Epoch 742/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5836 - val_loss: 0.7144 - val_accuracy: 0.4882\n",
      "Epoch 743/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5597 - val_loss: 0.7064 - val_accuracy: 0.4882\n",
      "Epoch 744/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5418 - val_loss: 0.7030 - val_accuracy: 0.4765\n",
      "Epoch 745/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5552 - val_loss: 0.6954 - val_accuracy: 0.4676\n",
      "Epoch 746/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5582 - val_loss: 0.6910 - val_accuracy: 0.4765\n",
      "Epoch 747/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5791 - val_loss: 0.7065 - val_accuracy: 0.4706\n",
      "Epoch 748/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5731 - val_loss: 0.6876 - val_accuracy: 0.4941\n",
      "Epoch 749/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5731 - val_loss: 0.6888 - val_accuracy: 0.4971\n",
      "Epoch 750/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5463 - val_loss: 0.6957 - val_accuracy: 0.4882\n",
      "Epoch 751/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6777 - accuracy: 0.5716 - val_loss: 0.7008 - val_accuracy: 0.4912\n",
      "Epoch 752/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.5627 - val_loss: 0.6989 - val_accuracy: 0.4941\n",
      "Epoch 753/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6764 - accuracy: 0.5836 - val_loss: 0.6959 - val_accuracy: 0.5029\n",
      "Epoch 754/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5701 - val_loss: 0.7012 - val_accuracy: 0.4941\n",
      "Epoch 755/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5463 - val_loss: 0.6921 - val_accuracy: 0.4941\n",
      "Epoch 756/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5522 - val_loss: 0.6927 - val_accuracy: 0.4941\n",
      "Epoch 757/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6770 - accuracy: 0.5701 - val_loss: 0.6988 - val_accuracy: 0.4765\n",
      "Epoch 758/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6795 - accuracy: 0.5642 - val_loss: 0.6932 - val_accuracy: 0.4765\n",
      "Epoch 759/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6792 - accuracy: 0.5746 - val_loss: 0.6923 - val_accuracy: 0.4824\n",
      "Epoch 760/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5358 - val_loss: 0.6913 - val_accuracy: 0.4794\n",
      "Epoch 761/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6784 - accuracy: 0.5657 - val_loss: 0.6894 - val_accuracy: 0.4882\n",
      "Epoch 762/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6816 - accuracy: 0.5582 - val_loss: 0.6923 - val_accuracy: 0.4676\n",
      "Epoch 763/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6814 - accuracy: 0.5537 - val_loss: 0.6875 - val_accuracy: 0.5088\n",
      "Epoch 764/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6819 - accuracy: 0.5537 - val_loss: 0.6975 - val_accuracy: 0.4676\n",
      "Epoch 765/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5701 - val_loss: 0.6919 - val_accuracy: 0.4735\n",
      "Epoch 766/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6828 - accuracy: 0.5388 - val_loss: 0.7024 - val_accuracy: 0.4794\n",
      "Epoch 767/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6797 - accuracy: 0.5612 - val_loss: 0.7071 - val_accuracy: 0.4735\n",
      "Epoch 768/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6802 - accuracy: 0.5582 - val_loss: 0.7103 - val_accuracy: 0.4765\n",
      "Epoch 769/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.5701 - val_loss: 0.7082 - val_accuracy: 0.4735\n",
      "Epoch 770/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6845 - accuracy: 0.5552 - val_loss: 0.7154 - val_accuracy: 0.4824\n",
      "Epoch 771/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6801 - accuracy: 0.5672 - val_loss: 0.6931 - val_accuracy: 0.4941\n",
      "Epoch 772/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6778 - accuracy: 0.5701 - val_loss: 0.7021 - val_accuracy: 0.4882\n",
      "Epoch 773/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6818 - accuracy: 0.5552 - val_loss: 0.7114 - val_accuracy: 0.4824\n",
      "Epoch 774/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6817 - accuracy: 0.5493 - val_loss: 0.7094 - val_accuracy: 0.4912\n",
      "Epoch 775/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6778 - accuracy: 0.5448 - val_loss: 0.7031 - val_accuracy: 0.4941\n",
      "Epoch 776/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5463 - val_loss: 0.6942 - val_accuracy: 0.4882\n",
      "Epoch 777/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6808 - accuracy: 0.5522 - val_loss: 0.7004 - val_accuracy: 0.4647\n",
      "Epoch 778/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6836 - accuracy: 0.5478 - val_loss: 0.6957 - val_accuracy: 0.5029\n",
      "Epoch 779/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.5552 - val_loss: 0.6889 - val_accuracy: 0.4882\n",
      "Epoch 780/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6820 - accuracy: 0.5552 - val_loss: 0.7067 - val_accuracy: 0.4765\n",
      "Epoch 781/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5627 - val_loss: 0.6960 - val_accuracy: 0.4941\n",
      "Epoch 782/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6812 - accuracy: 0.5687 - val_loss: 0.6925 - val_accuracy: 0.4706\n",
      "Epoch 783/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5522 - val_loss: 0.6885 - val_accuracy: 0.4882\n",
      "Epoch 784/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6791 - accuracy: 0.5478 - val_loss: 0.6897 - val_accuracy: 0.4882\n",
      "Epoch 785/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6782 - accuracy: 0.5448 - val_loss: 0.6957 - val_accuracy: 0.4912\n",
      "Epoch 786/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6813 - accuracy: 0.5657 - val_loss: 0.6949 - val_accuracy: 0.4882\n",
      "Epoch 787/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6809 - accuracy: 0.5493 - val_loss: 0.6924 - val_accuracy: 0.4794\n",
      "Epoch 788/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6807 - accuracy: 0.5612 - val_loss: 0.6893 - val_accuracy: 0.4971\n",
      "Epoch 789/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5522 - val_loss: 0.6901 - val_accuracy: 0.4941\n",
      "Epoch 790/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5761 - val_loss: 0.6944 - val_accuracy: 0.4706\n",
      "Epoch 791/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5463 - val_loss: 0.6996 - val_accuracy: 0.4882\n",
      "Epoch 792/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5433 - val_loss: 0.6903 - val_accuracy: 0.4794\n",
      "Epoch 793/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6822 - accuracy: 0.5373 - val_loss: 0.6951 - val_accuracy: 0.4706\n",
      "Epoch 794/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5687 - val_loss: 0.7129 - val_accuracy: 0.4824\n",
      "Epoch 795/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6778 - accuracy: 0.5597 - val_loss: 0.6934 - val_accuracy: 0.4794\n",
      "Epoch 796/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5567 - val_loss: 0.6946 - val_accuracy: 0.4618\n",
      "Epoch 797/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5612 - val_loss: 0.6873 - val_accuracy: 0.4882\n",
      "Epoch 798/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5463 - val_loss: 0.7044 - val_accuracy: 0.4647\n",
      "Epoch 799/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.5478 - val_loss: 0.6905 - val_accuracy: 0.4765\n",
      "Epoch 800/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5627 - val_loss: 0.6883 - val_accuracy: 0.4912\n",
      "Epoch 801/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.5493 - val_loss: 0.6953 - val_accuracy: 0.4912\n",
      "Epoch 802/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5612 - val_loss: 0.6978 - val_accuracy: 0.4735\n",
      "Epoch 803/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6853 - accuracy: 0.5463 - val_loss: 0.6919 - val_accuracy: 0.4706\n",
      "Epoch 804/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5493 - val_loss: 0.6918 - val_accuracy: 0.5118\n",
      "Epoch 805/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5478 - val_loss: 0.6984 - val_accuracy: 0.4735\n",
      "Epoch 806/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5627 - val_loss: 0.7028 - val_accuracy: 0.4794\n",
      "Epoch 807/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5597 - val_loss: 0.6923 - val_accuracy: 0.4735\n",
      "Epoch 808/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5687 - val_loss: 0.6919 - val_accuracy: 0.4794\n",
      "Epoch 809/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5463 - val_loss: 0.6966 - val_accuracy: 0.4706\n",
      "Epoch 810/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5254 - val_loss: 0.6940 - val_accuracy: 0.5029\n",
      "Epoch 811/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6855 - accuracy: 0.5507 - val_loss: 0.7138 - val_accuracy: 0.4706\n",
      "Epoch 812/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5507 - val_loss: 0.6952 - val_accuracy: 0.4912\n",
      "Epoch 813/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5582 - val_loss: 0.6970 - val_accuracy: 0.4941\n",
      "Epoch 814/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5522 - val_loss: 0.6982 - val_accuracy: 0.4794\n",
      "Epoch 815/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5537 - val_loss: 0.6955 - val_accuracy: 0.4706\n",
      "Epoch 816/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5522 - val_loss: 0.6987 - val_accuracy: 0.4706\n",
      "Epoch 817/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5478 - val_loss: 0.6984 - val_accuracy: 0.4676\n",
      "Epoch 818/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5701 - val_loss: 0.6930 - val_accuracy: 0.5206\n",
      "Epoch 819/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5537 - val_loss: 0.6932 - val_accuracy: 0.5294\n",
      "Epoch 820/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5537 - val_loss: 0.6924 - val_accuracy: 0.5324\n",
      "Epoch 821/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5612 - val_loss: 0.6992 - val_accuracy: 0.5324\n",
      "Epoch 822/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5582 - val_loss: 0.6948 - val_accuracy: 0.5324\n",
      "Epoch 823/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5701 - val_loss: 0.7039 - val_accuracy: 0.5294\n",
      "Epoch 824/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5373 - val_loss: 0.7044 - val_accuracy: 0.5235\n",
      "Epoch 825/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5746 - val_loss: 0.6975 - val_accuracy: 0.5235\n",
      "Epoch 826/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5627 - val_loss: 0.6906 - val_accuracy: 0.4941\n",
      "Epoch 827/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5612 - val_loss: 0.6941 - val_accuracy: 0.5147\n",
      "Epoch 828/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5478 - val_loss: 0.7006 - val_accuracy: 0.5206\n",
      "Epoch 829/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5642 - val_loss: 0.7091 - val_accuracy: 0.5147\n",
      "Epoch 830/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5507 - val_loss: 0.6902 - val_accuracy: 0.5353\n",
      "Epoch 831/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5582 - val_loss: 0.6914 - val_accuracy: 0.5176\n",
      "Epoch 832/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5552 - val_loss: 0.6943 - val_accuracy: 0.5147\n",
      "Epoch 833/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5537 - val_loss: 0.6918 - val_accuracy: 0.5176\n",
      "Epoch 834/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5657 - val_loss: 0.6904 - val_accuracy: 0.4765\n",
      "Epoch 835/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5612 - val_loss: 0.6920 - val_accuracy: 0.4676\n",
      "Epoch 836/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5537 - val_loss: 0.6931 - val_accuracy: 0.4853\n",
      "Epoch 837/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.5537 - val_loss: 0.7040 - val_accuracy: 0.4706\n",
      "Epoch 838/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5642 - val_loss: 0.6903 - val_accuracy: 0.4882\n",
      "Epoch 839/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5433 - val_loss: 0.6905 - val_accuracy: 0.5059\n",
      "Epoch 840/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5701 - val_loss: 0.6973 - val_accuracy: 0.4912\n",
      "Epoch 841/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5657 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 842/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6833 - accuracy: 0.5567 - val_loss: 0.7059 - val_accuracy: 0.4735\n",
      "Epoch 843/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5597 - val_loss: 0.6977 - val_accuracy: 0.4735\n",
      "Epoch 844/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5612 - val_loss: 0.6957 - val_accuracy: 0.4706\n",
      "Epoch 845/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5522 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 846/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5687 - val_loss: 0.7004 - val_accuracy: 0.4794\n",
      "Epoch 847/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5537 - val_loss: 0.6968 - val_accuracy: 0.4971\n",
      "Epoch 848/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6786 - accuracy: 0.5701 - val_loss: 0.6970 - val_accuracy: 0.4882\n",
      "Epoch 849/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6829 - accuracy: 0.5463 - val_loss: 0.6950 - val_accuracy: 0.4765\n",
      "Epoch 850/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5687 - val_loss: 0.6957 - val_accuracy: 0.4882\n",
      "Epoch 851/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5657 - val_loss: 0.6967 - val_accuracy: 0.4882\n",
      "Epoch 852/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5716 - val_loss: 0.6996 - val_accuracy: 0.4735\n",
      "Epoch 853/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5537 - val_loss: 0.6942 - val_accuracy: 0.4912\n",
      "Epoch 854/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5567 - val_loss: 0.6869 - val_accuracy: 0.5118\n",
      "Epoch 855/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6844 - accuracy: 0.5448 - val_loss: 0.7122 - val_accuracy: 0.4706\n",
      "Epoch 856/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5582 - val_loss: 0.6905 - val_accuracy: 0.4912\n",
      "Epoch 857/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5493 - val_loss: 0.7063 - val_accuracy: 0.4676\n",
      "Epoch 858/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5642 - val_loss: 0.6987 - val_accuracy: 0.4706\n",
      "Epoch 859/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5537 - val_loss: 0.7004 - val_accuracy: 0.4765\n",
      "Epoch 860/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5463 - val_loss: 0.6989 - val_accuracy: 0.4588\n",
      "Epoch 861/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5597 - val_loss: 0.6945 - val_accuracy: 0.4765\n",
      "Epoch 862/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5896 - val_loss: 0.7014 - val_accuracy: 0.4647\n",
      "Epoch 863/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5313 - val_loss: 0.6889 - val_accuracy: 0.5000\n",
      "Epoch 864/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5478 - val_loss: 0.6928 - val_accuracy: 0.4912\n",
      "Epoch 865/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5507 - val_loss: 0.6997 - val_accuracy: 0.4735\n",
      "Epoch 866/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5522 - val_loss: 0.7035 - val_accuracy: 0.4676\n",
      "Epoch 867/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5552 - val_loss: 0.6917 - val_accuracy: 0.4765\n",
      "Epoch 868/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5612 - val_loss: 0.6916 - val_accuracy: 0.4765\n",
      "Epoch 869/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5642 - val_loss: 0.6910 - val_accuracy: 0.4765\n",
      "Epoch 870/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5507 - val_loss: 0.6960 - val_accuracy: 0.4912\n",
      "Epoch 871/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5463 - val_loss: 0.6980 - val_accuracy: 0.4882\n",
      "Epoch 872/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5597 - val_loss: 0.6935 - val_accuracy: 0.4647\n",
      "Epoch 873/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5612 - val_loss: 0.6912 - val_accuracy: 0.4971\n",
      "Epoch 874/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5552 - val_loss: 0.6894 - val_accuracy: 0.4912\n",
      "Epoch 875/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5701 - val_loss: 0.6983 - val_accuracy: 0.5000\n",
      "Epoch 876/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5448 - val_loss: 0.7015 - val_accuracy: 0.5029\n",
      "Epoch 877/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5582 - val_loss: 0.7011 - val_accuracy: 0.4794\n",
      "Epoch 878/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5552 - val_loss: 0.7031 - val_accuracy: 0.5000\n",
      "Epoch 879/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5433 - val_loss: 0.7018 - val_accuracy: 0.5088\n",
      "Epoch 880/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5567 - val_loss: 0.7183 - val_accuracy: 0.4765\n",
      "Epoch 881/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5776 - val_loss: 0.7001 - val_accuracy: 0.5029\n",
      "Epoch 882/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5597 - val_loss: 0.7077 - val_accuracy: 0.4824\n",
      "Epoch 883/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5836 - val_loss: 0.7142 - val_accuracy: 0.4794\n",
      "Epoch 884/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6838 - accuracy: 0.5313 - val_loss: 0.7043 - val_accuracy: 0.4794\n",
      "Epoch 885/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5522 - val_loss: 0.7153 - val_accuracy: 0.4912\n",
      "Epoch 886/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6839 - accuracy: 0.5388 - val_loss: 0.7175 - val_accuracy: 0.4588\n",
      "Epoch 887/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5672 - val_loss: 0.7045 - val_accuracy: 0.4794\n",
      "Epoch 888/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5478 - val_loss: 0.7020 - val_accuracy: 0.4676\n",
      "Epoch 889/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5612 - val_loss: 0.6943 - val_accuracy: 0.4706\n",
      "Epoch 890/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5522 - val_loss: 0.6960 - val_accuracy: 0.4824\n",
      "Epoch 891/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5657 - val_loss: 0.6994 - val_accuracy: 0.5294\n",
      "Epoch 892/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5791 - val_loss: 0.6952 - val_accuracy: 0.4765\n",
      "Epoch 893/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5493 - val_loss: 0.6893 - val_accuracy: 0.4824\n",
      "Epoch 894/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5657 - val_loss: 0.6981 - val_accuracy: 0.4765\n",
      "Epoch 895/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5642 - val_loss: 0.6904 - val_accuracy: 0.4971\n",
      "Epoch 896/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5552 - val_loss: 0.6958 - val_accuracy: 0.4765\n",
      "Epoch 897/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5507 - val_loss: 0.6944 - val_accuracy: 0.4824\n",
      "Epoch 898/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5582 - val_loss: 0.6953 - val_accuracy: 0.4794\n",
      "Epoch 899/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5701 - val_loss: 0.6946 - val_accuracy: 0.4735\n",
      "Epoch 900/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5552 - val_loss: 0.6912 - val_accuracy: 0.4824\n",
      "Epoch 901/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5388 - val_loss: 0.7181 - val_accuracy: 0.5147\n",
      "Epoch 902/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5433 - val_loss: 0.7187 - val_accuracy: 0.5118\n",
      "Epoch 903/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5567 - val_loss: 0.7017 - val_accuracy: 0.4971\n",
      "Epoch 904/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.5687 - val_loss: 0.6959 - val_accuracy: 0.5059\n",
      "Epoch 905/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5522 - val_loss: 0.7058 - val_accuracy: 0.4794\n",
      "Epoch 906/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5642 - val_loss: 0.7014 - val_accuracy: 0.4765\n",
      "Epoch 907/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6837 - accuracy: 0.5388 - val_loss: 0.6897 - val_accuracy: 0.4794\n",
      "Epoch 908/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5493 - val_loss: 0.7118 - val_accuracy: 0.4824\n",
      "Epoch 909/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5463 - val_loss: 0.6994 - val_accuracy: 0.4735\n",
      "Epoch 910/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5687 - val_loss: 0.6926 - val_accuracy: 0.4941\n",
      "Epoch 911/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6756 - accuracy: 0.5672 - val_loss: 0.6853 - val_accuracy: 0.5147\n",
      "Epoch 912/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5597 - val_loss: 0.6902 - val_accuracy: 0.4941\n",
      "Epoch 913/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5463 - val_loss: 0.7071 - val_accuracy: 0.4529\n",
      "Epoch 914/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5597 - val_loss: 0.6938 - val_accuracy: 0.5265\n",
      "Epoch 915/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5642 - val_loss: 0.6962 - val_accuracy: 0.5235\n",
      "Epoch 916/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5507 - val_loss: 0.6953 - val_accuracy: 0.5147\n",
      "Epoch 917/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.6769 - accuracy: 0.5507 - val_loss: 0.6971 - val_accuracy: 0.5088\n",
      "Epoch 918/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6782 - accuracy: 0.5582 - val_loss: 0.6992 - val_accuracy: 0.5088\n",
      "Epoch 919/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5597 - val_loss: 0.6993 - val_accuracy: 0.5382\n",
      "Epoch 920/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6765 - accuracy: 0.5627 - val_loss: 0.6989 - val_accuracy: 0.5294\n",
      "Epoch 921/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5597 - val_loss: 0.6945 - val_accuracy: 0.5088\n",
      "Epoch 922/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6846 - accuracy: 0.5463 - val_loss: 0.6887 - val_accuracy: 0.4971\n",
      "Epoch 923/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5627 - val_loss: 0.6983 - val_accuracy: 0.4794\n",
      "Epoch 924/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5463 - val_loss: 0.6995 - val_accuracy: 0.4735\n",
      "Epoch 925/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5597 - val_loss: 0.6937 - val_accuracy: 0.4912\n",
      "Epoch 926/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5537 - val_loss: 0.6916 - val_accuracy: 0.4882\n",
      "Epoch 927/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5567 - val_loss: 0.6995 - val_accuracy: 0.4676\n",
      "Epoch 928/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6769 - accuracy: 0.5627 - val_loss: 0.7110 - val_accuracy: 0.4706\n",
      "Epoch 929/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5746 - val_loss: 0.6939 - val_accuracy: 0.4794\n",
      "Epoch 930/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5537 - val_loss: 0.6957 - val_accuracy: 0.5029\n",
      "Epoch 931/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5657 - val_loss: 0.6927 - val_accuracy: 0.4941\n",
      "Epoch 932/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5716 - val_loss: 0.6992 - val_accuracy: 0.4706\n",
      "Epoch 933/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5448 - val_loss: 0.6960 - val_accuracy: 0.4794\n",
      "Epoch 934/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5642 - val_loss: 0.7114 - val_accuracy: 0.4882\n",
      "Epoch 935/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5478 - val_loss: 0.7199 - val_accuracy: 0.4853\n",
      "Epoch 936/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5507 - val_loss: 0.6987 - val_accuracy: 0.5088\n",
      "Epoch 937/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5597 - val_loss: 0.7045 - val_accuracy: 0.4941\n",
      "Epoch 938/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5493 - val_loss: 0.7099 - val_accuracy: 0.4706\n",
      "Epoch 939/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5448 - val_loss: 0.7024 - val_accuracy: 0.4706\n",
      "Epoch 940/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6802 - accuracy: 0.5821 - val_loss: 0.7120 - val_accuracy: 0.4912\n",
      "Epoch 941/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5597 - val_loss: 0.7097 - val_accuracy: 0.4853\n",
      "Epoch 942/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5373 - val_loss: 0.7129 - val_accuracy: 0.4853\n",
      "Epoch 943/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6766 - accuracy: 0.5642 - val_loss: 0.6989 - val_accuracy: 0.4971\n",
      "Epoch 944/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5552 - val_loss: 0.7064 - val_accuracy: 0.4735\n",
      "Epoch 945/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5507 - val_loss: 0.7026 - val_accuracy: 0.4882\n",
      "Epoch 946/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5507 - val_loss: 0.7060 - val_accuracy: 0.4765\n",
      "Epoch 947/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5672 - val_loss: 0.6967 - val_accuracy: 0.5059\n",
      "Epoch 948/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5627 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
      "Epoch 949/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6789 - accuracy: 0.5627 - val_loss: 0.7296 - val_accuracy: 0.4676\n",
      "Epoch 950/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5433 - val_loss: 0.7063 - val_accuracy: 0.4824\n",
      "Epoch 951/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6779 - accuracy: 0.5522 - val_loss: 0.6908 - val_accuracy: 0.4824\n",
      "Epoch 952/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5537 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
      "Epoch 953/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5388 - val_loss: 0.6946 - val_accuracy: 0.4971\n",
      "Epoch 954/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5612 - val_loss: 0.7005 - val_accuracy: 0.4912\n",
      "Epoch 955/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5582 - val_loss: 0.7002 - val_accuracy: 0.4765\n",
      "Epoch 956/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.5582 - val_loss: 0.7158 - val_accuracy: 0.4853\n",
      "Epoch 957/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6836 - accuracy: 0.5448 - val_loss: 0.6938 - val_accuracy: 0.5088\n",
      "Epoch 958/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.5343 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
      "Epoch 959/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5284 - val_loss: 0.6884 - val_accuracy: 0.5088\n",
      "Epoch 960/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5701 - val_loss: 0.6851 - val_accuracy: 0.5353\n",
      "Epoch 961/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5537 - val_loss: 0.6858 - val_accuracy: 0.5412\n",
      "Epoch 962/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5612 - val_loss: 0.6904 - val_accuracy: 0.5059\n",
      "Epoch 963/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5657 - val_loss: 0.6879 - val_accuracy: 0.5235\n",
      "Epoch 964/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5537 - val_loss: 0.6888 - val_accuracy: 0.5088\n",
      "Epoch 965/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6785 - accuracy: 0.5478 - val_loss: 0.6907 - val_accuracy: 0.5088\n",
      "Epoch 966/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5403 - val_loss: 0.6920 - val_accuracy: 0.5029\n",
      "Epoch 967/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5284 - val_loss: 0.6942 - val_accuracy: 0.4971\n",
      "Epoch 968/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5537 - val_loss: 0.7018 - val_accuracy: 0.4735\n",
      "Epoch 969/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5597 - val_loss: 0.6885 - val_accuracy: 0.5235\n",
      "Epoch 970/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5567 - val_loss: 0.6960 - val_accuracy: 0.4971\n",
      "Epoch 971/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5448 - val_loss: 0.7043 - val_accuracy: 0.4971\n",
      "Epoch 972/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5627 - val_loss: 0.7021 - val_accuracy: 0.4941\n",
      "Epoch 973/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5388 - val_loss: 0.7058 - val_accuracy: 0.4912\n",
      "Epoch 974/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6819 - accuracy: 0.5716 - val_loss: 0.7142 - val_accuracy: 0.5000\n",
      "Epoch 975/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6767 - accuracy: 0.5612 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 976/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5478 - val_loss: 0.7014 - val_accuracy: 0.5029\n",
      "Epoch 977/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5552 - val_loss: 0.7090 - val_accuracy: 0.4882\n",
      "Epoch 978/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5642 - val_loss: 0.6949 - val_accuracy: 0.4971\n",
      "Epoch 979/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6779 - accuracy: 0.5746 - val_loss: 0.6907 - val_accuracy: 0.4941\n",
      "Epoch 980/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5478 - val_loss: 0.6950 - val_accuracy: 0.5059\n",
      "Epoch 981/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5597 - val_loss: 0.6966 - val_accuracy: 0.4971\n",
      "Epoch 982/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5657 - val_loss: 0.6928 - val_accuracy: 0.4912\n",
      "Epoch 983/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5552 - val_loss: 0.6922 - val_accuracy: 0.5059\n",
      "Epoch 984/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5478 - val_loss: 0.6939 - val_accuracy: 0.5029\n",
      "Epoch 985/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5642 - val_loss: 0.6895 - val_accuracy: 0.4912\n",
      "Epoch 986/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5597 - val_loss: 0.7061 - val_accuracy: 0.5029\n",
      "Epoch 987/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6807 - accuracy: 0.5388 - val_loss: 0.6973 - val_accuracy: 0.4853\n",
      "Epoch 988/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5537 - val_loss: 0.6919 - val_accuracy: 0.4971\n",
      "Epoch 989/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6785 - accuracy: 0.5761 - val_loss: 0.6933 - val_accuracy: 0.5147\n",
      "Epoch 990/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5612 - val_loss: 0.6936 - val_accuracy: 0.5176\n",
      "Epoch 991/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5582 - val_loss: 0.6903 - val_accuracy: 0.5294\n",
      "Epoch 992/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5582 - val_loss: 0.7692 - val_accuracy: 0.5088\n",
      "Epoch 993/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5716 - val_loss: 0.7084 - val_accuracy: 0.5118\n",
      "Epoch 994/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.5493 - val_loss: 0.7013 - val_accuracy: 0.4647\n",
      "Epoch 995/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5403 - val_loss: 0.6967 - val_accuracy: 0.4882\n",
      "Epoch 996/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5597 - val_loss: 0.7015 - val_accuracy: 0.5265\n",
      "Epoch 997/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5433 - val_loss: 0.7025 - val_accuracy: 0.5324\n",
      "Epoch 998/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5716 - val_loss: 0.7032 - val_accuracy: 0.5000\n",
      "Epoch 999/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5522 - val_loss: 0.7042 - val_accuracy: 0.4912\n",
      "Epoch 1000/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5731 - val_loss: 0.7172 - val_accuracy: 0.4618\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7172 - accuracy: 0.4618\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAB5+UlEQVR4nO2dd7gU1dnAf+/ubfQuHUEpilJFFCuKBRv2giWiX2LUGDW2xBI1tphYYyyxa9SIxoqKBQuWWAAVRBGkiBSl93br+f6Ymd2zszOzM7t3bz2/57nP3Z16ZnbmvOetR5RSGAwGg8HgJlbbDTAYDAZD3cQICIPBYDB4YgSEwWAwGDwxAsJgMBgMnhgBYTAYDAZPjIAwGAwGgydGQBgMgIg8ISI3hdx2oYgclO82GQy1jREQBoPBYPDECAiDoQEhIgW13QZDw8EICEO9wTbtXC4i34jIZhF5VEQ6isibIrJRRN4VkTba9mNE5DsRWScik0VkZ23dEBH5yt7vOaDEda4jRWS6ve+nIjIwZBuPEJGvRWSDiCwWketd6/exj7fOXj/OXt5ERO4QkZ9EZL2IfGIvGykiSzzuw0H25+tF5AUReVpENgDjRGS4iHxmn+MXEblXRIq0/XcRkUkiskZElovIVSLSSUS2iEg7bbuhIrJSRArDXLuh4WEEhKG+cTxwMNAXOAp4E7gK6ID1PF8IICJ9gWeBi+11E4HXRKTI7ixfAZ4C2gL/tY+Lve8Q4DHgt0A74EFggogUh2jfZuBXQGvgCOA8ETnGPu72dnv/abdpMDDd3u92YDdgL7tNVwBVIe/J0cAL9jmfASqBPwDtgRHAKOB8uw0tgHeBt4AuQG/gPaXUMmAycJJ23DOA8Uqp8pDtMDQwjIAw1Df+qZRarpRaCnwMfKGU+loptQ14GRhib3cy8IZSapLdwd0ONMHqgPcECoG7lVLlSqkXgKnaOc4BHlRKfaGUqlRKPQmU2vsFopSarJSaqZSqUkp9gyWk9rdXnwq8q5R61j7vaqXUdBGJAWcDFymlltrn/FQpVRrynnymlHrFPudWpdSXSqnPlVIVSqmFWALOacORwDKl1B1KqW1KqY1KqS/sdU8CpwOISBwYiyVEDY0UIyAM9Y3l2uetHt+b25+7AD85K5RSVcBioKu9bqlKrVT5k/Z5e+BS20SzTkTWAd3t/QIRkT1E5APbNLMeOBdrJI99jPkeu7XHMnF5rQvDYlcb+orI6yKyzDY73RKiDQCvAv1FpBeWlrZeKTUlyzYZGgBGQBgaKj9jdfQAiIhgdY5LgV+ArvYyhx7a58XAzUqp1tpfU6XUsyHO+x9gAtBdKdUK+BfgnGcxsKPHPquAbT7rNgNNteuIY5mndNwlmR8AZgN9lFItsUxweht28Gq4rYU9j6VFnIHRHho9RkAYGirPA0eIyCjbyXoplpnoU+AzoAK4UEQKReQ4YLi278PAubY2ICLSzHY+twhx3hbAGqXUNhEZjmVWcngGOEhEThKRAhFpJyKDbe3mMeBOEekiInERGWH7PH4ASuzzFwLXAJl8IS2ADcAmEdkJOE9b9zrQWUQuFpFiEWkhInto6/8NjAPGYAREo8cICEODRCk1B2sk/E+sEfpRwFFKqTKlVBlwHFZHuAbLX/GStu804DfAvcBaYJ69bRjOB24QkY3AtViCyjnuIuBwLGG1BstBPchefRkwE8sXsgb4GxBTSq23j/kIlvazGUiJavLgMizBtBFL2D2ntWEjlvnoKGAZMBc4QFv/Pyzn+FdKKd3sZmiEiJkwyGAw6IjI+8B/lFKP1HZbDLWLERAGgyGBiOwOTMLyoWys7fYYahdjYjIYDACIyJNYORIXG+FgAKNBGAwGg8EHo0EYDAaDwZMGU9irffv2qmfPnrXdDIPBYKhXfPnll6uUUu7cGqABCYiePXsybdq02m6GwWAw1CtExDec2ZiYDAaDweCJERAGg8Fg8MQICIPBYDB40mB8EF6Ul5ezZMkStm3bVttNaTCUlJTQrVs3CgvNHDIGQ0OnQQuIJUuW0KJFC3r27Elq4U5DNiilWL16NUuWLKFXr1613RyDwZBnGrSJadu2bbRr184Ih2pCRGjXrp3RyAyGRkKDFhCAEQ7VjLmfBkPjocELCIPBYMiGGYvX8e3S9bXdjFrFCIg8snr1agYPHszgwYPp1KkTXbt2TXwvKysL3HfatGlceOGFNdRSg8Hg5uj7/seR//yktptRqzRoJ3Vt065dO6ZPnw7A9ddfT/PmzbnssssS6ysqKigo8P4Jhg0bxrBhw2qimY2OxWu28PHcVZy6R4/MGxsMjRijQdQw48aN49xzz2WPPfbgiiuuYMqUKYwYMYIhQ4aw1157MWfOHAAmT57MkUceCVjC5eyzz2bkyJHssMMO3HPPPbV5CfWe3/x7Gle9PJO1m4O1OIOhsdNoNIi/vPYds37eUK3H7N+lJdcdtUvk/ZYsWcKnn35KPB5nw4YNfPzxxxQUFPDuu+9y1VVX8eKLL6btM3v2bD744AM2btxIv379OO+880wuQpaUVlQBsGZLGW2aFdVyawyGukujERB1iRNPPJF4PA7A+vXrOfPMM5k7dy4iQnl5uec+RxxxBMXFxRQXF7PddtuxfPlyunXrVpPNbjC0bmoJ1nVbjAZhMATRaARENiP9fNGsWbPE5z//+c8ccMABvPzyyyxcuJCRI0d67lNcXJz4HI/HqaioyHczGyytm1gCYu1mb2FsMBgsjA+illm/fj1du3YF4IknnqjdxjQSmhRZ2tu2ispabonBULcxAqKWueKKK7jyyisZMmSI0QpqCMFK9qusqpnpdv/+1mz+9tbsGjlXfWXeio0cetdHrN9iaXXjHp/CG9/8Usut8ubbpes5/B8fs7m04b+vjcbEVNtcf/31nstHjBjBDz/8kPh+0003ATBy5MiEucm977fffpuPJjYe7GTwmpqO/f7J8wH44+idauaE9ZB/vDePOcs3MvmHFRw9uCuT56xk8pyVHDHwiNpuWhp/ffN7Zv2yga8WrWXfPp4TsTUY8qpBiMhoEZkjIvNE5E8e68eJyEoRmW7//Vpb93cR+U5EvheRe8TUeGjQHPnPj7lz0g+ZN6wGnAeppjQIQ2ac36SmhHYuOG2M5dAlKaUYdtMk/vPFompqVX7Im4AQkThwH3AY0B8YKyL9PTZ9Tik12P57xN53L2BvYCCwK7A7sH++2mqofb5duoF73ptbI+dyxhpV9aE3aiQ4fa1CUVXHBbfz3OQyYlUKVm0q46qXZ1ZPo/JEPjWI4cA8pdQCpVQZMB44OuS+CigBioBioBBYnpdWGuoFW8oq6PmnN3jmC9/pc0PjvNiNWUDset3bXPbfGbXdjAR6Z1vXfxenebkYNer2FSbJp4DoCizWvi+xl7k5XkS+EZEXRKQ7gFLqM+AD4Bf7722l1PfuHUXkHBGZJiLTVq5cWf1XYMgLFZVVqIidwM/rtgLw6Mc/5nx+572u4wPVQCoqq3Laf1NpBS98uSSnY1RWVd9ov8I+TmVV8nNdJSkgoKpKZWWqrOtC0KG2o5heA3oqpQYCk4AnAUSkN7Az0A1LqBwoIvu6d1ZKPaSUGqaUGtahQ8N2FjUU1m8tp/fVb/KvDxdE2u+Ie6yiaSWF8ZzbUN99EK9OX0rvq9/kx1Wba7UdO141sVqK2X3501petyOWLvvvDEbd8WHOx8wniqSJ6fRHv2DHqyZGPoYRELAU6K5972YvS6CUWq2UKrW/PgLsZn8+FvhcKbVJKbUJeBMYkce2GmqIlRutyYb+++XiDFum4pTHaFZcDQKiDvggSisqEyGdUXHCP+csq97SMdkw65cNrNxYmnlDjfLKqpQ6WJ/OW5WyfqmtLdZV1tm/WywmfDp/dVbHqCfyIa8CYirQR0R6iUgRcAowQd9ARDprX8cAjhlpEbC/iBSISCGWgzrNxFQfOOCAA3j77bdTlt19992cd955ntuPHDmSadOmAXD44Yezbt26tG2uv/56br/99sDzvvLKK8yaNSvx/dprr+Xdd9+N2PrqxzEfFMSS9tso5qbq1CBq0xk67rGpDLrhnVo7f3Wy+83v8tWitaG3v/y/Mxhy46TE715P+soEc1dsAnJ3UtcH8iYglFIVwAXA21id+/NKqe9E5AYRGWNvdqEdyjoDuBAYZy9/AZgPzARmADOUUq/lq635ZOzYsYwfPz5l2fjx4xk7dmzGfSdOnEjr1q2zOq9bQNxwww0cdNBBWR2rOnHMOvFY8tGLYnOuqKyGN8t+s70Ota28koU1YLr5bEF2I0/QO1TvLqq8sor5Kzdlf3yl+GH5xkj7zFuePN/CVZvZVp6epV5VZR33lek/2+20riRXTW7t5jJWbKz5aXBzcVLnes0LVm6irCI3P1QY8uqDUEpNVEr1VUrtqJS62V52rVJqgv35SqXULkqpQUqpA5RSs+3llUqp3yqldlZK9VdKXZLPduaTE044gTfeeCMxQdDChQv5+eefefbZZxk2bBi77LIL1113nee+PXv2ZNUqS/2++eab6du3L/vss0+iJDjAww8/zO67786gQYM4/vjj2bJlC59++ikTJkzg8ssvZ/DgwcyfP59x48bxwgsvAPDee+8xZMgQBgwYwNlnn01paWnifNdddx1Dhw5lwIABzJ5d/dm/lR4aRJROv2PL4swbZcDJpPbSXK544RtG3j65TmfJ6k5SL256fRaj7viQ5Ru8O81MGtuEGT9zyF0fMWlW+MDBwgKrMdvKKxl5+2QufT49QurRT37kkLs+Snwvtx3tuY6mh9w4ieE3v5fbQUKi37tcMrNyueTVm0o58I4PuW5C/hNmG08m9Zt/gmXVHHPcaQAcdmvgJm3btmX48OG8+eabHH300YwfP56TTjqJq666irZt21JZWcmoUaP45ptvGDhwoOcxvvzyS8aPH8/06dOpqKhg6NCh7Lab5a457rjj+M1vfgPANddcw6OPPsrvf/97xowZw5FHHskJJ5yQcqxt27Yxbtw43nvvPfr27cuvfvUrHnjgAS6++GIA2rdvz1dffcX999/P7bffziOPPJLjTUrFGTXGNQFRXpUcCW0qreCH5RsZ2qNNyn7De7ZlysI1/Lx+G+WVVZRXVvHB7JUcsFMHmhYlH+PZyzbQoXkx7Zr7CxLnxfZyUjs25c1lFTQrrt7Xo7yyisJ4dYzJrHb/tHozP6/bSpfWTVLWOtewfms5HVuWeLQjuHv6/hdLe/hh+UYO7t+RlRtLWbuljL4dW/ju41zX9MXrAPjoh/SowulL1qV8L6uoollxcGc55cc1DOnRuprum9W+3ts1p3mWv63+yERNlCuvrOKrn9ayxw7tstIgpi5cw8Burdi4zRq8/G9e9lpoWGo7iqlRoJuZHPPS888/z9ChQxkyZAjfffddijnIzccff8yxxx5L06ZNadmyJWPGjEms+/bbb9l3330ZMGAAzzzzDN99911gW+bMmUOvXr3o27cvAGeeeSYffZQc1R133HEA7LbbbixcuDDbS/bF6ZQL48mXq1LrsK5+eSbH3f9pmsmgwhYiU35cw+1vz2H8lMX87j9f8dzUVGf36Ls/5tC7Pw5sQzIPIn1dkd2uTJ1oNvztzerRyJy+5ZaJs9nr1vcj719RFWyaiLn6vf1v+yBl5O+F04Gf8tDnVhs9tnF3p2VOqG5AZ3nSg59xxzvVk2G/ubSCY+77H+c/81XWx9AHFVEViDve+YGTH/qcb5asQ0W0Dv2wfCMn/uszbn7j+4RgUjXgvWk8GkSGkX4+Ofroo/nDH/7AV199xZYtW2jbti233347U6dOpU2bNowbN45t27KzoY4bN45XXnmFQYMG8cQTTzB58uSc2uqUFa/OkuIfzFnB4G6tadOsKNE56aMvXYP4afUWAH5cuZntWiRHv7qfYu6KTRQXWB3Shq3pbVy1KTiq5v3ZKwBvO3ChfdxM9t0flm/kl/XbEGC/vuFCrOdEsOv/uGozazaXMbRHa1775hcO37UTBT6j6Ck/rmF4r7aApVU4TtSyiipem/EzRw7snGIvDxJ+qzeV8okdVeQ48beUZa56W+RqW5jAA+ceT/sp2MGdiz9Fp9Ju09cZzhdEVQ4mptl21NmazWX0aNs00r7OM/3D8o3JPB77EX1txs+UVVRx/G7VPz+M0SBqgObNm3PAAQdw9tlnM3bsWDZs2ECzZs1o1aoVy5cv58033wzcf7/99uOVV15h69atbNy4kddeS/rrN27cSOfOnSkvL+eZZ55JLG/RogUbN6Z3SP369WPhwoXMmzcPgKeeeor9989fFZNNpRWc9fhUzn5yKqD5IOLePojtWlgCapnLfq5vk0v0yOI1W1hth1h6RTE5HV0mAXHIXR9x5mNT+NVjU/ISDXXA7ZM5/oFPefPbZVz47Nc8YBf8g/TR+UkPfpb4vP9tkxOf//n+XH7/7NdMmPFzyvZBSXZnPDqFb5asB6IlEuq/p1cbvXA0iEyhogVulSZLnKPkkoiXIiAiPonOaWMikZM0k7679C77+WmLeboaKgx4YQREDTF27FhmzJjB2LFjGTRoEEOGDGGnnXbi1FNPZe+99w7cd+jQoZx88skMGjSIww47jN133z2x7sYbb2SPPfZg7733ZqedktVCTznlFG677TaGDBnC/PnJzqWkpITHH3+cE088kQEDBhCLxTj33HOr/4JtnI7WSeryjGLSOn9nvV7qed6KTcz6JTXm39nj1RkpqTW+fDJ3FTOXrE8ZDVd6aRABAuK5qYtYubGU711tCWtP9op6yTTS/mW9JSjvmPRDQhCFDQtetMbKJ1i1KXXmvKAOUr/PUUwYbnu8VxPd1x82CideTQLCaZLX7+7wv3mrmGH7UbzQTUxRTTzO7/biV0sihXbP+nkD731vab0x7V4sXbeVaQvX8PHcVTkVDgyi8ZiYapljjjkm5aHwmxxINxHpPoCrr76aq6++Om378847zzOnYu+9907xa+jnGzVqFF9//XXaPvr5hg0blrO5CpKdZ9x+gB1hUODjpHZGle9oETQH3ZmaWau/CwtWbg7l/D390S8AeOviZEK+pw/CMTFVpppV1mwu448vzmSnTguZvSxVM6tUKtSL5PUKVymIB7zb67cmk+lenbGUY4d0C90tldkTIrk7o3IfDWKuywQWZZTrLrvhJTTTfBAhBUR1aRBOk4Iy6E97xHpOFt7qXWZcd99E9TM79+TV6T/z2/12DL3f4fckfWpxSb23J/zL0h6/zMFsFoTRIAxZ8b95q3jr28wTuiQqX9rvuOOD0EeF+gvr13mlIikvZ6aXY8naLYnP+n6eJiZbQHw8NzW712mjWzgEnf+lr5ZkbJu7I/1x1WYe/SRZb6pIkx6bSp0OP/CQCcpc9/LZKYv4dul637DiUneH7XGib5euZ/yURTz8UWqplIkzf0nRTKKYmDq0CA5d3lJWyR3vzOGOd+ZwxQszUoRmGCqrFHe+M4d37UGH/rwtXLU5cS2PfBxc/uWtb3/ho7nJ6Cz9Guev3MRj2u/mhS5cggb8z09b7KvFxGOxGi0RYzQIQ1ZkGmklSMTsW29EmZcGoXVkYXMidPX+lIc+D2zHr5+cltxPO7yXqcHxQdz97lwuPqhvctuAl/LUh7/wPP8lHrkAbiqrFHpy+MkPfsYKrXSFblJwGh+2eygtT+3wr3zJCvN+95L9PLd33w6vS/arvTR+6mKuH6PN+x6ikY4GkanDe2fW8hSNsnlxIdce5TVzgDeTZi3nnvfnea47+4mpLFi1mUN26chNbwQXazj36dToJ10zO+GBT1m7pZwzRmzvq83qg4EgIX/FC98A3u9WPFazJWIavAYRtWqoIRj3/Xz9m599trRwOmGnnyuvSGoQSin+9tZsvluatHu7R71erNlcyn0fzE9ZtqXMP+LKiRuHVMFSVaX465vf8/y0xdzxjpV8uMknQS5TaOiYez+horKK+yfP43OfLGmvUaP78XSfXzfDBPWjSime/HRhyrI0jcDGL4rJ3fHc+8G8lIzqTM74igz2eff1O7911Mq0BXGhvLKKa16ZmajyC/C3t2Ynns+tZZVc+dI3rN9SHvjbOffotRnBz7EX+u1wtJq7Jv3A1IVruOrlmWk1pVIGJ1lqAQWxWI1WIW7QGkRJSQmrV6+mXbt2OaXFGyyUUqxevZqSkmT46QX/+ZojB3bx3cfRCBwnmvOyFsSELWWVKdE5kNohKqU8f7evFq1LW/bUZz9xzn47hL8YYPXmspSS1xcc2JshPVozffE6BnVvnbJtphf6myXr+XzBGv7+liVoMmpWznFdnbLb2ZgqIPyd1JVViusmpObAVPhkKvuZ8byucNxjU3zbmtYGTfCE6cScZyNqZ9mypIBP5q3i6c8X8fO6ZLTbA5Pnc8EBvWlWXMB/pizi2SmLaVZUwBBX0qVO0yJLfbs9q1yLdJPa/ZPnJ6aY/W7pel69YJ/ENvr9yzTg8CMeE2Niqi66devGkiVLMHNFVB8lJSV069YN8E/s06lSqQKiLJFJ7a286p2XUuFjzauUf6ck6VYaIH3kesYjU5iycA0AXVqlZiCHCY1MPU9mJy3ojsulfL1oXdr16lrAFwvW8MWCNZ7mCa/2Ocvcs7Sd8eiUtG3DkKlj0js95/orKqs49+kvueDAPmnX7xwvathpyyaFCcHp9l87Qsf5bWMxCXyGmuaQLX/qw18kPnv9JvNWpOZv6Bqafi//OvF7+nRswQkh8hiMgKhGCgsL6dWrV203o1HjvPziMjEVxMRj9JzayVcqRSxCrHmYFyfVB5G6zhEOXscKc+xYhmQ0L23I6bgvGj8dgFZNClPW6xrEW98tA2BQt1Zpx/HqZFOc/1rn7efk9RJqug8kU0eu/57Op0VrtvDu9yuYt2ITg11amdNhRu3wigtiWjRc6kDDuU6nrfFYcLZC0xyqA/uZ8Bw2uxIMdSGt38sHbSd5GAFh5VAYH4ShnvLD8o0MvXFSolCc8/I7naejITw3bXFCWDjERFI6qSgvgkKlbH/R+K89t7tlYtIRGWT7fmfWcp76PJl8dGuIMhn6aLa0Ij37+P3ZK1jgygoefMMkfv9ssq1pdnqPTsirP/W6loQGofyd/wOvf5uef3qDrxet9TQx6dFmr2ew0//70+T9cv90C1dvSVRxddhWXsnet74fWYOoqFKJ58gRmg5ux3dcvDWIeSs2MuymSWwsDS8sc0W/zDDJla9OT8/xefGrJczxiKTLF0ZAGKqVJz5dyJrNZYmok6QPwlqvm5DWbklN4IrFxPUShT+vUqkC5dXp3p2ZXmY7U0jtn19JVst0ynMEoWsIfqPL56alT5SkO0h96xVpeI24gzpZhf+1brAd+Pd9MM/TTKILiD+9FFzs8t4PvCOF/Ph53dasJgeq1ASEG0dA6BqEl3Hv6c8XsWpTGd8u3ZC2rl2zorw4gquUtwbhx8XPTfdc/oQrGCGfGAFhqFachDhnBObng4B0M0xcJCX6JZNTVOe2t+ew398ne67zM2GUhQypnR6QWaujjzr9BERxPMYKnzLcEOykdvAUEBmuJVPxweLCOF5u6ngegzuy7YQrKpVvB+sIjkotGMLrEoI62TbNilKmEb3q5Zkc7ErWDMt+f/8g8Vlvsq41+uHUG3Pz3c81N5Ngg/ZBGGoeZ8DpqNDOi+zYsisCch6s0Nfk96i2ab8ifX6dY5mHGciLl79aknkjUgVaqceEOWAl4gUV7Ut3UqcfxysCJigqRqnM2lJJQTyjBpENQb9gtrb0yirlax4sdWkQBfEoXiwLt3npP18sitxGh0Vr9CTN5HHDJPsVF+Q+e2KuGAFhSKPfNW8ypEdrxp8zgtvfnsO9H8xj/i2Hh+osHDOL0yc7IzlnT72jcpeziEmq7XrQX97hj6N3Ilt6/ukNHv7VMN/O8/MFazyX69z29mye/CxcITRd4B14h/eIszAeC5xnwu3I9tJEPCOWAjQEhcqoYTQpimX0QUTl989+HZhfkLUGUaV8tb9THvqcbeWVKVPbRg1xr+4ooZ5/eiPUdvNXbmLHDs0T30sKY3kroRGWvJqYRGS0iMwRkXki8ieP9eNEZKWITLf/fq2t6yEi74jI9yIyS0R65rOtBsucsa28ktKKqkTn+a8PrZjusC9NzGVicuRB0kmdPM42V6ZvPJYeofHc1OxHb2CVLdi0Lfuy5e6EvCAyRbWAJSDWuXwvOlsCEuUcvDr7TBpCeQaHjp8GsdVHEwpDpuSzbB3BlVVVvhrEptKKFAEayxDF5EVNTOXpxeI1W1Kmai0pjPPhnMy+r3ySNw1CROLAfcDBwBJgqohMUEq5A+ifU0pd4HGIfwM3K6UmiUhzoHZ+tUbE4fd8nBa77bxqYc0BCROTEwfvaBD2ct3p6jafuE1MAD3aNWPh6i1kS5RpM3MlTMfy4EfzWb7Bf74Kd2ikl5PaSyP6y2v+eSlhTExFBTHPDnvByvzNz53tpEyWAAhf6C+qGyVMNn8+GPf41BSNrSjurdXVJPnUIIYD85RSC5RSZcB44OgwO4pIf6BAKTUJQCm1SSmVfS/RwFmUQwcKVkf9y/qtacIB9Oxd//2VUixes4XFmr21Slk+ASfT1dEg9G3ctYJiLic1QPc2qdNp1mXcJjMvgoSDF+575HcMZ5IfL35et5WtGSb9yWaOglyJWmLDobJKhdLWwNFKox0/7LHzga6pF8RjiQm0MpGvWIJ8+iC6AnpM3xJgD4/tjheR/YAfgD8opRYDfYF1IvIS0At4F/iTUirlKReRc4BzAHr06FH9V1APePu7Zfz2qS95+FfDOLh/x6yOcclzM3hjpndlVkcwBGkQj37yY1qhsyqlGHbTu4nvsZjluNarpLpfxHhM0uzr1TUXcU2QD9NEdYxmn/liETOXrg/cpkqpGq9blu3EPRUBTmo3iujO8NoUEDpzl29Mm3vEj3zNB1Hbb99rQE+l1EBgEvCkvbwA2Be4DNgd2AEY595ZKfWQUmqYUmpYhw7hpn1saDhlgecsyy70rbSi0lc46ASFnHo5e92bx0TYsC01csNtYvpl/ba06I5w5b/rBnkRENV0TGeWOD+qVLSw4uogW+FXWaXS/Fd+LF+/LUVrDUNt+SDcRBGg1TRlRhr51CCWAt21793sZQmUUnrZy0eAv9uflwDTlVILAETkFWBP4NF8Nba+4rzUfrWNMnHdq99l3ggCJ1n3som7M0UrqxRrNqc6Z71Gau6Xsz4JiHyMPGuqs1KoGq3xA9mbmCoqVYozN4ioyXv1lfqoQUwF+ohILxEpAk4BJugbiEhn7esY4Htt39Yi4qgFBxK2Olwjo9JjfoUoZJow3qFKKeat2MS8Fekx/F4di3s0um5LeZqACPOSvz87WWjx9wf2DtXW2iKbrOBMeOVB5IOtZZU8NzU9yzufZOsAr6yqYlsdGeXXJi20cOl654NQSlWIyAXA20AceEwp9Z2I3ABMU0pNAC4UkTFABbAG24yklKoUkcuA98QKYv4SeDhfba3PpJYUyGL/kKO4KqUSU3+6S1l72XjdMmOHDs3STUwhzAR68ltJDoXVaoLH/7ew2o9ZUxrE+7NXsGRt9Qu4IMIOTtyUV4XXIBoy3do2Tfgo6uWc1EqpicBE17Jrtc9XAlf67DsJGJjP9jUEKnMVECHNCrpG4HaceWkQ7nISS9ZuTbODRzXJ1KUpPYb2aO05L0V14w579eKaI3bOOBtaJmpaOORCZaXigxC1sRo6hdp0tPl6NWrbSW3Ikdw1iHACQlcSDvvHxynrvGTMeJe54sdVm7n73bkpy6KaT/I1SsqGpkV1owhBSWGM7m2b1nYzapTVm8uyjoBqSOjvQ74mRDMCop5TVZWbDyLszFZu/4FXG6ISWYPI6iz5wZmJrLaZfeNhiXm0GwP9OrZgzeZouSQNldTpyvMjMBvPk9VAyVmDCNm5O3M253IMNys3RnvRYyKMGeQ/vWlNElRPKSzVNegriNcl0ZkdZ47YPtR2TYrirNuSudBdY6AmNGojIOo5ibLGWXYSlQEmpvu0EMF3v/e3+YYth+0mqKqpFyJwz9ghobfv1LKEs/buGbFV/gzbPjm3cZNq0CCmXHVQzseA3CuuhqFds6K8Hv+Sg/uF2q5ZcZwFq7KLfhromolvxrWHZHWcXPjvuSOq7Vg1MTAwAqKek9Qgsvspg4q43fa2v9ZQHSxZE80xGmZKRp2YkFOhPje6ptSsGgREdXW62WSbHz6gU6Tt/YRQ2JF/JpoWh7ufufh+3CPu4sLkfTttj5qpxFCdliB9utXHxu1efQfWMAKinpOc0jP6vkqFz0jNB5kyaQ/bNdmJFcVjtG4arUONxaRaC6/p0VpFPpO5RCEWE8/5pTPhnkgmGw3i1/vuEGl7Px/X9WN2iXxuL8IKuVx8P+77pPtubj52QNbHjUJ1+gr0+cL32KFdtR035Rx5OaqhxtDnHY5KbQqHMOijxSgd/R692gLWiPGqw3fmjD23p201jNZTykhXk/03m+7i7yekRn8XRtQe99qxHU1C5JTcM3ZI4l7GfcwZ7ugZLznSq32zSO0LIhcNwj07XiykYK1O85qXu87rUQoj9GvC9WQERD3HiSCqUoo3Z/7CaY98Hrh9eWUVR9/7CYfe9RH3fjA3cNuapGPL4rRlzUKaHXR27tySG4/ZFbA6q44tS7jxmF2rxU6vR2v5jXijCqKoheSG9mjNobukmoeiXtupe/QIJSDGDOrCmMFWUEBBgBAarbXHS7M6cVg002AQuZj29I54zx3aht6vR7vMYcTXHtnfc/mv9+mVMcLw4TOGpS0L8/tka1aOghEQ9ZxKrRz3ec98xf/mrQ5UY5et38aMJeuZs3xjpMlwdLzmyj0xon/AzZ89XrBsHMGFcUmM7vVRvt6577lDW576v+GRj637awZ3b83lh/bjiAGdU7ZpHjG6KarmF49JWodTGGEoedGoPhy2a+fQ99a5bUF9nC7kvARnpjDcSw7uG6otkGpiinLdkCpIo9z3HhnyTC4a1YejAqLrdMHkLmcP3s7mML9PUYFxUhsy4NjF9YqsflGns37ewL7aJOrZcMJu3TxV7gtH9cnpuG08/AttI/ocwLKVOwJSNyHondhBO3dk3z7Rq//qPojighi/O6A3HVqkaj6dWpWEOpYzEo4aIRwToSCevQ/iDwf3JR6T8MJXOXk2/l2Ffg1e8yhn8h3t1zf8b9FUE8CtmljHHd4rnDagDxjaN0/XWP3o3iZYQPzh4L4pDm83KXPaefzeXgI0jAZRE3NWGwFRz3H6PX3mNL+qnP/9MvdibIXxmOd8wEEvSNjjujl7n16h9n3xvL04f+SOgDXJiqNV6f2mfkuyzToN46S+7ihvU4Obx8+yNJioTksv30dYB++VhyXn987UAT10xm5Asj9zC6H9+nZIhGzq1+ClXR43pGvguaKY2XQT0wH9LMGSaTKk//x6D/5xymBK7Gd01E7bcctx4Z3S7Zv7C7j7TxsKZEhUzfC4uQU+eDvj7z55MHefPDjxPaoGlQ1GQNRzvISB3wvndtJlQ1FcPLOviwviWWdzg/fDHrbj2237Ngm7/I4dmic6vx3aJyeAj2rrd9ipU4vE51QNwruD7dq6Cf07t8x4XGfUG7VZWzyK1IXVII7UzCCZ7u0h9v102uc+x2G7dmL3ntY16HW6vARnJmdwFCHZxHZSj96lE81LrM9byoJDmTu3bsLRg5NC6uTdu9OqSWHoc7YM2HbXLlYUml/QQseWJfTrmHyGvK40rInpmCFdOUYTtjWR/1I3CsoYssZrkhe9M6yssmYKK4jHcn6gzt1/RyoqqzwraRYXxHj5/L056t5PMh7nzYv2JR4Tigti7H/bZCC1w7r2yP4cuNN2kdo2qHtr/nX6bozs14GSwjiPnjksJfQvm3Igj545jKE92jDkxklAahSTnwahdzxFBbFqr8a6cVt6FnFY4ecW4P/5zR6c+vAXgfs4x9afnXtPHcLhu3bWtklu76VBeLFvn/aJ2QXdP82L5+1FqyYFzF+5md8+9WXKuk329bdpVpQod+10zoVx4c6TBtN7O2tg4NQMSzY9+Pmf9If9KK9UHH5Paq2x5sUF/Pvs4fzqsSlp+ziWN6/B0X2nDmX0rp04frduPPP5TxwzpKvnFKJe+4YxMZlMakNGvEZf+kh37MOf0/vqN4HwYX1+9OvUnMKCmGd4bHFBjI6twtl1d+7ckr4dW7B9u2aJEbr+sA/v1ZaeWYRGjt61U6Ik+KidO6Y4jFNMTCGPN2rnjrTR/C2DurVOfPbrCEWEXbtaGsThu2ZORvNyWkYlyBYdk2Rn4+6I9tqxfcZje2kQRw7skvIsqQANwis6zTqGJmBcEmK37dvQe7sWadFaAK2aWgJ42PZt6Gs/OzvbGlt5peKoQV3YuXPLxDLQn63ge92nYwv6d7H2a1lSwF47WgOMgriwX98O7N6zTdo+zrG9Bl9HDOxMPCa0bVbE70f1oXvbpp5RbuLxRIbJ98hFYw+LERD1HK+BsW4BmvJjcjrQXJ+nTaWVvmGGIhLoyMyEvmuJ5s9495L9sj6mjj7Kznbg9Y9TBic+uwXEWXv35OMrDgDghqN35aXz96JrmyYh2uW9/Nnf7EmnlpbD+6n/G87Nx+7qe4wOLYr5Px9/TUwkYb7LZsTp54NI2Ua7Bt3hesXofrxx4b6e+5y4W3KyybDKnQgcM7grz/5mT44b2pUjBnRm/Dl7cu7+OwbuF3VgNOkP+/H+ZSO1UvrWNXllKzv31O3X8rtf/bu05IVzRzDnptGBbQgz94kJczVkxMu84De3cK4+iO5tmgQWqcvGhOU0VR9F6SPiHTs0d++S6DizOU8u6NfuHil3a9M0UXa7pDDO0B5tQnV8fvb3ETu2Swiy7VqUMKR7+uhVZ1D31p7LYyIctHNHAAqzyP7uY5trgjK+9WdQ79j6d27pGy0UiwkX2jMEbuejZXghIva9EUSEPXdoR7sAJzKENzE59OnYgvbNi5PmNfuHaFFSSN+Oqc+j3yMf9K4N69mW4oJ4QtP00iJDaRDGSW3IhJdt3S+KKVcT08h+26XF+TctivO/Px0IhFN53dOGOi+H/j41S5lKMf2Y71yyH59fOSp0uyGznX5Qt1Z8duWBie/ONfnhCLEgmRvGNxC0iXPoeCxzzLu+9vih3fi1rVGUVVZx6/ED+fDykZFzNMCKVnr3kv04Ybfuvts41/nX4wakCIhM+Q8XHdSX9y7d33MQ4IXfHcjUmbo7a/2Wf3nNQXz154M996vyMK+9dP7ePP/bZME9v4i4MIMlZ1CkVHoRvyg+iOqqh+V5jrwdGRCR0SIyR0TmicifPNaPE5GVIjLd/vu1a31LEVkiIvfms515Z+ta+Ob5vBza08Tk0+tUh1OrRUlqJ7Nrl1Z0bW2ZUsK8FN1cZhcnC1fPrciUQd2ypDB0voGDn1bl0LykgM6tkm1zrsmPMLWYhm2fOT4/jGITj8Vo18waZTuJeSUBYcXd2zZJuT9FBTG2b5d9uYve27UgqK93nsFe7ZtxwE7JnAav8E2deExShEOLDALMrzPOZI6RhBkofV275sW+2e/OQEsfqTcvLqBL6+S99dUgIg7G9FyLXvILO2/9MmBrC2dA1i5CTkdU8hbFJCJx4D7gYGAJMFVEJiilZrk2fU4pdYHPYW4EPspXG2uM1y6CWa9Cx12sPw/mLNtIm6aFbBfBfPLjqs38tDq99PHyDdvo6DqOUqpawuLcJiZdPQ4Tluq2m158UF/O2rtXijM4HwlAunzwugvZZDRn4uD+HTNuExTi6XRscRHaNCvi6z8fnIiS+vrPh6Tc+5RsXQVn7d0r1DSks244lLsm/cDDH/8YuF1Q7kgiMVGEU4f34MEPF7BozZbIJpApVx8U6LT3O1qm5y7bx94rggtS74XfoCvqOfXtPyi+FGbDn/hP4D5Ou/wsBtVBPjWI4cA8pdQCpVQZMB44OuzOIrIb0BF4J0/tqzm22I7izSt9Nzn07o8Ycev7kQ57wO2T2eBRznrMvf9LW1ZeqXLSIJxdu7mySvX+LcxL4d4kFpMU4VDXOcmnrlCUWP7U0gvht2/TrChhJmxSFA8sXBd2MNC0qCCRWxBEkE3dic3v2a4pIpIQYlF9XpmuKVvc9yLsT+X2QTiIxzZuMmlPkPxdlfugIdm3jxWFtnfvzNFo2ZJPAdEV0FN3l9jL3BwvIt+IyAsi0h1ARGLAHcBlQScQkXNEZJqITFu50r/zrXWK7USZ0uAJcrxGAqs3lXpO0L65NNo8B8vWbws0E2TCqRjaq32zhH0b3NFBmZ/yzRmSmmqLsJ3G344fyIJbDk989wpRjEKQnyLRgUQcIEYdT4aRJUGDi1OH92DBLYcntF+/kXeuZDu+yT5z3vqfrkEkP/sN3sMMxiTlc/Q2DuvZlvm3HB661Eg21LaT+jWgp1JqIDAJeNJefj4wUSm1JGhnpdRDSqlhSqlhHTpEr61TYxTZdtbnTocf3oGvn7H+QnDm41M464mpaclpV708M1ITxj0xJeNDWxSP0b2tt+1dNxfoI/6o2u2Grf7TRR4xoDM9PSpntiwp4JTd/Z2k1cnAbq3SKn22KClg7HBrQhkRSXH2HznI8gns71NP6PABndL8LjqBTurECDPzTdY7mKjlO8KM9IMiKt33xBnoVHce16WHhJt1zk1QBx9EVZWPiUm717pPrkOLYo62q99eNMoOxlizAF6/BKqCy4G0bBKsOf12v+T8HYf075h4T/KdTZ3PTOqlgP5Wd7OXJVBKrda+PgL83f48AthXRM4HmgNFIrJJKZXm6K4XtNASfv5zYvLzkNMy7jp/heVjqFKKF75cwj6929OpVQkLVkabdnHJmq0ZBcQPNx+W+NzzT2+krNMfRD1aKepodX2AgLjPrmvj5pvrD414lmC8RpROJzzhgn3S1s0MOP/QHm1YeOsRvuvvP82qaaTfT/3seZprPhJhotuimCf9ynPkQtA9zoS7GWHveaWvD8L637KkIMVBPvVqawrZf5wyJLnxi7+BpdNg8KnQLb2st9UeRXFBnIW3HsFJD34Gv6Sud1/7Q7/yPk4+yKcGMRXoIyK9RKQIOAWYoG8gInqt5DHA9wBKqdOUUj2UUj2xzEz/rrfCAUDlXm5h3ZZyLvvvDM600/3LI86UVlIYyylRrkVK6GlyedjR6uDurWlSGA8Ml8wnQYlmNUnHlsXcelxywp9rjtjZd9urD+9PqyaFaQEHmTgmQ3E8N+6+f+zw9N8oioCo1JzWNcXoXTpxqs+0oU47zt1/Bwrj4pkR7UVV4jpSlzuXFcp0FbMFSGX6wOiSQ/rRtChOH61WU01kR0chbxqEUqpCRC4A3gbiwGNKqe9E5AZgmlJqAnChiIwBKoA1wLh8tadWqSzL+RCOQFixcRsQbYY1sJxmt7/zQ+TzPn7W7pz1+FR6dUiGSZZr1VzDyIdcRn/VxWl7bM/sXzby1Oc/ea6vqZH8F1cdlPL9sAGdueaInT0jjkbv2onRIcp1pBxv106h8wocnA70t/vtwJWHewusKEm7fh1rPvmXXX3WC+f6dtu+LXNvPtx3OzeOickt6BwTUyj5F7Nrc1WlC4j9+3Zg1g2pGdU1UYAvCnn1QSilJiql+iqldlRK3Wwvu9YWDiilrlRK7aKUGqSUOkApNdvjGE8EhMHWDypKvZfPDz83g9vWX+FRctsLJ8ZbKcWmiI5tgN17tmWPXm35izb3sK69uJ2sxw7pym3alJiHD4jWwUXhN/v24vJDs7NLNzS8OqvbThiYsdQ2WIl1u3Rpya/26um7TZjSDw5/P34gw3u2pUfbZnBTJ/j0n/xz7JCUmefCcsae2/vO1haWtD73s/vgpswhyJlMTKE0pLg9BvfQIDw3b0wCwmBTWQatusMIl5z79J7Qh3A6Yqc7Dmticso/rN0S7gF107y4gOd+O4Le2yXVYP3c7pH3XScP5sRhSROFY4PPB1cf0Z/fHdA784Y2XlnbyXUNA/33OHFYd+7U5g/wo0OLYt64cN/A5MBMSWw6w3q25flzR1jJhBVb4Z1rOGpQl8BRvh83HrNr6HlB/EjrdN++Ciq2ZVQbnZpmbkHg7BaqL09oEOEGZ43GxGTQqCiFgmI49Gb4TEsKT0wXmrl7cpfUCCsgoka0OFxycF92297bVqubmPzCNG85dkBgtm9t4n4FT9m9eyRBU92MHd4jVFJbEPnuVrINFa0L+LZdVYH4a0ZeMxPqy0Pdk7gtIEJqEGHnQKkpjICoCSrLIJ6eDj978XJaL19Ghw7+6q4z6tU75StfmsmqTeH8GtlmWQZNIaoLJ7+y134Ow9rET1beevxA7xU1RLPiAs7Yc3tf/4ihGqgohRXfw3aauaqqMulE9sBrZkIIN093gpjdxYbUIKKY8gAo32pdW5PW0fYLiREQNUFFKRTYuQM994WF1oQkO5XPggf6UXrNmoCdLZyOXil4dsqi0KfORxq+IyDaNivi/tPzZ0JqTFw+uh9NiuLs0qVlWr2rKFTH/BJ+3HvqkFBVRpON0dqydiG06VndTQrPR7dZf/v/MbmsqgLwz+JPFOtzaQqO1hwquS0ezcQUWev+176wei5cvz7afiExAqImqCxNahAnPgmr5lD21IkUVWyyVgeYi5yHsNw2iEbt8LOdajOIZnY5hD8fuXPGonaGcLQsKeQqnwiiMNSEBejIgV0yb6SjP3sbfq5dAbHW1s7WaYMrFZy81rZpESs3lqaVzXB8GpnKjANJH0RIE1PkOmSr50bbPiJGQNQEFWXJkUSzdtBsL9a37EeHNVbFxorSTZkPYZuYokYi+QmUG47ehWtf/S7SsRwuOqgPbZsVMWZQtHj7OkM9tqdnoi4k3iXRKyRaHd/zvx1R7dOwhmKLNb0pm1cll2UY1T9+1u58+MPKtGqvHVuWcPOxuybm2QgkYWIKKSDqmN+ubrWmoVJZZjmpNZTmkyj6+DZaEpwZXVEV7aX6Zf1WwL8Uxhl7Zl9DvmlRAb/df8c6F5KXiTrVd1YzLUusAUjUpLq8klJC1+pqhvdqyz598ldczhdHMGzRBUTwO9WldZNEiRU3p+2xvXWvF0+BDb94bgNEDnMNrUFsXQcLJofbNgeMgKgJXE5qpRStNsxJfC+Zeh9Hxj8PPESYvIcRO7RLfF661hIQXhrEk2cPr9dRKYZ0RuzYjrtPHszVAZnZNY9e6reWu5pt66z/W9cml2UwMYXi0YPhvuH+6yM7qfX7FPDOjz8V/h26OHbWGAFRE2hO6tMf+YK+17xJQUWqxtCMrYGH+JVdYsOPzq1KUuLFHTXeS0AM75m/6o+G2kFEOGZI1+hRMPnEQ4OoNSrsqL9y7T0L2WlnpHRDwMpoJXm3b5usWCBBAmLZt6GOlyuhfBAi8hLwKPCmUtVQWKixoTmpP5lnqbjxym0pmzTFJ9s6gN7bNWfeik10aVXChN/vQ7tmRVw0qg//eG8upbbj28tJ7VYe3r1kP4ridahjyTO1oTu9ffF+GWfKa3ik+yBqjUr7/SrbklyWocJqtZB42cIJiMMHdIKXrM/v/mE/Cgp8uujq0H5CEFas3w+cCswVkVtFxNQ3cFNVCW9cBt+/nrp84f+syImC4IiHPxS+yHNFN8DUR0KfcswgK6pkYLfWtG9ejIgkZjEL0iD0zNAd2zeh98y76VGQOdS2vlObDtx+nVqkTbbU4NFveG2PKxMahC4g8jw3yZSHYck0+1zhOnR98LJj+6b+U8XW0P0MJSCUUu8qpU4DhgILgXdF5FMROUtECvPZwHrDmh9h6sPwwlmpy5+wi4O5EuXGlV3BS5X78HHJyMSyPWKz4Y1LE9/Xby1na7n/g+WVdenMlbylrILFa7Z4ahCOb3nyZSOZcFxT+Ph2eLV+l7uKgnG/1BR1SEA4GoQ+8s53myZeBj9/lX7eIKpCtq+G7mfoMFcRaQecDpwBfA08A+wDnAmMzEfj6hVOdIRf5dZ4qhydXDWYyVWDGdKyNftum+y5y7CbJgWesjCeXlWyyBYaf3huBoBnYpOjQfRs3wzW2yOqGlJZDY2IWtYgdurUgtnLNlrRSlUVUNIKtmkJZfnWIHTCmrP0+1RfBISIvAz0A54CjlJKOXFdz4nItHw1rl6xZXXw+nJvJ/TXi9aBOzKxbDMUNUspr+FFkUeZC/eyLWXpD2bKCNqxyRY2BvNHQw50rYto97sm7P0uXj5/b0sDd7SHktYuAVGDbQo7AEsREAHPa10yMQH3KKX6K6X+qgkHAJRSNTe9UV1GT8C5vlXyLxve/GPmbYACj9BBL6HhJiXE1Qn7K2w8GdFOdvqArln+PoZw1LIG0aQobiW5OeX2S1y/d41qECGvXxckn98Hf98Rln7lsV3dEhD9RaS180VE2tjTgRoc9AQcD+b3HscrXy/1XHdm2R+5ofwMXqjcz1rw89ehTlngYWKKXA2ydKP1P9bwk+rdA7KXz9+LH246zHtjQ/VSmyZMx+y744Gpy2uyTdloEO/fZPUrn9wVvF0eCdub/EYptc75opRaC/wm004iMlpE5ojIPBFJmzJURMaJyEoRmW7//dpePlhEPhOR70TkGxE5OWQ7a48tAVFAuxzLqCeXcvFz0z1Xf1g1iMcqD+Oy8nNhyOmZzVU2jr9B7/j8qqv6okd1NDIK4rFQGpchW+qIk9oREK26pS6vSRNTNj6I5MJqbUoUwg4b4yIiyi6ELiJxgsogJre5DzgYWAJMFZEJSqlZrk2f85gxbgvwK6XUXBHpAnwpIm/rQqpOUVUJq/yn86wqCG++2VrYhqLNq4iHiMl0NAidoqgahGNiWr/E8keoSihqnlRL1i+F4ubp6rnBkAlVuz6IBI6JyW1Gres+iMSy2hMQYXuTt7Ac0qNEZBTwrL0siOHAPKXUAqVUGTAeCJUbrpT6QSk11/78M7AC6BCyrTXPE0fC3Hd8V3+7Onxc5QvfbyVeVc7K1Zm1CCcj+kxtqshYTMLPSlVZkZzAaNFncEtn+Gs3qywywKwJcFd/uGPn2n3Bq4mTd7dmutu3NmoBNUp0DaI2TUx2HaQCVzRITbYp7PsTseZavgkrIP4IfACcZ/+9B1yRYZ+uwGLt+xJ7mZvjbTPSCyLS3b1SRIZjaSvzPdadIyLTRGTaypUrw11JPlj0qfV/z/Nh7Hh+OOjxlNUfdTw99KEWrLFGO+UVmYt7bdeyhIW3HsGeWg0mCOeoBmCrj1lsxrPW//VLrP/lm/3Dd+sRQ3q0YeGtRySmYTXkmRQndS1GkDmCwO1nq0kndVgTW33UIJRSVUqpB5RSJ9h/DypVLeL3NaCnUmogMAl4Ul8pIp2xQmvP8irxoZR6SCk1TCk1rEOHOqBgdBkK/Q7jkNdTk+LKitv57JBOlf2TlJZnN4c0RHBUb/ZxrDshr7p/ImQ1SoMhSR0xMTkdrDtD0vggMhKqJxGRPvYIf5aILHD+Muy2FNA1gm72sgRKqdVKKacI0SNAYnoyEWkJvAFcrZQKLnVai/zn84Up36cuTB+V3/P+vNDHcx6FbR75C2ls2wAzX7AmY9EIrUHYM9ul4WgLiz5LLlv2jVUyxJl4xbM962HZzHDnNuSHTStgVX4nkQlNnSm14bTDJSBWuN2hUQ8boeMO7YPw2K4W711YE9PjwANABXAA8G/g6Qz7TAX6iEgvESkCTgEm6BvYGoLDGOB7e3kR8DLwb6XUCyHbWCu89OqLyS+dB3Liv6xOdY1qDsCXVf5zO3vhaBDbyv3V33+dPpRz9tsBvnwCXvw/mHRtyvrQPog3fayELbta/ol57yaXPXEE3D0A/hEwf/PTx8O/9qlrs9Y0Lu7sD/fWwdSk2vRBJDQIV3f39lXVc9ww5KJBhDlPnt65sAKiiVLqPUCUUj8ppa4HjgjaQSlVAVwAvI3V8T+vlPpORG4QkTH2ZhfaoawzgAuBcfbyk4D9gHFaCOzgKBdWE8xYvI6Osg6Ao0tvgA7JGoa7lz7A5X3f4qSya9P2+/iKAzIee1vAzHGjd+1sTU/pZIVuWpGyPvI81Jd8D9esgEvnQPNO0Ky95XeIypKpdgPqv7+i3hJy5rIaoa5oEM65q70IVz40iCxNTHm6v2HDXEtFJIZVzfUCLFNR80w7KaUmAhNdy67VPl8JXOmx39Nk1lBqneMe+JSxYiWaLVWpPpBK4qwpK6CS1FpIPdo2TamP9OAZu/Hbp75MfE9oEBUhHGiOj8CVN6EX+Dt0l468P3tFetkO3afQbDtr5qsWnaBpO6ssiE9pkEBiBZbjr2xz2gx6hsZIHfFB+JmYcj5sHjQIr+1CaRBVQPWXVA+rQVwENMUa5e+GVbTvzGpvTX1CKc6Vlzkh/hEA62jG0fd+krLJe7NXpO12wQG9UyZBP3SXTrQoTsrphA+iNMNI8PMHktFGm1dZ5qCJV8Bn99OjzPJ5PHTGbjx4xjBaNUkWCjwh/iGsmpfqgI5r44TCJjD7dfjfPf7nfufPMOm6ZAnlxHFsoZCNcDHUDJtWwOf/ys4ksfYn+PLJzNs51BkNwsdJnfuBU7/OehV+nm59nvOma9McophKN8D//pEMga3wmDumtjQIO+HtZKXUZcAm4KwMuzQONi7j8sLn2aCa8EHlICooYMaS9Rl3W7W5NC2ZTX/M9tihHSyG5RtSJxRKoaIU3tIS07eshvdugF+sCq5vFEHPbf9JTLbuVG+9/9QhHP7SqfDQM3CBT41FZ+T/+X3+5//UFh67HANdhmj7FlmmKSMg6i4vnG0FJ+ywP2wXcXrSJ4+CdT/BgBOgyGeeghTqiIDImwbhuqbnf2X9v349PHtK6rrQPggPwb34C+uvfT/oNxpKN2VuSzWRUYOww1n3ycvZ6zN27aU/lp/DWeXhiusBVFaqRJluB6U9FHv33g6ARas8HoLEuV1JdFXlVkSTiza2gIjbTuuBnezOv2xTUoM49sHUnXb/v9TvQwMURXfoa0KDaLzlO+o8W9dZ/7MJW3aeu2w6u1oNc7X/6xrEoLFWddecjltTPgibCnvQ6JW/Ucs+iK9FZALwXyDhvVRKvZSXVtUH7JdljWoZabdf77tDosN20B+zYntO4dWbSvGV3175Cxt/SVvUtbVVWsDRIEQf2Tuf3eUHityupYCXIE1A2NVXjICouyQevSxMTE4UUOjOqA5rELGCaoj8yUcUU9B2yn+b2tIgbEqA1cCBwFH235F5aVEdZ6+/vsepD3+e6KRX0yL0vkN6tKZJUTy13DauYntFlsyetjCg1Ma3L6Yvq0g3STkT2Ds1m6rKtMikyX+1/rvngXBNbBSY+v/E4fDA3nD/XpbN1ZlW9fHDrNyMfx9t+TuWTINnx1qhs4b88Mnd1p/OrFfhtYvho9vh4zvshfazl03n6Dy3oe3p2jmcki41waIv4Knjks+bV5hrrADPDn7rWnj00OB8H4conXJ1aBAO2TqysyCUBqGUMn4Hm5/Xb+Pn9dtgYDgN4o+jd+Jvb80GwoWfFsWtTl1EeT6/fxy9E6zSBESzDrDZLjMiscQD9toFSatgXBwBoWkQs+25s91F+Hrul/q97yEwPSCgbPm31su24MOk9qGq4LWLYMFkeOdqWPYtbFgCG5ZCm+39j2XInnevS1/m2MQd9r1U+5KDBhHaPKWdI9ektCi89GsrqXPDEmjTUwtz1baJF3p3xt++BIs/t0psH3V38HlqKg/Cfb4aNDGFzaR+XEQec//lpUX1hS2rqUKozGDH3GvHZJmNXX0mqFHaiyT2Syg+L3C/Ts1TTUzFLWHfy6zPw8+BUVYU8YDtkprA4B5WG5uKR/RDU1cZkHgBHHGn9bnHCDI69mIFli23shSatE4ud4RF6cbknBNmMujaR3LRIOzuImwNozqTMBnBxBQpZyKKDyJkBx5GkHgm09Wuiel1rLIXb2AV6muJFdHUeNm8ivWqOa2bWRUimxbF+ejy9AQ4vezFdUf19zyU85y++ru9Ey9hTHv4igpiDOzWKrntljXQqkfyAE4nX1kOTe1KpZoj+5ZjB/Dq7/amQ7HHw9fMo7Kpc7zyLZkTryRuRT5VlFnCKnFR9gO7da0VpgfJsNiyzXWo82ig+N5fp+OrAQFRV6Z49QpzjcWDO1V31nXQcUO1IYcwVzeeGkQtZlIrpV7U/p7BynSug/n8NciWVayhBe2bW5E7rZoU0qNdepVQXUAUF3gnsoza2Ypc2rlzy8RDrGsQZ+y5feI8zrlpt6P1uWP/ZCdf1CzZuWsCoqQwzqDurZPzT+sUe5jImne0/rfsmjnSo7LUck5Xlqa+gLNesf6vmEWio7h3N5j/PtzSBV7+bfBxGxvzP7CmqF1pzyvy/evW93WLrO8zxlvfN4WsWvz+jd7LExpENo20961pDeL6VjDh9zkcwEODkBieNyHRQftoEK/8LjmVcJRRu37Pln9nHWPh/9K3ezioyoJjYqp7Tmo3fYDtqrMhdY1Fq7ewfqs1ev7u5/VUVinmrdiYWL91/UpWqxb07WiZUn5ZbzmJT9wtddaqoniM6dcezJfXHOR7rjtPGszHVxxgCZOEicniw8tHcuVhOyW2VVXKMjF1HgSnvQhH3w87HQlH/QP2vigZSeT1EjuTA+l4qdLdh8OYe+Gwv1nTNJ78jG/bAeucFaXh1GOnA1zik4fRWHECD5wCiU4SpDP97NRHrP9rfwx3vIRT2k0OZr6EBhE2ZFXrgDvumv15Ab76d/R9HAHlmSgnwaYaPw0ixR/nIwB1wdhpgKVl6+/jgg+t/99PICvqWpiriGwk9W4sw5ojosGy320f0LV1E+46eTAnPfgZV4zux9/fmpNYv2jxItaoznRpZYWJHjHAqjvYrnlqiYmighitm3pPvtfT1jhKCuNpcxTEsH7w7dtZCUnOox2r2GyZfZq2gz6a0NltnPU/EYro8fBmmDc7efI4DD0j+X3nDAFrBUV2/SWxXohe+/tHrYRtQ2Mj8bu55i5wHMJOpxzG9BF4nho0MenPoDtaLq+4haCPBhHkg4iFKFvhpyHpArTf4ZaWrkfwBb2jYc5Xg2GuYaOYwsdyNiCWrtvK+3a5jNm/bKSIcgbLPGKi2E7W8WVVX4oKYnxz/SE0sUNKK11hoX6VVWfdcGhaPgTg2wGIQAfW0WHJJGuBl+8ANBOzxwPjN/9DrsSLLQ1i7Y/Wy+B2fOss/sL6v2a+FUIb87jess1WW4uaWy9D8watrFroOQaLp1r3AGDjMnt5NQmIRJhriA5l2UzLp6UqrWi3XHwQfuerKLUmpnJMpvnAK8xVbA1i00prebN2rnaG0LT8OnjH5+YcJ16Yat51hwtv+NkSoHqQhxcbl8Ev33hbAmpZgzgWeF8ptd7+3hoYqZR6JS+tqkP860NrIrtmxXFOjb/H9YVJVXeJ6kDnojgtS5IRQwf0246HP06aAZoVe9/ipkU+t95+eGKuEd6YwV35w/z/Y5epdnx26x7uPZ0D2P99Yry1UFj6BRbkTaXvYfDDm97rCoqtzsTRDtzZ2Do/fpT8/Pn9sJd7OnKssuH6XBTXZy5hUu9xOq81P8IbWjjqO1db9yjKyDbwPCFNTOVbrdLtbXeANQugfd/kvmErxoapxfTqBTDzebjSnvs8H3hFJjk+iNt7W9+dZyxS3SYfAfHUMdp5BGKFrnvmekfv3NkSxFekTZqZyjtXR29LjoTNpL5OKfVyoilKrROR64BX8tKqOsjGbRX0lKTj95Kyc5lQtRf/dJmU9urdnh//enjiuzspLjPpTmqAMYO6wMta8s72e/vsHqC+VpRCi85wzoewbZ3lhA7LCY9ZeQwSs0b2d/RNrosXpZqO4sXp+3th145KQxcOjQXnOfEaHUIyYTFnDcImk3nDybRfY88LtuqH5KAkGx+En4Bw5hypKM2fgPCsxZTJB5GDBpHyXNsaRIqJyUOLc5teD70l2nwVtVxqw+upDLtvvaOiMv1mr9pUSjOS2crTVD8qKGBYz7Zp20YXCvrO6WGu3tv5nCMo29WJOGrewfqLQlFTaG9PfuSOhnKX9nbP/euHu8xHY8bp+P0KHWZynoZBKUKHuXolw4mtvWTjg/DtwPIZChvgpPa7j5Huc4i2i9hl8LX7GaZkSfu+/us8m1K7UUzTROROEdnR/rsT+DLjXvWUMk1AnB6fxGUFz7HPogcYHpudWL5GtaBFcQEdWlTzvAceYa4ALA+ZiZp4sF37V1XBzP/m1jYHdzmOuMsJH9YM4iUgZnpMIOjVaW5dC988H+48DnPfhdUZ1PjawvndvEo5Q9IH4XQESsHXzyQnjQrDxMthyZTU46SdR1mVgSff4tHGiGGuqQdOfvzpM8uWrjP3bcu85jB7Iqxb7H2o0k3WtWfSglbPt8KqPZ3UPgOsIAGhT+27bnH4TjlemBS4375k5TFBcPubtAl3bIda1iB+D/wZeA7rbk8CfpeXFtUByiusH64D67ip8HEqlSQm8gGYW9WVTTSh2EPTyBn7wdy5U3OOGZwMb+WBEWEPYP1zPzDf2XUVw4ZJBqFrCHucm95JhdYgXJEt65daU6i62bY+XZi8cj7MmWiF+2oz+QXyzPHW/7ro00gICB8NwjHrOP9/mQGvng/z34PjHw13jqkPpx/PzZyJ/iGyuUQx6Z8fH239v359cvkr51kaynV25zl+rFVG5nKP+dzf+iN8/bRVtqVnQKHpZ06w/p9uP/vuMFfvRturPQTEw6OSnx/aH871yGNIQ/NBbF0LL2hVi4I69aiVZmu5FtNm4E8ZN3QhIqOBf2BNdfSIUupW1/pxwG1YM9QB3KuUesRedyZwjb38JqVUhJlKcqO00np52okVjfC78ot4q2p4Yv2IHdrBgtVURJ3aMxTWg3vniQOhSxaRHX6lFDyqvWaNSGon+7bLeeYWEHtfDAf/BT78O3xws1UT6PMH0p2dHgUHAW9zx/ol1v8GUznW/t3Kfe5BQnOwO/Yyu5DBusXZle7265w8ysYnm5hDHkSYEa5yCcHNPkmBTjRe6Ubv9X7tSIli8jMxefkrbDZqGsSW1aRen09fICQ1iLRt6r4GEbYW0yQ7csn53kZE3s6wTxy4DzgM6A+MFRGvWhPPKaUG23+OcGgLXAfsAQwHrhORiHcse8oqrJvd1hYQa+wo31E7WeGWTu2kyHM/hyGXOHXwNzHlcxKfpi4/jFtAON+dzrywqaURuNvkG1fuZQ+PWFm0ruNcj58GkTAx2ffI6chFspuHOmx10RRyyKSO4oPwM7MlmuH4QqLOS6GbmDJsG6rUhnZNQaVNdBNTyv4Bx47qsK9lH0R7pdS6RFuUWkvmTOrhwDyl1AKlVBkwHjg65PkOBSYppdbY55oEjA65b86UVVSxHWt5tPB2ANbYJb3H7d0TSM6vkBci19xPO4D3/nqp7+qmqSsnw+2DcCd9FTWHgiaWHbmy3AqnvL4VzH3H+/jfPG+VnJjw++Qx9GitdYut/V84O7g8uUP5VstEpduU570HH9/pvf38D6yS2WDZz9+/OfM5HNYttkI53R3E/+6BH96BFbOtqWIlQIN4+dxkiY0fP7LO70S9LP7CKssRlVfOt6YfdfjwNjvDN6DXylTN9cPbXNpkCAHh1bFWlqUvS2mH84xHFBBBTurXLoKFn6RGMS37Ft660r/zDyMA9TBX9zbu769qVnu3Xy8TeZqQKayAqBKRROC9iPQk8xC3K6B7mZbYy9wcLyLfiMgLItI9yr4ico6ITBORaStXhqxRE4KyyiqGxObRRMr4vqo7Yw7Yh98f2Js9d2jHqXv04K/HDeD8kTvy4nl7Vds5k3jUyony4/uZmPKpQfTaD3YcBR12gpP+nXRiF7WwZu4acb71fZ9LYNCpMOR0K/GqYqsV0rpsprX+7Su9jz/5r/D6JVa5hR/tMgXOfaoshzcusT5/+yJsWu59DP1+/PAWTH/Gmlvb4enj4L2/eO/71DHJ2kaPj4aP/u53J9KZcAF8/ZTV+ehM+jP850Qr52PKg7DBNgF6mdlmPJvULN77i3V+3bzy2oX+52/V3Xv5xl/gXe16P7gJ/j0m+Foydcwf3JSaQa+P3KMMeDIJiFhEDcIvzFXnyyfgiSNSndRPH2fl6vg9U6FMaFqYa1p7Xe/o11oZj6iD0Kw0wsyEdVJfDXwiIh9i3dl9gXOq4fyvAc8qpUpF5LfAk1iTEoVCKfUQ8BDAsGHDqs3e87c3Z9MKS809r/xibu/bORHOesuxAwC4YvROvvvnhJcG4UwTGWl/1+0Iba/Ngra94AxtcsGfPrX+l7SCY/+VXN6sHRz7gPV56BnWvNr6KD6IRARNZer3im2pL96WVdCyc/r+ulkk4fDNYQKjyvL0aC4vHHOJOxQ40Zby1PV+fhg3elZ80D4tOsN6n2ggr8FEGGdnaIeovV1Q5VS/fJ2g9Y6JKWjU7nWOFPkQIsw1U1hviokpQAA6Ya6ZNAiHER7Jo5moyCBUsyRsNde3sKq3zgGeBS4FMg1JlwL68KUbSWe0c9zVSinnaXgE2C3svvlCKcUHc1bSxJ47Yexe/Rjao8bcH9pDrL0YkeoX+fgwarIGkmNSChoFOWYpp1ppJtwvayLqx9U5+pUT0c0imWzcYQjrHHfa55c86FyPMyoOKyCcEhyZCBJiCZNRyM4lUQso4oxykqG0thu9PV4Cwnm+ctEgfJ9NzRwVd5lG0zYNaWJKOKld7fXdJ4tcl8pqeKY9CFtq49fARVgd9XRgT+Azgkf7U4E+ItILq3M/BTjVddzOSiknvGYM8L39+W3gFs0xfQjgY3+oXtZuKef42Ef8tdAKHfztQbuCTz2lvOClAUzPUE01aP+qSrh3WDIjtiZwOrtAAWE7tj8Iac93jjn+VMt/4Zhc3B2qU+Zg1xOskM3yLVbW+U9aSOKr5/ufxynl/OdV1ov9+QPJdQ9o2evlW+GZk6BVV0Dg2xfgmAdgcMojnhzZ6R213uE4AsL5vbxKsnsx4z/htgvKSakst6730L+GO5Y78Szs9np5F505b0GZS7NduxD+OVQ7hMd+zjWpSqsq8COj4MLplibr2YwIiXIJjVZSKyN/94rXgZMfH/dzkTrHUemCuHRj8nlL2SULAVEdgx4PwpqYLgJ2Bz5XSh0gIjsBHpk0SZRSFSJyAVZnHwceU0p9JyI3ANOUUhOAC0VkDFABrAHG2fuuEZEbsYQMwA1KqTURry0r1mwuZXR8SnJBYbOaOK2Gh5PZcVCOvBLa9bZs/Rl2T+y/ZU1SODTrAGf51FOqThJRTAECwq/YoO8xtY5Oj/TxezG+1RLufvKJVw96Ecs2WaGGb2nR3cu/1dZvtqam1K03716fLiCckZ3+e+r+IHd+Q3WOBAtKgnNSnDlD/Hw/voQUEEo3MXms90rGm/NW5nPpUUzfPGd9/uEt2PM8v4bY++m/t8+z6TwrErOcy2B17J94BDDoglIvr6EPSESSz65bE/EbtGVTbyusFhiRsAJim1Jqm4ggIsVKqdkikjE7SSk1EZjoWnat9vlKfDQDpdRjwGMh21dtbNxWwTa0CIIwdubqxCvMdYs9/8PIMKkorv1109KAE5PlMvJJFBNTWMTnpcnF+R70UmXKLfA6r5d5yBFgunlBN08556nOF3znMdZcA8UtgwVE1I4oqomJDCamLR51p9wahacGoZVGdxLKgvx0XhVa/QYHlZoJUzcxFZR4HNcvLFs3JUny2XX/xn6+Db9nPYg8aRBhdZkldh7EK8AkEXkV+Clwj3pCZZVi+YZtiZyGDdsqKNPlZk3Po+zlpN6yOnyH6jYx6Tb5qNmZ2RImkzqoJLgXfk720g2w4nvvdZlw/B9O0p1OJl+Al+O3dFOyjIJ7u9Xzrb+qKsuM4uB0EtWpOTjPTkkGAeHZSYZxUmcQEFWVltab0CB8TExeyZvu31nvRCvLrefZeaY3rUiWyN62zr89es6Ig997rfu4EhpEuU+Qgc+90gWBU4vJvVw/l5usfBC166Q+Vim1Til1PVbJjUeBY/LSohpm3ZYy9rjlPf7w3HTKKqo487EplGDf7LAlI6oVj8iSLavTk9F8d3eZqHQNokXH3JsXhjAmpkJ7RNZt93DHnDfJe/mka5MZrm0jZp4v+wamPQ537ZK+zi+j2WGCR2ipqoS/+9jBX/qNZVt/aH947NDUfSC7bGg/iuwkq76jo2kJsUzackgN4r0brDLazrPnp0F4Jfi583W+1vxvr10Et+1o+ZbA9l/Zz1hQBnjC5xRCg0gICM0HUVnqHWQQNrHTz8Tk52QP+5vp11DLGkQCpdSHSqkJdvJbvadZcQHNiuJMnPkLM5da5SOaUEZVUQv43ZQMe+cBLw2ibEvypc98APu/Y2Ky7cwnPAaDT6uOFmYmbE39i2fCGa/ApT9E1yjc9NgLTn4683ZuZvskmWXSIMK8xF4dwLJv0pdB9iPAoWemL2vVDX43FQ6+IVrClbvTPMyV7+GewtMPpwN3fGdBYa6Z2rBV08icaVl1EgIlhOYjApcvgMvm4Tt40Wfuc8zLFaXeAsXvmvTS3oEmJh8BEdZqoQv0PEUxVVNx+fpLSWGc8w/oTUWV4vgHrPj9JpRRtd0u+Z3lyg8vH0T51vBTNroFzGZbQOw8pub8KWFLJrfuYZUUaNHRmvs6F/oe4p3/0LxT8H5+o+ZMI7KgDs/pQKP4R7LVIPzKQnfoa3XMQVqBu6MXSV3WfQ+f/TJ09okwVCfrPYKAcGvt+n3x0ugTvp0wnapYuTjNO2Q2MYE28i+LZo5LMzH5CAjfMNeQGoT+PtdmHkRD5yy7hAZAKzYxIj6LgpJ8TV6SCZeJSSko32zNxxBqd9f+W1ZBcasadrYHFDzzI+e5IcS6TjetfTKJHRZ96r187tvBJSyCkuxmvWKFX77+h+Bzp7Qjy0mS/BLwHOIBZtK0Dsr1e6U5Zu3fde2PVvmRaY97+4bcI2Zdg8ikfbg1s5QO2+NaZr2a+n3VvFQfT0q7IvggFn+R1L7KNnvPpujn+3LPHudckzubfvMKPMnGxFSbPoiGTtOiAkb2sybQOS7+sbXQd0rPPOPWACrLrM9hO1B3sb7Nq5Lz7dYULeyRvG/YoQcDT05+7jTQ+r/LsdHO6zW/dabf0W8+hY9ug+cCTHJBAuK/46zY/JkR5qvINqvby4TU77Dk50A/mocGoS/zG5R8cpeVb/L6xd5zciTqStkalJ4HkVGTcHXcmQTEilmp5/yvh8ktcegQ1Vydzn3Wq0nta/Kt3tvqpbt13LPHOe3+5C7/tvm1MyxGQOSXf52+G11aldBB7A7jCJ/CbfnGbWLSK6CGO4C9u+OkjhABVV2UtLTKgQfNTe1Gr+t/7sfW/ic+Yf3/9fvp21/jM/q6fj2c8qz1uV1vaJappmSWVFdxtC5DM29zgivaWzebORpE6+2ta79+PXQbllwfJCDcnbW7Y3L7hbxG/07ZcR1nBOz4B5z5nyGzIHS3KZOJKYH93Ou5Kn7bpH32Ob/zLvrWYvLB7aSOGrbq3v7C6cnPfnOZ5Gk+CCMgbEoK41x2aD/asoGKph1rPrzVwR2mWhZRQKSZmFZHT0qra3j5FoJMK871xgrzpz3lUsdJJ5MJDIKTNR0Noril9/pAH4SHiUnvaIpCJIl63QfnGXYERCyemtkfhN4m91SdgWVDMjc1VCa11/ahA0Rs3KP5qNGQ7rb5zn4XplhgbhgBoXHc0G6c2L8pBS0iztdcrbg6eEdNj+qkdti8KnyIbF0laoSTY44TyZ/2VF0ConmI0OMg86IjKEs8/C8QbM+e/0H6svdvch1f90N4jFK3rrVKfOtO0sT82vbgRndSz37Dvz2QrOzr7LdUm9k46Fq+fhqWZJoFOUwtJn1z+zqizs2gm5iU8jZ9BpF2nSHaWstTjjYa4ltX5x5ymQvuPAbHRl7cIuwB0vevqQS5XDnyLu95iAuKrRLh/Y+FhR9B2x2s5XtdCJ/eY30ecnpy+w47wU5Hwv5XwFotn/PIu+GNS63Il8GnRatxpdOiS+rsYmHpuS8s/Dh1WSYTWJ9D0iOV4oVwyE2WkOo0ALoNh318HOJBI3Z38biyjemZzLq5wys35NN/Wv+321k7rmtwozupX/q1f3sgeX+OfdAq8a6XsMg0En8kQyRcZA3C3iby3AzuPIhcNYiY9XunRcXlX4MwAsLNZrusRW3h9kE4eQxhzUS6iamqyqpbFMZUUBcYdrb/uqPvs/73OSi57JAbrT838UI4xe78HTPHdrvAsLOsJK6ta2DACdkLiGFnhS8y2Hkw/DLd+nzM/ZawvlUzKzX30FZbdoMNdnb3af9Nd6SXtIK9fp/8/mufJEJI7/CjMvBEa64ESM1JSEPrfB3tKpF0FrGaa9P2MOgUmHh56vKMiXxRCBkWC9FDkN0mpsg+CA8Tk/57OxgTUy2wZVUt2+w9wlQhu0xqJ9kr5xDSeoxjYnLMHY4pJuqoUCfKiFA3F8SL030nXiYmt63dncXrZ07yItd5QFKydQOSB/U2JwoPOmGuPqU2/HDumd/MhNkSJorJa/ucIoRU9HaHNjEZDaJm2LImtURCTUf96LjDXB0NInSbNA0kqv+iIeJ0piW2E7dNTyuOP5cXKsoLr48evRLXvByg7mVuYdaqW/jzexWZi0LY0a/eqSXqS2mJcpVl3qWtg87pPndQTkeo42bpg8hFQCgVvShiaCe1PmFR7c4o17CZr4VR7v4bS62uLdwmJmcEGNYHoUdBldvmlcYsIFp0hCPugD52/aPjH4Vvxlu2+7CM+ac1H7ZDJAGhvexuzXTEBanrdzvL8jesmgPLZ0Jv25wWi1kmtmXfWtuHquprM/pWq9Lp3LfD76MTtnNLuSeukNZsO8jq1iDChLmmbG5vE3YSJ09U9LwG9yDCvf/Z71jFCZ87QzuN0SBqhiNur93zuzWI8i1WBx827FY3MSU0iEZsYgLYXXOMNmsHI35nVV4Ny6Cx2QuIxORJHp3EwJNSHY/Nt7Pm7554hfW998HJdboTPgpN21rHzFZAhO3cvPwDCQ0iagfpCAjXfc419ySqk9oRIrkWwosq2Arc5k/Xu9/DKYEScarYLDA+iKpKWP5dbbdCw+WDKNsSsYPXNBAniakxaxB+RHlpdft6rCBihVTHnu5xPom77OLx1PPlKTs2EmE7d73zTTy79vOXrZPWvV/OFW8jmpgcchEQ2ZiY3D6nUCameuikFpHRIjJHROaJiK9eLCLHi4gSkWH290IReVJEZorI9yKSv+lGt65NzhaVTYp7dZOmQWyNNqudbmKaMd767NTMNyTJJCD8OrVYYbSXcbtd/M8nsdTzOL+dEzLaqmv48wThNbrMpuMP4tlT9BNa/5z6UpFNTPb2G1zT0OcqMKP6IBKmshwFU3VrEA71OYpJROLAfcBhQH9grIj099iuBdaUpl9oi08EipVSA4DdgN+KSM+8NLSouRVzfdQ/4JLZeTlFJLxKbUTRINx5FOBflbMxo3da7hyCC76ES1yF2P7vXet/vMiapCgMZ70J+1xsn8+jk4jFU5OonN9u8GnWvrscF+48mfDqPNwCoo3PPBbZDJrcSYRRj5EY5LhMSpVlVthw1kT0QWRj0kr7nVV0DSqsBlEDUUz5HDIPB+YppRbYc0eMB4722O5G4G+A7glSQDMRKQCaAGVAyLcyIoUlVsz1buNqbkKdQNyZ1FEFhFasr6LUCqPMZo7bho7+0rVylbto3zv9WXAihwqK0vMS/Bze2++V7DDCmJgS/gqx9q22ci8B8zo79NjTe9fqEBBRnz+/7SvLoeOu0dvjEDXMNRvNocD1rmZjYkqEQtu/v19b67mJqSupU7ovsZclEJGhQHellDv//gVgM/ALsAi4XSkVlKXTcHDXYiqPmuimaRCVZd4zYRlchHDwOZ1evCh9/uMgH48zCvUUEIKniam68bo897n8nrFs5kd2j7xzLVbnsGV1bmXro5qYstEg0mqEZeODsE1MUQYI9VBABCIiMeBO4FKP1cOBSqAL0Au4VER28DjGOSIyTUSmrVy5Mq/trTG8wlyjOJn1TOqKUg97piGFXU+ArsO817XqAUV2eLGTT7HbOOg9yvrca3/rf1DhQKeOz27j0tfF4qmdR958YJqEaNHZ6oAyCYjt98m+TW5nclRNyO+cFVtznNckYhRTNvW2vPIRomaAO9eYcNY3zFpMSwFdd+9mL3NoAewKTBbrBnQCJojIGOBU4C2lVDmwQkT+BwwDFugnUEo9BDwEMGzYsPzEedU0aXNKr7FqC4Xe3zWJiNEg/PnzKmu0GotZ5cNjBakv2oVfJz+XtIRrVlovrwhcvdzqaKsq4D9a3sz/vQuPauVAipol93MjMe8opupGd2Ze9I11Tvfc2bFCyzxSYYfdnjnBXp6hTae9AM+ckLosTMfaaUBqYb6UtgR03u6kwe57wuLPM58PXB1tiE7XK2pq91/D1Ef893ELA6Wih5knnglx/Q+gHmoQU4E+ItJLRIqAU4AJzkql1HqlVHulVE+lVE/gc2CMUmoallnpQAARaQbsCdQBD3JN4FFqI1LpD73UhtEgAokXJjujgmKrM9Q78nhBavZuQVGykykssfZ1318vbULfT0fiNWNi0jWIeKF1Te72SCw1GTMof0OnuUexwTACoigg8TPonG5BG8l8Uw0aRKYSLV6/f9Qwc9F8URCurfVNQCilKoALgLeB74HnlVLficgNtpYQxH1AcxH5DkvQPK6U+iZfba1T6BrE6vmWkzpKdVndxFRZmlvNIUN0omZZR07eygKvSXC8KoZ6nT+TecNrnzACIqhj37o2YL8a9EH8+GH0c6RpitWgQYT5DepjopxSaqJSqq9Sakel1M32smuVUhM8th1paw8opTYppU5USu2ilOqvlLotn+2sU+hRSAsmWx/9Jqb33F/XIMqMgKgJDrja+t+sQ7j5HRxi8dTOI1+TVHlFKAUJCD2UNJPQylZAtO+T+r1p++TI2ZlTep9L0vdbPdfdgMzn8trWS5CHmWZ42NnWgM1vIHCwq7qwUuE1iDa9rD9nEqk0U5MPsYLqm+HQfei8HNWQA5oG4JRh6LVf9P1Rlg8i06T2htzpPtyaCvLyedHut8RStcN8aRBN2qQvSwtF1QTE6L96t6nf4enHyUZAxItTneItu8IV860pYnUOui5dSKTlWEQQEPq2Xj6hw/6e+Rjt+8AVC1JDoy/ThFaPEa77rcIXGexzCFw0PfkMRSlzUt9MTIYs0TOps6nGqofJGid1zRPFJi6xVIGSp5fcE3f5CN3c5Zcv4CX8vBzrXlOZpnwV1whcAo7v2jdKDa2gY3m9F1EEtN7+mMtPlW1RQb8qrpmei3iBERCNBj3MtXyzZSKKUuY4xcRknNQ1TrZzRUANCwhXhdIUAaG1Sy8X7lU6PEyn6r4naSVGApyxactctvZIZjltW6/3IlsBES/U5hkpTp0fPIprwP08hM1/MhpEI8KtQUSuxKoJmIpt6ZmdhvwSL4R9L4VjHsi8rfNbN2lr/c+THRmA334Eo/+mn9zVlnhyWUoJ8nHJ+Snc/qwTnwzXQQ89I/W7xHw0Lc+MvtSvzsyCfuuDyKRBgFUOPiqxQqsE90F/sQTP6S+kb+Nnvtrzd7D93nb7XN3xuIkw6rrkXCa+5zcaRCNC90FsySJETjMxRS3TYageRl0Lg0/NvJ0zina2zSYxKyydB8Ge5ya/J0anmlBwOtCYy6x04DX2Z02D6DwIdjnGf9TdZYjHuRwEvOoiZSoqePHM9MmSstYgNAHRoov1f9t6ayraULhCh7fbKVl3q+0OsN/lqdsNPdP7MLscm5z3w30v2/eGfT0c9W7iRoNoPOgmorJsBIRr/yJT6rvOIa4cA3cF35rAea6czluPYnL7FRxzlN6pVlUl9/NC11zdmocI3tqCl4DQOnXPqsbZahBamxynclB4rRtdmHlqQy6h5+ebkljyd882SMFoEI0I/SHJxsSkV8Ks2GrmgqiLdB5k/XfPvZynaSM96WQXvXOS42LxdIHl4Di0Uxzqld7bOmzWSt+4I4aUSu1gXdVlUtCP7/UutE2rwOOPn8PdmYAnUs2zsM4Fezu30HUitgqKk/ciJwGRnzwIM6NcnUNPdMsmj8He38wmV3c5/UVY/q1Wc8fuPKpqUIM46h/w40cweyLMeSNVg3CPdr0ERFUGAbH2x+Rnr2c4ZcTrkhAnPuGxjnQn+anPW/WwRvwOFk+BV2wT2k5HWmaxbeutch4TL0s/lt6mw++AHQ+EfkdY3zOV04DMHbLb9KWb7c542RJsP30K2/WH2Xat0mwFhDExNSJ0E1FVefTiZM7+ZVus/1EmGzLUDE3bpua21IYG0bqHNY2p03GJ2y+gkRAQWgedSYPQcwHSBITy7tCcTrftjsllekfrrtHU91Cr5Em7Ha2S/Q4d+lmTLvXYE4b/xvtYeptiMdj5qOTxQ2klOYzYdzwQ2vS0fE+xWOZ7mYlY3AiIRoMe5lpZHl2DcB6yxHSjRoOo8yQ0iBoUEGlt0JzU7tFxwgehCYhMGoQ7DDSNgA428sxv7n38ujUfJ7WbML6IsB1yGNOP8UEYwqPP51CeRdKNvX/pRuu/cVLXffxmUKuZk9v/9MmLXJ1ajxHWf70ER6ZRr94xugc5ux6Xun7no6z/O9mZ2nq5kq67BTXeG3ebhpxu/ddNZ857tevx6fs7PqIgMnb8Po6VPoekb9ptd/u/T9n5TEj+NAjjg6hr6GGquZiYtqy2/kcp9GeoHRzTRm1oEClJaj6ZuwNPhB32T63cmimKiQABccRd8N5frM97/d7KHwAYeRXscW5q9eIdRlrhrcUZcgF03G068h9w0A2p75IIXPFjagVbh52PsuqfrfrB+n7Fj+nl0Z3r+80HPm3w0Mau+DGZU6LT91CrXIdXZdww6JFQ1YzRIOoaug+isiJ69UpnfyeKxAiIuo9jYqrJMNe0NsRSBydu3J1XQoPwMQHp1+Ie5MQLSHSwzTpo0Vwx79L2rXtAk9ZBrU/FLSDiBdDM4z1o2tZ/AKZrMU3bpq937pFXh281wvt8fpUNshUOYAsIU6yvcaCr+ZVl0cpsJA+iCYgoc0kYaoXayINwE4unDk4ykckHkZIn4NEJJ9bnoYJtvqrippAhv8G9XT6JxetnuW9DNmiqaVV5dvXvJZZ0tEUZeRlqh53s8MoBJwZvlw/0ObP3v8L6HCaKJ5MP4qDrk5+DAi2yccwO/VWwn2DnTNPNRKDYrrHU/2jouW9yeUK++bS/JoTUgddY0WLGxNSI0EeTlRXZzeegPzBeBdYMdYt2O1rlwrsMrvlzV5ZZ/wubWLb369cH1/5xbO5BGoTEU+sveZlxEpE7WXSkY/5p1Zbyo0O/6Mf045Snrf8n/RvGvZ6+3rf9AeVDqov9Loc/LrTaYAREI0EPc60qz87E5Ki98eIaUrcN9RYnxyFsOLQT/eN0SF4mFr+y1Tr5NDHVCBnaL+7t8kh91SBEZLSIzBGReSLyp4DtjhcRJSLDtGUDReQzEflORGaKSCMZCutO6rLsTUxgJgsyZMYrCS4IRxsI1CAidCt5m4c7RxwB5qcBhC2PkU8NwiGPAiJvYa4iEseaW/pgYAkwVUQmKKVmubZrAVwEfKEtKwCeBs5QSs0QkXZAeb7aWqdImJiwTUxGQBjyiFchviASGkQIAXHQX6DzwNR1h95i/d//CijdkF4KPBcOuTna9Ly5kNFEVoOaUacBULY5L4fOZx7EcGCeUmoBgIiMB44GZrm2uxH4G3C5tuwQ4Bul1AwApdTqPLazbuEutZHN7FQJAdFIlC5D9kTVIJznMYwG4ZS/1hnxO+t/07ZwzP2hmxmKvS6ovmMl8kP8OvqwJrIa0CAOviFvh86nftcVWKx9X2IvSyAiQ4HuSqk3XPv2BZSIvC0iX4nIFV4nEJFzRGSaiExbuXKl1yb1j5Qw1ywS5fRjGA3CkAlHgwg7Na3zPIbRIBoyCROTnw+ivvpWUqm1X1JEYsCdwKUeqwuAfYDT7P/Hisgo90ZKqYeUUsOUUsM6dOiQ1/bWGM6DtWxm7hqEmY/akImW9mQ5xX4JXy7cTmqvjrAhCIgWna3/fsUuW3e3/vtGGdZAFFMNkE8T01Kgu/a9m73MoQWwKzBZrIesEzBBRMZgaRsfKaVWAYjIRGAo8F4e21u3+OUb678eex0Wo0EYwnLSv2Hhx9CiU7jtvYImTvmPNYPcpGth5n+9hcaZr1tZ0/WFI++E3qOgm08tqLHjrfvmlfkNqdGI9Zh8ivqpQB8R6SUiRcApwARnpVJqvVKqvVKqp1KqJ/A5MEYpNQ14GxggIk1th/X+pPsuGi4SS2ZCZxMb74QeGh+EIRPN2lvTXobFK6x1pyMsTWTwaf7b9NrXmpazvlDcIrWEuJuw962eaxB5ExBKqQrgAqzO/nvgeaXUdyJyg60lBO27Fsv8NBWYDnzl4adowIg1G1ysMFqRssTuRoMw5Ikgn5jfjHSNkobhg8hrNVel1ERgomvZtT7bjnR9fxor1LXx4RTfato2O2eXiWIy5IugvBwjGDwwGoShunGEQrYagFMd1K9ypMGQLUFBE042dmXjSFkKxEQxGfJGYm7gLEJcQRMwRoMwVDPuaT91EgKirGbaUqdpGFFMRkDUSeyHK5scCDA+CEPtUGjPXugk3zVmjAZhyBvOw5W1BmF8EIY8s+f56cscAVErU6fWMXY4wPq/05G1244cMVOO1kUSiW5ZCohENVfjgzDkgevXey8PWxG2MdBpV//7VI8wGkSdJEcTE8YHYagFHA3C0GAwAqIukquT2kwWZKgNspoe11CXMb9oXcTxb2X7wlXZYYbGSW2oaQafVu/t7oYkRkDUSXJ0UldWWP+NgDDUNNVdwttQqxgTU10k4aTO0snsxKEbAWEwGHLACIi6iBPmmrOJyfggDAZD9hgBURfJ1UldaXwQBoMhd4yAqJPkGObqCAgzYZDBYMgBIyDqIgkNIksTk/FBGAyGasAIiLrIpmXWfyefITJ2gTDjgzAYDDlgBERdps8hue1vBITBYMgBIyDqMq175La/mQ/CYDDkQF4FhIiMFpE5IjJPRP4UsN3xIqJEZJhreQ8R2SQil+WznXWWXGvbGA3CYDDkQN4EhIjEgfuAw4D+wFgR6e+xXQvgIuALj8PcCbyZrzbWeXKtjmkEhMFgyIF8ahDDgXlKqQVKqTJgPHC0x3Y3An8DtukLReQY4Efguzy2sW5T1Cy3/Zu2q552GAyGRkk+BURXYLH2fYm9LIGIDAW6K6XecC1vDvwR+EvQCUTkHBGZJiLTVq5cWT2trkvkqkEUmfLLBoMhe2rNSS0iMSwT0qUeq68H7lJKbQo6hlLqIaXUMKXUsA4dOuShlbVMgZmAxWAw1B75rOa6FOiufe9mL3NoAewKTBar9lAnYIKIjAH2AE4Qkb8DrYEqEdmmlLo3j+2tewRNEB/EyKtg1Q/V2xaDwdDoyKeAmAr0EZFeWILhFOBUZ6VSaj3Q3vkuIpOBy5RS04B9teXXA5sanXDIhZF/rO0WGAyGBkDeTExKqQrgAuBt4HvgeaXUdyJyg60lGAwGg6EOk9cJg5RSE4GJrmXX+mw70mf59dXeMIPBYDBkxMwoVxc57mFo1j7zdgaDwZBHjICoiww8qbZbYDAYDKYWk8FgMBi8MQLCYDAYDJ4YAWEwGAwGT4yAMBgMBoMnRkAYDAaDwRMjIAwGg8HgiREQBoPBYPDECAiDwWAweCJKqdpuQ7UgIiuBn3I4RHtgVTU1p75grrnh09iuF8w1R2V7pZTnfAkNRkDkiohMU0oNy7xlw8Fcc8OnsV0vmGuuToyJyWAwGAyeGAFhMBgMBk+MgEjyUG03oBYw19zwaWzXC+aaqw3jgzAYDAaDJ0aDMBgMBoMnRkAYDAaDwZNGLyBEZLSIzBGReSLyp9puT3UhIt1F5AMRmSUi34nIRfbytiIySUTm2v/b2MtFRO6x78M3IjK0dq8ge0QkLiJfi8jr9vdeIvKFfW3PiUiRvbzY/j7PXt+zVhueJSLSWkReEJHZIvK9iIxo6L+ziPzBfq6/FZFnRaSkof3OIvKYiKwQkW+1ZZF/VxE5095+roicGaUNjVpAiEgcuA84DOgPjBWR/rXbqmqjArhUKdUf2BP4nX1tfwLeU0r1Ad6zv4N1D/rYf+cAD9R8k6uNi4Dvte9/A+5SSvUG1gL/Zy//P2Ctvfwue7v6yD+At5RSOwGDsK69wf7OItIVuBAYppTaFYgDp9DwfucngNGuZZF+VxFpC1wH7AEMB65zhEoolFKN9g8YAbytfb8SuLK225Wna30VOBiYA3S2l3UG5tifHwTGatsntqtPf0A3+8U5EHgdEKwM0wL3bw68DYywPxfY20ltX0PE620F/Ohud0P+nYGuwGKgrf27vQ4c2hB/Z6An8G22vyswFnhQW56yXaa/Rq1BkHzQHJbYyxoUtko9BPgC6KiU+sVetQzoaH9uKPfibuAKoMr+3g5Yp5SqsL/r15W4Znv9env7+kQvYCXwuG1We0REmtGAf2el1FLgdmAR8AvW7/YlDft3doj6u+b0ezd2AdHgEZHmwIvAxUqpDfo6ZQ0pGkycs4gcCaxQSn1Z222pQQqAocADSqkhwGaSZgegQf7ObYCjsYRjF6AZ6aaYBk9N/K6NXUAsBbpr37vZyxoEIlKIJRyeUUq9ZC9eLiKd7fWdgRX28oZwL/YGxojIQmA8lpnpH0BrESmwt9GvK3HN9vpWwOqabHA1sARYopT6wv7+ApbAaMi/80HAj0qplUqpcuAlrN++If/ODlF/15x+78YuIKYCfezohyIsR9eEWm5TtSAiAjwKfK+UulNbNQFwIhnOxPJNOMt/ZUdD7Ams11TZeoFS6kqlVDelVE+s3/J9pdRpwAfACfZm7mt27sUJ9vb1aqStlFoGLBaRfvaiUcAsGvDvjGVa2lNEmtrPuXPNDfZ31oj6u74NHCIibWzN6xB7WThq2wlT23/A4cAPwHzg6tpuTzVe1z5Y6uc3wHT773As2+t7wFzgXaCtvb1gRXTNB2ZiRYjU+nXkcP0jgdftzzsAU4B5wH+BYnt5if19nr1+h9pud5bXOhiYZv/WrwBtGvrvDPwFmA18CzwFFDe03xl4FsvHUo6lKf5fNr8rcLZ97fOAs6K0wZTaMBgMBoMnjd3EZDAYDAYfjIAwGAwGgydGQBgMBoPBEyMgDAaDweCJERAGg8Fg8MQICIOhDiAiI53qswZDXcEICIPBYDB4YgSEwRABETldRKaIyHQRedCee2KTiNxlz0/wnoh0sLcdLCKf2/X5X9Zq9/cWkXdFZIaIfCUiO9qHby7JeR2esbOEDYZawwgIgyEkIrIzcDKwt1JqMFAJnIZVLG6aUmoX4EOs+vsA/wb+qJQaiJXd6ix/BrhPKTUI2AsrWxasirsXY81NsgNWfSGDodYoyLyJwWCwGQXsBky1B/dNsIqlVQHP2ds8DbwkIq2A1kqpD+3lTwL/FZEWQFel1MsASqltAPbxpiilltjfp2PNBfBJ3q/KYPDBCAiDITwCPKmUujJlocifXdtlW7+mVPtciXk/DbWMMTEZDOF5DzhBRLaDxPzA22O9R04V0VOBT5RS64G1IrKvvfwM4EOl1EZgiYgcYx+jWESa1uRFGAxhMSMUgyEkSqlZInIN8I6IxLCqbP4Oa5Ke4fa6FVh+CrDKMf/LFgALgLPs5WcAD4rIDfYxTqzByzAYQmOquRoMOSIim5RSzWu7HQZDdWNMTAaDwWDwxGgQBoPBYPDEaBAGg8Fg8MQICIPBYDB4YgSEwWAwGDwxAsJgMBgMnhgBYTAYDAZP/h/G0QH+bsIzSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "21/21 [==============================] - 1s 18ms/step - loss: 5.6073 - accuracy: 0.4821 - val_loss: 5.6131 - val_accuracy: 0.5088\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 5.0764 - accuracy: 0.4821 - val_loss: 5.1314 - val_accuracy: 0.5118\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 4.8874 - accuracy: 0.4821 - val_loss: 4.8176 - val_accuracy: 0.5118\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 4.6582 - accuracy: 0.4836 - val_loss: 4.4989 - val_accuracy: 0.5118\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 4.3822 - accuracy: 0.4866 - val_loss: 4.2776 - val_accuracy: 0.5118\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 4.0578 - accuracy: 0.4836 - val_loss: 3.6645 - val_accuracy: 0.5118\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 3.6708 - accuracy: 0.4776 - val_loss: 3.2732 - val_accuracy: 0.5118\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 3.0645 - accuracy: 0.4836 - val_loss: 2.4229 - val_accuracy: 0.5118\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.2507 - accuracy: 0.4836 - val_loss: 1.6419 - val_accuracy: 0.5118\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.4503 - accuracy: 0.4866 - val_loss: 1.0832 - val_accuracy: 0.5118\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.1151 - accuracy: 0.4836 - val_loss: 0.9819 - val_accuracy: 0.5118\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.0176 - accuracy: 0.4851 - val_loss: 0.9385 - val_accuracy: 0.5118\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9814 - accuracy: 0.4821 - val_loss: 0.9135 - val_accuracy: 0.5118\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9562 - accuracy: 0.4821 - val_loss: 0.8916 - val_accuracy: 0.5118\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.9325 - accuracy: 0.4836 - val_loss: 0.8718 - val_accuracy: 0.5118\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.9138 - accuracy: 0.4836 - val_loss: 0.8536 - val_accuracy: 0.5147\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8994 - accuracy: 0.4881 - val_loss: 0.8372 - val_accuracy: 0.5147\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8817 - accuracy: 0.4836 - val_loss: 0.8220 - val_accuracy: 0.5176\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8666 - accuracy: 0.4836 - val_loss: 0.8085 - val_accuracy: 0.5206\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8500 - accuracy: 0.4925 - val_loss: 0.7965 - val_accuracy: 0.5206\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8393 - accuracy: 0.4851 - val_loss: 0.7839 - val_accuracy: 0.5235\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8275 - accuracy: 0.4925 - val_loss: 0.7728 - val_accuracy: 0.5206\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8196 - accuracy: 0.4851 - val_loss: 0.7627 - val_accuracy: 0.5206\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.8064 - accuracy: 0.4896 - val_loss: 0.7530 - val_accuracy: 0.5147\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7965 - accuracy: 0.4881 - val_loss: 0.7446 - val_accuracy: 0.5206\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7902 - accuracy: 0.4925 - val_loss: 0.7366 - val_accuracy: 0.5206\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7835 - accuracy: 0.5015 - val_loss: 0.7294 - val_accuracy: 0.5235\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7711 - accuracy: 0.5000 - val_loss: 0.7223 - val_accuracy: 0.5176\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7702 - accuracy: 0.4955 - val_loss: 0.7164 - val_accuracy: 0.5176\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7545 - accuracy: 0.4985 - val_loss: 0.7107 - val_accuracy: 0.5206\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7548 - accuracy: 0.5030 - val_loss: 0.7064 - val_accuracy: 0.5235\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7445 - accuracy: 0.5075 - val_loss: 0.7022 - val_accuracy: 0.5206\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7406 - accuracy: 0.5090 - val_loss: 0.6982 - val_accuracy: 0.5176\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7393 - accuracy: 0.5090 - val_loss: 0.6950 - val_accuracy: 0.5235\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7321 - accuracy: 0.5015 - val_loss: 0.6925 - val_accuracy: 0.5353\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7274 - accuracy: 0.5179 - val_loss: 0.6904 - val_accuracy: 0.5412\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7265 - accuracy: 0.5075 - val_loss: 0.6886 - val_accuracy: 0.5353\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7204 - accuracy: 0.5164 - val_loss: 0.6875 - val_accuracy: 0.5294\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7232 - accuracy: 0.5254 - val_loss: 0.6869 - val_accuracy: 0.5294\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7202 - accuracy: 0.5269 - val_loss: 0.6871 - val_accuracy: 0.5324\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7142 - accuracy: 0.5134 - val_loss: 0.6888 - val_accuracy: 0.5441\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7126 - accuracy: 0.5134 - val_loss: 0.7201 - val_accuracy: 0.5412\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.7142 - accuracy: 0.5134 - val_loss: 0.7196 - val_accuracy: 0.5471\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7085 - accuracy: 0.5328 - val_loss: 0.7193 - val_accuracy: 0.5588\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7072 - accuracy: 0.5254 - val_loss: 0.7193 - val_accuracy: 0.5500\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7130 - accuracy: 0.5269 - val_loss: 0.7192 - val_accuracy: 0.5529\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6974 - accuracy: 0.5224 - val_loss: 0.7203 - val_accuracy: 0.5588\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.7073 - accuracy: 0.5343 - val_loss: 0.7199 - val_accuracy: 0.5559\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7043 - accuracy: 0.5328 - val_loss: 0.7205 - val_accuracy: 0.5618\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7033 - accuracy: 0.5328 - val_loss: 0.7221 - val_accuracy: 0.5588\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7041 - accuracy: 0.5134 - val_loss: 0.7536 - val_accuracy: 0.5618\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6998 - accuracy: 0.5328 - val_loss: 0.7534 - val_accuracy: 0.5676\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7009 - accuracy: 0.5612 - val_loss: 0.7535 - val_accuracy: 0.5618\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7111 - accuracy: 0.5030 - val_loss: 0.7535 - val_accuracy: 0.5588\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7029 - accuracy: 0.5343 - val_loss: 0.7535 - val_accuracy: 0.5706\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7249 - accuracy: 0.5045 - val_loss: 0.7537 - val_accuracy: 0.5647\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6976 - accuracy: 0.5403 - val_loss: 0.7536 - val_accuracy: 0.5647\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7070 - accuracy: 0.5119 - val_loss: 0.7533 - val_accuracy: 0.5676\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7069 - accuracy: 0.5269 - val_loss: 0.7533 - val_accuracy: 0.5706\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7016 - accuracy: 0.5343 - val_loss: 0.7385 - val_accuracy: 0.5647\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7218 - accuracy: 0.5179 - val_loss: 0.7533 - val_accuracy: 0.5706\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6967 - accuracy: 0.5507 - val_loss: 0.7533 - val_accuracy: 0.5706\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7048 - accuracy: 0.5343 - val_loss: 0.7532 - val_accuracy: 0.5706\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6966 - accuracy: 0.5119 - val_loss: 0.7194 - val_accuracy: 0.5618\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6983 - accuracy: 0.5254 - val_loss: 0.7203 - val_accuracy: 0.5618\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.6942 - accuracy: 0.5418 - val_loss: 0.7319 - val_accuracy: 0.5676\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.7002 - accuracy: 0.5493 - val_loss: 0.7531 - val_accuracy: 0.5676\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5309 - val_loss: 0.6906 - val_accuracy: 0.5091\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5353 - val_loss: 0.6936 - val_accuracy: 0.5242\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5485 - val_loss: 0.6931 - val_accuracy: 0.5424\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6756 - accuracy: 0.5603 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5471 - val_loss: 0.6921 - val_accuracy: 0.5364\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6847 - accuracy: 0.5279 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5456 - val_loss: 0.6924 - val_accuracy: 0.5394\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5324 - val_loss: 0.6942 - val_accuracy: 0.4939\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5397 - val_loss: 0.6892 - val_accuracy: 0.5424\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5426 - val_loss: 0.6895 - val_accuracy: 0.5606\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5265 - val_loss: 0.6879 - val_accuracy: 0.5364\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5250 - val_loss: 0.6921 - val_accuracy: 0.5212\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6870 - accuracy: 0.5441 - val_loss: 0.6931 - val_accuracy: 0.5273\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6867 - accuracy: 0.5338 - val_loss: 0.6890 - val_accuracy: 0.5455\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5235 - val_loss: 0.6893 - val_accuracy: 0.5303\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5515 - val_loss: 0.6893 - val_accuracy: 0.4970\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5544 - val_loss: 0.6880 - val_accuracy: 0.5242\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5382 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5353 - val_loss: 0.6893 - val_accuracy: 0.5000\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6766 - accuracy: 0.5500 - val_loss: 0.6888 - val_accuracy: 0.5212\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5235 - val_loss: 0.6901 - val_accuracy: 0.5424\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5515 - val_loss: 0.6892 - val_accuracy: 0.5485\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5559 - val_loss: 0.6905 - val_accuracy: 0.5394\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.5676 - val_loss: 0.6878 - val_accuracy: 0.5788\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5441 - val_loss: 0.6928 - val_accuracy: 0.5212\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5515 - val_loss: 0.6914 - val_accuracy: 0.5515\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5265 - val_loss: 0.6932 - val_accuracy: 0.5242\n",
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6943 - accuracy: 0.5574 - val_loss: 0.6948 - val_accuracy: 0.5303\n",
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5353 - val_loss: 0.6917 - val_accuracy: 0.5545\n",
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5588 - val_loss: 0.6903 - val_accuracy: 0.4970\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5426 - val_loss: 0.6951 - val_accuracy: 0.4970\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5382 - val_loss: 0.6954 - val_accuracy: 0.5273\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5515 - val_loss: 0.7070 - val_accuracy: 0.5212\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5353 - val_loss: 0.6889 - val_accuracy: 0.5515\n",
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6821 - accuracy: 0.5324 - val_loss: 0.6975 - val_accuracy: 0.5091\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5441 - val_loss: 0.6963 - val_accuracy: 0.4939\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6831 - accuracy: 0.5265 - val_loss: 0.6878 - val_accuracy: 0.5455\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5456 - val_loss: 0.6984 - val_accuracy: 0.4818\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5485 - val_loss: 0.6921 - val_accuracy: 0.5091\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5382 - val_loss: 0.7013 - val_accuracy: 0.5182\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5647 - val_loss: 0.6901 - val_accuracy: 0.5333\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5574 - val_loss: 0.6871 - val_accuracy: 0.5333\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6785 - accuracy: 0.5441 - val_loss: 0.6876 - val_accuracy: 0.5273\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5368 - val_loss: 0.6906 - val_accuracy: 0.5121\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5206 - val_loss: 0.6880 - val_accuracy: 0.5364\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5397 - val_loss: 0.6862 - val_accuracy: 0.5424\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6847 - accuracy: 0.5529 - val_loss: 0.6869 - val_accuracy: 0.5273\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5250 - val_loss: 0.6873 - val_accuracy: 0.5788\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5632 - val_loss: 0.6868 - val_accuracy: 0.5697\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6859 - accuracy: 0.5221 - val_loss: 0.6876 - val_accuracy: 0.5667\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5353 - val_loss: 0.6910 - val_accuracy: 0.4970\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5441 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6776 - accuracy: 0.5279 - val_loss: 0.6873 - val_accuracy: 0.5667\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5441 - val_loss: 0.6895 - val_accuracy: 0.5424\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5500 - val_loss: 0.6892 - val_accuracy: 0.5273\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5471 - val_loss: 0.6931 - val_accuracy: 0.5273\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5324 - val_loss: 0.6932 - val_accuracy: 0.5212\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5485 - val_loss: 0.6892 - val_accuracy: 0.5455\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5353 - val_loss: 0.6904 - val_accuracy: 0.5394\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6757 - accuracy: 0.5500 - val_loss: 0.6956 - val_accuracy: 0.4939\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5353 - val_loss: 0.7029 - val_accuracy: 0.4788\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5441 - val_loss: 0.6912 - val_accuracy: 0.5364\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5382 - val_loss: 0.6923 - val_accuracy: 0.5242\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5559 - val_loss: 0.6950 - val_accuracy: 0.4909\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5294 - val_loss: 0.6945 - val_accuracy: 0.4909\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6761 - accuracy: 0.5471 - val_loss: 0.6911 - val_accuracy: 0.5424\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5471 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5250 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6856 - accuracy: 0.5382 - val_loss: 0.6965 - val_accuracy: 0.4939\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5544 - val_loss: 0.6991 - val_accuracy: 0.5000\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5132 - val_loss: 0.6987 - val_accuracy: 0.4939\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6836 - accuracy: 0.5353 - val_loss: 0.6972 - val_accuracy: 0.4970\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5235 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5176 - val_loss: 0.6886 - val_accuracy: 0.5848\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6848 - accuracy: 0.5338 - val_loss: 0.6897 - val_accuracy: 0.5333\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5412 - val_loss: 0.6969 - val_accuracy: 0.5333\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6755 - accuracy: 0.5324 - val_loss: 0.6861 - val_accuracy: 0.5667\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6864 - accuracy: 0.5485 - val_loss: 0.6904 - val_accuracy: 0.5212\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5485 - val_loss: 0.6933 - val_accuracy: 0.5364\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5456 - val_loss: 0.6864 - val_accuracy: 0.5364\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5441 - val_loss: 0.6873 - val_accuracy: 0.5394\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6825 - accuracy: 0.5397 - val_loss: 0.6936 - val_accuracy: 0.5121\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5338 - val_loss: 0.6896 - val_accuracy: 0.5485\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5676 - val_loss: 0.6889 - val_accuracy: 0.5455\n",
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6752 - accuracy: 0.5618 - val_loss: 0.6916 - val_accuracy: 0.5364\n",
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5279 - val_loss: 0.6991 - val_accuracy: 0.4788\n",
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5485 - val_loss: 0.6923 - val_accuracy: 0.5061\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5353 - val_loss: 0.6916 - val_accuracy: 0.5242\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6835 - accuracy: 0.5456 - val_loss: 0.6879 - val_accuracy: 0.5848\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5309 - val_loss: 0.6909 - val_accuracy: 0.5394\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6785 - accuracy: 0.5471 - val_loss: 0.6877 - val_accuracy: 0.5758\n",
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5426 - val_loss: 0.6976 - val_accuracy: 0.5242\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6842 - accuracy: 0.5324 - val_loss: 0.7022 - val_accuracy: 0.4909\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5309 - val_loss: 0.7016 - val_accuracy: 0.5242\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5397 - val_loss: 0.6917 - val_accuracy: 0.5273\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5441 - val_loss: 0.6879 - val_accuracy: 0.5394\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5485 - val_loss: 0.6986 - val_accuracy: 0.5515\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5485 - val_loss: 0.7012 - val_accuracy: 0.5333\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5368 - val_loss: 0.6901 - val_accuracy: 0.5455\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5515 - val_loss: 0.6925 - val_accuracy: 0.5212\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5485 - val_loss: 0.6914 - val_accuracy: 0.5394\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5382 - val_loss: 0.6937 - val_accuracy: 0.5333\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6958 - accuracy: 0.5588 - val_loss: 0.6866 - val_accuracy: 0.5455\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5412 - val_loss: 0.6910 - val_accuracy: 0.5455\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6848 - accuracy: 0.5235 - val_loss: 0.6867 - val_accuracy: 0.5697\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6840 - accuracy: 0.5338 - val_loss: 0.6883 - val_accuracy: 0.5333\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5618 - val_loss: 0.6863 - val_accuracy: 0.5455\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6766 - accuracy: 0.5574 - val_loss: 0.6919 - val_accuracy: 0.5485\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6821 - accuracy: 0.5456 - val_loss: 0.6912 - val_accuracy: 0.5455\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.5441 - val_loss: 0.6881 - val_accuracy: 0.5455\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.5412 - val_loss: 0.6860 - val_accuracy: 0.5424\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5515 - val_loss: 0.6866 - val_accuracy: 0.5394\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5500 - val_loss: 0.6867 - val_accuracy: 0.5545\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5265 - val_loss: 0.6868 - val_accuracy: 0.5455\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5441 - val_loss: 0.6871 - val_accuracy: 0.5394\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6841 - accuracy: 0.5279 - val_loss: 0.6872 - val_accuracy: 0.5000\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6807 - accuracy: 0.5353 - val_loss: 0.6873 - val_accuracy: 0.5182\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5382 - val_loss: 0.6915 - val_accuracy: 0.5364\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6766 - accuracy: 0.5706 - val_loss: 0.6960 - val_accuracy: 0.5000\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5500 - val_loss: 0.6936 - val_accuracy: 0.5182\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5324 - val_loss: 0.6907 - val_accuracy: 0.5424\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6777 - accuracy: 0.5544 - val_loss: 0.6883 - val_accuracy: 0.5394\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5074 - val_loss: 0.6930 - val_accuracy: 0.5121\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5515 - val_loss: 0.6993 - val_accuracy: 0.4970\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5368 - val_loss: 0.6917 - val_accuracy: 0.5394\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5426 - val_loss: 0.6919 - val_accuracy: 0.5212\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5382 - val_loss: 0.6929 - val_accuracy: 0.5242\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6851 - accuracy: 0.5294 - val_loss: 0.6901 - val_accuracy: 0.5485\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5471 - val_loss: 0.6891 - val_accuracy: 0.5394\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5603 - val_loss: 0.6903 - val_accuracy: 0.5394\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6755 - accuracy: 0.5574 - val_loss: 0.6947 - val_accuracy: 0.5333\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6855 - accuracy: 0.5250 - val_loss: 0.6951 - val_accuracy: 0.5000\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5441 - val_loss: 0.7054 - val_accuracy: 0.5000\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6845 - accuracy: 0.5324 - val_loss: 0.7103 - val_accuracy: 0.4758\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6833 - accuracy: 0.5324 - val_loss: 0.6952 - val_accuracy: 0.5030\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.5515 - val_loss: 0.7058 - val_accuracy: 0.4909\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.5324 - val_loss: 0.7042 - val_accuracy: 0.4788\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5324 - val_loss: 0.7000 - val_accuracy: 0.4848\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5397 - val_loss: 0.6978 - val_accuracy: 0.5333\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5500 - val_loss: 0.6866 - val_accuracy: 0.5939\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5500 - val_loss: 0.6894 - val_accuracy: 0.5394\n",
      "Epoch 507/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5426 - val_loss: 0.6896 - val_accuracy: 0.5394\n",
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5441 - val_loss: 0.6922 - val_accuracy: 0.5394\n",
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5471 - val_loss: 0.6943 - val_accuracy: 0.5242\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7020 - accuracy: 0.5279 - val_loss: 0.6919 - val_accuracy: 0.5242\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5382 - val_loss: 0.6998 - val_accuracy: 0.4939\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5559 - val_loss: 0.6900 - val_accuracy: 0.5455\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5485 - val_loss: 0.7114 - val_accuracy: 0.4970\n",
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.5544 - val_loss: 0.6981 - val_accuracy: 0.4879\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5456 - val_loss: 0.6974 - val_accuracy: 0.5030\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5588 - val_loss: 0.7018 - val_accuracy: 0.4818\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6976 - accuracy: 0.5221 - val_loss: 0.7427 - val_accuracy: 0.5121\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.7321 - accuracy: 0.4662 - val_loss: 0.7029 - val_accuracy: 0.4788\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6973 - accuracy: 0.4956 - val_loss: 0.6901 - val_accuracy: 0.5091\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6892 - accuracy: 0.4971 - val_loss: 0.6873 - val_accuracy: 0.5212\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.5235 - val_loss: 0.6877 - val_accuracy: 0.5394\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5544 - val_loss: 0.6876 - val_accuracy: 0.5333\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5471 - val_loss: 0.6877 - val_accuracy: 0.5424\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5647 - val_loss: 0.6880 - val_accuracy: 0.5333\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5294 - val_loss: 0.6872 - val_accuracy: 0.5182\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6768 - accuracy: 0.5500 - val_loss: 0.6870 - val_accuracy: 0.5333\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5279 - val_loss: 0.6869 - val_accuracy: 0.5303\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5544 - val_loss: 0.6867 - val_accuracy: 0.5364\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5221 - val_loss: 0.6866 - val_accuracy: 0.5545\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5471 - val_loss: 0.6878 - val_accuracy: 0.5364\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5426 - val_loss: 0.6873 - val_accuracy: 0.5545\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5338 - val_loss: 0.6874 - val_accuracy: 0.5758\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6776 - accuracy: 0.5559 - val_loss: 0.6874 - val_accuracy: 0.5485\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6770 - accuracy: 0.5500 - val_loss: 0.6869 - val_accuracy: 0.5636\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6763 - accuracy: 0.5471 - val_loss: 0.6866 - val_accuracy: 0.5485\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5397 - val_loss: 0.6868 - val_accuracy: 0.5455\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5250 - val_loss: 0.6879 - val_accuracy: 0.5273\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5279 - val_loss: 0.6863 - val_accuracy: 0.5455\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6767 - accuracy: 0.5471 - val_loss: 0.6865 - val_accuracy: 0.5485\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5382 - val_loss: 0.6866 - val_accuracy: 0.5455\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5441 - val_loss: 0.6870 - val_accuracy: 0.5242\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6772 - accuracy: 0.5368 - val_loss: 0.6885 - val_accuracy: 0.5515\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5647 - val_loss: 0.6886 - val_accuracy: 0.5424\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5265 - val_loss: 0.6870 - val_accuracy: 0.5697\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5456 - val_loss: 0.6919 - val_accuracy: 0.5333\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5176 - val_loss: 0.6899 - val_accuracy: 0.5333\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5353 - val_loss: 0.6868 - val_accuracy: 0.5939\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6813 - accuracy: 0.5574 - val_loss: 0.6917 - val_accuracy: 0.5182\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5279 - val_loss: 0.6939 - val_accuracy: 0.4939\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6748 - accuracy: 0.5544 - val_loss: 0.6946 - val_accuracy: 0.5030\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6742 - accuracy: 0.5588 - val_loss: 0.6914 - val_accuracy: 0.5242\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5603 - val_loss: 0.6905 - val_accuracy: 0.5364\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6779 - accuracy: 0.5368 - val_loss: 0.6925 - val_accuracy: 0.5121\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5574 - val_loss: 0.6932 - val_accuracy: 0.5152\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5368 - val_loss: 0.6952 - val_accuracy: 0.5121\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.5662 - val_loss: 0.6977 - val_accuracy: 0.5061\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5456 - val_loss: 0.7089 - val_accuracy: 0.4818\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6786 - accuracy: 0.5588 - val_loss: 0.6975 - val_accuracy: 0.4970\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5529 - val_loss: 0.6974 - val_accuracy: 0.4879\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5485 - val_loss: 0.6916 - val_accuracy: 0.5333\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6823 - accuracy: 0.5647 - val_loss: 0.6850 - val_accuracy: 0.5545\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5294 - val_loss: 0.6871 - val_accuracy: 0.5545\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5397 - val_loss: 0.6851 - val_accuracy: 0.5545\n",
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5338 - val_loss: 0.6862 - val_accuracy: 0.5485\n",
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6811 - accuracy: 0.5426 - val_loss: 0.6850 - val_accuracy: 0.5545\n",
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6763 - accuracy: 0.5485 - val_loss: 0.6840 - val_accuracy: 0.5455\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.5588 - val_loss: 0.6882 - val_accuracy: 0.5303\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5338 - val_loss: 0.6874 - val_accuracy: 0.5333\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5368 - val_loss: 0.6897 - val_accuracy: 0.5515\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5485 - val_loss: 0.6865 - val_accuracy: 0.5424\n",
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6776 - accuracy: 0.5338 - val_loss: 0.6915 - val_accuracy: 0.5333\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.5382 - val_loss: 0.6933 - val_accuracy: 0.5394\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5206 - val_loss: 0.6866 - val_accuracy: 0.5545\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5368 - val_loss: 0.6909 - val_accuracy: 0.5364\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5309 - val_loss: 0.6870 - val_accuracy: 0.5455\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5368 - val_loss: 0.6874 - val_accuracy: 0.5212\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5544 - val_loss: 0.6871 - val_accuracy: 0.5424\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6758 - accuracy: 0.5662 - val_loss: 0.6876 - val_accuracy: 0.5091\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5324 - val_loss: 0.6870 - val_accuracy: 0.5091\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5309 - val_loss: 0.6874 - val_accuracy: 0.5667\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6780 - accuracy: 0.5500 - val_loss: 0.6907 - val_accuracy: 0.5455\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5221 - val_loss: 0.6902 - val_accuracy: 0.5485\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6777 - accuracy: 0.5529 - val_loss: 0.6912 - val_accuracy: 0.5394\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6798 - accuracy: 0.5162 - val_loss: 0.6928 - val_accuracy: 0.4939\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5235 - val_loss: 0.7044 - val_accuracy: 0.4909\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6760 - accuracy: 0.5662 - val_loss: 0.6951 - val_accuracy: 0.5364\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6778 - accuracy: 0.5603 - val_loss: 0.6912 - val_accuracy: 0.5606\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5338 - val_loss: 0.6864 - val_accuracy: 0.5455\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6781 - accuracy: 0.5544 - val_loss: 0.6863 - val_accuracy: 0.5333\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5456 - val_loss: 0.6874 - val_accuracy: 0.5182\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6760 - accuracy: 0.5426 - val_loss: 0.6860 - val_accuracy: 0.5485\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6784 - accuracy: 0.5441 - val_loss: 0.6899 - val_accuracy: 0.5121\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5338 - val_loss: 0.6856 - val_accuracy: 0.5576\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6790 - accuracy: 0.5574 - val_loss: 0.6860 - val_accuracy: 0.5333\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6832 - accuracy: 0.5485 - val_loss: 0.6889 - val_accuracy: 0.5485\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5235 - val_loss: 0.6909 - val_accuracy: 0.5394\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6827 - accuracy: 0.5412 - val_loss: 0.6895 - val_accuracy: 0.5061\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5294 - val_loss: 0.6886 - val_accuracy: 0.5091\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5324 - val_loss: 0.6884 - val_accuracy: 0.5576\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5441 - val_loss: 0.6886 - val_accuracy: 0.5212\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6769 - accuracy: 0.5456 - val_loss: 0.6869 - val_accuracy: 0.5606\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5426 - val_loss: 0.6867 - val_accuracy: 0.5545\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5353 - val_loss: 0.6885 - val_accuracy: 0.5333\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5235 - val_loss: 0.6926 - val_accuracy: 0.5394\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.5456 - val_loss: 0.6844 - val_accuracy: 0.5364\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6810 - accuracy: 0.5338 - val_loss: 0.6854 - val_accuracy: 0.5455\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6771 - accuracy: 0.5471 - val_loss: 0.6856 - val_accuracy: 0.5485\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6790 - accuracy: 0.5544 - val_loss: 0.6859 - val_accuracy: 0.5455\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5559 - val_loss: 0.6863 - val_accuracy: 0.5424\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5235 - val_loss: 0.6855 - val_accuracy: 0.5333\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6782 - accuracy: 0.5500 - val_loss: 0.6876 - val_accuracy: 0.5394\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6760 - accuracy: 0.5485 - val_loss: 0.6856 - val_accuracy: 0.5333\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5412 - val_loss: 0.6863 - val_accuracy: 0.5364\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5618 - val_loss: 0.6872 - val_accuracy: 0.5364\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6895 - accuracy: 0.5206 - val_loss: 0.6957 - val_accuracy: 0.4970\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6850 - accuracy: 0.5353 - val_loss: 0.6893 - val_accuracy: 0.5455\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6783 - accuracy: 0.5441 - val_loss: 0.6896 - val_accuracy: 0.5455\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6827 - accuracy: 0.5206 - val_loss: 0.6914 - val_accuracy: 0.5303\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.5456 - val_loss: 0.6889 - val_accuracy: 0.5879\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5397 - val_loss: 0.6891 - val_accuracy: 0.5848\n",
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6825 - accuracy: 0.5412 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6763 - accuracy: 0.5441 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6789 - accuracy: 0.5515 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6796 - accuracy: 0.5441 - val_loss: 0.6945 - val_accuracy: 0.5273\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.5559 - val_loss: 0.6936 - val_accuracy: 0.5182\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5265 - val_loss: 0.6889 - val_accuracy: 0.5697\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6816 - accuracy: 0.5456 - val_loss: 0.6888 - val_accuracy: 0.5394\n",
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5485 - val_loss: 0.6868 - val_accuracy: 0.5242\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.5588 - val_loss: 0.6849 - val_accuracy: 0.5485\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5485 - val_loss: 0.6867 - val_accuracy: 0.5788\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5382 - val_loss: 0.6855 - val_accuracy: 0.5515\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5441 - val_loss: 0.6859 - val_accuracy: 0.5545\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5176 - val_loss: 0.6938 - val_accuracy: 0.5242\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5412 - val_loss: 0.6881 - val_accuracy: 0.5667\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5544 - val_loss: 0.6877 - val_accuracy: 0.5485\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5574 - val_loss: 0.6908 - val_accuracy: 0.5242\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5515 - val_loss: 0.6888 - val_accuracy: 0.5879\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5368 - val_loss: 0.6851 - val_accuracy: 0.5394\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6828 - accuracy: 0.5309 - val_loss: 0.6901 - val_accuracy: 0.5485\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5412 - val_loss: 0.6893 - val_accuracy: 0.5364\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6762 - accuracy: 0.5412 - val_loss: 0.6877 - val_accuracy: 0.5485\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5500 - val_loss: 0.6880 - val_accuracy: 0.5970\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.5485 - val_loss: 0.6875 - val_accuracy: 0.5667\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6744 - accuracy: 0.5515 - val_loss: 0.6882 - val_accuracy: 0.5424\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5294 - val_loss: 0.6890 - val_accuracy: 0.5576\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5559 - val_loss: 0.6880 - val_accuracy: 0.4939\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5397 - val_loss: 0.6860 - val_accuracy: 0.5515\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6785 - accuracy: 0.5382 - val_loss: 0.6881 - val_accuracy: 0.5667\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5559 - val_loss: 0.6889 - val_accuracy: 0.5636\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5485 - val_loss: 0.6952 - val_accuracy: 0.5030\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5206 - val_loss: 0.6903 - val_accuracy: 0.5364\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6809 - accuracy: 0.5309 - val_loss: 0.6885 - val_accuracy: 0.5061\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5603 - val_loss: 0.6888 - val_accuracy: 0.5333\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6806 - accuracy: 0.5132 - val_loss: 0.6911 - val_accuracy: 0.4909\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6760 - accuracy: 0.5500 - val_loss: 0.6899 - val_accuracy: 0.5061\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6745 - accuracy: 0.5500 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5338 - val_loss: 0.6883 - val_accuracy: 0.5121\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5426 - val_loss: 0.6885 - val_accuracy: 0.5273\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6805 - accuracy: 0.5603 - val_loss: 0.6870 - val_accuracy: 0.5848\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7009 - accuracy: 0.5294 - val_loss: 0.6861 - val_accuracy: 0.5212\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5338 - val_loss: 0.6871 - val_accuracy: 0.5182\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6745 - accuracy: 0.5765 - val_loss: 0.6864 - val_accuracy: 0.5758\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5676 - val_loss: 0.6883 - val_accuracy: 0.5515\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5382 - val_loss: 0.6877 - val_accuracy: 0.5788\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6781 - accuracy: 0.5500 - val_loss: 0.6884 - val_accuracy: 0.5788\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5471 - val_loss: 0.6865 - val_accuracy: 0.5939\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5485 - val_loss: 0.6866 - val_accuracy: 0.5818\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5353 - val_loss: 0.6865 - val_accuracy: 0.5818\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5515 - val_loss: 0.6909 - val_accuracy: 0.5333\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5265 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5544 - val_loss: 0.6959 - val_accuracy: 0.5212\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6797 - accuracy: 0.5588 - val_loss: 0.7085 - val_accuracy: 0.5212\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6820 - accuracy: 0.5382 - val_loss: 0.6906 - val_accuracy: 0.5455\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6815 - accuracy: 0.5382 - val_loss: 0.6933 - val_accuracy: 0.4848\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.5647 - val_loss: 0.7007 - val_accuracy: 0.4879\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6789 - accuracy: 0.5485 - val_loss: 0.7200 - val_accuracy: 0.4909\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6818 - accuracy: 0.5456 - val_loss: 0.7124 - val_accuracy: 0.5000\n",
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6788 - accuracy: 0.5574 - val_loss: 0.7083 - val_accuracy: 0.4970\n",
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5353 - val_loss: 0.7076 - val_accuracy: 0.5000\n",
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6819 - accuracy: 0.5441 - val_loss: 0.7009 - val_accuracy: 0.4848\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6816 - accuracy: 0.5265 - val_loss: 0.6975 - val_accuracy: 0.4879\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5426 - val_loss: 0.6858 - val_accuracy: 0.5758\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6847 - accuracy: 0.5309 - val_loss: 0.7161 - val_accuracy: 0.4939\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6870 - accuracy: 0.5294 - val_loss: 0.6916 - val_accuracy: 0.5394\n",
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5206 - val_loss: 0.6883 - val_accuracy: 0.5303\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5265 - val_loss: 0.6854 - val_accuracy: 0.5909\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.5221 - val_loss: 0.6856 - val_accuracy: 0.5667\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6814 - accuracy: 0.5279 - val_loss: 0.6852 - val_accuracy: 0.5303\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5662 - val_loss: 0.6870 - val_accuracy: 0.5909\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6786 - accuracy: 0.5500 - val_loss: 0.6876 - val_accuracy: 0.5242\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5515 - val_loss: 0.6872 - val_accuracy: 0.5697\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6757 - accuracy: 0.5544 - val_loss: 0.6888 - val_accuracy: 0.5697\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6763 - accuracy: 0.5676 - val_loss: 0.6885 - val_accuracy: 0.5727\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6795 - accuracy: 0.5250 - val_loss: 0.6923 - val_accuracy: 0.5273\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5412 - val_loss: 0.6908 - val_accuracy: 0.5364\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5412 - val_loss: 0.6898 - val_accuracy: 0.5394\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6774 - accuracy: 0.5662 - val_loss: 0.6880 - val_accuracy: 0.5636\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6763 - accuracy: 0.5426 - val_loss: 0.6884 - val_accuracy: 0.5758\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6772 - accuracy: 0.5603 - val_loss: 0.6874 - val_accuracy: 0.5848\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6742 - accuracy: 0.5647 - val_loss: 0.6892 - val_accuracy: 0.5424\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.5279 - val_loss: 0.6872 - val_accuracy: 0.5667\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5441 - val_loss: 0.6907 - val_accuracy: 0.5303\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5456 - val_loss: 0.6869 - val_accuracy: 0.5727\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5471 - val_loss: 0.6864 - val_accuracy: 0.5788\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5368 - val_loss: 0.6899 - val_accuracy: 0.5182\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6760 - accuracy: 0.5676 - val_loss: 0.6974 - val_accuracy: 0.4879\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5191 - val_loss: 0.6896 - val_accuracy: 0.5212\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5485 - val_loss: 0.6863 - val_accuracy: 0.5848\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5485 - val_loss: 0.6863 - val_accuracy: 0.5333\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6764 - accuracy: 0.5456 - val_loss: 0.6875 - val_accuracy: 0.5394\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.5426 - val_loss: 0.6859 - val_accuracy: 0.5364\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5147 - val_loss: 0.6870 - val_accuracy: 0.5242\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6773 - accuracy: 0.5662 - val_loss: 0.6864 - val_accuracy: 0.5909\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5426 - val_loss: 0.6912 - val_accuracy: 0.5152\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5603 - val_loss: 0.6864 - val_accuracy: 0.5545\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5618 - val_loss: 0.6854 - val_accuracy: 0.5182\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5412 - val_loss: 0.6876 - val_accuracy: 0.5364\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.5603 - val_loss: 0.6854 - val_accuracy: 0.5364\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5529 - val_loss: 0.6849 - val_accuracy: 0.5424\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5618 - val_loss: 0.6846 - val_accuracy: 0.5727\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5294 - val_loss: 0.6905 - val_accuracy: 0.5212\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6814 - accuracy: 0.5309 - val_loss: 0.6872 - val_accuracy: 0.5455\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5500 - val_loss: 0.6873 - val_accuracy: 0.5333\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5426 - val_loss: 0.6912 - val_accuracy: 0.5515\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5309 - val_loss: 0.6897 - val_accuracy: 0.5364\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5426 - val_loss: 0.6898 - val_accuracy: 0.5333\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5397 - val_loss: 0.6866 - val_accuracy: 0.5879\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5294 - val_loss: 0.6893 - val_accuracy: 0.5303\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6777 - accuracy: 0.5456 - val_loss: 0.6911 - val_accuracy: 0.5182\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5559 - val_loss: 0.6928 - val_accuracy: 0.5152\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5368 - val_loss: 0.6877 - val_accuracy: 0.5061\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5485 - val_loss: 0.6895 - val_accuracy: 0.5424\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.5515 - val_loss: 0.6875 - val_accuracy: 0.5606\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5382 - val_loss: 0.6876 - val_accuracy: 0.5576\n",
      "Epoch 735/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6748 - accuracy: 0.5382 - val_loss: 0.6867 - val_accuracy: 0.5242\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6834 - accuracy: 0.5426 - val_loss: 0.6912 - val_accuracy: 0.5273\n",
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5412 - val_loss: 0.6896 - val_accuracy: 0.5303\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5309 - val_loss: 0.6920 - val_accuracy: 0.5152\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5765 - val_loss: 0.6874 - val_accuracy: 0.5485\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5397 - val_loss: 0.6857 - val_accuracy: 0.5636\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6761 - accuracy: 0.5544 - val_loss: 0.6888 - val_accuracy: 0.5424\n",
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5441 - val_loss: 0.6866 - val_accuracy: 0.5697\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6801 - accuracy: 0.5500 - val_loss: 0.6857 - val_accuracy: 0.5545\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6778 - accuracy: 0.5471 - val_loss: 0.6887 - val_accuracy: 0.5364\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6874 - accuracy: 0.5221 - val_loss: 0.7041 - val_accuracy: 0.5000\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5353 - val_loss: 0.6973 - val_accuracy: 0.4970\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6795 - accuracy: 0.5441 - val_loss: 0.6936 - val_accuracy: 0.5364\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6788 - accuracy: 0.5397 - val_loss: 0.6931 - val_accuracy: 0.5455\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6769 - accuracy: 0.5485 - val_loss: 0.6870 - val_accuracy: 0.5485\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6760 - accuracy: 0.5309 - val_loss: 0.6869 - val_accuracy: 0.5242\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6769 - accuracy: 0.5441 - val_loss: 0.6897 - val_accuracy: 0.5455\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6800 - accuracy: 0.5324 - val_loss: 0.6856 - val_accuracy: 0.5636\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5485 - val_loss: 0.6874 - val_accuracy: 0.5545\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5412 - val_loss: 0.6870 - val_accuracy: 0.5667\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6769 - accuracy: 0.5559 - val_loss: 0.6846 - val_accuracy: 0.5576\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6785 - accuracy: 0.5353 - val_loss: 0.6843 - val_accuracy: 0.5606\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6782 - accuracy: 0.5382 - val_loss: 0.6853 - val_accuracy: 0.5848\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6803 - accuracy: 0.5324 - val_loss: 0.6859 - val_accuracy: 0.5485\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5441 - val_loss: 0.6917 - val_accuracy: 0.4970\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5529 - val_loss: 0.6877 - val_accuracy: 0.5515\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6982 - accuracy: 0.5338 - val_loss: 0.6881 - val_accuracy: 0.5273\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6770 - accuracy: 0.5471 - val_loss: 0.6854 - val_accuracy: 0.5364\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5515 - val_loss: 0.6861 - val_accuracy: 0.5273\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6777 - accuracy: 0.5500 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5779 - val_loss: 0.6891 - val_accuracy: 0.5273\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6768 - accuracy: 0.5382 - val_loss: 0.6866 - val_accuracy: 0.5152\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6775 - accuracy: 0.5471 - val_loss: 0.6844 - val_accuracy: 0.5545\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5426 - val_loss: 0.6852 - val_accuracy: 0.5576\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6762 - accuracy: 0.5544 - val_loss: 0.6857 - val_accuracy: 0.5242\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6804 - accuracy: 0.5397 - val_loss: 0.6861 - val_accuracy: 0.5636\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6737 - accuracy: 0.5544 - val_loss: 0.6843 - val_accuracy: 0.5636\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5309 - val_loss: 0.6872 - val_accuracy: 0.5394\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6747 - accuracy: 0.5500 - val_loss: 0.6857 - val_accuracy: 0.5394\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5191 - val_loss: 0.6861 - val_accuracy: 0.5697\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6766 - accuracy: 0.5456 - val_loss: 0.6859 - val_accuracy: 0.5697\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5559 - val_loss: 0.6871 - val_accuracy: 0.5576\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5309 - val_loss: 0.6895 - val_accuracy: 0.5364\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6770 - accuracy: 0.5456 - val_loss: 0.6968 - val_accuracy: 0.5303\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5559 - val_loss: 0.6886 - val_accuracy: 0.5242\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5500 - val_loss: 0.6944 - val_accuracy: 0.5212\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5471 - val_loss: 0.7032 - val_accuracy: 0.4788\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5279 - val_loss: 0.6856 - val_accuracy: 0.5273\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6760 - accuracy: 0.5735 - val_loss: 0.6884 - val_accuracy: 0.5485\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5544 - val_loss: 0.6912 - val_accuracy: 0.5273\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6761 - accuracy: 0.5500 - val_loss: 0.6895 - val_accuracy: 0.5364\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6792 - accuracy: 0.5441 - val_loss: 0.6873 - val_accuracy: 0.5455\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6800 - accuracy: 0.5500 - val_loss: 0.6870 - val_accuracy: 0.5333\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6779 - accuracy: 0.5412 - val_loss: 0.6848 - val_accuracy: 0.5697\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6771 - accuracy: 0.5353 - val_loss: 0.6893 - val_accuracy: 0.5212\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6963 - accuracy: 0.5603 - val_loss: 0.6833 - val_accuracy: 0.5455\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.5397 - val_loss: 0.6860 - val_accuracy: 0.5364\n",
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5382 - val_loss: 0.6934 - val_accuracy: 0.5333\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5544 - val_loss: 0.6927 - val_accuracy: 0.5091\n",
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6766 - accuracy: 0.5485 - val_loss: 0.6916 - val_accuracy: 0.5394\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6772 - accuracy: 0.5515 - val_loss: 0.6907 - val_accuracy: 0.5182\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.6767 - accuracy: 0.5574 - val_loss: 0.6901 - val_accuracy: 0.5455\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6784 - accuracy: 0.5471 - val_loss: 0.6911 - val_accuracy: 0.5364\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5250 - val_loss: 0.6895 - val_accuracy: 0.5364\n",
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6772 - accuracy: 0.5485 - val_loss: 0.6928 - val_accuracy: 0.5394\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6757 - accuracy: 0.5647 - val_loss: 0.6879 - val_accuracy: 0.5515\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6751 - accuracy: 0.5603 - val_loss: 0.6994 - val_accuracy: 0.5303\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5456 - val_loss: 0.6936 - val_accuracy: 0.4939\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6758 - accuracy: 0.5574 - val_loss: 0.6908 - val_accuracy: 0.5091\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6766 - accuracy: 0.5412 - val_loss: 0.6894 - val_accuracy: 0.5212\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.5603 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6773 - accuracy: 0.5412 - val_loss: 0.6907 - val_accuracy: 0.5364\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6782 - accuracy: 0.5426 - val_loss: 0.6910 - val_accuracy: 0.5364\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6746 - accuracy: 0.5515 - val_loss: 0.6913 - val_accuracy: 0.5303\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6793 - accuracy: 0.5485 - val_loss: 0.6882 - val_accuracy: 0.5182\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6784 - accuracy: 0.5397 - val_loss: 0.6980 - val_accuracy: 0.4848\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.6812 - accuracy: 0.5309 - val_loss: 0.6860 - val_accuracy: 0.5606\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6749 - accuracy: 0.5779 - val_loss: 0.6856 - val_accuracy: 0.5424\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5441 - val_loss: 0.6865 - val_accuracy: 0.5394\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6777 - accuracy: 0.5309 - val_loss: 0.6851 - val_accuracy: 0.5424\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5500 - val_loss: 0.6860 - val_accuracy: 0.5667\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6801 - accuracy: 0.5441 - val_loss: 0.6886 - val_accuracy: 0.5152\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6796 - accuracy: 0.5294 - val_loss: 0.6884 - val_accuracy: 0.5182\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5265 - val_loss: 0.6865 - val_accuracy: 0.5212\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6766 - accuracy: 0.5426 - val_loss: 0.6881 - val_accuracy: 0.5303\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6764 - accuracy: 0.5676 - val_loss: 0.6843 - val_accuracy: 0.5424\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6794 - accuracy: 0.5368 - val_loss: 0.6844 - val_accuracy: 0.5424\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6788 - accuracy: 0.5559 - val_loss: 0.6940 - val_accuracy: 0.5394\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6772 - accuracy: 0.5544 - val_loss: 0.6847 - val_accuracy: 0.5364\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6751 - accuracy: 0.5265 - val_loss: 0.6842 - val_accuracy: 0.5455\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5603 - val_loss: 0.6855 - val_accuracy: 0.5758\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5485 - val_loss: 0.6912 - val_accuracy: 0.5121\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5294 - val_loss: 0.6883 - val_accuracy: 0.5424\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5368 - val_loss: 0.6866 - val_accuracy: 0.5545\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6749 - accuracy: 0.5485 - val_loss: 0.6875 - val_accuracy: 0.5212\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6760 - accuracy: 0.5485 - val_loss: 0.6968 - val_accuracy: 0.5061\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5603 - val_loss: 0.6970 - val_accuracy: 0.5152\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6740 - accuracy: 0.5456 - val_loss: 0.6939 - val_accuracy: 0.5061\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6800 - accuracy: 0.5382 - val_loss: 0.6904 - val_accuracy: 0.5030\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5412 - val_loss: 0.6889 - val_accuracy: 0.5273\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5515 - val_loss: 0.6888 - val_accuracy: 0.5152\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6759 - accuracy: 0.5471 - val_loss: 0.6905 - val_accuracy: 0.5152\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6756 - accuracy: 0.5647 - val_loss: 0.6875 - val_accuracy: 0.5242\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6843 - accuracy: 0.5588 - val_loss: 0.6873 - val_accuracy: 0.5606\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.5441 - val_loss: 0.6908 - val_accuracy: 0.5515\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5588 - val_loss: 0.6875 - val_accuracy: 0.5424\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6778 - accuracy: 0.5735 - val_loss: 0.6882 - val_accuracy: 0.5424\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5382 - val_loss: 0.6884 - val_accuracy: 0.5394\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6765 - accuracy: 0.5691 - val_loss: 0.6868 - val_accuracy: 0.5273\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6754 - accuracy: 0.5618 - val_loss: 0.6859 - val_accuracy: 0.5394\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6749 - accuracy: 0.5485 - val_loss: 0.6871 - val_accuracy: 0.5303\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6784 - accuracy: 0.5382 - val_loss: 0.6863 - val_accuracy: 0.5515\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5441 - val_loss: 0.6961 - val_accuracy: 0.5152\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5456 - val_loss: 0.6847 - val_accuracy: 0.5424\n",
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5500 - val_loss: 0.6872 - val_accuracy: 0.5455\n",
      "Epoch 850/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5221 - val_loss: 0.6856 - val_accuracy: 0.5485\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6792 - accuracy: 0.5750 - val_loss: 0.6865 - val_accuracy: 0.5394\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.5574 - val_loss: 0.6907 - val_accuracy: 0.5364\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6798 - accuracy: 0.5368 - val_loss: 0.6879 - val_accuracy: 0.5545\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7206 - accuracy: 0.5059 - val_loss: 0.7658 - val_accuracy: 0.4970\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7070 - accuracy: 0.5015 - val_loss: 0.7205 - val_accuracy: 0.4879\n",
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6852 - accuracy: 0.5176 - val_loss: 0.7076 - val_accuracy: 0.4758\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6845 - accuracy: 0.5088 - val_loss: 0.7046 - val_accuracy: 0.4727\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6850 - accuracy: 0.5044 - val_loss: 0.7040 - val_accuracy: 0.4727\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6780 - accuracy: 0.5441 - val_loss: 0.7092 - val_accuracy: 0.4818\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6801 - accuracy: 0.5559 - val_loss: 0.7061 - val_accuracy: 0.4909\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5147 - val_loss: 0.6998 - val_accuracy: 0.5182\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.5147 - val_loss: 0.7022 - val_accuracy: 0.4970\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5235 - val_loss: 0.7017 - val_accuracy: 0.4697\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5176 - val_loss: 0.7024 - val_accuracy: 0.4758\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6826 - accuracy: 0.5176 - val_loss: 0.7029 - val_accuracy: 0.4758\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6787 - accuracy: 0.5265 - val_loss: 0.7022 - val_accuracy: 0.4788\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6804 - accuracy: 0.5456 - val_loss: 0.7016 - val_accuracy: 0.5000\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5529 - val_loss: 0.6989 - val_accuracy: 0.4758\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6761 - accuracy: 0.5485 - val_loss: 0.6999 - val_accuracy: 0.4970\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6843 - accuracy: 0.5485 - val_loss: 0.6997 - val_accuracy: 0.4727\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6841 - accuracy: 0.5456 - val_loss: 0.7008 - val_accuracy: 0.4758\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5412 - val_loss: 0.6992 - val_accuracy: 0.5273\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6777 - accuracy: 0.5412 - val_loss: 0.7004 - val_accuracy: 0.4758\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5691 - val_loss: 0.7020 - val_accuracy: 0.4758\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6755 - accuracy: 0.5485 - val_loss: 0.7027 - val_accuracy: 0.4727\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6815 - accuracy: 0.5382 - val_loss: 0.7056 - val_accuracy: 0.4697\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6832 - accuracy: 0.5191 - val_loss: 0.7057 - val_accuracy: 0.4697\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6773 - accuracy: 0.5338 - val_loss: 0.7007 - val_accuracy: 0.4788\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5456 - val_loss: 0.7033 - val_accuracy: 0.4545\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6821 - accuracy: 0.5191 - val_loss: 0.7012 - val_accuracy: 0.4848\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5515 - val_loss: 0.6987 - val_accuracy: 0.5424\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6798 - accuracy: 0.5324 - val_loss: 0.6976 - val_accuracy: 0.5242\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6828 - accuracy: 0.5353 - val_loss: 0.6985 - val_accuracy: 0.5242\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.5382 - val_loss: 0.7022 - val_accuracy: 0.4697\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5500 - val_loss: 0.7038 - val_accuracy: 0.4727\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6817 - accuracy: 0.5162 - val_loss: 0.7031 - val_accuracy: 0.4727\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6799 - accuracy: 0.5574 - val_loss: 0.7006 - val_accuracy: 0.4788\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5471 - val_loss: 0.6986 - val_accuracy: 0.4879\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5485 - val_loss: 0.6986 - val_accuracy: 0.4909\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6766 - accuracy: 0.5471 - val_loss: 0.7005 - val_accuracy: 0.4758\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5515 - val_loss: 0.6992 - val_accuracy: 0.4939\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6771 - accuracy: 0.5632 - val_loss: 0.6991 - val_accuracy: 0.4909\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.5353 - val_loss: 0.7010 - val_accuracy: 0.4818\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.5397 - val_loss: 0.7005 - val_accuracy: 0.4879\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.5250 - val_loss: 0.6981 - val_accuracy: 0.4818\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5397 - val_loss: 0.6974 - val_accuracy: 0.5000\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.5750 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6775 - accuracy: 0.5574 - val_loss: 0.6965 - val_accuracy: 0.4848\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6952 - accuracy: 0.5529 - val_loss: 0.6963 - val_accuracy: 0.4848\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5559 - val_loss: 0.6962 - val_accuracy: 0.4939\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5294 - val_loss: 0.6966 - val_accuracy: 0.4727\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5191 - val_loss: 0.6980 - val_accuracy: 0.4848\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6788 - accuracy: 0.5250 - val_loss: 0.6957 - val_accuracy: 0.4970\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6760 - accuracy: 0.5382 - val_loss: 0.6956 - val_accuracy: 0.4879\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6776 - accuracy: 0.5368 - val_loss: 0.6966 - val_accuracy: 0.5061\n",
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5897 - val_loss: 0.6970 - val_accuracy: 0.5061\n",
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6843 - accuracy: 0.5324 - val_loss: 0.6976 - val_accuracy: 0.4545\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7004 - accuracy: 0.5309 - val_loss: 0.6974 - val_accuracy: 0.4697\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.5147 - val_loss: 0.7015 - val_accuracy: 0.4848\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6812 - accuracy: 0.5132 - val_loss: 0.6986 - val_accuracy: 0.4606\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.5309 - val_loss: 0.6954 - val_accuracy: 0.5242\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6797 - accuracy: 0.5059 - val_loss: 0.6969 - val_accuracy: 0.5152\n",
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6805 - accuracy: 0.5309 - val_loss: 0.6970 - val_accuracy: 0.5061\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6795 - accuracy: 0.5632 - val_loss: 0.6987 - val_accuracy: 0.5152\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6823 - accuracy: 0.5132 - val_loss: 0.6970 - val_accuracy: 0.5091\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6812 - accuracy: 0.5529 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6803 - accuracy: 0.5456 - val_loss: 0.6943 - val_accuracy: 0.4909\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6779 - accuracy: 0.5691 - val_loss: 0.6952 - val_accuracy: 0.4818\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5176 - val_loss: 0.6948 - val_accuracy: 0.4939\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6801 - accuracy: 0.5515 - val_loss: 0.6943 - val_accuracy: 0.4879\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6800 - accuracy: 0.5118 - val_loss: 0.6967 - val_accuracy: 0.4909\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6789 - accuracy: 0.5426 - val_loss: 0.6947 - val_accuracy: 0.5303\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6802 - accuracy: 0.5500 - val_loss: 0.6949 - val_accuracy: 0.4848\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6798 - accuracy: 0.5691 - val_loss: 0.6956 - val_accuracy: 0.5061\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6768 - accuracy: 0.5618 - val_loss: 0.6943 - val_accuracy: 0.4909\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6799 - accuracy: 0.5544 - val_loss: 0.6951 - val_accuracy: 0.5182\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6824 - accuracy: 0.5294 - val_loss: 0.6989 - val_accuracy: 0.5152\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6813 - accuracy: 0.5191 - val_loss: 0.6962 - val_accuracy: 0.5061\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6755 - accuracy: 0.5632 - val_loss: 0.6960 - val_accuracy: 0.5030\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.5176 - val_loss: 0.7042 - val_accuracy: 0.5121\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6789 - accuracy: 0.5353 - val_loss: 0.7003 - val_accuracy: 0.5152\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6766 - accuracy: 0.5426 - val_loss: 0.6976 - val_accuracy: 0.5152\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6789 - accuracy: 0.5368 - val_loss: 0.6998 - val_accuracy: 0.5152\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6781 - accuracy: 0.5559 - val_loss: 0.6949 - val_accuracy: 0.4818\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6824 - accuracy: 0.5324 - val_loss: 0.6963 - val_accuracy: 0.5061\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6797 - accuracy: 0.5235 - val_loss: 0.6940 - val_accuracy: 0.4939\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6759 - accuracy: 0.5412 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6782 - accuracy: 0.5324 - val_loss: 0.6948 - val_accuracy: 0.4758\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.5544 - val_loss: 0.6956 - val_accuracy: 0.5030\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6769 - accuracy: 0.5294 - val_loss: 0.6992 - val_accuracy: 0.4818\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6825 - accuracy: 0.5235 - val_loss: 0.7037 - val_accuracy: 0.4727\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6997 - accuracy: 0.5426 - val_loss: 0.7058 - val_accuracy: 0.4697\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7009 - accuracy: 0.5515 - val_loss: 0.7020 - val_accuracy: 0.4788\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6782 - accuracy: 0.5529 - val_loss: 0.6965 - val_accuracy: 0.4909\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6757 - accuracy: 0.5397 - val_loss: 0.6945 - val_accuracy: 0.4818\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6998 - accuracy: 0.5618 - val_loss: 0.6951 - val_accuracy: 0.5121\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.5368 - val_loss: 0.6978 - val_accuracy: 0.4879\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6780 - accuracy: 0.5618 - val_loss: 0.6955 - val_accuracy: 0.4818\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6807 - accuracy: 0.5338 - val_loss: 0.6961 - val_accuracy: 0.5091\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6787 - accuracy: 0.5441 - val_loss: 0.6980 - val_accuracy: 0.4939\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6871 - accuracy: 0.5250 - val_loss: 0.7026 - val_accuracy: 0.5061\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.5456 - val_loss: 0.7011 - val_accuracy: 0.4788\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6992 - accuracy: 0.5691 - val_loss: 0.6998 - val_accuracy: 0.5000\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6788 - accuracy: 0.5324 - val_loss: 0.6985 - val_accuracy: 0.4818\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6832 - accuracy: 0.5221 - val_loss: 0.6979 - val_accuracy: 0.4879\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6778 - accuracy: 0.5279 - val_loss: 0.6946 - val_accuracy: 0.4939\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6909 - accuracy: 0.4985 - val_loss: 0.7122 - val_accuracy: 0.5000\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6764 - accuracy: 0.5265 - val_loss: 0.7060 - val_accuracy: 0.4758\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6789 - accuracy: 0.5618 - val_loss: 0.6996 - val_accuracy: 0.4788\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6970 - accuracy: 0.5515 - val_loss: 0.7014 - val_accuracy: 0.4970\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6827 - accuracy: 0.5412 - val_loss: 0.7052 - val_accuracy: 0.4758\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6793 - accuracy: 0.5485 - val_loss: 0.7034 - val_accuracy: 0.4697\n",
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5353 - val_loss: 0.6979 - val_accuracy: 0.4818\n",
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6774 - accuracy: 0.5544 - val_loss: 0.6947 - val_accuracy: 0.5152\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6790 - accuracy: 0.5618 - val_loss: 0.6946 - val_accuracy: 0.5030\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6975 - accuracy: 0.5500 - val_loss: 0.6935 - val_accuracy: 0.5273\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6803 - accuracy: 0.5515 - val_loss: 0.6965 - val_accuracy: 0.4909\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6984 - accuracy: 0.5324 - val_loss: 0.7006 - val_accuracy: 0.4758\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6808 - accuracy: 0.5294 - val_loss: 0.6991 - val_accuracy: 0.4909\n",
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6762 - accuracy: 0.5368 - val_loss: 0.6994 - val_accuracy: 0.4788\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6804 - accuracy: 0.5456 - val_loss: 0.6973 - val_accuracy: 0.4939\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6755 - accuracy: 0.5279 - val_loss: 0.6958 - val_accuracy: 0.4939\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6782 - accuracy: 0.5353 - val_loss: 0.6938 - val_accuracy: 0.5303\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6749 - accuracy: 0.5662 - val_loss: 0.6940 - val_accuracy: 0.5030\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6798 - accuracy: 0.5412 - val_loss: 0.6960 - val_accuracy: 0.4970\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6952 - accuracy: 0.5618 - val_loss: 0.6938 - val_accuracy: 0.4939\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7011 - accuracy: 0.5382 - val_loss: 0.7733 - val_accuracy: 0.4879\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.8234 - accuracy: 0.4632 - val_loss: 0.7766 - val_accuracy: 0.4727\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.8170 - accuracy: 0.4544 - val_loss: 0.7405 - val_accuracy: 0.4879\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7619 - accuracy: 0.4397 - val_loss: 0.7280 - val_accuracy: 0.4848\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7478 - accuracy: 0.4647 - val_loss: 0.7203 - val_accuracy: 0.4818\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7436 - accuracy: 0.4515 - val_loss: 0.7130 - val_accuracy: 0.4697\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7266 - accuracy: 0.4824 - val_loss: 0.7048 - val_accuracy: 0.5212\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.7123 - accuracy: 0.5118 - val_loss: 0.7007 - val_accuracy: 0.4879\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7032 - accuracy: 0.5147 - val_loss: 0.7001 - val_accuracy: 0.4758\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6955 - accuracy: 0.5176 - val_loss: 0.7007 - val_accuracy: 0.4727\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6923 - accuracy: 0.5221 - val_loss: 0.7036 - val_accuracy: 0.4455\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6868 - accuracy: 0.5294 - val_loss: 0.7042 - val_accuracy: 0.4515\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6880 - accuracy: 0.5382 - val_loss: 0.6991 - val_accuracy: 0.4727\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.5250 - val_loss: 0.6990 - val_accuracy: 0.4667\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5471 - val_loss: 0.6995 - val_accuracy: 0.4606\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6830 - accuracy: 0.5382 - val_loss: 0.6997 - val_accuracy: 0.4909\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5515 - val_loss: 0.6988 - val_accuracy: 0.5000\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6822 - accuracy: 0.5412 - val_loss: 0.6996 - val_accuracy: 0.5030\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.5456 - val_loss: 0.6966 - val_accuracy: 0.4818\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6840 - accuracy: 0.5529 - val_loss: 0.6966 - val_accuracy: 0.4697\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6811 - accuracy: 0.5618 - val_loss: 0.6970 - val_accuracy: 0.4788\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5529 - val_loss: 0.6958 - val_accuracy: 0.4909\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6819 - accuracy: 0.5456 - val_loss: 0.6956 - val_accuracy: 0.4909\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.6813 - accuracy: 0.5397 - val_loss: 0.6955 - val_accuracy: 0.5364\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.5364\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_accuracy=[]\n",
    "val_loss=[]\n",
    "train_accuracy=[]\n",
    "train_loss=[]\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features,train_labels=data_array[train_index],label_array[train_index]\n",
    "    val_features,val_labels=data_array[val_index],label_array[val_index]\n",
    "    scaler=StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "    model=cnnmodel()\n",
    "    history = model.fit(train_features,train_labels,epochs=1000,batch_size=32,validation_data=(val_features,val_labels))\n",
    "    val_accuracy.append(model.evaluate(val_features,val_labels)[1])\n",
    "    \n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49741533398628235"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.mean(val_accuracy)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras import optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (None, 64)                4800      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,706\n",
      "Trainable params: 5,578\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def rnnmodel():\n",
    "    model = Sequential()\n",
    "    #model.add(LSTM(128,  input_shape=(2049,32),activation='relu', return_sequences=True))\n",
    "\n",
    "    model.add(layers.SimpleRNN(64, input_shape=(2049,10)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(10))\n",
    "\n",
    "    optimizer = optimizers.Adam(clipvalue=0.5)\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    " \n",
    "model=rnnmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  4  5  7  8 10 11 13 14 16 17 19 20 23 24 26 28 29 31 32 34 35\n",
      " 36 38 40 41 43 44 46 47 48 49 50 51 52 53 55 56 58 59 61 62 64 65 67 68\n",
      " 70 71 74 75 77 79 80 82 83 85 86 87 89 91 92 94 95 97 98]\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 291ms/step - loss: 2.9010 - accuracy: 0.0448 - val_loss: 0.9546 - val_accuracy: 0.0882\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 1.7246 - accuracy: 0.0746 - val_loss: 0.8129 - val_accuracy: 0.0588\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 1.2865 - accuracy: 0.0746 - val_loss: 0.7510 - val_accuracy: 0.1176\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 1s 274ms/step - loss: 0.9976 - accuracy: 0.1045 - val_loss: 0.7132 - val_accuracy: 0.0882\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.8445 - accuracy: 0.0896 - val_loss: 0.6937 - val_accuracy: 0.0588\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.7380 - accuracy: 0.1343 - val_loss: 0.6860 - val_accuracy: 0.0588\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 1s 278ms/step - loss: 0.6396 - accuracy: 0.1642 - val_loss: 0.6774 - val_accuracy: 0.0882\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.5805 - accuracy: 0.1343 - val_loss: 0.6574 - val_accuracy: 0.0588\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.5510 - accuracy: 0.1791 - val_loss: 0.6353 - val_accuracy: 0.0588\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.5061 - accuracy: 0.1493 - val_loss: 0.6159 - val_accuracy: 0.0882\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.4811 - accuracy: 0.1045 - val_loss: 0.6017 - val_accuracy: 0.0588\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.4533 - accuracy: 0.1642 - val_loss: 0.5941 - val_accuracy: 0.0588\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.4279 - accuracy: 0.1194 - val_loss: 0.5805 - val_accuracy: 0.0588\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.4167 - accuracy: 0.1343 - val_loss: 0.5630 - val_accuracy: 0.0588\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.4012 - accuracy: 0.1194 - val_loss: 0.5522 - val_accuracy: 0.0588\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.3914 - accuracy: 0.1343 - val_loss: 0.5457 - val_accuracy: 0.0588\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.3766 - accuracy: 0.1045 - val_loss: 0.5445 - val_accuracy: 0.0588\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.3586 - accuracy: 0.0896 - val_loss: 0.5370 - val_accuracy: 0.0882\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.3431 - accuracy: 0.1343 - val_loss: 0.5300 - val_accuracy: 0.0882\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 0.3230 - accuracy: 0.1343 - val_loss: 0.5185 - val_accuracy: 0.0588\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.3422 - accuracy: 0.1045 - val_loss: 0.5043 - val_accuracy: 0.0294\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.3095 - accuracy: 0.0597 - val_loss: 0.4922 - val_accuracy: 0.0588\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.3105 - accuracy: 0.0896 - val_loss: 0.4885 - val_accuracy: 0.0294\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2983 - accuracy: 0.1194 - val_loss: 0.4875 - val_accuracy: 0.0588\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.3086 - accuracy: 0.1493 - val_loss: 0.4884 - val_accuracy: 0.0882\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.3130 - accuracy: 0.1343 - val_loss: 0.4882 - val_accuracy: 0.0882\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.2719 - accuracy: 0.1194 - val_loss: 0.4820 - val_accuracy: 0.0882\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.2738 - accuracy: 0.1194 - val_loss: 0.4776 - val_accuracy: 0.0882\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.2704 - accuracy: 0.1343 - val_loss: 0.4779 - val_accuracy: 0.0588\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2663 - accuracy: 0.1045 - val_loss: 0.4776 - val_accuracy: 0.0882\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2810 - accuracy: 0.1493 - val_loss: 0.4852 - val_accuracy: 0.0588\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2408 - accuracy: 0.1045 - val_loss: 0.4863 - val_accuracy: 0.0588\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2399 - accuracy: 0.1343 - val_loss: 0.4826 - val_accuracy: 0.0588\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.2559 - accuracy: 0.1642 - val_loss: 0.4858 - val_accuracy: 0.0588\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.2461 - accuracy: 0.1343 - val_loss: 0.4949 - val_accuracy: 0.0588\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2523 - accuracy: 0.1343 - val_loss: 0.5080 - val_accuracy: 0.0588\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2406 - accuracy: 0.1194 - val_loss: 0.5135 - val_accuracy: 0.0588\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.2615 - accuracy: 0.0896 - val_loss: 0.5061 - val_accuracy: 0.0588\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 1s 209ms/step - loss: 0.2439 - accuracy: 0.1343 - val_loss: 0.4904 - val_accuracy: 0.0588\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 216ms/step - loss: 0.2342 - accuracy: 0.1045 - val_loss: 0.4922 - val_accuracy: 0.0588\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.2392 - accuracy: 0.1493 - val_loss: 0.4773 - val_accuracy: 0.0588\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.2324 - accuracy: 0.1493 - val_loss: 0.4649 - val_accuracy: 0.0588\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 1s 208ms/step - loss: 0.2327 - accuracy: 0.1642 - val_loss: 0.4673 - val_accuracy: 0.0588\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.2317 - accuracy: 0.1194 - val_loss: 0.4683 - val_accuracy: 0.0588\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.2458 - accuracy: 0.1045 - val_loss: 0.4670 - val_accuracy: 0.0588\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.2217 - accuracy: 0.1343 - val_loss: 0.4666 - val_accuracy: 0.0294\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.2276 - accuracy: 0.1045 - val_loss: 0.4766 - val_accuracy: 0.0294\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.2162 - accuracy: 0.1642 - val_loss: 0.4814 - val_accuracy: 0.0294\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.2154 - accuracy: 0.0746 - val_loss: 0.4745 - val_accuracy: 0.0294\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.2084 - accuracy: 0.1493 - val_loss: 0.4705 - val_accuracy: 0.0294\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4705 - accuracy: 0.0294\n",
      "[  2   3   5   6   8   9  11  12  14  15  17  18  20  21  22  23  25  26\n",
      "  27  29  30  32  33  35  37  38  39  41  42  44  45  47  50  53  54  56\n",
      "  57  59  60  62  63  65  66  68  69  71  72  73  74  76  77  78  80  81\n",
      "  83  84  86  88  89  90  92  93  95  96  98  99 100]\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 262ms/step - loss: 2.0518 - accuracy: 0.1791 - val_loss: 0.8104 - val_accuracy: 0.1176\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 226ms/step - loss: 1.3413 - accuracy: 0.1642 - val_loss: 0.6832 - val_accuracy: 0.1176\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 1.0350 - accuracy: 0.1194 - val_loss: 0.6189 - val_accuracy: 0.0882\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.8623 - accuracy: 0.1493 - val_loss: 0.5768 - val_accuracy: 0.1176\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.7743 - accuracy: 0.1194 - val_loss: 0.5502 - val_accuracy: 0.0882\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 1s 284ms/step - loss: 0.6513 - accuracy: 0.1343 - val_loss: 0.5264 - val_accuracy: 0.0588\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.6021 - accuracy: 0.1791 - val_loss: 0.5020 - val_accuracy: 0.1176\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.5392 - accuracy: 0.1493 - val_loss: 0.4767 - val_accuracy: 0.0882\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.4989 - accuracy: 0.1045 - val_loss: 0.4556 - val_accuracy: 0.0882\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.4692 - accuracy: 0.1791 - val_loss: 0.4468 - val_accuracy: 0.0882\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.4467 - accuracy: 0.1194 - val_loss: 0.4462 - val_accuracy: 0.0588\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.4366 - accuracy: 0.1493 - val_loss: 0.4383 - val_accuracy: 0.0588\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.4050 - accuracy: 0.1045 - val_loss: 0.4219 - val_accuracy: 0.0588\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 0.3913 - accuracy: 0.1642 - val_loss: 0.4070 - val_accuracy: 0.0294\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.3835 - accuracy: 0.1791 - val_loss: 0.3978 - val_accuracy: 0.0588\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.3771 - accuracy: 0.1493 - val_loss: 0.3892 - val_accuracy: 0.0294\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.3455 - accuracy: 0.1642 - val_loss: 0.3806 - val_accuracy: 0.0294\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.3333 - accuracy: 0.2239 - val_loss: 0.3733 - val_accuracy: 0.0294\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.3452 - accuracy: 0.1343 - val_loss: 0.3659 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.3194 - accuracy: 0.1343 - val_loss: 0.3571 - val_accuracy: 0.0294\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.3100 - accuracy: 0.1343 - val_loss: 0.3516 - val_accuracy: 0.0882\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2959 - accuracy: 0.1343 - val_loss: 0.3480 - val_accuracy: 0.0294\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.2704 - accuracy: 0.1940 - val_loss: 0.3520 - val_accuracy: 0.0588\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2712 - accuracy: 0.1642 - val_loss: 0.3540 - val_accuracy: 0.0588\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 1s 269ms/step - loss: 0.2616 - accuracy: 0.1642 - val_loss: 0.3542 - val_accuracy: 0.0588\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.2532 - accuracy: 0.1343 - val_loss: 0.3434 - val_accuracy: 0.0294\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.2297 - accuracy: 0.1493 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2328 - accuracy: 0.1791 - val_loss: 0.3360 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 1s 235ms/step - loss: 0.2172 - accuracy: 0.1343 - val_loss: 0.3319 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 241ms/step - loss: 0.2282 - accuracy: 0.1194 - val_loss: 0.3351 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.2446 - accuracy: 0.1045 - val_loss: 0.3295 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.2342 - accuracy: 0.0746 - val_loss: 0.3233 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 1s 223ms/step - loss: 0.2100 - accuracy: 0.0896 - val_loss: 0.3244 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 221ms/step - loss: 0.2128 - accuracy: 0.1493 - val_loss: 0.3210 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.2069 - accuracy: 0.1343 - val_loss: 0.3173 - val_accuracy: 0.0882\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.1992 - accuracy: 0.1045 - val_loss: 0.3160 - val_accuracy: 0.0294\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2153 - accuracy: 0.0896 - val_loss: 0.3150 - val_accuracy: 0.0294\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 0.1897 - accuracy: 0.1194 - val_loss: 0.3077 - val_accuracy: 0.0294\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.1962 - accuracy: 0.0896 - val_loss: 0.3043 - val_accuracy: 0.0294\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 246ms/step - loss: 0.1831 - accuracy: 0.1194 - val_loss: 0.3014 - val_accuracy: 0.0294\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 262ms/step - loss: 0.1945 - accuracy: 0.0746 - val_loss: 0.2977 - val_accuracy: 0.0294\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 1s 253ms/step - loss: 0.1982 - accuracy: 0.1194 - val_loss: 0.3087 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 0.1830 - accuracy: 0.1343 - val_loss: 0.3081 - val_accuracy: 0.0294\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.1700 - accuracy: 0.0746 - val_loss: 0.3098 - val_accuracy: 0.0588\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.1884 - accuracy: 0.0746 - val_loss: 0.3101 - val_accuracy: 0.0588\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.1921 - accuracy: 0.1194 - val_loss: 0.3009 - val_accuracy: 0.0588\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 1s 219ms/step - loss: 0.1984 - accuracy: 0.1493 - val_loss: 0.2957 - val_accuracy: 0.0294\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.1824 - accuracy: 0.1642 - val_loss: 0.2908 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.1804 - accuracy: 0.0746 - val_loss: 0.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.1774 - accuracy: 0.1493 - val_loss: 0.3283 - val_accuracy: 0.0294\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3283 - accuracy: 0.0294\n",
      "[  0   1   3   4   6   7   9  10  12  13  15  16  18  19  21  22  24  25\n",
      "  27  28  30  31  33  34  36  37  39  40  42  43  45  46  48  49  51  52\n",
      "  54  55  57  58  60  61  63  64  66  67  69  70  72  73  75  76  78  79\n",
      "  81  82  84  85  87  88  90  91  93  94  96  97  99 100]\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 258ms/step - loss: 2.0829 - accuracy: 0.1029 - val_loss: 0.6688 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 1.3774 - accuracy: 0.1324 - val_loss: 0.5984 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 1.0013 - accuracy: 0.1176 - val_loss: 0.5668 - val_accuracy: 0.0303\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.7909 - accuracy: 0.1324 - val_loss: 0.5480 - val_accuracy: 0.0303\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 1s 229ms/step - loss: 0.6904 - accuracy: 0.0882 - val_loss: 0.5419 - val_accuracy: 0.0303\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 0.6088 - accuracy: 0.0441 - val_loss: 0.5232 - val_accuracy: 0.0303\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.5710 - accuracy: 0.0882 - val_loss: 0.5052 - val_accuracy: 0.0303\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 1s 263ms/step - loss: 0.5143 - accuracy: 0.0735 - val_loss: 0.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.4663 - accuracy: 0.0735 - val_loss: 0.5004 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.4544 - accuracy: 0.1176 - val_loss: 0.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 1s 248ms/step - loss: 0.4291 - accuracy: 0.0441 - val_loss: 0.4849 - val_accuracy: 0.0303\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 247ms/step - loss: 0.4077 - accuracy: 0.0588 - val_loss: 0.4519 - val_accuracy: 0.0303\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 1s 225ms/step - loss: 0.3975 - accuracy: 0.1176 - val_loss: 0.4365 - val_accuracy: 0.0303\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.3670 - accuracy: 0.0441 - val_loss: 0.4221 - val_accuracy: 0.0303\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.3578 - accuracy: 0.1029 - val_loss: 0.4052 - val_accuracy: 0.0303\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.3357 - accuracy: 0.1176 - val_loss: 0.3866 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 1s 283ms/step - loss: 0.3487 - accuracy: 0.1029 - val_loss: 0.3745 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.3117 - accuracy: 0.0882 - val_loss: 0.3636 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 1s 251ms/step - loss: 0.3129 - accuracy: 0.0882 - val_loss: 0.3506 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2874 - accuracy: 0.0735 - val_loss: 0.3436 - val_accuracy: 0.0303\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.2795 - accuracy: 0.0735 - val_loss: 0.3419 - val_accuracy: 0.0303\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.2753 - accuracy: 0.0735 - val_loss: 0.3396 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 1s 271ms/step - loss: 0.2659 - accuracy: 0.0882 - val_loss: 0.3373 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2768 - accuracy: 0.0441 - val_loss: 0.3276 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.2671 - accuracy: 0.0882 - val_loss: 0.3232 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 1s 230ms/step - loss: 0.2358 - accuracy: 0.1324 - val_loss: 0.3250 - val_accuracy: 0.0303\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 1s 232ms/step - loss: 0.2365 - accuracy: 0.0588 - val_loss: 0.3221 - val_accuracy: 0.0606\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.2428 - accuracy: 0.1176 - val_loss: 0.3201 - val_accuracy: 0.0606\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 0.2356 - accuracy: 0.0441 - val_loss: 0.3227 - val_accuracy: 0.0909\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 1s 239ms/step - loss: 0.2231 - accuracy: 0.0735 - val_loss: 0.3305 - val_accuracy: 0.0303\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2221 - accuracy: 0.0441 - val_loss: 0.3354 - val_accuracy: 0.0606\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 1s 231ms/step - loss: 0.2310 - accuracy: 0.0588 - val_loss: 0.3385 - val_accuracy: 0.0606\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 1s 259ms/step - loss: 0.2112 - accuracy: 0.0882 - val_loss: 0.3338 - val_accuracy: 0.0606\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.2030 - accuracy: 0.0588 - val_loss: 0.3347 - val_accuracy: 0.0606\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 1s 243ms/step - loss: 0.2024 - accuracy: 0.1324 - val_loss: 0.3264 - val_accuracy: 0.0606\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 1s 217ms/step - loss: 0.2023 - accuracy: 0.0735 - val_loss: 0.3169 - val_accuracy: 0.0303\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 0.1906 - accuracy: 0.0588 - val_loss: 0.3108 - val_accuracy: 0.0303\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 0.2050 - accuracy: 0.0735 - val_loss: 0.3140 - val_accuracy: 0.0606\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2529 - accuracy: 0.0588 - val_loss: 0.2900 - val_accuracy: 0.0909\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 1s 237ms/step - loss: 0.2325 - accuracy: 0.1176 - val_loss: 0.3050 - val_accuracy: 0.0303\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.2409 - accuracy: 0.0294 - val_loss: 0.3151 - val_accuracy: 0.0303\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 1s 215ms/step - loss: 0.2091 - accuracy: 0.0735 - val_loss: 0.3614 - val_accuracy: 0.0303\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 1s 227ms/step - loss: 0.1992 - accuracy: 0.0735 - val_loss: 0.3645 - val_accuracy: 0.0909\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 0.2620 - accuracy: 0.1176 - val_loss: 0.3769 - val_accuracy: 0.0909\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 1s 240ms/step - loss: 0.2360 - accuracy: 0.1176 - val_loss: 0.3618 - val_accuracy: 0.2121\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.2389 - accuracy: 0.1324 - val_loss: 0.3357 - val_accuracy: 0.1515\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 1s 249ms/step - loss: 0.2138 - accuracy: 0.1324 - val_loss: 0.3235 - val_accuracy: 0.0606\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 258ms/step - loss: 0.2052 - accuracy: 0.1324 - val_loss: 0.3305 - val_accuracy: 0.0606\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 1s 260ms/step - loss: 0.2005 - accuracy: 0.1029 - val_loss: 0.3348 - val_accuracy: 0.0909\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 1s 245ms/step - loss: 0.2169 - accuracy: 0.1324 - val_loss: 0.3217 - val_accuracy: 0.0909\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3217 - accuracy: 0.0909\n"
     ]
    }
   ],
   "source": [
    "val_accuracy=[]\n",
    "val_loss=[]\n",
    "train_accuracy=[]\n",
    "train_loss=[]\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features,train_labels=data_array[train_index],label_array[train_index]\n",
    "    val_features,val_labels=data_array[val_index],label_array[val_index]\n",
    "    scaler=StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "    model=rnnmodel()\n",
    "    history = model.fit(train_features,train_labels,epochs=50,batch_size=16,validation_data=(val_features,val_labels))\n",
    "    val_accuracy.append(model.evaluate(val_features,val_labels)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(estimators)\n\u001b[1;32m     31\u001b[0m kfold \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 32\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStandardized: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (results\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, results\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 378\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    334\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 870\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:870\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:809\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:844\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    843\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 844\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    899\u001b[0m     _assert_all_finite(\n\u001b[1;32m    900\u001b[0m         array,\n\u001b[1;32m    901\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    902\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    903\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "# Binary Classification with Sonar Dataset: Standardized\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(label_array)\n",
    "encoded_Y = encoder.transform(label_array)\n",
    "\n",
    "\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(2049,32), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# evaluate baseline model with standardized dataset\n",
    "data_array = scaler.fit_transform(data_array.reshape(-1, data_array.shape[-1])).reshape(data_array.shape)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(model=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(pipeline, data_array, encoded_Y, cv=kfold,error_score='raise')\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.9.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/nprins/.local/lib/python3.8/site-packages (from scikeras) (1.1.2)\n",
      "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nprins/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/nprins/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/nprins/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/nprins/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.23.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=0.21->scikeras) (2.4.6)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
