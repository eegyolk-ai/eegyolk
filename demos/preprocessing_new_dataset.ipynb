{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare new EEG data for training of machine-learning models\n",
    "\n",
    "In this notebook, the preprocessing for machine learning purposes is done. Also, some exploration and visualization is done to better understand the new data at hand. This is inspired by the previous work of Bjorn Bruns, but applied to a new dataset.\n",
    "\n",
    "+ Import data.\n",
    "+ Apply filters (bandpass).\n",
    "+ Detect potential bad channels and replace them by interpolation.\n",
    "+ Detect potential bad epochs and remove them.\n",
    "+ Extract features\n",
    "+ Select features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages & links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import seaborn as sns\n",
    "\n",
    "from mne_features.feature_extraction import extract_features\n",
    "import eegyolk\n",
    "from eegyolk.config import Config\n",
    "from eegyolk.raw import RawData\n",
    "from eegyolk.cnt import CntReader\n",
    "# from eegyolk.helper_functions import rt\n",
    "\n",
    "config = Config()\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## before we would\n",
    "## Search all *.cnt files and get paths, code, and age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired = RawData(config.get_directory('data'), config.get_directory('metadata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>cnt_path</th>\n",
       "      <th>cnt_file</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_days</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>/volume-ceph/DDP_projectfolder/11mnd mmn/035_1...</td>\n",
       "      <td>035_11_jc_mmn36_slp_mmn25_slp</td>\n",
       "      <td>11</td>\n",
       "      <td>331.0</td>\n",
       "      <td>11.033333</td>\n",
       "      <td>0.919444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>/volume-ceph/DDP_projectfolder/11mnd mmn/027_1...</td>\n",
       "      <td>027_11_jc_mmn25_wk</td>\n",
       "      <td>11</td>\n",
       "      <td>326.0</td>\n",
       "      <td>10.866667</td>\n",
       "      <td>0.905556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>/volume-ceph/DDP_projectfolder/11mnd mmn/025_1...</td>\n",
       "      <td>025_11_mc_mmn36_wk</td>\n",
       "      <td>11</td>\n",
       "      <td>360.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>/volume-ceph/DDP_projectfolder/11mnd mmn/035_1...</td>\n",
       "      <td>035_11_jc_mmn36slp_mmn25_slp_2</td>\n",
       "      <td>11</td>\n",
       "      <td>331.0</td>\n",
       "      <td>11.033333</td>\n",
       "      <td>0.919444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>/volume-ceph/DDP_projectfolder/11mnd mmn/030_1...</td>\n",
       "      <td>030_11_jc_mmn36_wk_mmn25_wk</td>\n",
       "      <td>11</td>\n",
       "      <td>328.0</td>\n",
       "      <td>10.933333</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                           cnt_path  \\\n",
       "0    35  /volume-ceph/DDP_projectfolder/11mnd mmn/035_1...   \n",
       "1    27  /volume-ceph/DDP_projectfolder/11mnd mmn/027_1...   \n",
       "2    25  /volume-ceph/DDP_projectfolder/11mnd mmn/025_1...   \n",
       "3    35  /volume-ceph/DDP_projectfolder/11mnd mmn/035_1...   \n",
       "4    30  /volume-ceph/DDP_projectfolder/11mnd mmn/030_1...   \n",
       "\n",
       "                         cnt_file  age_group  age_days  age_months  age_years  \n",
       "0   035_11_jc_mmn36_slp_mmn25_slp         11     331.0   11.033333   0.919444  \n",
       "1              027_11_jc_mmn25_wk         11     326.0   10.866667   0.905556  \n",
       "2              025_11_mc_mmn36_wk         11     360.0   12.000000   1.000000  \n",
       "3  035_11_jc_mmn36slp_mmn25_slp_2         11     331.0   11.033333   0.919444  \n",
       "4     030_11_jc_mmn36_wk_mmn25_wk         11     328.0   10.933333   0.911111  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquired.raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired = RawDataBDF(config.get_directory('data_2022'), config.get_directory('metadata_2022'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now let's add some blocks to get the new dataset into the same configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cmoore/eegyolk/demos'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = '/volume-ceph/ePodium_projectfolder/dataset/101b.bdf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Group_AccToParents</th>\n",
       "      <th>Age_original_a</th>\n",
       "      <th>Age_days_a</th>\n",
       "      <th>Age_months_a</th>\n",
       "      <th>CDIpresent_a</th>\n",
       "      <th>CDIpresent_b</th>\n",
       "      <th>Age_original_b</th>\n",
       "      <th>Age_days_b</th>\n",
       "      <th>Age_months_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>M</td>\n",
       "      <td>At risk</td>\n",
       "      <td>20;23</td>\n",
       "      <td>623</td>\n",
       "      <td>20.766667</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Ja</td>\n",
       "      <td>23;22</td>\n",
       "      <td>712</td>\n",
       "      <td>23.733333333333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>F</td>\n",
       "      <td>Control</td>\n",
       "      <td>20;20</td>\n",
       "      <td>620</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Ja</td>\n",
       "      <td>23;17</td>\n",
       "      <td>707</td>\n",
       "      <td>23.566666666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>F</td>\n",
       "      <td>At risk</td>\n",
       "      <td>20;24</td>\n",
       "      <td>624</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Ja</td>\n",
       "      <td>24;8</td>\n",
       "      <td>728</td>\n",
       "      <td>24.266666666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>M</td>\n",
       "      <td>At risk</td>\n",
       "      <td>18;12</td>\n",
       "      <td>552</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Ja</td>\n",
       "      <td>20;30</td>\n",
       "      <td>630</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>At risk</td>\n",
       "      <td>17;4</td>\n",
       "      <td>514</td>\n",
       "      <td>17.133333</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Ja</td>\n",
       "      <td>20;11</td>\n",
       "      <td>611</td>\n",
       "      <td>20.366666666666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParticipantID Sex Group_AccToParents Age_original_a  Age_days_a  \\\n",
       "0            101   M            At risk          20;23         623   \n",
       "1            102   F            Control          20;20         620   \n",
       "2            103   F            At risk          20;24         624   \n",
       "3            104   M            At risk          18;12         552   \n",
       "4            105   F            At risk           17;4         514   \n",
       "\n",
       "   Age_months_a CDIpresent_a CDIpresent_b Age_original_b Age_days_b  \\\n",
       "0     20.766667           Ja           Ja          23;22        712   \n",
       "1     20.666667           Ja           Ja          23;17        707   \n",
       "2     20.800000           Ja           Ja           24;8        728   \n",
       "3     18.400000           Ja           Ja          20;30        630   \n",
       "4     17.133333           Ja           Ja          20;11        611   \n",
       "\n",
       "         Age_months_b  \n",
       "0  23.733333333333334  \n",
       "1  23.566666666666666  \n",
       "2  24.266666666666666  \n",
       "3                  21  \n",
       "4  20.366666666666667  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = '/volume-ceph/ePodium_projectfolder/metadata/children.txt'\n",
    "m = pd.read_csv(metadata, sep='\\t')\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the age ranges within groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "data = acquired.breakdown_by_age()\n",
    "bins = 20\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16,16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i + 1 > len(data):\n",
    "        ax.remove()\n",
    "    else:\n",
    "        ax.hist(data[i]['age_months'], bins=bins)\n",
    "        ax.set_xlabel('Age (months)')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title(f'Frequency histogram, bins={bins}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "data = acquired.group_by()\n",
    "bins = 20\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16,16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i + 1 > len(data):\n",
    "        ax.remove()\n",
    "    else:\n",
    "        ax.hist(data[i]['age_months'], bins=bins)\n",
    "        ax.set_xlabel('Age (months)')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title(f'Frequency histogram, bins={bins}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(16,16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i+1 > len(data):\n",
    "        ax.remove()\n",
    "    else:\n",
    "        sns.swarmplot(ax=ax, x=\"age_group\", y=\"age_months\", data=data[i])\n",
    "        ax.set_xlabel('Age group')\n",
    "        ax.set_ylabel('Age (months)')\n",
    "        ax.set_title('Chronological age vs. age group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(16,16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i + 1 > len(data):\n",
    "        ax.remove()\n",
    "    else:    \n",
    "        sns.boxplot(\n",
    "            ax=ax,\n",
    "            x=\"age_group\",\n",
    "            y=\"age_months\",\n",
    "            data=data[i],\n",
    "            showmeans=True, \n",
    "            meanprops={\n",
    "                \"marker\":\"o\",\n",
    "                \"markerfacecolor\":\"white\", \n",
    "                \"markeredgecolor\":\"black\",\n",
    "                \"markersize\":\"6\",\n",
    "                }\n",
    "        )\n",
    "        ax.set_xlabel('Age group')\n",
    "        ax.set_ylabel('Age (months)')\n",
    "        ax.set_title('Chronological age vs. age group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check files with no label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.unlabeled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the missing age data based on the age group the subject is in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the age group (i.e. 11, 17, 23, .. months etc) of all the subjects, based on the folder the files are in and based on the file name. We have got the exact ages (in days) of most subjects seperately, which we have added to the DataFrame above. For some of the subjects, we don't have the exact age and therefore we set this equal to the age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.fill_unlabeled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below should now return an empty dataframe, because all empty fields have been filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.unlabeled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the CNT files are not usable. They are unusable for multiple reasons. Here are few:\n",
    "\n",
    "1. Some are missing a header (the header section usually appears to be filled with null bytes).\n",
    "2. The CNT format itself is ambiguous about whether 4 or 2 bytes are used per event per channel.\n",
    "   It's also not always possible to guess the correct number of bytes per event.  Some of these\n",
    "   files will, however, cause problems when trying to read them.\n",
    "3. CNT files have to have an acquisition date.  MNE authors believe that two formats are possible:\n",
    "   `%m/%d/%y` and `%d/%m/%y`.  However, the original data contains a third, unrecognized format\n",
    "   that uses three digits to store the year.  Possibly, it's this one:\n",
    "   [FAST](https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/time/FastDateFormat.html)\n",
    "4. I've also encountered other errors, where the reader complained about the number of bytes or\n",
    "   indexing errors, which I didn't investigate in depth.\n",
    "   \n",
    "The fraction of damaged original files is less than 1% of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.filter_broken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`acquired.filter_broken()` will read the file headers and split the whole data into two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.raw_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.raw_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import EEG data (from .cnt files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CNT file or a bunch of CNT files using MNE library \n",
    "data_raw = acquired.as_mne[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data type: {}\\n\\n{}\\n'.format(type(data_raw), data_raw))\n",
    "\n",
    "# Get the sample rate\n",
    "print('Sample rate:', data_raw.info['sfreq'], 'Hz')\n",
    "\n",
    "# Get the size of the matrix\n",
    "print('Size of the matrix: {}\\n'.format(data_raw.get_data().shape))\n",
    "\n",
    "# The mne.info class can be used to learn more about the data.\n",
    "print(data_raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show data as pandas dataframe (i.e. as a table).\n",
    "The raw data itself is just an array dimensions are no. of channels and timepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = data_raw.to_data_frame()\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info['bads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band-pass filter (between 1 and 40 Hz. was 0.5 to 30Hz in Stober 2016)\n",
    "data_raw.filter(1, 40, fir_design='firwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the first 5 channels, from 1 s to 10 s.\n",
    "sfreq = data_raw.info['sfreq']\n",
    "data, times = data_raw[:5, int(sfreq * 1):int(sfreq * 10)]\n",
    "\n",
    "fig = plt.subplots(figsize=(10,8))\n",
    "plt.plot(times, data.T)\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel('$\\mu V$')\n",
    "plt.title('Channels: 1-5')\n",
    "plt.legend(data_raw.ch_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mne plots\n",
    "There are many nice plotting options included in mne. They are, however, not always interactive and fully functional in Jupyter notebooks... so better try them out from a python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.plot(duration=10, block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, event_id = mne.events_from_annotations(data_raw)\n",
    "print(events[:10, :])\n",
    "print(event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which unique event indentifiers there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_event_types = set(events[:, 2])\n",
    "print(unique_event_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for most common event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take forever to run because it needs to read every CNT file in the dataset\n",
    "# It also doesn't seem to be very useful anyways.\n",
    "\n",
    "# print(acquired.count_events())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display signal around one type of event\n",
    "Selects signal for specific event ID and plots time window from tmin to tmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start of each epoch (200ms before the trigger)\n",
    "tmin = -0.2\n",
    "\n",
    "# end of each epoch (500ms after the trigger)\n",
    "tmax = 0.5\n",
    "\n",
    "# means from the first instant to t = 0\n",
    "baseline = None, 0\n",
    "\n",
    "picks = mne.pick_types(data_raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "\n",
    "print(picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(\n",
    "    data_raw,\n",
    "    events,\n",
    "    event_id,\n",
    "    tmin,\n",
    "    tmax,\n",
    "    proj=True,\n",
    "    picks=picks,\n",
    "    baseline=baseline,\n",
    "    preload=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data in tabular structure as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df = epochs.to_data_frame()\n",
    "epochs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs['55'].average()\n",
    "evoked.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot_topomap(times=[0.1], size=3., title=\"Topo plot\", time_unit='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot topomaps for different time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot_topomap(times=np.array([0, 0.016, 0.030, 0.060, 0.070, 0.1, 0.2, 0.5]), time_unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test other event type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs['2'].average()\n",
    "evoked.plot()\n",
    "evoked.plot_topomap(times=[0.1], size=3., title=\"Topo plot\", time_unit='s');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evoked.plot_topomap(times=np.array([0, 0.016, 0.030, 0.060, 0.070, 0.1, 0.2, 0.5]), time_unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a montage to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montages specify the exact electrode placement on the scalp of the subject. This contains coordinates relative to a point on the scalp. Often this data is included in the EEG data (.cnt file). Unfortunately for us, we don't have this information. The electrode placement information can be used to fix broken channels by using the channels surrounding this channel. Even though we don't have the exact locations, we do know the electrode placement system used: 10-20. We can use this to approximate the locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When looking at the maps above, the electrode placement seems to be incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax2d = fig.add_subplot(121)\n",
    "ax3d = fig.add_subplot(122, projection='3d')\n",
    "data_raw.plot_sensors(ch_type='eeg', axes=ax2d)\n",
    "data_raw.plot_sensors(ch_type='eeg', axes=ax3d, kind='3d')\n",
    "ax3d.view_init(azim=70, elev=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_from_raw = mne.channels.make_eeg_layout(data_raw.info)\n",
    "layout_from_raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfortunately, we don't have the exact sensor locations. Therefore, we try to approximate them with a standard montage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard montages come with the mne package. They're based on well known and often used electrode placement systems (10-20 in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "montage.ch_names = [ch_name.upper() for ch_name in montage.ch_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.plot(kind='topomap', show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_1020 = data_raw.copy().set_montage(montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, after setting the 1020 montage, the maps look different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax2d = fig.add_subplot(121)\n",
    "ax3d = fig.add_subplot(122, projection='3d')\n",
    "data_raw_1020.plot_sensors(ch_type='eeg', axes=ax2d)\n",
    "data_raw_1020.plot_sensors(ch_type='eeg', axes=ax3d, kind='3d')\n",
    "ax3d.view_init(azim=70, elev=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_from_raw = mne.channels.make_eeg_layout(data_raw_1020.info)\n",
    "layout_from_raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom cnt-file import function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CntReader(acquired)\n",
    "\n",
    "signals, labels, channel_names = reader.read(\n",
    "    acquired.raw_good['cnt_path'][30],\n",
    "    acquired.raw_good['age_months'][0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction and save processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine how to store the processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we're determining what the best method is to extract and save the features. At the end, we combine all the parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reader.save_preprocessed(config.get_directory('preprocessed'), limit=10, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the stuff below is the explanation of how the original author came up with the function above (can be safely ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features that can be used for machine learning models\n",
    "\n",
    "All of the below has been implemented as part of `CntReader.save_preprocessed_row()` and happens automatically during parsing.\n",
    "\n",
    "### Extract features from the raw data to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rms(data):\n",
    "    \"\"\"Root-mean squared value of the data (per channel).\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (n_channels, n_times)\n",
    "    Returns\n",
    "    -------\n",
    "    output : ndarray, shape (n_channels,)\n",
    "    Notes\n",
    "    -----\n",
    "    Alias of the feature function: *rms*\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(data, 2), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features from the raw data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = {\n",
    "    'mean',\n",
    "    ('root_mean_squared', compute_rms),\n",
    "    'hjorth_mobility',\n",
    "    'hjorth_complexity',\n",
    "    'variance',\n",
    "    'std',\n",
    "    'kurtosis',\n",
    "    'skewness',\n",
    "    'app_entropy',\n",
    "    'zero_crossings',\n",
    "    'energy_freq_bands',\n",
    "    'spect_edge_freq',\n",
    "    'ptp_amp',\n",
    "}\n",
    "\n",
    "x_new = extract_features(signals, 500.0, selected_features, return_as_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data had a shape of (1917, 30, 501) - the extracted features data is almost 30 times smaller (before feature selection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for highly correlated features and remove one of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features are often highly correlated and therefore don't add a lot of additional information to the model. To further reduce dimensionality, one of the two highly correlated features can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_1 = x_new.iloc[:, x_new.columns.get_level_values(1) == 'ch1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only the first channel for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = x_new_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation.ge(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly correlated (>0.90), channel 0:\n",
    "- std & rms (0.926)\n",
    "- std & ptp_amp (0.9688)\n",
    "- std & variance (0.952)\n",
    "- ptp_amp & variance (0.900)\n",
    "\n",
    "Highly correlated (>0.90), channel 1:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- rms & ptp_amp\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 2:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- rms & ptp_amp\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 3:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 3:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 4:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 5:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- rms & ptp_amp\n",
    "- ptp_amp & variance\n",
    "\n",
    "After inspecting a few channels and the correlation between the features, the features `std` and `ptp_amp` can be removed, because they have a high correlation with eachother, `rms` and `variance`.  Removing these two features will reduce the dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction after selection\n",
    "\n",
    "Removed features: `std`, `ptp_amp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_selection = {\n",
    "    'mean', ('root_mean_squared', compute_rms),\n",
    "    'hjorth_mobility',\n",
    "    'hjorth_complexity',\n",
    "    'variance',\n",
    "    'kurtosis',\n",
    "    'skewness',\n",
    "    'app_entropy',\n",
    "    'zero_crossings',\n",
    "    'energy_freq_bands',\n",
    "    'spect_edge_freq',\n",
    "}\n",
    "\n",
    "x_new_selection = extract_features(signals, 500.0, selected_features_selection, return_as_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_new_selection.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different channels aren't identifiable by the current naming method. Map the numbers to the actual channel name and flatten the MultiIndex column dataframe.\n",
    "\n",
    "### Sanity check: test loading the saved file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pd.read_hdf(\n",
    "    os.path.join(\n",
    "        config.get_directory('preprocessed'),\n",
    "        'extracted_features_040_11_jc_mmn36_wk_mmn25_wk.h5',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
