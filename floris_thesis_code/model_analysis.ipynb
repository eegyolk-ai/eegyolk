{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Analysis\n",
    "\n",
    "This notebook contains three sections which analyse the data and models trained in the *model_training.ipynb* notebook:\n",
    "\n",
    "+ In section [1. Load data and model](#1ma) the data and trained model of the ePodium and the DDP dataset are loaded.\n",
    "+ In section [2. Make predictions on test set](#2ma) the loaded model is used to make predictions on the test set. \n",
    "+ In section [3. Show results](#3ma) the loss of the test set is calculated and the predictions are plotted in a scatterplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages\n",
    "Note: This notebook may output tensorflow errors if cuda is not properly installed. The notebook still functions with these errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Local\n",
    "import local_paths\n",
    "from functions import epodium, display_helper, processing\n",
    "from functions.epodium import Epodium\n",
    "from functions.ddp import DDP\n",
    "from functions.sequences import EpodiumSequence, DDPSequence\n",
    "\n",
    "# Models\n",
    "from models.dl_4_tsc import encoder_model, fully_convolutional_model, resnet_model\n",
    "from models.eeg_dl import transformer_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "<a id=\"1ma\"></a>\n",
    "## 1. Load data and model\n",
    "\n",
    "Choose the DDP or ePodium dataset to make predictions on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_dataset(dataset_name):\n",
    "    global labels, dataset\n",
    "    if dataset_name == \"epodium\":\n",
    "        dataset = Epodium()\n",
    "        labels = dataset.create_labels(local_paths.ePod_metadata)\n",
    "    elif dataset_name == \"ddp\":\n",
    "        dataset = DDP()\n",
    "        directory_age_metadata = os.path.join(local_paths.DDP_metadata, \"ages\")\n",
    "        labels = dataset.create_labels(local_paths.DDP_dataset, directory_age_metadata)\n",
    "\n",
    "    print(f\"Using dataset: {dataset_name}.\")\n",
    "\n",
    "# Widget settings\n",
    "dataset_name_w = ipywidgets.RadioButtons(description='Dataset:', options=[\"ddp\", \"epodium\"], value=\"ddp\")\n",
    "ui = ipywidgets.HBox([dataset_name_w])\n",
    "out = ipywidgets.interactive_output(choose_dataset, {'dataset_name': dataset_name_w})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a trained model\n",
    "Choose from the trained models in the _local_paths.models_ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required plot setting:\n",
    "%matplotlib inline \n",
    "\n",
    "# history = []\n",
    "                                       \n",
    "def load_model(trained_model):\n",
    "    try:\n",
    "        base_path = os.path.join(local_paths.models, trained_model)\n",
    "    except:\n",
    "        print(\"No models found.\")\n",
    "        return\n",
    "    path_history = os.path.join(base_path, \"history.npy\")\n",
    "    path_model = os.path.join(base_path, \"model\")\n",
    "    path_testset = os.path.join(base_path, \"subsets\", \"test_set.txt\")\n",
    "    path_weights = os.path.join(base_path, \"weights.h5\")\n",
    "    \n",
    "    global model\n",
    "    global testset\n",
    "    global history\n",
    "\n",
    "    # Load Model\n",
    "    if(os.path.exists(path_model)):\n",
    "        print(f\"\\nLoading Model: '{model_name_w.value}'.\")\n",
    "\n",
    "        # Loads the entire model from a folder:\n",
    "        model = tf.keras.models.load_model(path_model)\n",
    "        model.load_weights(path_weights)\n",
    "        # Reads the test-set of the trained model and puts the experiment names into a list:\n",
    "        testset = open(path_testset, \"r\").read().split()\n",
    "        # Loads the training history dictionary:\n",
    "        history = np.load(path_history, allow_pickle=True).item()        \n",
    "\n",
    "        # Show Loss of Training History\n",
    "        print(f\"\\nThe lowest validation loss is: {round(min(history['val_loss']), 3)} at epoch {np.argmin(history['val_loss'])}\\n\")\n",
    "        if \"age\" in trained_model:\n",
    "            xlim, ylim = [0,100], [0,150000]\n",
    "        elif \"dyslexia\" in trained_model:\n",
    "            xlim, ylim = [0,100], [0,0.1]\n",
    "        else:\n",
    "            xlim, ylim = None, None\n",
    "        display_helper.show_plot(x=range(len(history['loss'])), \n",
    "                                 y=[history['loss'], history['val_loss']], \n",
    "                                 legend=[\"loss\",\"validation loss\"], \n",
    "                                 xlabel=\"epochs\", ylabel=\"validation loss (MSE)\", \n",
    "                                 title=f\"Loss during training ({trained_model})\",\n",
    "                                 xlim=xlim, ylim=ylim)\n",
    "        \n",
    "        # Load Model predictions\n",
    "        predictions_file_name = \"predictions_age_\"+dataset_name_w.value+\".txt\"\n",
    "        predictions_path = os.path.join(local_paths.models, model_name_w.value, predictions_file_name)\n",
    "\n",
    "        if os.path.exists(predictions_path):\n",
    "            global results\n",
    "            results = np.loadtxt(predictions_path)\n",
    "            print(f\"Results loaded: {predictions_file_name} from {model_name_w.value}\")    \n",
    "        else:\n",
    "            print(f\"Could not load {predictions_file_name} from {model_name_w.value}, make predictions in the following code.\")\n",
    "\n",
    "    else: \n",
    "        print(\"The model is untrained.\")\n",
    "       \n",
    "    \n",
    "\n",
    "# Find all models in 'local_paths.models' \n",
    "all_trained_models = sorted(f for f in os.listdir(os.path.join(local_paths.models)) if not \".\" in f)\n",
    "# models_dataset = [m for m in all_trained_models if dataset_name_w.value in m] \n",
    "\n",
    "\n",
    "# Widget for selecting the trained models\n",
    "model_name_w = ipywidgets.RadioButtons(options=all_trained_models, description='Models:')\n",
    "display(model_name_w)\n",
    "out = ipywidgets.interactive_output(load_model, {'trained_model': model_name_w})\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "<a id='2ma'></a>\n",
    "### 2. Make predictions on test set\n",
    "\n",
    "The predictions are made by predicting the label of multiple ERPs generated from the same experiment. Each ERP is different, since a random subset of the total number of epochs is used for creating the ERPs.\n",
    "\n",
    "+ *n_passthroughs* is the number of predictions made from the same experiment. A higher number takes longer to process but is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_passthroughs = 30\n",
    "\n",
    "predictions_path = os.path.join(local_paths.models, model_name_w.value, \"predictions_age_\"+dataset_name_w.value+\".txt\")\n",
    "if os.path.exists(predictions_path):\n",
    "    print(f\"The predictions of model '{model_name_w.value}' to dataset '{dataset_name_w.value}' are already saved.\")\n",
    "else:\n",
    "    results = []\n",
    "\n",
    "    # Transfer learning, get entire ePodium dataset as testset:\n",
    "    if dataset_name_w.value  == \"epodium\" and \"ddp\" in model_name_w.value:\n",
    "        testset = processing.valid_experiments(dataset, local_paths.ePod_epochs_events, min_standards=180, min_deviants=80)\n",
    "\n",
    "    # For each experiment in the test-set\n",
    "    for i, experiment in enumerate(testset):\n",
    "        # Set up relevant sequence (each experiment gets its own sequence)\n",
    "        if dataset_name_w.value == \"ddp\":\n",
    "            test_sequence = DDPSequence([experiment], labels, local_paths.DDP_epochs, \n",
    "                                        batch_size=1, n_instances_per_experiment=n_passthroughs, \n",
    "                                        n_trials_averaged=30, standardise=True)\n",
    "\n",
    "        elif dataset_name_w.value  == \"epodium\":\n",
    "\n",
    "            if \"dyslexia\" in model_name_w.value:\n",
    "                test_sequence = EpodiumSequence([experiment], labels, local_paths.ePod_epochs,\n",
    "                                                batch_size=n_passthroughs, label='dyslexia', \n",
    "                                                n_trials_averaged=80, input_type=\"MMR\", standardise=True)\n",
    "            else:\n",
    "                epochs_26ch_directory = os.path.join(local_paths.ePod, \"epochs_fif_500Hz_26ch\")\n",
    "                test_sequence = EpodiumSequence([experiment], labels, epochs_26ch_directory, \n",
    "                                                batch_size=n_passthroughs, label='age',\n",
    "                                                n_trials_averaged=30, input_type=\"standard\", standardise=True)               \n",
    "\n",
    "        # Get experiment\n",
    "        x, y = test_sequence.__getitem__(0)\n",
    "\n",
    "        # Make a prediction with the model.\n",
    "        real_pred = [y[0], np.squeeze(model.predict(x, verbose=0)).mean()]\n",
    "        results.append(real_pred)\n",
    "\n",
    "        print(f\"{i+1}/{len(testset)} predicted.\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    results = np.array(results)\n",
    "\n",
    "    # Save results\n",
    "    if os.path.exists(predictions_path):\n",
    "        os.remove(predictions_path)\n",
    "    np.savetxt(predictions_path, results)\n",
    "    print(f\"Results saved to: {predictions_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a id='3ma'></a>\n",
    "### 3. Show results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate test loss\n",
    "\n",
    "The *Root Mean Square Error* (RMSE) is used to compare the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.diff(results)/30\n",
    "squared_error = np.square(error)\n",
    "mean_squared_error = np.average(squared_error)\n",
    "root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "print(f\"RMSE: {round(root_mean_squared_error,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Mean Absolute Error* (MAE) is used to compare the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error = np.absolute(error)\n",
    "mean_absolute_error = np.average(absolute_error)\n",
    "round(mean_absolute_error,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate color of testset\n",
    "\n",
    "The experiments in the testset are colored from blue to red, where red means that more trials are rejected in the experiment. This can indicate more noise in the EEG signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color of dots depend on estimated amount of noise in data\n",
    "\n",
    "list_n_standards = []\n",
    "\n",
    "if dataset_name_w.value == 'epodium':\n",
    "    standard_id = [2, 5, 8, 11]\n",
    "\n",
    "    if \"ddp\" in model_name_w.value:\n",
    "        testset_temp = processing.valid_experiments(dataset, local_paths.ePod_epochs_events, min_standards=180, min_deviants=80)\n",
    "    else:\n",
    "        testset_temp = testset        \n",
    "\n",
    "    for experiment in testset_temp:\n",
    "        events_path = os.path.join(local_paths.ePod_epochs_events, experiment + '_events.txt')\n",
    "        events = np.loadtxt(events_path, dtype=int)\n",
    "\n",
    "        n_standards = 0    \n",
    "        for i in range(4):\n",
    "            n_standards += np.count_nonzero(events[:,2] == standard_id[i])\n",
    "        list_n_standards.append(n_standards)\n",
    "\n",
    "    # Flip, so noisy experiments have a high (red) color value\n",
    "    color = 1 - (np.array(list_n_standards) - min(list_n_standards)) / (max(list_n_standards) - min(list_n_standards))\n",
    "    \n",
    "if dataset_name_w.value == 'ddp':    \n",
    "    for experiment in testset:\n",
    "        events_path = os.path.join(local_paths.DDP_epochs_events, experiment + '_events.txt')\n",
    "        events = np.loadtxt(events_path, dtype=int)\n",
    "        \n",
    "        n_standards = np.count_nonzero(events[:,2] == 1)\n",
    "        list_n_standards.append(n_standards)\n",
    "    color = 1 - (np.array(list_n_standards) - min(list_n_standards)) / (max(list_n_standards) - min(list_n_standards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot results ages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_info = model_name_w.value.split(\"_\")\n",
    "\n",
    "ages_real = np.array(results)[:,0]/30\n",
    "\n",
    "# Correction values for DDP dataset\n",
    "a = 0.3728\n",
    "b = 12.78\n",
    "\n",
    "correction_point = (a-1) * ages_real + b\n",
    "correction_avg = (a-1) * np.average(ages_real) + b\n",
    "\n",
    "ages_predicted = np.array(results)[:,1]/30 - correction_avg\n",
    "\n",
    "corr_coef = round(np.corrcoef(ages_real, ages_predicted)[0, 1], 3)\n",
    "r2 = round(sklearn.metrics.r2_score(ages_real, ages_predicted), 3)\n",
    "\n",
    "display_helper.show_plot(ages_real, \n",
    "                         ages_predicted, \n",
    "                         f\"Age prediction on ePod (DDP {model_info[1]}) $R^2 = ${r2} \", \n",
    "                         \"Actual age (months)\",\n",
    "                         \"Predicted age (months)\",\n",
    "                         scatter=True,\n",
    "                         scatter_color=color,\n",
    "                         show=False)\n",
    "                         #xlim = [5,46],\n",
    "                         #ylim = [5,46])\n",
    "plt.grid()\n",
    "\n",
    "if dataset_name_w.value == \"ddp\":\n",
    "    x, y = 5, 50\n",
    "elif dataset_name_w.value  == \"epodium\":\n",
    "    x, y = 15, 25\n",
    "\n",
    "# Line where predicted=actual:\n",
    "plt.plot([x, y], [x, y]) \n",
    "\n",
    "a, b = np.polyfit(ages_real, ages_predicted, 1)\n",
    "plt.plot([x, y], [a*x+b, a*y+b]) \n",
    "plt.draw()\n",
    "plt.savefig(\"fig3.png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nline coef. a = {round(a,3)} b = {round(b,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional tools: \n",
    "\n",
    "The following tools are not yet properly cleaned up and ordered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot results risk of dyslexia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = model_name_w.value.split(\"_\")\n",
    "\n",
    "risk_real = np.array(results)[:,0]\n",
    "risk_predicted = np.array(results)[:,1]\n",
    "\n",
    "corr_coef = round(np.corrcoef(risk_real, risk_predicted)[0, 1], 3)\n",
    "r2 = round(corr_coef**2,3)\n",
    "\n",
    "display_helper.show_plot(risk_real, \n",
    "                         risk_predicted, \n",
    "                         f\"Predicting parental dyslexia from MMR (ePod {model_info[1]})\", \n",
    "                         \"Parents' average score on reading tests\",\n",
    "                         \"Predicted average score\",\n",
    "                         scatter_color=color,\n",
    "                         scatter=True,\n",
    "                         show=False)\n",
    "plt.grid()\n",
    "\n",
    "x, y = 0.4, 1\n",
    "plt.plot([x, y], [x, y]) \n",
    "\n",
    "m, c = np.polyfit(risk_real, risk_predicted, 1)\n",
    "plt.plot([x, y], [x*m+c, y*m+c]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset in different dimension (sampling_rate, channels)\n",
    "sample_rate=501\n",
    "channels=dataset.channels_epod_ddp\n",
    "\n",
    "# Loop over each epochs_fif file\n",
    "experiment_paths = glob.glob(os.path.join(local_paths.ePod_epochs, '*.fif'))\n",
    "for experiment_path in experiment_paths:\n",
    "    path_epochs_ddp_dims = os.path.join(local_paths.ePod, \"epochs_fif_500Hz_26ch\", experiment + \"_epo.fif\")\n",
    "    if os.path.exists(path_epochs_ddp_dims):\n",
    "        continue\n",
    "        \n",
    "    filename_events = os.path.basename(experiment_path)\n",
    "    experiment = filename_events.split((\"_epo.fif\"))[0]\n",
    "    \n",
    "    # Load and modify epochs\n",
    "    print(f\"Modifying experiment {experiment}\")\n",
    "    path_epochs = os.path.join(local_paths.ePod_epochs, experiment + \"_epo.fif\")\n",
    "    epochs = mne.read_epochs(path_epochs, verbose=0)\n",
    "    epochs.pick_channels(dataset.channels_epod_ddp)\n",
    "    epochs.resample(sample_rate)\n",
    "    \n",
    "    # Save epochs with new dimensions\n",
    "    epochs.save(path_epochs_ddp_dims)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool to calculate mean score\n",
    "array = np.array(labels[\"Dyslexia_score\"])-0.68\n",
    "square = np.square(array)\n",
    "np.average(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram dyslexia score\n",
    "x = labels[\"Dyslexia_score\"]\n",
    "plt.hist(labels[\"Dyslexia_score\"], bins=16, range=(0.2,1))\n",
    "plt.title('Parents\\' scores on EMT, Klepel, and VC tests')\n",
    "plt.xlabel('Normalized average score')\n",
    "plt.yticks(np.arange(0, 21, 4.0))\n",
    "\n",
    "plt.grid(axis=\"y\", linewidth =0.5)\n",
    "#plt.ylabel('')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save array of strings\n",
    "path = os.path.join(local_paths.models, \"clean_epod_experiments.txt\")\n",
    "array = np.array(testset)\n",
    "np.savetxt(path, array, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_experiments = processing.valid_experiments(dataset, local_paths.ePod_epochs_events, min_standards=180, min_deviants=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_events = glob.glob(os.path.join(local_paths.ePod_epochs_events, '*.txt'))\n",
    "\n",
    "occurences = np.zeros(len(paths_events))\n",
    "\n",
    "standard_id = [2, 5, 8, 11]\n",
    "\n",
    "for i, path_events in enumerate(paths_events):\n",
    "    events = np.loadtxt(path_events, dtype=int)[:,2]\n",
    "    occurences[i] = np.count_nonzero((events == 2) | (events == 5) | (events == 8) | (events == 11))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "plt.hist(occurences, bins=6)\n",
    "plt.title('Check standard trial in each experiment in ePod (10 bins)')\n",
    "plt.ylabel('Experiments')\n",
    "plt.xlabel('Clean standard trials')\n",
    "plt.ylim([0,420])\n",
    "plt.xlim([0,2500])\n",
    "\n",
    "#plt.yticks(np.arange(0, 21, 4.0))\n",
    "#     if dataset.is_valid_experiment(events[:, 2], min_standards,\n",
    "#                                    min_deviants, min_firststandards):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_experiments\n",
    "\n",
    "for i in range(4):\n",
    "            s_invalid = np.count_nonzero(events == self.standard_id[i])\\\n",
    "                < min_standards\n",
    "            d_invalid = np.count_nonzero(events == self.deviant_id[i])\\\n",
    "                < min_deviants\n",
    "            fs_invalid = np.count_nonzero(events == self.firststandard_id[i])\\\n",
    "                < min_firststandards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_passthroughs = 100\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for n_passthrough in range(n_passthroughs):\n",
    "    # For each experiment in the test-set\n",
    "    results = []\n",
    "    for i, experiment in enumerate(testset):\n",
    "        # Set up relevant sequence (each experiment gets its own sequence)\n",
    "        if dataset_name_w.value == \"ddp\":\n",
    "            test_sequence = DDPSequence([experiment], labels, local_paths.DDP_epochs, batch_size=1,\n",
    "                                        n_instances_per_experiment=n_passthrough+1, n_trials_averaged=30,\n",
    "                                        standardise=True)\n",
    "      \n",
    "        # Get experiment\n",
    "        x, y = test_sequence.__getitem__(0)\n",
    "\n",
    "        # Make a prediction with the model.\n",
    "        real_pred = [y[0], np.squeeze(model.predict(x, verbose=0)).mean()]\n",
    "        results.append(real_pred)\n",
    "    all_results.append(results)\n",
    "    print(n_passthrough+1)\n",
    "all_results = np.array(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results2= all_results\n",
    "errors = []\n",
    "for i in range(n_passthroughs):\n",
    "    error = np.diff(all_results[i])\n",
    "    squared_error = np.square(error)\n",
    "    mean_squared_error = np.average(squared_error)\n",
    "    root_mean_squared_error = np.sqrt(mean_squared_error)\n",
    "    \n",
    "    absolute_error = np.absolute(error)\n",
    "    mean_absolute_error = np.average(absolute_error)\n",
    "    \n",
    "    errors.append(mean_absolute_error)\n",
    "\n",
    "\n",
    "display_helper.show_plot(x=range(n_passthroughs), \n",
    "                         y=np.array(errors)/30, \n",
    "                         xlabel=\"Number of ERPs used for prediction\", ylabel=\"Average MAE (months)\", \n",
    "                         title=f\"Average error of predictions (DDP encoder)\",\n",
    "                         xlim=[0,100])# , ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot of reading scores versus predicted age\n",
    "dys_scores = np.zeros(len(ages_predicted))\n",
    "\n",
    "\n",
    "for i, experiment in enumerate(epod_testset):\n",
    "    paticipant = experiment[0:3]\n",
    "    participant_labels = labels.loc[labels[\"Participant\"] == int(paticipant)]\n",
    "    dys_scores[i] = participant_labels[\"Dyslexia_score\"]\n",
    "\n",
    "corr_coef = round(np.corrcoef(dys_scores, ages_predicted)[0, 1], 3)\n",
    "r2 = round(corr_coef**2,3)\n",
    "    \n",
    "display_helper.show_plot(x=dys_scores, \n",
    "                     y=ages_predicted, \n",
    "                     xlabel=\"Parents' average score on reading tests\", ylabel=\"Predicted age (months)\", \n",
    "                     title=f\"Parental dyslexia vs predicted age in ePod (DDP encoder std) $R^2$ = {r2}\",\n",
    "                     scatter_color=color,\n",
    "                     scatter=True,\n",
    "                     show=False)\n",
    "plt.grid()\n",
    "\n",
    "x, y = 0.4, 1\n",
    "m, c = np.polyfit(dys_scores, ages_predicted, 1)\n",
    "plt.plot([x, y], [x*m+c, y*m+c]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epod_testset = processing.valid_experiments(dataset, local_paths.ePod_epochs_events, min_standards=180, min_deviants=80)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5f6ecf0357e95e30953d0cf08844b8b26fdbdf1f780a6e218131c917612a57e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
