{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data for DL models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple preprocessing pipeline for the DL models data.\n",
    "\n",
    "- Load raw EEG data from files;\n",
    "- Load metadata from files (ages of subjects);\n",
    "- Apply filters (bandpass);\n",
    "- Detect potential bad channels and replace them by interpolation;\n",
    "- Detect potential bad epochs and remove them;\n",
    "- Save processed data and metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages & links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import mne\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config_for_repro_prepro import PATH_RAW_DATA, PATH_METADATA, PATH_DATA_PROCESSED_DL\n",
    "\n",
    "import fnmatch\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search all *.cnt files and get paths, code, and age group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plug in new data as data files to run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Projects\\EEG_explorer\\Data_Old\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(PATH_RAW_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_df = pd.DataFrame(file_name_list, columns=[\"file_name\"])\n",
    "# sorted_df['has_month'] = sorted_df[\"file_name\"].str.contains('17m') | sorted_df[\"file_name\"].str.contains('29m')\n",
    "# sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show me classes on df?\n",
    "# \n",
    "# for p in dir(sorted_df[\"file_name\"].str):\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, let's shortcut to just ones where I am sure of the age:\n",
    "\n",
    "# aged_df = sorted_df[sorted_df.has_month]\n",
    "# #aged_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make me some local dirs\n",
    "# os.mkdir('17mnd_mmn')\n",
    "# os.mkdir('29mnd_mmn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Projects\\\\EEG_explorer\\\\Data_Old'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_RAW_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import glob\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "\n",
    "\n",
    "# old_eegs_file_root = \"C:/Projects/EEG_explorer/Data_Old/\"\n",
    "\n",
    "# pattern = os.path.join(PATH_RAW_DATA, '*.cnt')\n",
    "\n",
    "# originals = glob.glob(pattern, recursive=True)\n",
    "# src = old_eegs_file_root\n",
    "# trg  = '17mnd_mmn'\n",
    "# trg2 = '29mnd_mmn'\n",
    "\n",
    "# files1= []\n",
    "\n",
    "# for file in originals:\n",
    "#     if '17m' in file:\n",
    "#         shutil.copy2(os.path.join(src,file), trg)\n",
    "#     if '29m' in file:\n",
    "#         shutil.copy2(os.path.join(src,file), trg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '17mnd_mmn',\n",
       " '29mnd_mmn',\n",
       " 'deep_learning_pre_process_published_old-Copy2.ipynb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_names = {\n",
    "    17: '17mnd_mmn',\n",
    "    29: '29mnd_mmn',\n",
    "}\n",
    "    \n",
    "df_list = []\n",
    "\n",
    "for age_group, directory in dir_names.items(): # Go into every age group folder        \n",
    "    dir_path = directory\n",
    "    file_names = os.listdir(dir_path)\n",
    "    cnt_paths = [os.path.join(dir_path, file_name) for file_name in fnmatch.filter(file_names, \"*.cnt\")]\n",
    "    cnt_files = [x.split('/')[-1][:-4] for x in cnt_paths]\n",
    "    #codes = [int(re.search(r'\\d+', x).group()) for x in cnt_files]\n",
    "    df = pd.DataFrame(list(zip( cnt_paths, cnt_files)), columns =[ 'cnt_path','cnt_file']) \n",
    "    \n",
    "    df['age_group'] = age_group\n",
    "    df_list.append(df)\n",
    "\n",
    "cnt_files = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(17, '17mnd_mmn'), (29, '29mnd_mmn')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_names.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we can optionally get into matching the published files to files on another directory\n",
    "we will make two tables and compare hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17mnd_mmn\\602-115-17m-mc-mmn.cnt</td>\n",
       "      <td>6285bba3aadba0a2efa5d2c941eb193a3a66223c5caba3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17mnd_mmn\\604-133-17m-jc-mmn36.cnt</td>\n",
       "      <td>4277f04e7f14a65c68bb768cb056e26c8e24b32c166d56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17mnd_mmn\\605-131-17m-jc-mmn.cnt</td>\n",
       "      <td>10679da12409265f60f538959ae84751c5fcb9b77ee513...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17mnd_mmn\\607-000-17m-jc-mmn1_36.cnt</td>\n",
       "      <td>2c7923bf82ad1a4ba577225a1e60d78d4f99e96a3c609e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17mnd_mmn\\608-170-17m-mc-mmn36_2.cnt</td>\n",
       "      <td>7c574edb7deb4c687ad79afabaf0cc67215f7d41217909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>17mnd_mmn\\753-470-17m-mr-mmn36.cnt</td>\n",
       "      <td>ccfd67842b21e618ab05ac2842f847a8f3c2b799eb01ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>17mnd_mmn\\754-472-17m-jr-mmn36.cnt</td>\n",
       "      <td>70c42b135d47b99d064fb2cdc3ca99ca24b12053e06007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>17mnd_mmn\\755-471-17m-mr-mmn36.cnt</td>\n",
       "      <td>341fa6f10a938dedd23ae599de36f6bb0fa6b2a90d211f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>17mnd_mmn\\757-487-17m-jr-mmn36.cnt</td>\n",
       "      <td>dd72207c7fbda99fd3fa6969aace4410ced7342cb51202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>17mnd_mmn\\758-465-17m-mr-mmn36.cnt</td>\n",
       "      <td>6b15ee9ce8cebccd5d8659bd8b2c6d6c71170273b98f8e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file_name  \\\n",
       "0       17mnd_mmn\\602-115-17m-mc-mmn.cnt   \n",
       "1     17mnd_mmn\\604-133-17m-jc-mmn36.cnt   \n",
       "2       17mnd_mmn\\605-131-17m-jc-mmn.cnt   \n",
       "3   17mnd_mmn\\607-000-17m-jc-mmn1_36.cnt   \n",
       "4   17mnd_mmn\\608-170-17m-mc-mmn36_2.cnt   \n",
       "..                                   ...   \n",
       "59    17mnd_mmn\\753-470-17m-mr-mmn36.cnt   \n",
       "60    17mnd_mmn\\754-472-17m-jr-mmn36.cnt   \n",
       "61    17mnd_mmn\\755-471-17m-mr-mmn36.cnt   \n",
       "62    17mnd_mmn\\757-487-17m-jr-mmn36.cnt   \n",
       "63    17mnd_mmn\\758-465-17m-mr-mmn36.cnt   \n",
       "\n",
       "                                                 hash  \n",
       "0   6285bba3aadba0a2efa5d2c941eb193a3a66223c5caba3...  \n",
       "1   4277f04e7f14a65c68bb768cb056e26c8e24b32c166d56...  \n",
       "2   10679da12409265f60f538959ae84751c5fcb9b77ee513...  \n",
       "3   2c7923bf82ad1a4ba577225a1e60d78d4f99e96a3c609e...  \n",
       "4   7c574edb7deb4c687ad79afabaf0cc67215f7d41217909...  \n",
       "..                                                ...  \n",
       "59  ccfd67842b21e618ab05ac2842f847a8f3c2b799eb01ad...  \n",
       "60  70c42b135d47b99d064fb2cdc3ca99ca24b12053e06007...  \n",
       "61  341fa6f10a938dedd23ae599de36f6bb0fa6b2a90d211f...  \n",
       "62  dd72207c7fbda99fd3fa6969aace4410ced7342cb51202...  \n",
       "63  6b15ee9ce8cebccd5d8659bd8b2c6d6c71170273b98f8e...  \n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import new_core_helper_functions\n",
    "\n",
    "good_files = new_core_helper_functions.hash_it_up_right_all('17mnd_mmn','.cnt')\n",
    "good_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make old Bjorn dataset from files on drive\n",
    "# # bjorn_directory=  'C:\\Projects\\EEG_explorer\\Data\\17mnd mmn'\n",
    "\n",
    "# old_files = new_core_helper_functions.hash_it_up_right_all('C:/Projects/EEG_explorer/Data/17mnd mmn','.cnt')\n",
    "# old_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and add codes on old files\n",
    "\n",
    "import fnmatch\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import helper_functions\n",
    "\n",
    "dir_names = {\n",
    "    17: '17mnd_mmn',\n",
    "    29: '29mnd_mmn',\n",
    "}\n",
    "    \n",
    "\n",
    "df_list = []\n",
    "\n",
    "for age_group, directory in dir_names.items(): # Go into every age group folder        \n",
    "    dir_path = directory\n",
    "    file_names = os.listdir(dir_path)\n",
    "    cnt_paths = [os.path.join(dir_path, file_name) for file_name in fnmatch.filter(file_names, \"*.cnt\")]\n",
    "    #cnt_files1 = [x.split('/')[-1][:-4] for x in cnt_paths]\n",
    "    cnt_files = [x.split('/')[-1][10:-4] for x in cnt_paths]\n",
    "    codes = [int(re.search(r'\\d+', x).group()) for x in cnt_files]\n",
    "    df = pd.DataFrame(list(zip( codes, cnt_paths, cnt_files)), columns =['code', 'cnt_path','cnt_file']) \n",
    "    \n",
    "    df['age_group'] = age_group\n",
    "    df_list.append(df)\n",
    "\n",
    "code_files = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>cnt_path</th>\n",
       "      <th>cnt_file</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602</td>\n",
       "      <td>17mnd_mmn\\602-115-17m-mc-mmn.cnt</td>\n",
       "      <td>602-115-17m-mc-mmn</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>604</td>\n",
       "      <td>17mnd_mmn\\604-133-17m-jc-mmn36.cnt</td>\n",
       "      <td>604-133-17m-jc-mmn36</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>605</td>\n",
       "      <td>17mnd_mmn\\605-131-17m-jc-mmn.cnt</td>\n",
       "      <td>605-131-17m-jc-mmn</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>607</td>\n",
       "      <td>17mnd_mmn\\607-000-17m-jc-mmn1_36.cnt</td>\n",
       "      <td>607-000-17m-jc-mmn1_36</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>608</td>\n",
       "      <td>17mnd_mmn\\608-170-17m-mc-mmn36_2.cnt</td>\n",
       "      <td>608-170-17m-mc-mmn36_2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>749</td>\n",
       "      <td>29mnd_mmn\\749-032-29m-jr-mmn36.cnt</td>\n",
       "      <td>749-032-29m-jr-mmn36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>751</td>\n",
       "      <td>29mnd_mmn\\751-452-29m-jr-mmn36.cnt</td>\n",
       "      <td>751-452-29m-jr-mmn36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>753</td>\n",
       "      <td>29mnd_mmn\\753-470-29m-mr-mmn36.cnt</td>\n",
       "      <td>753-470-29m-mr-mmn36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>755</td>\n",
       "      <td>29mnd_mmn\\755-471-29m-mr-mmn.cnt</td>\n",
       "      <td>755-471-29m-mr-mmn</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>758</td>\n",
       "      <td>29mnd_mmn\\758-465-29m-mr-mmn36.cnt</td>\n",
       "      <td>758-465-29m-mr-mmn36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                              cnt_path                cnt_file  \\\n",
       "0    602      17mnd_mmn\\602-115-17m-mc-mmn.cnt      602-115-17m-mc-mmn   \n",
       "1    604    17mnd_mmn\\604-133-17m-jc-mmn36.cnt    604-133-17m-jc-mmn36   \n",
       "2    605      17mnd_mmn\\605-131-17m-jc-mmn.cnt      605-131-17m-jc-mmn   \n",
       "3    607  17mnd_mmn\\607-000-17m-jc-mmn1_36.cnt  607-000-17m-jc-mmn1_36   \n",
       "4    608  17mnd_mmn\\608-170-17m-mc-mmn36_2.cnt  608-170-17m-mc-mmn36_2   \n",
       "..   ...                                   ...                     ...   \n",
       "37   749    29mnd_mmn\\749-032-29m-jr-mmn36.cnt    749-032-29m-jr-mmn36   \n",
       "38   751    29mnd_mmn\\751-452-29m-jr-mmn36.cnt    751-452-29m-jr-mmn36   \n",
       "39   753    29mnd_mmn\\753-470-29m-mr-mmn36.cnt    753-470-29m-mr-mmn36   \n",
       "40   755      29mnd_mmn\\755-471-29m-mr-mmn.cnt      755-471-29m-mr-mmn   \n",
       "41   758    29mnd_mmn\\758-465-29m-mr-mmn36.cnt    758-465-29m-mr-mmn36   \n",
       "\n",
       "    age_group  \n",
       "0          17  \n",
       "1          17  \n",
       "2          17  \n",
       "3          17  \n",
       "4          17  \n",
       "..        ...  \n",
       "37         29  \n",
       "38         29  \n",
       "39         29  \n",
       "40         29  \n",
       "41         29  \n",
       "\n",
       "[106 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_files['file_name'] = code_files.cnt_path\n",
    "# full_code_files =code_files.merge(old_files, on = 'file_name', how= 'right')\n",
    "# full_code_files.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goodies = good_files.merge(old_files, on = 'hash')\n",
    "# goodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for all age files and create DataFrame containing all ages per subject code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age_files = {\n",
    "    17: 'ages_17mnths.txt',\n",
    "    29: 'ages_29mnths.txt',\n",
    "}\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for age_group, age_file in age_files.items():\n",
    "    df = pd.read_csv(os.path.join(PATH_METADATA, 'ages', age_file), sep=\"\\t\")\n",
    "    df['age_group'] = age_group\n",
    "    df_list.append(df)\n",
    "\n",
    "age_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Projects\\\\EEG_explorer\\\\ePODIUM_Metadata'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "PATH_METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>age_days</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>524</td>\n",
       "      <td>17.466667</td>\n",
       "      <td>1.455556</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>507</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>1.408333</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>528</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>1.422222</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>514</td>\n",
       "      <td>17.133333</td>\n",
       "      <td>1.427778</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>754</td>\n",
       "      <td>874</td>\n",
       "      <td>29.133333</td>\n",
       "      <td>2.427778</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>755</td>\n",
       "      <td>862</td>\n",
       "      <td>28.733333</td>\n",
       "      <td>2.394444</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>756</td>\n",
       "      <td>872</td>\n",
       "      <td>29.066667</td>\n",
       "      <td>2.422222</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>757</td>\n",
       "      <td>875</td>\n",
       "      <td>29.166667</td>\n",
       "      <td>2.430556</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>758</td>\n",
       "      <td>868</td>\n",
       "      <td>28.933333</td>\n",
       "      <td>2.411111</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     code  age_days  age_months  age_years  age_group\n",
       "0       3       524   17.466667   1.455556         17\n",
       "1       5       507   16.900000   1.408333         17\n",
       "2       7       528   17.600000   1.466667         17\n",
       "3       8       512   17.066667   1.422222         17\n",
       "4       9       514   17.133333   1.427778         17\n",
       "..    ...       ...         ...        ...        ...\n",
       "269   754       874   29.133333   2.427778         29\n",
       "270   755       862   28.733333   2.394444         29\n",
       "271   756       872   29.066667   2.422222         29\n",
       "272   757       875   29.166667   2.430556         29\n",
       "273   758       868   28.933333   2.411111         29\n",
       "\n",
       "[545 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the .cnt files with the age information we have on the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(code_files, age_df, how='left', on=['age_group', 'code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>cnt_path</th>\n",
       "      <th>cnt_file</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_days</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>749</td>\n",
       "      <td>29mnd_mmn\\749-032-29m-jr-mmn36.cnt</td>\n",
       "      <td>749-032-29m-jr-mmn36</td>\n",
       "      <td>29</td>\n",
       "      <td>879</td>\n",
       "      <td>29.300000</td>\n",
       "      <td>2.441667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>751</td>\n",
       "      <td>29mnd_mmn\\751-452-29m-jr-mmn36.cnt</td>\n",
       "      <td>751-452-29m-jr-mmn36</td>\n",
       "      <td>29</td>\n",
       "      <td>869</td>\n",
       "      <td>28.966667</td>\n",
       "      <td>2.413889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>753</td>\n",
       "      <td>29mnd_mmn\\753-470-29m-mr-mmn36.cnt</td>\n",
       "      <td>753-470-29m-mr-mmn36</td>\n",
       "      <td>29</td>\n",
       "      <td>867</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>2.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>755</td>\n",
       "      <td>29mnd_mmn\\755-471-29m-mr-mmn.cnt</td>\n",
       "      <td>755-471-29m-mr-mmn</td>\n",
       "      <td>29</td>\n",
       "      <td>862</td>\n",
       "      <td>28.733333</td>\n",
       "      <td>2.394444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>758</td>\n",
       "      <td>29mnd_mmn\\758-465-29m-mr-mmn36.cnt</td>\n",
       "      <td>758-465-29m-mr-mmn36</td>\n",
       "      <td>29</td>\n",
       "      <td>868</td>\n",
       "      <td>28.933333</td>\n",
       "      <td>2.411111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code                            cnt_path              cnt_file  \\\n",
       "101   749  29mnd_mmn\\749-032-29m-jr-mmn36.cnt  749-032-29m-jr-mmn36   \n",
       "102   751  29mnd_mmn\\751-452-29m-jr-mmn36.cnt  751-452-29m-jr-mmn36   \n",
       "103   753  29mnd_mmn\\753-470-29m-mr-mmn36.cnt  753-470-29m-mr-mmn36   \n",
       "104   755    29mnd_mmn\\755-471-29m-mr-mmn.cnt    755-471-29m-mr-mmn   \n",
       "105   758  29mnd_mmn\\758-465-29m-mr-mmn36.cnt  758-465-29m-mr-mmn36   \n",
       "\n",
       "     age_group  age_days  age_months  age_years  \n",
       "101         29       879   29.300000   2.441667  \n",
       "102         29       869   28.966667   2.413889  \n",
       "103         29       867   28.900000   2.408333  \n",
       "104         29       862   28.733333   2.394444  \n",
       "105         29       868   28.933333   2.411111  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check files with no label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>cnt_path</th>\n",
       "      <th>cnt_file</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_days</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [code, cnt_path, cnt_file, age_group, age_days, age_months, age_years]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.loc[merged_df['age_days'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the missing age data based on the age group the subject is in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the age group (i.e. 11, 17, 23, .. months etc) of all the subjects, based on the folder the files are in and based on the file name. We have got the exact ages (in days) of most subjects seperately, which we have added to the DataFrame above. For some of the subjects, we don't have the exact age and therefore we set this equal to the age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['age_months'].fillna(merged_df['age_group'], inplace=True)\n",
    "merged_df['age_days'].fillna(merged_df['age_group']*30, inplace=True)\n",
    "merged_df['age_years'].fillna(merged_df['age_group']/12, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below should now return an empty dataframe, because all empty fields have been filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>cnt_path</th>\n",
       "      <th>cnt_file</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_days</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [code, cnt_path, cnt_file, age_group, age_days, age_months, age_years]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.loc[merged_df['age_days'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom cnt-file import function and data standardize function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cnt_file(file,\n",
    "                  label_group,\n",
    "                  event_idx = [2, 3, 4, 5, 12, 13, 14, 15],\n",
    "                  channel_set = \"30\",\n",
    "                  tmin = -0.2,\n",
    "                  tmax = 0.8,\n",
    "                  lpass = 0.5, \n",
    "                  hpass = 40, \n",
    "                  threshold = 5, \n",
    "                  max_bad_fraction = 0.2,\n",
    "                  max_bad_channels = 2):\n",
    "    \"\"\" Function to read cnt file. Run bandpass filter. \n",
    "    Then detect and correct/remove bad channels and bad epochs.\n",
    "    Store resulting epochs as arrays.\n",
    "    \n",
    "    Args:\n",
    "    --------\n",
    "    file: str\n",
    "        Name of file to import.\n",
    "    label_group: int\n",
    "        Unique ID of specific group (must be >0).\n",
    "    channel_set: str\n",
    "        Select among pre-defined channel sets. Here: \"30\" or \"62\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if channel_set == \"30\":\n",
    "        channel_set = ['O2', 'O1', 'OZ', 'PZ', 'P4', 'CP4', 'P8', 'C4', 'TP8', 'T8', 'P7', \n",
    "                       'P3', 'CP3', 'CPZ', 'CZ', 'FC4', 'FT8', 'TP7', 'C3', 'FCZ', 'FZ', \n",
    "                       'F4', 'F8', 'T7', 'FT7', 'FC3', 'F3', 'FP2', 'F7', 'FP1']\n",
    "    elif channel_set == \"62\":\n",
    "        channel_set = ['O2', 'O1', 'OZ', 'PZ', 'P4', 'CP4', 'P8', 'C4', 'TP8', 'T8', 'P7', \n",
    "                       'P3', 'CP3', 'CPZ', 'CZ', 'FC4', 'FT8', 'TP7', 'C3', 'FCZ', 'FZ', \n",
    "                       'F4', 'F8', 'T7', 'FT7', 'FC3', 'F3', 'FP2', 'F7', 'FP1', 'AFZ', 'PO3', \n",
    "                       'P1', 'POZ', 'P2', 'PO4', 'CP2', 'P6', 'M1', 'CP6', 'C6', 'PO8', 'PO7', \n",
    "                       'P5', 'CP5', 'CP1', 'C1', 'C2', 'FC2', 'FC6', 'C5', 'FC1', 'F2', 'F6', \n",
    "                       'FC5', 'F1', 'AF4', 'AF8', 'F5', 'AF7', 'AF3', 'FPZ']\n",
    "    else:\n",
    "        print(\"Predefined channel set given by 'channel_set' not known...\")\n",
    "        \n",
    "    \n",
    "    # Initialize array\n",
    "    signal_collection = np.zeros((0,len(channel_set),501))\n",
    "    label_collection = [] #np.zeros((0))\n",
    "    channel_names_collection = []\n",
    "    \n",
    "    # Import file\n",
    "    try:\n",
    "        data_raw = mne.io.read_raw_cnt(file, eog='auto', preload=True, verbose=False)\n",
    "    except ValueError:\n",
    "        print(\"ValueError\")\n",
    "        print(\"Could not load file:\", file)\n",
    "        return None, None, None\n",
    "    \n",
    "    # Band-pass filter (between 0.5 and 40 Hz. was 0.5 to 30Hz in Stober 2016)\n",
    "    data_raw.filter(0.5, 40, fir_design='firwin')\n",
    "\n",
    "    # Get events from annotations in the data\n",
    "    events_from_annot, event_dict = mne.events_from_annotations(data_raw)\n",
    "    \n",
    "    # Set baseline:\n",
    "    baseline = (None, 0)  # means from the first instant to t = 0\n",
    "\n",
    "    # Select channels to exclude (if any)\n",
    "    channels_exclude = [x for x in data_raw.ch_names if x not in channel_set]\n",
    "    channels_exclude = [x for x in channels_exclude if x not in ['HEOG', 'VEOG']]\n",
    "    \n",
    "    for event_id in event_idx:\n",
    "        if str(event_id) in event_dict:\n",
    "            # Pick EEG channels\n",
    "            picks = mne.pick_types(data_raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                               #exclude=data_exclude)#'bads'])\n",
    "                                   include=channel_set, exclude=channels_exclude)#'bads'])\n",
    "\n",
    "            epochs = mne.Epochs(data_raw, events=events_from_annot, event_id=event_dict,\n",
    "                                tmin=tmin, tmax=tmax, proj=True, picks=picks,\n",
    "                                baseline=baseline, preload=True, event_repeated='merge', verbose=False)\n",
    "\n",
    "            # Detect potential bad channels and epochs\n",
    "            bad_channels, bad_epochs = helper_functions.select_bad_epochs(epochs,\n",
    "                                                                          event_id,\n",
    "                                                                          threshold = threshold,\n",
    "                                                                          max_bad_fraction = max_bad_fraction)\n",
    "\n",
    "            # Interpolate bad channels\n",
    "            # ------------------------------------------------------------------\n",
    "            if len(bad_channels) > 0:\n",
    "                if len(bad_channels) > max_bad_channels:\n",
    "                    print(20*'--')\n",
    "                    print(\"Found too many bad channels (\" + str(len(bad_channels)) + \")\")\n",
    "                    return None, None, None\n",
    "                else:\n",
    "                    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "                    montage.ch_names = [ch_name.upper() for ch_name in montage.ch_names]\n",
    "                    data_raw.set_montage(montage)\n",
    "                    \n",
    "                    # MARK: Think about using all channels before removing (62 -> 30), to enable for better interpolation\n",
    "                    \n",
    "                    # Mark bad channels:\n",
    "                    data_raw.info['bads'] = bad_channels\n",
    "                    # Pick EEG channels:\n",
    "                    picks = mne.pick_types(data_raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                                       #exclude=data_exclude)#'bads'])\n",
    "                                       include=channel_set, exclude=channels_exclude)#'bads'])\n",
    "                    epochs = mne.Epochs(data_raw, events=events_from_annot, event_id=event_dict,\n",
    "                                        tmin=tmin, tmax=tmax, proj=True, picks=picks,\n",
    "                                        baseline=baseline, preload=True, verbose=False)\n",
    "                    \n",
    "                    # Interpolate bad channels using functionality of 'mne'\n",
    "                    epochs.interpolate_bads()\n",
    "                    \n",
    "\n",
    "            # Get signals as array and add to total collection\n",
    "            channel_names_collection.append(epochs.ch_names)\n",
    "            signals_cleaned = epochs[str(event_id)].drop(bad_epochs).get_data()\n",
    "            signal_collection = np.concatenate((signal_collection, signals_cleaned), axis=0)\n",
    "            label_collection += [event_id + label_group] * signals_cleaned.shape[0]\n",
    "\n",
    "    return signal_collection, label_collection, channel_names_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions to import and process EEG data from cnt files.\n",
    "\"\"\"\n",
    "def standardize_EEG(data_array,\n",
    "                    std_aim = 1,\n",
    "                    centering = 'per_channel',\n",
    "                    scaling = 'global'):\n",
    "    \"\"\" Center data around 0 and adjust standard deviation.\n",
    "\n",
    "    Args:\n",
    "    --------\n",
    "    data_array: np.ndarray\n",
    "        Input data.\n",
    "    std_aim: float/int\n",
    "        Target standard deviation for rescaling/normalization.\n",
    "    centering: str\n",
    "        Specify if centering should be done \"per_channel\", or \"global\".\n",
    "    scaling: str\n",
    "        Specify if scaling should be done \"per_channel\", or \"global\".\n",
    "    \"\"\"\n",
    "    if centering == 'global':\n",
    "        data_mean = data_array.mean()\n",
    "\n",
    "        # Center around 0\n",
    "        data_array = data_array - data_mean\n",
    "\n",
    "    elif centering == 'per_channel':\n",
    "        for i in range(data_array.shape[1]):\n",
    "\n",
    "            data_mean = data_array[:,i,:].mean()\n",
    "\n",
    "            # Center around 0\n",
    "            data_array[:,i,:] = data_array[:,i,:] - data_mean\n",
    "\n",
    "    else:\n",
    "        print(\"Centering method not known.\")\n",
    "        return None\n",
    "\n",
    "    if scaling == 'global':\n",
    "        data_std = data_array.std()\n",
    "\n",
    "        # Adjust std to std_aim\n",
    "        data_array = data_array * std_aim/data_std\n",
    "\n",
    "    elif scaling == 'per_channel':\n",
    "        for i in range(data_array.shape[1]):\n",
    "\n",
    "            data_std = data_array[:,i,:].std()\n",
    "\n",
    "            # Adjust std to std_aim\n",
    "            data_array[:,i,:] = data_array[:,i,:] * std_aim/data_std\n",
    "    else:\n",
    "        print(\"Given method is not known.\")\n",
    "        return None\n",
    "\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Projects\\\\EEG_explorer\\\\Data/data_processed_DL/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DATA_PROCESSED_DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking out file: 602-115-17m-mc-mmn\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw602-115-17m-mc-mmn.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_602-115-17m-mc-mmn.csv already exist.\n",
      "Checking out file: 604-133-17m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw604-133-17m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_604-133-17m-jc-mmn36.csv already exist.\n",
      "Checking out file: 605-131-17m-jc-mmn\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw605-131-17m-jc-mmn.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_605-131-17m-jc-mmn.csv already exist.\n",
      "Checking out file: 607-000-17m-jc-mmn1_36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw607-000-17m-jc-mmn1_36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_607-000-17m-jc-mmn1_36.csv already exist.\n",
      "Checking out file: 608-170-17m-mc-mmn36_2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw608-170-17m-mc-mmn36_2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_608-170-17m-mc-mmn36_2.csv already exist.\n",
      "Checking out file: 609-158-17m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw609-158-17m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_609-158-17m-jc-mmn36.csv already exist.\n",
      "Checking out file: 610_185_17m_jc_mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw610_185_17m_jc_mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_610_185_17m_jc_mmn36.csv already exist.\n",
      "Checking out file: 611_157_17m_mc_mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw611_157_17m_mc_mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_611_157_17m_mc_mmn36.csv already exist.\n",
      "Checking out file: 613-176-17m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw613-176-17m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_613-176-17m-mc-mmn36.csv already exist.\n",
      "Checking out file: 618-163-17m-j-c-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw618-163-17m-j-c-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_618-163-17m-j-c-mmn36.csv already exist.\n",
      "Checking out file: 619-247-17m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw619-247-17m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_619-247-17m-mc-mmn36.csv already exist.\n",
      "Checking out file: 620_313_17m_jc_mmn36_waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw620_313_17m_jc_mmn36_waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_620_313_17m_jc_mmn36_waak.csv already exist.\n",
      "Checking out file: 622-189-17m-jc-mmn36-2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw622-189-17m-jc-mmn36-2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_622-189-17m-jc-mmn36-2.csv already exist.\n",
      "Checking out file: 623_321_17m_mc_mmn36_waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw623_321_17m_mc_mmn36_waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_623_321_17m_mc_mmn36_waak.csv already exist.\n",
      "Checking out file: 624-373-17m-mc-mmn36-waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw624-373-17m-mc-mmn36-waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_624-373-17m-mc-mmn36-waak.csv already exist.\n",
      "Checking out file: 625-253-17m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw625-253-17m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_625-253-17m-jc-mmn36.csv already exist.\n",
      "Checking out file: 626-377-17m-jc-mmn36-waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw626-377-17m-jc-mmn36-waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_626-377-17m-jc-mmn36-waak.csv already exist.\n",
      "Checking out file: 627-356-17m-mc-mmn36-waak\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Used Annotations descriptions: ['0', '13', '3', '66']\n",
      "Found 651 bad epochs in a total of 30  channels.\n",
      "Found bad channel (more than 160.0  bad epochs): Channel no:  3\n",
      "Found bad channel (more than 160.0  bad epochs): Channel no:  6\n",
      "Found bad channel (more than 160.0  bad epochs): Channel no:  8\n",
      "Marked 328 bad epochs in a total of 800  epochs.\n",
      "----------------------------------------\n",
      "Found too many bad channels (3)\n",
      "Checking out file: 628-369-17m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw628-369-17m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_628-369-17m-mc-mmn36.csv already exist.\n",
      "Checking out file: 629-357-jc-17m-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw629-357-jc-17m-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_629-357-jc-17m-mmn36.csv already exist.\n",
      "Checking out file: 630-372-17m-jc-mmn36-waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw630-372-17m-jc-mmn36-waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_630-372-17m-jc-mmn36-waak.csv already exist.\n",
      "Checking out file: 632-399-17m-jc-mmn36-waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw632-399-17m-jc-mmn36-waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_632-399-17m-jc-mmn36-waak.csv already exist.\n",
      "Checking out file: 633-403-17m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw633-403-17m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_633-403-17m-jc-mmn36.csv already exist.\n",
      "Checking out file: 635-364-17m-mc-mmn36\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n",
      "Used Annotations descriptions: ['0', '13', '3', '66']\n",
      "Found 658 bad epochs in a total of 30  channels.\n",
      "Found bad channel (more than 154.8  bad epochs): Channel no:  17\n",
      "Found bad channel (more than 154.8  bad epochs): Channel no:  8\n",
      "Found bad channel (more than 154.8  bad epochs): Channel no:  10\n",
      "Marked 85 bad epochs in a total of 774  epochs.\n",
      "----------------------------------------\n",
      "Found too many bad channels (3)\n",
      "Checking out file: 636-468-17m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw636-468-17m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_636-468-17m-jc-mmn36.csv already exist.\n",
      "Checking out file: 637-479-17m-mc-mmn36-2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw637-479-17m-mc-mmn36-2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_637-479-17m-mc-mmn36-2.csv already exist.\n",
      "Checking out file: 637-479-17m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw637-479-17m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_637-479-17m-mc-mmn36.csv already exist.\n",
      "Checking out file: 639-484-17m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw639-484-17m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_639-484-17m-jc-mmn36.csv already exist.\n",
      "Checking out file: 640-464-17m-jc-mmn36-2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw640-464-17m-jc-mmn36-2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_640-464-17m-jc-mmn36-2.csv already exist.\n",
      "Checking out file: 640-464-17m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw640-464-17m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_640-464-17m-jc-mmn36.csv already exist.\n",
      "Checking out file: 642-485-17m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw642-485-17m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_642-485-17m-jc-mmn36.csv already exist.\n",
      "Checking out file: 646-478-17m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw646-478-17m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_646-478-17m-mc-mmn36.csv already exist.\n",
      "Checking out file: 707-060-17m-jd-mmn\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw707-060-17m-jd-mmn.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_707-060-17m-jd-mmn.csv already exist.\n",
      "Checking out file: 707-060-17m-jr-mmn\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw707-060-17m-jr-mmn.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_707-060-17m-jr-mmn.csv already exist.\n",
      "Checking out file: 719-079-jr-17m-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw719-079-jr-17m-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_719-079-jr-17m-mmn36.csv already exist.\n",
      "Checking out file: 720-166-17m-jr-mmn\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw720-166-17m-jr-mmn.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_720-166-17m-jr-mmn.csv already exist.\n",
      "Checking out file: 720-166-17m-jr-mmn2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw720-166-17m-jr-mmn2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_720-166-17m-jr-mmn2.csv already exist.\n",
      "Checking out file: 724-116-17m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw724-116-17m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_724-116-17m-jr-mmn36.csv already exist.\n",
      "Checking out file: 725_161_17m_jr_mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw725_161_17m_jr_mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_725_161_17m_jr_mmn36.csv already exist.\n",
      "Checking out file: 725_161_17m_jr_mmn36_2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw725_161_17m_jr_mmn36_2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_725_161_17m_jr_mmn36_2.csv already exist.\n",
      "Checking out file: 726_126_17m-jr_mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw726_126_17m-jr_mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_726_126_17m-jr_mmn36.csv already exist.\n",
      "Checking out file: 726_126_17m-jr_mmn36b\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw726_126_17m-jr_mmn36b.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_726_126_17m-jr_mmn36b.csv already exist.\n",
      "Checking out file: 730-201-17m-jr-mmn\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw730-201-17m-jr-mmn.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_730-201-17m-jr-mmn.csv already exist.\n",
      "Checking out file: 731-197-17m-jr-mmn\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw731-197-17m-jr-mmn.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_731-197-17m-jr-mmn.csv already exist.\n",
      "Checking out file: 731-197-17m-jr-mmn2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw731-197-17m-jr-mmn2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_731-197-17m-jr-mmn2.csv already exist.\n",
      "Checking out file: 734_230_17m_mr_mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw734_230_17m_mr_mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_734_230_17m_mr_mmn36.csv already exist.\n",
      "Checking out file: 735-125-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw735-125-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_735-125-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 739-368-17m-mr-mmn36-2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw739-368-17m-mr-mmn36-2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_739-368-17m-mr-mmn36-2.csv already exist.\n",
      "Checking out file: 739-368-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw739-368-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_739-368-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 740-396-17m-jr-mmn36-waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw740-396-17m-jr-mmn36-waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_740-396-17m-jr-mmn36-waak.csv already exist.\n",
      "Checking out file: 742-421-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw742-421-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_742-421-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 743-475-17m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw743-475-17m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_743-475-17m-jr-mmn36.csv already exist.\n",
      "Checking out file: 745-466-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw745-466-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_745-466-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 746-438-17m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw746-438-17m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_746-438-17m-jr-mmn36.csv already exist.\n",
      "Checking out file: 747-410-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw747-410-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_747-410-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 748-402-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw748-402-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_748-402-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 749-461-17m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw749-461-17m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_749-461-17m-jr-mmn36.csv already exist.\n",
      "Checking out file: 751-542-17m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw751-542-17m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_751-542-17m-jr-mmn36.csv already exist.\n",
      "Checking out file: 752-457-17m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw752-457-17m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_752-457-17m-jr-mmn36.csv already exist.\n",
      "Checking out file: 753-470-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw753-470-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_753-470-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 754-472-17m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw754-472-17m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_754-472-17m-jr-mmn36.csv already exist.\n",
      "Checking out file: 755-471-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw755-471-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_755-471-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 757-487-17m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw757-487-17m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_757-487-17m-jr-mmn36.csv already exist.\n",
      "Checking out file: 758-465-17m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw758-465-17m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_758-465-17m-mr-mmn36.csv already exist.\n",
      "Checking out file: 602-115-29m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw602-115-29m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_602-115-29m-mc-mmn36.csv already exist.\n",
      "Checking out file: 604-133-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw604-133-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_604-133-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 605-131-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw605-131-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_605-131-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 607-128-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw607-128-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_607-128-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 608-170-29m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw608-170-29m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_608-170-29m-mc-mmn36.csv already exist.\n",
      "Checking out file: 609-158-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw609-158-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_609-158-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 610-185-29m-jc-mmn36-2-waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw610-185-29m-jc-mmn36-2-waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_610-185-29m-jc-mmn36-2-waak.csv already exist.\n",
      "Checking out file: 613-176-29m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw613-176-29m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_613-176-29m-mc-mmn36.csv already exist.\n",
      "Checking out file: 618-163-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw618-163-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_618-163-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 622-189-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw622-189-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_622-189-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 623-321-29m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw623-321-29m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_623-321-29m-mc-mmn36.csv already exist.\n",
      "Checking out file: 625-253-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw625-253-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_625-253-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 628-369-29m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw628-369-29m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_628-369-29m-mc-mmn36.csv already exist.\n",
      "Checking out file: 629-357-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw629-357-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_629-357-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 630-372-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw630-372-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_630-372-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 632-399-29m-jc-mmn36-2\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw632-399-29m-jc-mmn36-2.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_632-399-29m-jc-mmn36-2.csv already exist.\n",
      "Checking out file: 633-403-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw633-403-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_633-403-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 635-364-29m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw635-364-29m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_635-364-29m-mc-mmn36.csv already exist.\n",
      "Checking out file: 639-484-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw639-484-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_639-484-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 640-464-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw640-464-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_640-464-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 642-485-29m-jc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw642-485-29m-jc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_642-485-29m-jc-mmn36.csv already exist.\n",
      "Checking out file: 646-478-29m-mc-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw646-478-29m-mc-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_646-478-29m-mc-mmn36.csv already exist.\n",
      "Checking out file: 707-060-29m-jr-mmn36-waak\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw707-060-29m-jr-mmn36-waak.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_707-060-29m-jr-mmn36-waak.csv already exist.\n",
      "Checking out file: 719-079-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw719-079-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_719-079-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 724-116-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw724-116-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_724-116-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 725-161-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw725-161-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_725-161-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 726-126-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw726-126-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_726-126-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 730-201-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw730-201-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_730-201-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 734-230-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw734-230-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_734-230-29m-mr-mmn36.csv already exist.\n",
      "Checking out file: 735-125-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw735-125-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_735-125-29m-mr-mmn36.csv already exist.\n",
      "Checking out file: 739-368-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw739-368-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_739-368-29m-mr-mmn36.csv already exist.\n",
      "Checking out file: 740-396-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw740-396-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_740-396-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 742-421-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw742-421-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_742-421-29m-mr-mmn36.csv already exist.\n",
      "Checking out file: 745-166-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw745-166-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_745-166-29m-mr-mmn36.csv already exist.\n",
      "Checking out file: 746-438-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw746-438-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_746-438-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 747-410-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw747-410-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_747-410-29m-mr-mmn36.csv already exist.\n",
      "Checking out file: 748-402-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw748-402-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_748-402-29m-mr-mmn36.csv already exist.\n",
      "Checking out file: 749-032-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw749-032-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_749-032-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 751-452-29m-jr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw751-452-29m-jr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_751-452-29m-jr-mmn36.csv already exist.\n",
      "Checking out file: 753-470-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw753-470-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_753-470-29m-mr-mmn36.csv already exist.\n",
      "Checking out file: 755-471-29m-mr-mmn\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw755-471-29m-mr-mmn.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_755-471-29m-mr-mmn.csv already exist.\n",
      "Checking out file: 758-465-29m-mr-mmn36\n",
      "Skipping because C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_raw758-465-29m-mr-mmn36.npy and C:/Projects\\EEG_explorer\\Data/data_processed_DL/processed_metadata_758-465-29m-mr-mmn36.csv already exist.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from itertools import islice\n",
    "\n",
    "for i, file in islice(merged_df.iterrows(), 0, None): # Enables you to set starting row of DataFrame\n",
    "    print(f\"Checking out file: {file['cnt_file']}\")\n",
    "        \n",
    "    filename_processed_raw = os.path.join(PATH_DATA_PROCESSED_DL, \"processed_raw\" + file['cnt_file'] + \".npy\")\n",
    "    filename_metadata = os.path.join(PATH_DATA_PROCESSED_DL, \"processed_metadata_\" + file['cnt_file'] + \".csv\")\n",
    "    \n",
    "    # Step 1: Check if file don't already exist, else skip\n",
    "    if os.path.exists(filename_processed_raw) and os.path.exists(filename_metadata):\n",
    "        print(f\"Skipping because {filename_processed_raw} and {filename_metadata} already exist.\")\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # Step 2: Import data and labels \n",
    "    signal_collect, label_collect, ch_names = read_cnt_file(file['cnt_path'],\n",
    "                                                            file['age_months'],\n",
    "                                                            event_idx = [2, 3, 4, 5, 12, 13, 14, 15],\n",
    "                                                            channel_set = \"30\",\n",
    "                                                            tmin = -0.2,\n",
    "                                                            tmax = 0.8,\n",
    "                                                            lpass = 0.5, \n",
    "                                                            hpass = 40, \n",
    "                                                            threshold = 5, \n",
    "                                                            max_bad_fraction = 0.2,\n",
    "                                                            max_bad_channels = 2)    \n",
    "    \n",
    "    if signal_collect is None:\n",
    "        continue\n",
    "        \n",
    "    # Step 3: standardize data\n",
    "    if signal_collect is not None:\n",
    "        signal_collect = standardize_EEG(signal_collect,\n",
    "                                         std_aim = 1,\n",
    "                                         centering = 'per_channel',\n",
    "                                         scaling = 'global')\n",
    "\n",
    "    # Step 4: Save raw data and metadata\n",
    "    if signal_collect is not None:\n",
    "        np.save(filename_processed_raw, signal_collect)\n",
    "        pd.DataFrame(file).transpose().to_csv(filename_metadata, sep=',', index=False, header=True)     \n",
    "    \n",
    "    # TODO: 1. Try saving 2. Retry after n seconds if fails 3. If fails m times, continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform .npy to .zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 5s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Step 1: Get all the files in the output folder\n",
    "file_names = os.listdir(PATH_DATA_PROCESSED_DL)\n",
    "\n",
    "# Step 2: Get the full paths of the files (without extensions)\n",
    "files = [os.path.splitext(file_name)[0] for file_name in fnmatch.filter(file_names, \"*.npy\")]\n",
    "\n",
    "for file in files:\n",
    "    # Step 0: Get the NumPy file name\n",
    "    np_name = file + \".npy\"\n",
    "\n",
    "    # Step 1: Load existing NumPy array\n",
    "    X = np.load(os.path.join(PATH_DATA_PROCESSED_DL, np_name))\n",
    "\n",
    "    # Step 2: Open a Zarr file with the same name and assign the number of epochs as chunks to the file\n",
    "    zarr_name = np_name.replace(\".npy\", \".zarr\")\n",
    "    z_file =  zarr.open(os.path.join(PATH_DATA_PROCESSED_DL, zarr_name), \n",
    "                        mode='w', \n",
    "                        shape=X.shape, \n",
    "                        chunks=(1, X.shape[1], X.shape[2]))\n",
    "    z_file[:] = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Remove files that have len(npy array) == 0\n",
    "\n",
    "We now do this afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(foo([\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     10\u001b[0m bar()\n\u001b[1;32m---> 11\u001b[0m \u001b[43mbaz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mbaz\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbaz\u001b[39m():\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mfoo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36mfoo\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfoo\u001b[39m(a: \u001b[38;5;28mint\u001b[39m, b: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
