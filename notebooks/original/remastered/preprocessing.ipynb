{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare EEG data for training of machine-learning models\n",
    "\n",
    "In this notebook, the preprocessing for machine learning purposes is done. Also, some exploration and visualization is done to better understand the data at hand.\n",
    "\n",
    "+ Import data.\n",
    "+ Apply filters (bandpass).\n",
    "+ Detect potential bad channels and replace them by interpolation.\n",
    "+ Detect potential bad epochs and remove them.\n",
    "+ Extract features\n",
    "+ Select features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages & links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import seaborn as sns\n",
    "\n",
    "from mne_features.feature_extraction import extract_features\n",
    "import eegyolk\n",
    "#from eegyolk.config import Config\n",
    "# from eegyolk.rawf import RawData\n",
    "from eegyolk.cnt import CntReader\n",
    "# from eegyolk.helper_functions import rt\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nCannot load config.\n\nPlease create a file in either one of the locations\nlisted below:\n./config.json\n/home/nprins/.epodium/config.json\n/etc/epodium/config.json\n\nWith the contents that specifies at least the root\ndirectory as follows:\n\n{\n    \"root\": \"/path/to/storage\"\n}\n\nThe default directory layout is expected to be:\n\n{\n    \"root\": \"/path/to/storage\",\n    \"data\": \"$root/data/\",\n    \"preprocessed\": \"$root/preprocessed/\",\n    \"metadata\": \"$root/metadata/\",\n    \"models\": \"$root/models/\"\n}\n\nYou can override any individual directory by specifying it\nin config.json.\n\n\"data\" and \"metadata\" directories are expected to exist.\nThe \"data\" directory is expected to have \"11mnd mmn\" ..\n\"47mnd mmn\" directories.  The \"metadata\" directory is\nexpected to have \"ages\" subdirectory with files named\n\"ages_11mnths.txt\" .. \"ages_47mnths.txt\".\n\nThe \"models\" and \"preprocessed\" directories need not\nexist.  They will be created if missing.  The \"preprocessed\"\ndirectory will be used to output CSV and h5 files when\nreading the raw CNT data.  The \"models\" directory will\nbe used to store regression and neural network models\ncreated by training the models on preprocessed data.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meegyolk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#from eegyolk.rawf import RawData\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/eegyolk/config.py:38\u001b[0m, in \u001b[0;36mConfig.__init__\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/eegyolk/config.py:99\u001b[0m, in \u001b[0;36mConfig.load\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m     97\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to load \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, p, e)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musage())\n\u001b[1;32m    101\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw)\n",
      "\u001b[0;31mValueError\u001b[0m: \nCannot load config.\n\nPlease create a file in either one of the locations\nlisted below:\n./config.json\n/home/nprins/.epodium/config.json\n/etc/epodium/config.json\n\nWith the contents that specifies at least the root\ndirectory as follows:\n\n{\n    \"root\": \"/path/to/storage\"\n}\n\nThe default directory layout is expected to be:\n\n{\n    \"root\": \"/path/to/storage\",\n    \"data\": \"$root/data/\",\n    \"preprocessed\": \"$root/preprocessed/\",\n    \"metadata\": \"$root/metadata/\",\n    \"models\": \"$root/models/\"\n}\n\nYou can override any individual directory by specifying it\nin config.json.\n\n\"data\" and \"metadata\" directories are expected to exist.\nThe \"data\" directory is expected to have \"11mnd mmn\" ..\n\"47mnd mmn\" directories.  The \"metadata\" directory is\nexpected to have \"ages\" subdirectory with files named\n\"ages_11mnths.txt\" .. \"ages_47mnths.txt\".\n\nThe \"models\" and \"preprocessed\" directories need not\nexist.  They will be created if missing.  The \"preprocessed\"\ndirectory will be used to output CSV and h5 files when\nreading the raw CNT data.  The \"models\" directory will\nbe used to store regression and neural network models\ncreated by training the models on preprocessed data.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../eegyolk') # path to helper functions\n",
    "\n",
    "#import rawf\n",
    "from eegyolk.config import Config\n",
    "#from eegyolk.rawf import RawData\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search all *.cnt files and get paths, code, and age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RawData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m acquired \u001b[38;5;241m=\u001b[39m \u001b[43mRawData\u001b[49m(config\u001b[38;5;241m.\u001b[39mget_directory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m), config\u001b[38;5;241m.\u001b[39mget_directory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RawData' is not defined"
     ]
    }
   ],
   "source": [
    "acquired = RawData(config.get_directory('data'), config.get_directory('metadata'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the age ranges within groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "data = acquired.breakdown_by_age()\n",
    "bins = 20\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16,16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i + 1 > len(data):\n",
    "        ax.remove()\n",
    "    else:\n",
    "        ax.hist(data[i]['age_months'], bins=bins)\n",
    "        ax.set_xlabel('Age (months)')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title(f'Frequency histogram, bins={bins}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(16,16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i+1 > len(data):\n",
    "        ax.remove()\n",
    "    else:\n",
    "        sns.swarmplot(ax=ax, x=\"age_group\", y=\"age_months\", data=data[i])\n",
    "        ax.set_xlabel('Age group')\n",
    "        ax.set_ylabel('Age (months)')\n",
    "        ax.set_title('Chronological age vs. age group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(16,16))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i + 1 > len(data):\n",
    "        ax.remove()\n",
    "    else:    \n",
    "        sns.boxplot(\n",
    "            ax=ax,\n",
    "            x=\"age_group\",\n",
    "            y=\"age_months\",\n",
    "            data=data[i],\n",
    "            showmeans=True, \n",
    "            meanprops={\n",
    "                \"marker\":\"o\",\n",
    "                \"markerfacecolor\":\"white\", \n",
    "                \"markeredgecolor\":\"black\",\n",
    "                \"markersize\":\"6\",\n",
    "                }\n",
    "        )\n",
    "        ax.set_xlabel('Age group')\n",
    "        ax.set_ylabel('Age (months)')\n",
    "        ax.set_title('Chronological age vs. age group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check files with no label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.unlabeled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the missing age data based on the age group the subject is in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the age group (i.e. 11, 17, 23, .. months etc) of all the subjects, based on the folder the files are in and based on the file name. We have got the exact ages (in days) of most subjects seperately, which we have added to the DataFrame above. For some of the subjects, we don't have the exact age and therefore we set this equal to the age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.fill_unlabeled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below should now return an empty dataframe, because all empty fields have been filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.unlabeled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the CNT files are not usable. They are unusable for multiple reasons. Here are few:\n",
    "\n",
    "1. Some are missing a header (the header section usually appears to be filled with null bytes).\n",
    "2. The CNT format itself is ambiguous about whether 4 or 2 bytes are used per event per channel.\n",
    "   It's also not always possible to guess the correct number of bytes per event.  Some of these\n",
    "   files will, however, cause problems when trying to read them.\n",
    "3. CNT files have to have an acquisition date.  MNE authors believe that two formats are possible:\n",
    "   `%m/%d/%y` and `%d/%m/%y`.  However, the original data contains a third, unrecognized format\n",
    "   that uses three digits to store the year.  Possibly, it's this one:\n",
    "   [FAST](https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/time/FastDateFormat.html)\n",
    "4. I've also encountered other errors, where the reader complained about the number of bytes or\n",
    "   indexing errors, which I didn't investigate in depth.\n",
    "   \n",
    "The fraction of damaged original files is less than 1% of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.filter_broken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`acquired.filter_broken()` will read the file headers and split the whole data into two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.raw_good.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquired.raw_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import EEG data (from .cnt files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CNT file or a bunch of CNT files using MNE library \n",
    "data_raw = acquired.as_mne[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data type: {}\\n\\n{}\\n'.format(type(data_raw), data_raw))\n",
    "\n",
    "# Get the sample rate\n",
    "print('Sample rate:', data_raw.info['sfreq'], 'Hz')\n",
    "\n",
    "# Get the size of the matrix\n",
    "print('Size of the matrix: {}\\n'.format(data_raw.get_data().shape))\n",
    "\n",
    "# The mne.info class can be used to learn more about the data.\n",
    "print(data_raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show data as pandas dataframe (i.e. as a table).\n",
    "The raw data itself is just an array dimensions are no. of channels and timepoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = data_raw.to_data_frame()\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info['bads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band-pass filter (between 1 and 40 Hz. was 0.5 to 30Hz in Stober 2016)\n",
    "data_raw.filter(1, 40, fir_design='firwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the first 5 channels, from 1 s to 10 s.\n",
    "sfreq = data_raw.info['sfreq']\n",
    "data, times = data_raw[:5, int(sfreq * 1):int(sfreq * 10)]\n",
    "\n",
    "fig = plt.subplots(figsize=(10,8))\n",
    "plt.plot(times, data.T)\n",
    "plt.xlabel('Seconds')\n",
    "plt.ylabel('$\\mu V$')\n",
    "plt.title('Channels: 1-5')\n",
    "plt.legend(data_raw.ch_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mne plots\n",
    "There are many nice plotting options included in mne. They are, however, not always interactive and fully functional in Jupyter notebooks... so better try them out from a python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.plot(duration=10, block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, event_id = mne.events_from_annotations(data_raw)\n",
    "print(events[:10, :])\n",
    "print(event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which unique event indentifiers there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_event_types = set(events[:, 2])\n",
    "print(unique_event_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for most common event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take forever to run because it needs to read every CNT file in the dataset\n",
    "# It also doesn't seem to be very useful anyways.\n",
    "\n",
    "# print(acquired.count_events())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display signal around one type of event\n",
    "Selects signal for specific event ID and plots time window from tmin to tmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start of each epoch (200ms before the trigger)\n",
    "tmin = -0.2\n",
    "\n",
    "# end of each epoch (500ms after the trigger)\n",
    "tmax = 0.5\n",
    "\n",
    "# means from the first instant to t = 0\n",
    "baseline = None, 0\n",
    "\n",
    "picks = mne.pick_types(data_raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "\n",
    "print(picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(\n",
    "    data_raw,\n",
    "    events,\n",
    "    event_id,\n",
    "    tmin,\n",
    "    tmax,\n",
    "    proj=True,\n",
    "    picks=picks,\n",
    "    baseline=baseline,\n",
    "    preload=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export data in tabular structure as a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_df = epochs.to_data_frame()\n",
    "epochs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs['55'].average()\n",
    "evoked.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot_topomap(times=[0.1], size=3., title=\"Topo plot\", time_unit='s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot topomaps for different time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot_topomap(times=np.array([0, 0.016, 0.030, 0.060, 0.070, 0.1, 0.2, 0.5]), time_unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test other event type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs['2'].average()\n",
    "evoked.plot()\n",
    "evoked.plot_topomap(times=[0.1], size=3., title=\"Topo plot\", time_unit='s');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evoked.plot_topomap(times=np.array([0, 0.016, 0.030, 0.060, 0.070, 0.1, 0.2, 0.5]), time_unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a montage to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montages specify the exact electrode placement on the scalp of the subject. This contains coordinates relative to a point on the scalp. Often this data is included in the EEG data (.cnt file). Unfortunately for us, we don't have this information. The electrode placement information can be used to fix broken channels by using the channels surrounding this channel. Even though we don't have the exact locations, we do know the electrode placement system used: 10-20. We can use this to approximate the locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When looking at the maps above, the electrode placement seems to be incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax2d = fig.add_subplot(121)\n",
    "ax3d = fig.add_subplot(122, projection='3d')\n",
    "data_raw.plot_sensors(ch_type='eeg', axes=ax2d)\n",
    "data_raw.plot_sensors(ch_type='eeg', axes=ax3d, kind='3d')\n",
    "ax3d.view_init(azim=70, elev=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_from_raw = mne.channels.make_eeg_layout(data_raw.info)\n",
    "layout_from_raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfortunately, we don't have the exact sensor locations. Therefore, we try to approximate them with a standard montage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard montages come with the mne package. They're based on well known and often used electrode placement systems (10-20 in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "montage.ch_names = [ch_name.upper() for ch_name in montage.ch_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage.plot(kind='topomap', show_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_1020 = data_raw.copy().set_montage(montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, after setting the 1020 montage, the maps look different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax2d = fig.add_subplot(121)\n",
    "ax3d = fig.add_subplot(122, projection='3d')\n",
    "data_raw_1020.plot_sensors(ch_type='eeg', axes=ax2d)\n",
    "data_raw_1020.plot_sensors(ch_type='eeg', axes=ax3d, kind='3d')\n",
    "ax3d.view_init(azim=70, elev=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_from_raw = mne.channels.make_eeg_layout(data_raw_1020.info)\n",
    "layout_from_raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom cnt-file import function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CntReader(acquired)\n",
    "\n",
    "signals, labels, channel_names = reader.read(\n",
    "    acquired.raw_good['cnt_path'][30],\n",
    "    acquired.raw_good['age_months'][0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction and save processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine how to store the processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we're determining what the best method is to extract and save the features. At the end, we combine all the parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reader.save_preprocessed(config.get_directory('preprocessed'), limit=10, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the stuff below is the explanation of how the original author came up with the function above (can be safely ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features that can be used for machine learning models\n",
    "\n",
    "All of the below has been implemented as part of `CntReader.save_preprocessed_row()` and happens automatically during parsing.\n",
    "\n",
    "### Extract features from the raw data to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rms(data):\n",
    "    \"\"\"Root-mean squared value of the data (per channel).\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (n_channels, n_times)\n",
    "    Returns\n",
    "    -------\n",
    "    output : ndarray, shape (n_channels,)\n",
    "    Notes\n",
    "    -----\n",
    "    Alias of the feature function: *rms*\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(data, 2), axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features from the raw data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = {\n",
    "    'mean',\n",
    "    ('root_mean_squared', compute_rms),\n",
    "    'hjorth_mobility',\n",
    "    'hjorth_complexity',\n",
    "    'variance',\n",
    "    'std',\n",
    "    'kurtosis',\n",
    "    'skewness',\n",
    "    'app_entropy',\n",
    "    'zero_crossings',\n",
    "    'energy_freq_bands',\n",
    "    'spect_edge_freq',\n",
    "    'ptp_amp',\n",
    "}\n",
    "\n",
    "x_new = extract_features(signals, 500.0, selected_features, return_as_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data had a shape of (1917, 30, 501) - the extracted features data is almost 30 times smaller (before feature selection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for highly correlated features and remove one of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features are often highly correlated and therefore don't add a lot of additional information to the model. To further reduce dimensionality, one of the two highly correlated features can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_1 = x_new.iloc[:, x_new.columns.get_level_values(1) == 'ch1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only the first channel for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = x_new_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation.ge(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly correlated (>0.90), channel 0:\n",
    "- std & rms (0.926)\n",
    "- std & ptp_amp (0.9688)\n",
    "- std & variance (0.952)\n",
    "- ptp_amp & variance (0.900)\n",
    "\n",
    "Highly correlated (>0.90), channel 1:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- rms & ptp_amp\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 2:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- rms & ptp_amp\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 3:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 3:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 4:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- ptp_amp & variance\n",
    "\n",
    "Highly correlated (>0.90), channel 5:\n",
    "- std & rms\n",
    "- std & ptp_amp\n",
    "- std & variance\n",
    "- rms & ptp_amp\n",
    "- ptp_amp & variance\n",
    "\n",
    "After inspecting a few channels and the correlation between the features, the features `std` and `ptp_amp` can be removed, because they have a high correlation with eachother, `rms` and `variance`.  Removing these two features will reduce the dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction after selection\n",
    "\n",
    "Removed features: `std`, `ptp_amp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_selection = {\n",
    "    'mean', ('root_mean_squared', compute_rms),\n",
    "    'hjorth_mobility',\n",
    "    'hjorth_complexity',\n",
    "    'variance',\n",
    "    'kurtosis',\n",
    "    'skewness',\n",
    "    'app_entropy',\n",
    "    'zero_crossings',\n",
    "    'energy_freq_bands',\n",
    "    'spect_edge_freq',\n",
    "}\n",
    "\n",
    "x_new_selection = extract_features(signals, 500.0, selected_features_selection, return_as_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_new_selection.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different channels aren't identifiable by the current naming method. Map the numbers to the actual channel name and flatten the MultiIndex column dataframe.\n",
    "\n",
    "### Sanity check: test loading the saved file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pd.read_hdf(\n",
    "    os.path.join(\n",
    "        config.get_directory('preprocessed'),\n",
    "        'extracted_features_040_11_jc_mmn36_wk_mmn25_wk.h5',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
