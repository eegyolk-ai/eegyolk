{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional machine learning models for age prediction on EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses traditional ML methods to predict the age of infants using EEG data. The EEG data is preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from eegyolk.config import Config\n",
    "from eegyolk.loaders import RegressionsLoader\n",
    "from eegyolk.ml import Regressions\n",
    "from eegyolk.nn import NnOptimizer\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. Get all the files in the output folder\n",
    "2. Get the full paths of the files without the .h5 or .csv extensions\n",
    "3. Load the features from the .h5 files\n",
    "4. Assign the proper labels to the files based on the metadata\n",
    "5. Assign the subject's code to the files based on the metadata\n",
    "6. Split the data into a training, validation and test set (NOTE: make sure data points from same subjects don't end up in same set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(df, prop, x, y):\n",
    "    sns.set()\n",
    "    ax = sns.scatterplot(x=x, y=y, hue=prop, palette='RdBu', data=df)\n",
    "\n",
    "    norm = plt.Normalize(df[prop].min(), df[prop].max())\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"RdBu\", norm=norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    # Remove the legend and add a colorbar\n",
    "    ax.get_legend().remove()\n",
    "    ax.figure.colorbar(sm)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rloader = RegressionsLoader(config.get_directory('preprocessed'), config.get_directory('models'), samples=100)\n",
    "rloader.load()\n",
    "rloader.split()\n",
    "regressions = Regressions(rloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we make predictions with dummy regressors as a simple baseline to see whether other models learn \"something\". From the sklearn docs: \n",
    "\n",
    "> `DummyRegressor` is a regressor that makes predictions using simple rules. This regressor is useful as a simple baseline to compare with other (real) regressors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['dummy'].fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['rf'].grid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['rf'].fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Linear Support Vector Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of training examples in the training set. According to the sklearn docs: \"The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to datasets with more than a couple of 10000 samples.\" \n",
    "\n",
    "They recommend using a linear SVR for large data sets. Therefore, let's try this first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lsv_result = regressions.algorithms['lsv'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(lsv_result.cv_results_).sort_values('rank_test_score').head(50)\n",
    "cv_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(cv_df, 'mean_test_score', \"param_linearsvr__C\", \"param_linearsvr__epsilon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lsv_gs_result = regressions.algorithms['lsv'].grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsv_gs_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df_gs = pd.DataFrame(lsv_gs_result.cv_results_).sort_values('rank_test_score').head(50)\n",
    "cv_df_gs.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(cv_df_gs, 'mean_test_score', \"param_linearsvr__C\", \"param_linearsvr__epsilon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on all data with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['lsv'].best_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: (Non-linear) Support Vector Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try fitting a SVR on a (small) chunk of the training data. The parameter search below is quite small, but a broader search has been done before. However, a more fine-grained search is still necessary. The downside of SVR with a non-linear kernel is that it's very slow to fit and predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nl_srv_result = regressions.algorithms['svr'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_srv_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rs_svr = pd.DataFrame(nl_srv_result.cv_results_).sort_values('rank_test_score')\n",
    "df_rs_svr = df_rs_svr.loc[df_rs_svr['param_svr__gamma'] < 0.0025].head(20)\n",
    "df_rs_svr.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(df_rs_svr, 'mean_test_score', 'param_svr__C', 'param_svr__epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"param_svr__gamma\", y=\"mean_test_score\", data=df_rs_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svr_gs_result = regressions.algorithms['svr'].grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_gs_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs_svr = pd.DataFrame(svr_gs_result.cv_results_).sort_values('rank_test_score')\n",
    "df_gs_svr.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(df_gs_svr, 'mean_test_score', 'param_svr__C', 'param_svr__epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svr_result = regressions.algorithms['svr'].best_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: SGD Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inschatting tijd, mijn computer:\n",
    "    \n",
    "- X min voor een SGD (1 configuratie)\n",
    "- RandomizedSearch: 250 iteraties, 5 folds per iteratie = 1250\n",
    "- 1250 SGD * X = X uur (Schatting met mijn 1 core)\n",
    "\n",
    "Memory usage:\n",
    "- X GB per core?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a SVR is computationally expensive. Therefore, we try prediction with an SGD Regressor. According to the sklearn documentation, it's best to start with a RandomizedSearchCV to find reasonable hyperparameters. Therefore, we start with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_result = regressions.algorithms['sgd'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rs_sgd = pd.DataFrame(sgd_result.cv_results_).sort_values('rank_test_score')\n",
    "df_rs_sgd = df_rs_sgd.loc[\n",
    "    df_rs_sgd['param_sgdregressor__loss'] == 'huber'\n",
    "].sort_values('rank_test_score').head(5000)\n",
    "df_rs_sgd.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"param_sgdregressor__alpha\", y=\"mean_test_score\", data=df_rs_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sgd_gs_result = regressions.algorithms['sgd'].grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_gs_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs_sgd = pd.DataFrame(sgd_gs_result.cv_results_).sort_values('rank_test_score')\n",
    "df_gs_sgd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(df_gs_sgd, 'mean_test_score', 'param_sgdregressor__alpha', 'param_sgdregressor__epsilon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['sgd'].best_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Relevance Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to the SVR is the Relevance Vector Machine, also used by Vandenbosch (2018). This isn't included in sklearn, but there are two packages called 'scikit-rvm' and 'sklearn-rvm' using the sklearn API that has implemented this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inschatting tijd, mijn computer:\n",
    "    \n",
    "- 4 min voor een RVR (1 configuratie)\n",
    "- RandomizedSearch: 250 iteraties, 5 folds per iteratie = 1250\n",
    "- 1250 RVR * 4 min = 84 uur (Schatting met mijn 2 cores)\n",
    "\n",
    "Memory usage:\n",
    "- 4 GB per core?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emrvr_result = regressions.algorithms['emrvr'].fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emrvr_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on best SVR parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regressions.algorithms['emrvr'].best_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inschatting tijd, mijn computer: \n",
    "\n",
    "- 4 min voor 1 RVR (1 configuratie). \n",
    "- GridSearch: 50 configuraties, 5 folds per configuratie = 250\n",
    "- 250 RVR * 4 min = 17 uur (Schatting met mijn 2 cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    TODO(wvxvw): The code below seems bogus.\n",
    "    The pipeline uses unexpected kernel.\n",
    "    I don't know why it does this. Need more info\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_rvm import EMRVR\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "parameters = {'svr__epsilon': [4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8],\n",
    "              'svr__gamma': ['scale', 'auto', 0.0015]\n",
    "}\n",
    "\n",
    "pipe  = make_pipeline(StandardScaler(),\n",
    "                      SVR(verbose=True, kernel='rbf'))\n",
    "\n",
    "RVR_gridsearch = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=10)\n",
    "\n",
    "RVR_gridsearch.fit(chunked_X_train[0], chunked_y_train[0])\n",
    "\n",
    "output_file = os.path.join(PATH_MODELS, 'RVR_gridsearch.joblib')\n",
    "dump(RVR_gridsearch, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RVR_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "try:\n",
    "    RVR_gridsearch\n",
    "except:\n",
    "    RVR_gridsearch = load(os.path.join(PATH_MODELS, 'RVR_gridsearch.joblib'))    \n",
    "\n",
    "# Update verbosity\n",
    "RVR_gridsearch.verbose = 0\n",
    "\n",
    "# R2\n",
    "score = RVR_gridsearch.score(X_test, y_test)\n",
    "\n",
    "# MSE\n",
    "predictions = RVR_gridsearch.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"Performance of Relevance Vector Regressor: R-squared = {score}, RMSE = {rmse} and MAE = {mae}.\")\n",
    "\n",
    "del rvr_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = NnOptimizer(rloader, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot NN training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    \"\"\" Plots the MSE, RMSE, and MAE loss for the training and validation data over time \"\"\"\n",
    "    \n",
    "    %matplotlib inline\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(12, 12), dpi=200)\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='training data')  \n",
    "    min_loss = min(history.history['val_loss'])\n",
    "    val_plot1 = ax1.plot(history.history['val_loss'], label='validation data')\n",
    "    ax1.axhline(y = min_loss, color = val_plot1[0].get_color(), linestyle='--') \n",
    "    x0,x1 = ax1.get_xlim()\n",
    "    ax1.text(x1, min_loss, \"{:.2f}\".format(min_loss), ha='left', va='center')\n",
    "    ax1.set_title('MSE loss')\n",
    "    ax1.set_ylabel('MSE')\n",
    "    ax1.set_xlabel('epochs')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['root_mean_squared_error'], label='training data')\n",
    "    min_loss = min(history.history['val_root_mean_squared_error'])\n",
    "    val_plot2 = ax2.plot(history.history['val_root_mean_squared_error'], label='validation data')\n",
    "    ax2.axhline(y = min_loss, color=val_plot2[0].get_color(), linestyle='--') \n",
    "    x0,x1 = ax2.get_xlim()\n",
    "    ax2.text(x1, min_loss, '{:.2f}'.format(min_loss), ha='left', va='center')\n",
    "    ax2.set_title('RMSE loss')\n",
    "    ax2.set_ylabel('RMSE')\n",
    "    ax2.set_xlabel('epochs')\n",
    "    ax2.legend()\n",
    "    \n",
    "    ax3.plot(history.history['mean_absolute_error'], label='training data')    \n",
    "    min_loss = min(history.history['val_mean_absolute_error'])\n",
    "    val_plot3 = ax3.plot(history.history['val_mean_absolute_error'], label='validation data')\n",
    "    ax3.axhline(y=min_loss, color=val_plot3[0].get_color(), linestyle='--') \n",
    "    x0,x1 = ax3.get_xlim()\n",
    "    ax3.text(x1, min_loss, \"{:.2f}\".format(min_loss), ha='left', va='center')\n",
    "    ax3.set_title('MAE loss')\n",
    "    ax3.set_ylabel('MAE')\n",
    "    ax3.set_xlabel('epochs')\n",
    "    ax3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has to be repeated multiple times because the output from optimizer prevents proper display of the plot\n",
    "history = optimizer.fit_model(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer.fit_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer.fit_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer.fit_model(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = optimizer.fit_model(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(optimizer.optimization_params):\n",
    "    prediction, rmse, mae = optimizer.predict(i)\n",
    "    print('\\n'.join((\n",
    "        f'Performance of simple FC neural network regressor #{i} ({p}):',\n",
    "        f'  RMSE: {rmse}',\n",
    "        f'  MAE: {mae}.',\n",
    "    )))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
